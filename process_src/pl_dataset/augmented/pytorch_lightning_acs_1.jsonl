{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\cli.py", "func_name": "function_0", "original_string": "def _torchrun_launch(args: Namespace, script_args: list[str]) -> None:\r\n    \"\"\"This will invoke `torchrun` programmatically to launch the given script in new processes.\"\"\"\r\n    import torch.distributed.run as torchrun\r\n\r\n    num_processes = 1 if args.strategy == \"dp\" else _get_num_processes(args.accelerator, args.devices)\r\n\r\n    torchrun_args = [\r\n        f\"--nproc_per_node={num_processes}\",\r\n        f\"--nnodes={args.num_nodes}\",\r\n        f\"--node_rank={args.node_rank}\",\r\n        f\"--master_addr={args.main_address}\",\r\n        f\"--master_port={args.main_port}\",\r\n        args.script,\r\n    ]\r\n    torchrun_args.extend(script_args)\r\n\r\n    os.environ.setdefault(\"OMP_NUM_THREADS\", str(_suggested_max_num_threads()))\r\n    torchrun.main(torchrun_args)", "language": "python", "code": "def _torchrun_launch(args: Namespace, script_args: list[str]) -> None:\r\n    \"\"\"This will invoke `torchrun` programmatically to launch the given script in new processes.\"\"\"\r\n    import torch.distributed.run as torchrun\r\n\r\n    num_processes = 1 if args.strategy == \"dp\" else _get_num_processes(args.accelerator, args.devices)\r\n\r\n    torchrun_args = [\r\n        f\"--nproc_per_node={num_processes}\",\r\n        f\"--nnodes={args.num_nodes}\",\r\n        f\"--node_rank={args.node_rank}\",\r\n        f\"--master_addr={args.main_address}\",\r\n        f\"--master_port={args.main_port}\",\r\n        args.script,\r\n    ]\r\n    torchrun_args.extend(script_args)\r\n\r\n    os.environ.setdefault(\"OMP_NUM_THREADS\", str(_suggested_max_num_threads()))\r\n    torchrun.main(torchrun_args)", "code_tokens": ["def", "_torchrun_launch", "(", "args", ":", "Namespace", ",", "script_args", ":", "list", "[", "str", "]", ")", "-", ">", "None", ":", "STRING", "import", "torch", ".", "distributed", ".", "run", "as", "torchrun", "num_processes", "=", "1", "if", "args", ".", "strategy", "=", "=", "STRING", "else", "_get_num_processes", "(", "args", ".", "accelerator", ",", "args", ".", "devices", ")", "torchrun_args", "=", "[", "fSTRING", ",", "fSTRING", ",", "fSTRING", ",", "fSTRING", ",", "fSTRING", ",", "args", ".", "script", ",", "]", "torchrun_args", ".", "extend", "(", "script_args", ")", "os", ".", "environ", ".", "setdefault", "(", "STRING", ",", "str", "(", "_suggested_max_num_threads", "(", ")", ")", ")", "torchrun", ".", "main", "(", "torchrun_args", ")"], "docstring": "set a good default number of threads for OMP to avoid warnings being emitted to the user", "docstring_tokens": ["set", "a", "good", "default", "number", "of", "threads", "for", "omp", "to", "avoid", "warnings", "being", "emitted", "to", "the", "user"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\cli.py", "start_line": 210, "end_line": 228, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\connector.py", "func_name": "function_1", "original_string": "def _check_config_and_set_final_flags(\r\n        self,\r\n        strategy: Union[str, Strategy],\r\n        accelerator: Union[str, Accelerator],\r\n        precision: Optional[_PRECISION_INPUT],\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]],\r\n    ) -> None:\r\n        \"\"\"This method checks:\r\n\r\n        1. strategy: whether the strategy name is valid, and sets the internal flags if it is.\r\n        2. accelerator: if the value of the accelerator argument is a type of accelerator (instance or string),\r\n            set self._accelerator_flag accordingly.\r\n        3. precision: The final value of the precision flag may be determined either by the precision argument or\r\n            by a plugin instance.\r\n        4. plugins: The list of plugins may contain a Precision plugin, CheckpointIO, ClusterEnvironment and others.\r\n            Additionally, other flags such as `precision` can populate the list with the\r\n            corresponding plugin instances.\r\n\r\n        \"\"\"\r\n        if plugins is not None:\r\n            plugins = [plugins] if not isinstance(plugins, Iterable) else plugins\r\n\r\n        if isinstance(strategy, str):\r\n            strategy = strategy.lower()\r\n\r\n        self._strategy_flag = strategy\r\n\r\n        if strategy != \"auto\" and strategy not in self._registered_strategies and not isinstance(strategy, Strategy):\r\n            raise ValueError(\r\n                f\"You selected an invalid strategy name: `strategy={strategy!r}`.\"\r\n                \" It must be either a string or an instance of `lightning.fabric.strategies.Strategy`.\"\r\n                \" Example choices: auto, ddp, ddp_spawn, deepspeed, dp, ...\"\r\n                \" Find a complete list of options in our documentation at https://lightning.ai\"\r\n            )\r\n\r\n        if (\r\n            accelerator not in self._registered_accelerators\r\n            and accelerator not in (\"auto\", \"gpu\")\r\n            and not isinstance(accelerator, Accelerator)\r\n        ):\r\n            raise ValueError(\r\n                f\"You selected an invalid accelerator name: `accelerator={accelerator!r}`.\"\r\n                f\" Available names are: auto, {', '.join(self._registered_accelerators)}.\"\r\n            )\r\n\r\n        is_ddp_str = isinstance(strategy, str) and \"ddp\" in strategy\r\n        is_dp_str = isinstance(strategy, str) and \"dp\" in strategy\r\n        is_deepspeed_str = isinstance(strategy, str) and \"deepspeed\" in strategy\r\n        is_parallel_strategy = isinstance(strategy, ParallelStrategy) or is_ddp_str or is_dp_str or is_deepspeed_str\r\n        is_mps_accelerator = MPSAccelerator.is_available() and (\r\n            accelerator in (\"mps\", \"auto\", \"gpu\", None) or isinstance(accelerator, MPSAccelerator)\r\n        )\r\n        if is_mps_accelerator and is_parallel_strategy:\r\n            raise ValueError(\r\n                f\"You set `strategy={strategy}` but strategies from the DDP family are not supported on the\"\r\n                f\" MPS accelerator. Either explicitly set `accelerator='cpu'` or change the strategy.\"\r\n            )\r\n\r\n        self._accelerator_flag = accelerator\r\n\r\n        precision_input = _convert_precision_to_unified_args(precision)\r\n\r\n        if plugins:\r\n            plugins_flags_types: dict[str, int] = Counter()\r\n            for plugin in plugins:\r\n                if isinstance(plugin, Precision):\r\n                    self._precision_instance = plugin\r\n                    plugins_flags_types[Precision.__name__] += 1\r\n                elif isinstance(plugin, CheckpointIO):\r\n                    self.checkpoint_io = plugin\r\n                    plugins_flags_types[CheckpointIO.__name__] += 1\r\n                elif isinstance(plugin, ClusterEnvironment):\r\n                    self._cluster_environment_flag = plugin\r\n                    plugins_flags_types[ClusterEnvironment.__name__] += 1\r\n                else:\r\n                    raise TypeError(\r\n                        f\"Found invalid type for plugin {plugin}. Expected one of: Precision, \"\r\n                        \"CheckpointIO, ClusterEnvironment.\"\r\n                    )\r\n\r\n            duplicated_plugin_key = [k for k, v in plugins_flags_types.items() if v > 1]\r\n            if duplicated_plugin_key:\r\n                raise ValueError(\r\n                    f\"Received multiple values for {', '.join(duplicated_plugin_key)} flags in `plugins`.\"\r\n                    \" Expected one value for each type at most.\"\r\n                )\r\n\r\n            if plugins_flags_types.get(Precision.__name__) and precision_input is not None:\r\n                raise ValueError(\r\n                    f\"Received both `precision={precision_input}` and `plugins={self._precision_instance}`. Choose one.\"\r\n                )\r\n\r\n        self._precision_input = \"32-true\" if precision_input is None else precision_input\r\n\r\n        if isinstance(self._strategy_flag, Strategy):\r\n            if self._strategy_flag._accelerator:\r\n                if self._accelerator_flag != \"auto\":\r\n                    raise ValueError(\"accelerator set through both strategy class and accelerator flag, choose one\")\r\n                self._accelerator_flag = self._strategy_flag._accelerator\r\n            if self._strategy_flag._precision:\r\n                if self._precision_instance:\r\n                    raise ValueError(\"precision set through both strategy class and plugins, choose one\")\r\n                self._precision_instance = self._strategy_flag._precision\r\n            if self._strategy_flag._checkpoint_io:\r\n                if self.checkpoint_io:\r\n                    raise ValueError(\"checkpoint_io set through both strategy class and plugins, choose one\")\r\n                self.checkpoint_io = self._strategy_flag._checkpoint_io\r\n            if getattr(self._strategy_flag, \"cluster_environment\", None):\r\n                if self._cluster_environment_flag:\r\n                    raise ValueError(\"cluster_environment set through both strategy class and plugins, choose one\")\r\n                self._cluster_environment_flag = getattr(self._strategy_flag, \"cluster_environment\")\r\n\r\n            if hasattr(self._strategy_flag, \"parallel_devices\") and self._strategy_flag.parallel_devices:\r\n                if self._strategy_flag.parallel_devices[0].type == \"cpu\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cpu\"):\r\n                        raise ValueError(\r\n                            f\"CPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cpu\"\r\n                if self._strategy_flag.parallel_devices[0].type == \"cuda\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cuda\", \"gpu\"):\r\n                        raise ValueError(\r\n                            f\"GPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cuda\"\r\n                self._parallel_devices = self._strategy_flag.parallel_devices", "language": "python", "code": "def _check_config_and_set_final_flags(\r\n        self,\r\n        strategy: Union[str, Strategy],\r\n        accelerator: Union[str, Accelerator],\r\n        precision: Optional[_PRECISION_INPUT],\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]],\r\n    ) -> None:\r\n        \"\"\"This method checks:\r\n\r\n        1. strategy: whether the strategy name is valid, and sets the internal flags if it is.\r\n        2. accelerator: if the value of the accelerator argument is a type of accelerator (instance or string),\r\n            set self._accelerator_flag accordingly.\r\n        3. precision: The final value of the precision flag may be determined either by the precision argument or\r\n            by a plugin instance.\r\n        4. plugins: The list of plugins may contain a Precision plugin, CheckpointIO, ClusterEnvironment and others.\r\n            Additionally, other flags such as `precision` can populate the list with the\r\n            corresponding plugin instances.\r\n\r\n        \"\"\"\r\n        if plugins is not None:\r\n            plugins = [plugins] if not isinstance(plugins, Iterable) else plugins\r\n\r\n        if isinstance(strategy, str):\r\n            strategy = strategy.lower()\r\n\r\n        self._strategy_flag = strategy\r\n\r\n        if strategy != \"auto\" and strategy not in self._registered_strategies and not isinstance(strategy, Strategy):\r\n            raise ValueError(\r\n                f\"You selected an invalid strategy name: `strategy={strategy!r}`.\"\r\n                \" It must be either a string or an instance of `lightning.fabric.strategies.Strategy`.\"\r\n                \" Example choices: auto, ddp, ddp_spawn, deepspeed, dp, ...\"\r\n                \" Find a complete list of options in our documentation at https://lightning.ai\"\r\n            )\r\n\r\n        if (\r\n            accelerator not in self._registered_accelerators\r\n            and accelerator not in (\"auto\", \"gpu\")\r\n            and not isinstance(accelerator, Accelerator)\r\n        ):\r\n            raise ValueError(\r\n                f\"You selected an invalid accelerator name: `accelerator={accelerator!r}`.\"\r\n                f\" Available names are: auto, {', '.join(self._registered_accelerators)}.\"\r\n            )\r\n\r\n        is_ddp_str = isinstance(strategy, str) and \"ddp\" in strategy\r\n        is_dp_str = isinstance(strategy, str) and \"dp\" in strategy\r\n        is_deepspeed_str = isinstance(strategy, str) and \"deepspeed\" in strategy\r\n        is_parallel_strategy = isinstance(strategy, ParallelStrategy) or is_ddp_str or is_dp_str or is_deepspeed_str\r\n        is_mps_accelerator = MPSAccelerator.is_available() and (\r\n            accelerator in (\"mps\", \"auto\", \"gpu\", None) or isinstance(accelerator, MPSAccelerator)\r\n        )\r\n        if is_mps_accelerator and is_parallel_strategy:\r\n            raise ValueError(\r\n                f\"You set `strategy={strategy}` but strategies from the DDP family are not supported on the\"\r\n                f\" MPS accelerator. Either explicitly set `accelerator='cpu'` or change the strategy.\"\r\n            )\r\n\r\n        self._accelerator_flag = accelerator\r\n\r\n        precision_input = _convert_precision_to_unified_args(precision)\r\n\r\n        if plugins:\r\n            plugins_flags_types: dict[str, int] = Counter()\r\n            for plugin in plugins:\r\n                if isinstance(plugin, Precision):\r\n                    self._precision_instance = plugin\r\n                    plugins_flags_types[Precision.__name__] += 1\r\n                elif isinstance(plugin, CheckpointIO):\r\n                    self.checkpoint_io = plugin\r\n                    plugins_flags_types[CheckpointIO.__name__] += 1\r\n                elif isinstance(plugin, ClusterEnvironment):\r\n                    self._cluster_environment_flag = plugin\r\n                    plugins_flags_types[ClusterEnvironment.__name__] += 1\r\n                else:\r\n                    raise TypeError(\r\n                        f\"Found invalid type for plugin {plugin}. Expected one of: Precision, \"\r\n                        \"CheckpointIO, ClusterEnvironment.\"\r\n                    )\r\n\r\n            duplicated_plugin_key = [k for k, v in plugins_flags_types.items() if v > 1]\r\n            if duplicated_plugin_key:\r\n                raise ValueError(\r\n                    f\"Received multiple values for {', '.join(duplicated_plugin_key)} flags in `plugins`.\"\r\n                    \" Expected one value for each type at most.\"\r\n                )\r\n\r\n            if plugins_flags_types.get(Precision.__name__) and precision_input is not None:\r\n                raise ValueError(\r\n                    f\"Received both `precision={precision_input}` and `plugins={self._precision_instance}`. Choose one.\"\r\n                )\r\n\r\n        self._precision_input = \"32-true\" if precision_input is None else precision_input\r\n\r\n        if isinstance(self._strategy_flag, Strategy):\r\n            if self._strategy_flag._accelerator:\r\n                if self._accelerator_flag != \"auto\":\r\n                    raise ValueError(\"accelerator set through both strategy class and accelerator flag, choose one\")\r\n                self._accelerator_flag = self._strategy_flag._accelerator\r\n            if self._strategy_flag._precision:\r\n                if self._precision_instance:\r\n                    raise ValueError(\"precision set through both strategy class and plugins, choose one\")\r\n                self._precision_instance = self._strategy_flag._precision\r\n            if self._strategy_flag._checkpoint_io:\r\n                if self.checkpoint_io:\r\n                    raise ValueError(\"checkpoint_io set through both strategy class and plugins, choose one\")\r\n                self.checkpoint_io = self._strategy_flag._checkpoint_io\r\n            if getattr(self._strategy_flag, \"cluster_environment\", None):\r\n                if self._cluster_environment_flag:\r\n                    raise ValueError(\"cluster_environment set through both strategy class and plugins, choose one\")\r\n                self._cluster_environment_flag = getattr(self._strategy_flag, \"cluster_environment\")\r\n\r\n            if hasattr(self._strategy_flag, \"parallel_devices\") and self._strategy_flag.parallel_devices:\r\n                if self._strategy_flag.parallel_devices[0].type == \"cpu\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cpu\"):\r\n                        raise ValueError(\r\n                            f\"CPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cpu\"\r\n                if self._strategy_flag.parallel_devices[0].type == \"cuda\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cuda\", \"gpu\"):\r\n                        raise ValueError(\r\n                            f\"GPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cuda\"\r\n                self._parallel_devices = self._strategy_flag.parallel_devices", "code_tokens": ["def", "_check_config_and_set_final_flags", "(", "self", ",", "strategy", ":", "Union", "[", "str", ",", "Strategy", "]", ",", "accelerator", ":", "Union", "[", "str", ",", "Accelerator", "]", ",", "precision", ":", "Optional", "[", "_PRECISION_INPUT", "]", ",", "plugins", ":", "Optional", "[", "Union", "[", "_PLUGIN_INPUT", ",", "Iterable", "[", "_PLUGIN_INPUT", "]", "]", "]", ",", ")", "-", ">", "None", ":", "STRING", "if", "plugins", "is", "not", "None", ":", "plugins", "=", "[", "plugins", "]", "if", "not", "isinstance", "(", "plugins", ",", "Iterable", ")", "else", "plugins", "if", "isinstance", "(", "strategy", ",", "str", ")", ":", "strategy", "=", "strategy", ".", "lower", "(", ")", "self", ".", "_strategy_flag", "=", "strategy", "if", "strategy", "!", "=", "STRING", "and", "strategy", "not", "in", "self", ".", "_registered_strategies", "and", "not", "isinstance", "(", "strategy", ",", "Strategy", ")", ":", "raise", "ValueError", "(", "fSTRING", "STRING", "STRING", "STRING", ")", "if", "(", "accelerator", "not", "in", "self", ".", "_registered_accelerators", "and", "accelerator", "not", "in", "(", "STRING", ",", "STRING", ")", "and", "not", "isinstance", "(", "accelerator", ",", "Accelerator", ")", ")", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "is_ddp_str", "=", "isinstance", "(", "strategy", ",", "str", ")", "and", "STRING", "in", "strategy", "is_dp_str", "=", "isinstance", "(", "strategy", ",", "str", ")", "and", "STRING", "in", "strategy", "is_deepspeed_str", "=", "isinstance", "(", "strategy", ",", "str", ")", "and", "STRING", "in", "strategy", "is_parallel_strategy", "=", "isinstance", "(", "strategy", ",", "ParallelStrategy", ")", "or", "is_ddp_str", "or", "is_dp_str", "or", "is_deepspeed_str", "is_mps_accelerator", "=", "MPSAccelerator", ".", "is_available", "(", ")", "and", "(", "accelerator", "in", "(", "STRING", ",", "STRING", ",", "STRING", ",", "None", ")", "or", "isinstance", "(", "accelerator", ",", "MPSAccelerator", ")", ")", "if", "is_mps_accelerator", "and", "is_parallel_strategy", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "self", ".", "_accelerator_flag", "=", "accelerator", "precision_input", "=", "_convert_precision_to_unified_args", "(", "precision", ")", "if", "plugins", ":", "plugins_flags_types", ":", "dict", "[", "str", ",", "int", "]", "=", "Counter", "(", ")", "for", "plugin", "in", "plugins", ":", "if", "isinstance", "(", "plugin", ",", "Precision", ")", ":", "self", ".", "_precision_instance", "=", "plugin", "plugins_flags_types", "[", "Precision", ".", "__name__", "]", "+", "=", "1", "elif", "isinstance", "(", "plugin", ",", "CheckpointIO", ")", ":", "self", ".", "checkpoint_io", "=", "plugin", "plugins_flags_types", "[", "CheckpointIO", ".", "__name__", "]", "+", "=", "1", "elif", "isinstance", "(", "plugin", ",", "ClusterEnvironment", ")", ":", "self", ".", "_cluster_environment_flag", "=", "plugin", "plugins_flags_types", "[", "ClusterEnvironment", ".", "__name__", "]", "+", "=", "1", "else", ":", "raise", "TypeError", "(", "fSTRING", "STRING", ")", "duplicated_plugin_key", "=", "[", "k", "for", "k", ",", "v", "in", "plugins_flags_types", ".", "items", "(", ")", "if", "v", ">", "1", "]", "if", "duplicated_plugin_key", ":", "raise", "ValueError", "(", "fSTRING", "STRING", ")", "if", "plugins_flags_types", ".", "get", "(", "Precision", ".", "__name__", ")", "and", "precision_input", "is", "not", "None", ":", "raise", "ValueError", "(", "fSTRING", ")", "self", ".", "_precision_input", "=", "STRING", "if", "precision_input", "is", "None", "else", "precision_input", "if", "isinstance", "(", "self", ".", "_strategy_flag", ",", "Strategy", ")", ":", "if", "self", ".", "_strategy_flag", ".", "_accelerator", ":", "if", "self", ".", "_accelerator_flag", "!", "=", "STRING", ":", "raise", "ValueError", "(", "STRING", ")", "self", ".", "_accelerator_flag", "=", "self", ".", "_strategy_flag", ".", "_accelerator", "if", "self", ".", "_strategy_flag", ".", "_precision", ":", "if", "self", ".", "_precision_instance", ":", "raise", "ValueError", "(", "STRING", ")", "self", ".", "_precision_instance", "=", "self", ".", "_strategy_flag", ".", "_precision", "if", "self", ".", "_strategy_flag", ".", "_checkpoint_io", ":", "if", "self", ".", "checkpoint_io", ":", "raise", "ValueError", "(", "STRING", ")", "self", ".", "checkpoint_io", "=", "self", ".", "_strategy_flag", ".", "_checkpoint_io", "if", "getattr", "(", "self", ".", "_strategy_flag", ",", "STRING", ",", "None", ")", ":", "if", "self"], "docstring": "MPS accelerator is incompatible with DDP family of strategies. It supports single-device operation only. handle the case when the user passes in a strategy instance which has an accelerator, precision, checkpoint io or cluster env set up TODO: improve the error messages below [RFC] handle precision plugin set up conflict?", "docstring_tokens": ["mps", "accelerator", "is", "incompatible", "with", "ddp", "family", "of", "strategies", "it", "supports", "single", "device", "operation", "only", "handle", "the", "case", "when", "the", "user", "passes", "in", "a", "strategy", "instance", "which", "has", "an", "accelerator", "precision", "checkpoint", "io", "or", "cluster", "env", "set", "up", "todo", "improve", "the", "error", "messages", "below", "rfc", "handle", "precision", "plugin", "set", "up", "conflict"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\connector.py", "start_line": 163, "end_line": 295, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\connector.py", "func_name": "function_2", "original_string": "def _check_strategy_and_fallback(self) -> None:\r\n        \"\"\"Checks edge cases when the strategy selection was a string input, and we need to fall back to a different\r\n        choice depending on other parameters or the environment.\"\"\"\r\n        strategy_flag = \"\" if isinstance(self._strategy_flag, Strategy) else self._strategy_flag\r\n\r\n        if strategy_flag == \"fsdp\" and self._accelerator_flag == \"tpu\":\r\n            strategy_flag = \"xla_fsdp\"\r\n        if strategy_flag == \"dp\" and self._accelerator_flag == \"cpu\":\r\n            rank_zero_warn(f\"{strategy_flag!r} is not supported on CPUs, hence setting `strategy='ddp'`.\")\r\n            strategy_flag = \"ddp\"\r\n        if strategy_flag in _DDP_FORK_ALIASES and \"fork\" not in torch.multiprocessing.get_all_start_methods():\r\n            raise ValueError(\r\n                f\"You selected `Fabric(strategy='{strategy_flag}')` but process forking is not supported on this\"\r\n                f\" platform. We recommend `Fabric(strategy='ddp_spawn')` instead.\"\r\n            )\r\n        if (\r\n            strategy_flag in _FSDP_ALIASES or type(self._strategy_flag) is FSDPStrategy\r\n        ) and self._accelerator_flag not in (\"cuda\", \"gpu\"):\r\n            raise ValueError(\r\n                \"You selected the FSDP strategy but FSDP is only available on GPU. Set `Fabric(accelerator='gpu', ...)`\"\r\n                \" to continue or select a different strategy.\"\r\n            )\r\n        if strategy_flag:\r\n            self._strategy_flag = strategy_flag", "language": "python", "code": "def _check_strategy_and_fallback(self) -> None:\r\n        \"\"\"Checks edge cases when the strategy selection was a string input, and we need to fall back to a different\r\n        choice depending on other parameters or the environment.\"\"\"\r\n        strategy_flag = \"\" if isinstance(self._strategy_flag, Strategy) else self._strategy_flag\r\n\r\n        if strategy_flag == \"fsdp\" and self._accelerator_flag == \"tpu\":\r\n            strategy_flag = \"xla_fsdp\"\r\n        if strategy_flag == \"dp\" and self._accelerator_flag == \"cpu\":\r\n            rank_zero_warn(f\"{strategy_flag!r} is not supported on CPUs, hence setting `strategy='ddp'`.\")\r\n            strategy_flag = \"ddp\"\r\n        if strategy_flag in _DDP_FORK_ALIASES and \"fork\" not in torch.multiprocessing.get_all_start_methods():\r\n            raise ValueError(\r\n                f\"You selected `Fabric(strategy='{strategy_flag}')` but process forking is not supported on this\"\r\n                f\" platform. We recommend `Fabric(strategy='ddp_spawn')` instead.\"\r\n            )\r\n        if (\r\n            strategy_flag in _FSDP_ALIASES or type(self._strategy_flag) is FSDPStrategy\r\n        ) and self._accelerator_flag not in (\"cuda\", \"gpu\"):\r\n            raise ValueError(\r\n                \"You selected the FSDP strategy but FSDP is only available on GPU. Set `Fabric(accelerator='gpu', ...)`\"\r\n                \" to continue or select a different strategy.\"\r\n            )\r\n        if strategy_flag:\r\n            self._strategy_flag = strategy_flag", "code_tokens": ["def", "_check_strategy_and_fallback", "(", "self", ")", "-", ">", "None", ":", "STRING", "strategy_flag", "=", "STRING", "if", "isinstance", "(", "self", ".", "_strategy_flag", ",", "Strategy", ")", "else", "self", ".", "_strategy_flag", "if", "strategy_flag", "=", "=", "STRING", "and", "self", ".", "_accelerator_flag", "=", "=", "STRING", ":", "strategy_flag", "=", "STRING", "if", "strategy_flag", "=", "=", "STRING", "and", "self", ".", "_accelerator_flag", "=", "=", "STRING", ":", "rank_zero_warn", "(", "fSTRING", ")", "strategy_flag", "=", "STRING", "if", "strategy_flag", "in", "_DDP_FORK_ALIASES", "and", "STRING", "not", "in", "torch", ".", "multiprocessing", ".", "get_all_start_methods", "(", ")", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "if", "(", "strategy_flag", "in", "_FSDP_ALIASES", "or", "type", "(", "self", ".", "_strategy_flag", ")", "is", "FSDPStrategy", ")", "and", "self", ".", "_accelerator_flag", "not", "in", "(", "STRING", ",", "STRING", ")", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "if", "strategy_flag", ":", "self", ".", "_strategy_flag", "=", "strategy_flag"], "docstring": "current fallback and check logic only apply to user pass in str config and object config TODO this logic should apply to both str and object config Change fsdp to xla_fsdp if using TPU", "docstring_tokens": ["current", "fallback", "and", "check", "logic", "only", "apply", "to", "user", "pass", "in", "str", "config", "and", "object", "config", "todo", "this", "logic", "should", "apply", "to", "both", "str", "and", "object", "config", "change", "fsdp", "to", "xla_fsdp", "if", "using", "tpu"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\connector.py", "start_line": 414, "end_line": 440, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\connector.py", "func_name": "function_3", "original_string": "def _init_strategy(self) -> None:\r\n        \"\"\"Instantiate the Strategy given depending on the setting of ``_strategy_flag``.\"\"\"\r\n        assert isinstance(self._strategy_flag, (str, Strategy))\r\n        if isinstance(self._strategy_flag, str):\r\n            self.strategy = STRATEGY_REGISTRY.get(self._strategy_flag)\r\n        else:\r\n            self.strategy = self._strategy_flag", "language": "python", "code": "def _init_strategy(self) -> None:\r\n        \"\"\"Instantiate the Strategy given depending on the setting of ``_strategy_flag``.\"\"\"\r\n        assert isinstance(self._strategy_flag, (str, Strategy))\r\n        if isinstance(self._strategy_flag, str):\r\n            self.strategy = STRATEGY_REGISTRY.get(self._strategy_flag)\r\n        else:\r\n            self.strategy = self._strategy_flag", "code_tokens": ["def", "_init_strategy", "(", "self", ")", "-", ">", "None", ":", "STRING", "assert", "isinstance", "(", "self", ".", "_strategy_flag", ",", "(", "str", ",", "Strategy", ")", ")", "if", "isinstance", "(", "self", ".", "_strategy_flag", ",", "str", ")", ":", "self", ".", "strategy", "=", "STRATEGY_REGISTRY", ".", "get", "(", "self", ".", "_strategy_flag", ")", "else", ":", "self", ".", "strategy", "=", "self", ".", "_strategy_flag"], "docstring": "The validation of `_strategy_flag` already happened earlier on in the connector", "docstring_tokens": ["the", "validation", "of", "_strategy_flag", "already", "happened", "earlier", "on", "in", "the", "connector"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\connector.py", "start_line": 442, "end_line": 449, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\connector.py", "func_name": "function_4", "original_string": "def _lazy_init_strategy(self) -> None:\r\n        \"\"\"Lazily set missing attributes on the previously instantiated strategy.\"\"\"\r\n        self.strategy.accelerator = self.accelerator\r\n        if self.precision:\r\n            self.strategy.precision = self.precision\r\n        if self.checkpoint_io:\r\n            self.strategy.checkpoint_io = self.checkpoint_io\r\n        if hasattr(self.strategy, \"cluster_environment\"):\r\n            if self.strategy.cluster_environment is None:\r\n                self.strategy.cluster_environment = self.cluster_environment\r\n            self.cluster_environment = self.strategy.cluster_environment\r\n        if hasattr(self.strategy, \"parallel_devices\"):\r\n            if self.strategy.parallel_devices:\r\n                self._parallel_devices = self.strategy.parallel_devices\r\n            else:\r\n                self.strategy.parallel_devices = self._parallel_devices\r\n        if hasattr(self.strategy, \"num_nodes\"):\r\n            self.strategy._num_nodes = self._num_nodes_flag\r\n        if hasattr(self.strategy, \"_set_world_ranks\"):\r\n            self.strategy._set_world_ranks()\r\n        self.strategy._configure_launcher()\r\n\r\n        if _IS_INTERACTIVE and self.strategy.launcher and not self.strategy.launcher.is_interactive_compatible:\r\n            raise RuntimeError(\r\n                f\"`Fabric(strategy={self._strategy_flag!r})` is not compatible with an interactive\"\r\n                \" environment. Run your code as a script, or choose one of the compatible strategies:\"\r\n                f\" `Fabric(strategy='dp'|'ddp_notebook')`.\"\r\n                \" In case you are spawning processes yourself, make sure to include the Fabric\"\r\n                \" creation inside the worker function.\"\r\n            )\r\n\r\n        if isinstance(self.accelerator, XLAAccelerator) and not isinstance(\r\n            self.strategy, (SingleDeviceXLAStrategy, XLAStrategy, XLAFSDPStrategy)\r\n        ):\r\n            raise ValueError(\r\n                \"The `XLAAccelerator` can only be used with a `SingleDeviceXLAStrategy`, `XLAStrategy`, or\"\r\n                f\" `XLAFSDPStrategy`. Found {self.strategy.__class__.__name__}.\"\r\n            )", "language": "python", "code": "def _lazy_init_strategy(self) -> None:\r\n        \"\"\"Lazily set missing attributes on the previously instantiated strategy.\"\"\"\r\n        self.strategy.accelerator = self.accelerator\r\n        if self.precision:\r\n            self.strategy.precision = self.precision\r\n        if self.checkpoint_io:\r\n            self.strategy.checkpoint_io = self.checkpoint_io\r\n        if hasattr(self.strategy, \"cluster_environment\"):\r\n            if self.strategy.cluster_environment is None:\r\n                self.strategy.cluster_environment = self.cluster_environment\r\n            self.cluster_environment = self.strategy.cluster_environment\r\n        if hasattr(self.strategy, \"parallel_devices\"):\r\n            if self.strategy.parallel_devices:\r\n                self._parallel_devices = self.strategy.parallel_devices\r\n            else:\r\n                self.strategy.parallel_devices = self._parallel_devices\r\n        if hasattr(self.strategy, \"num_nodes\"):\r\n            self.strategy._num_nodes = self._num_nodes_flag\r\n        if hasattr(self.strategy, \"_set_world_ranks\"):\r\n            self.strategy._set_world_ranks()\r\n        self.strategy._configure_launcher()\r\n\r\n        if _IS_INTERACTIVE and self.strategy.launcher and not self.strategy.launcher.is_interactive_compatible:\r\n            raise RuntimeError(\r\n                f\"`Fabric(strategy={self._strategy_flag!r})` is not compatible with an interactive\"\r\n                \" environment. Run your code as a script, or choose one of the compatible strategies:\"\r\n                f\" `Fabric(strategy='dp'|'ddp_notebook')`.\"\r\n                \" In case you are spawning processes yourself, make sure to include the Fabric\"\r\n                \" creation inside the worker function.\"\r\n            )\r\n\r\n        if isinstance(self.accelerator, XLAAccelerator) and not isinstance(\r\n            self.strategy, (SingleDeviceXLAStrategy, XLAStrategy, XLAFSDPStrategy)\r\n        ):\r\n            raise ValueError(\r\n                \"The `XLAAccelerator` can only be used with a `SingleDeviceXLAStrategy`, `XLAStrategy`, or\"\r\n                f\" `XLAFSDPStrategy`. Found {self.strategy.__class__.__name__}.\"\r\n            )", "code_tokens": ["def", "_lazy_init_strategy", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "strategy", ".", "accelerator", "=", "self", ".", "accelerator", "if", "self", ".", "precision", ":", "self", ".", "strategy", ".", "precision", "=", "self", ".", "precision", "if", "self", ".", "checkpoint_io", ":", "self", ".", "strategy", ".", "checkpoint_io", "=", "self", ".", "checkpoint_io", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "if", "self", ".", "strategy", ".", "cluster_environment", "is", "None", ":", "self", ".", "strategy", ".", "cluster_environment", "=", "self", ".", "cluster_environment", "self", ".", "cluster_environment", "=", "self", ".", "strategy", ".", "cluster_environment", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "if", "self", ".", "strategy", ".", "parallel_devices", ":", "self", ".", "_parallel_devices", "=", "self", ".", "strategy", ".", "parallel_devices", "else", ":", "self", ".", "strategy", ".", "parallel_devices", "=", "self", ".", "_parallel_devices", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "self", ".", "strategy", ".", "_num_nodes", "=", "self", ".", "_num_nodes_flag", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "self", ".", "strategy", ".", "_set_world_ranks", "(", ")", "self", ".", "strategy", ".", "_configure_launcher", "(", ")", "if", "_IS_INTERACTIVE", "and", "self", ".", "strategy", ".", "launcher", "and", "not", "self", ".", "strategy", ".", "launcher", ".", "is_interactive_compatible", ":", "raise", "RuntimeError", "(", "fSTRING", "STRING", "fSTRING", "STRING", "STRING", ")", "if", "isinstance", "(", "self", ".", "accelerator", ",", "XLAAccelerator", ")", "and", "not", "isinstance", "(", "self", ".", "strategy", ",", "(", "SingleDeviceXLAStrategy", ",", "XLAStrategy", ",", "XLAFSDPStrategy", ")", ")", ":", "raise", "ValueError", "(", "STRING", "fSTRING", ")"], "docstring": "TODO: should be moved to _check_strategy_and_fallback(). Current test check precision first, so keep this check here to meet error order", "docstring_tokens": ["todo", "should", "be", "moved", "to", "_check_strategy_and_fallback", "current", "test", "check", "precision", "first", "so", "keep", "this", "check", "here", "to", "meet", "error", "order"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\connector.py", "start_line": 499, "end_line": 538, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_5", "original_string": "def setup(\r\n        self,\r\n        module: nn.Module,\r\n        *optimizers: Optimizer,\r\n        scheduler: Optional[\"_LRScheduler\"] = None,\r\n        move_to_device: bool = True,\r\n        _reapply_compile: bool = True,\r\n    ) -> Any:  # no specific return because the way we want our API to look does not play well with mypy\r\n        r\"\"\"Set up a model and its optimizers for accelerated training.\r\n\r\n        Args:\r\n            module: A :class:`torch.nn.Module` to set up.\r\n            *optimizers: The optimizer(s) to set up. Can be zero or more optimizers.\r\n            scheduler: An optional learning rate scheduler to set up. Must be provided after optimizers if used.\r\n            move_to_device: If set ``True`` (default), moves the model to the correct device. Set this to ``False``\r\n                and alternatively use :meth:`to_device` manually.\r\n            _reapply_compile: If ``True`` (default), and the model was ``torch.compile``d before, the\r\n                corresponding :class:`~torch._dynamo.OptimizedModule` wrapper will be removed and reapplied with the\r\n                same settings after the model was set up by the strategy (e.g., after the model was wrapped by DDP,\r\n                FSDP etc.). Set it to ``False`` if compiling DDP/FSDP is causing issues.\r\n\r\n        Returns:\r\n            If no optimizers are passed, returns the wrapped module. If optimizers are passed, returns a tuple\r\n            containing the wrapped module and optimizers, and optionally the scheduler if provided, in the same\r\n            order they were passed in.\r\n\r\n        Note:\r\n            For certain strategies like FSDP, you may need to set up the model first using :meth:`setup_module`,\r\n            then create the optimizer, and finally set up the optimizer using :meth:`setup_optimizers`.\r\n\r\n        Example::\r\n\r\n            model, optimizer = fabric.setup(model, optimizer)\r\n\r\n            model, opt1, opt2, scheduler = fabric.setup(model, opt1, opt2, scheduler=scheduler)\r\n\r\n            model = fabric.setup(model)\r\n\r\n        \"\"\"\r\n        self._validate_setup(module, optimizers)\r\n        module, compile_kwargs = _unwrap_compiled(module) if _reapply_compile else (module, None)\r\n        original_module = module\r\n\r\n        module = self._precision.convert_module(module)\r\n\r\n        if move_to_device:\r\n            module = self._move_model_to_device(model=module, optimizers=list(optimizers))\r\n\r\n        if optimizers:\r\n            module, optimizers, scheduler = self._strategy.setup_module_and_optimizers(  # type: ignore[assignment]\r\n                module, list(optimizers), scheduler\r\n            )\r\n        else:\r\n            module = self._strategy.setup_module(module)\r\n\r\n        if compile_kwargs is not None:\r\n            module = _to_compiled(module, compile_kwargs)\r\n        module = _FabricModule(module, self._strategy, original_module=original_module)\r\n\r\n        _update_properties(\r\n            module, device=self.device if move_to_device else next(module.parameters(), torch.tensor(0)).device\r\n        )\r\n\r\n        optimizers = [_FabricOptimizer(optimizer, self._strategy, self._callbacks) for optimizer in optimizers]\r\n\r\n        self._models_setup += 1\r\n\r\n        if hasattr(original_module, \"_fabric\"):  # this is probably a LightningModule\r\n            original_module._fabric = self\r\n            original_module._fabric_optimizers = optimizers\r\n            if original_module not in self._callbacks:\r\n                self._callbacks.append(original_module)\r\n\r\n        self.call(\"on_after_setup\", fabric=self, module=module)\r\n\r\n        if optimizers:\r\n            return (module, *optimizers, scheduler) if scheduler is not None else (module, *optimizers)\r\n        return module", "language": "python", "code": "def setup(\r\n        self,\r\n        module: nn.Module,\r\n        *optimizers: Optimizer,\r\n        scheduler: Optional[\"_LRScheduler\"] = None,\r\n        move_to_device: bool = True,\r\n        _reapply_compile: bool = True,\r\n    ) -> Any:  # no specific return because the way we want our API to look does not play well with mypy\r\n        r\"\"\"Set up a model and its optimizers for accelerated training.\r\n\r\n        Args:\r\n            module: A :class:`torch.nn.Module` to set up.\r\n            *optimizers: The optimizer(s) to set up. Can be zero or more optimizers.\r\n            scheduler: An optional learning rate scheduler to set up. Must be provided after optimizers if used.\r\n            move_to_device: If set ``True`` (default), moves the model to the correct device. Set this to ``False``\r\n                and alternatively use :meth:`to_device` manually.\r\n            _reapply_compile: If ``True`` (default), and the model was ``torch.compile``d before, the\r\n                corresponding :class:`~torch._dynamo.OptimizedModule` wrapper will be removed and reapplied with the\r\n                same settings after the model was set up by the strategy (e.g., after the model was wrapped by DDP,\r\n                FSDP etc.). Set it to ``False`` if compiling DDP/FSDP is causing issues.\r\n\r\n        Returns:\r\n            If no optimizers are passed, returns the wrapped module. If optimizers are passed, returns a tuple\r\n            containing the wrapped module and optimizers, and optionally the scheduler if provided, in the same\r\n            order they were passed in.\r\n\r\n        Note:\r\n            For certain strategies like FSDP, you may need to set up the model first using :meth:`setup_module`,\r\n            then create the optimizer, and finally set up the optimizer using :meth:`setup_optimizers`.\r\n\r\n        Example::\r\n\r\n            model, optimizer = fabric.setup(model, optimizer)\r\n\r\n            model, opt1, opt2, scheduler = fabric.setup(model, opt1, opt2, scheduler=scheduler)\r\n\r\n            model = fabric.setup(model)\r\n\r\n        \"\"\"\r\n        self._validate_setup(module, optimizers)\r\n        module, compile_kwargs = _unwrap_compiled(module) if _reapply_compile else (module, None)\r\n        original_module = module\r\n\r\n        module = self._precision.convert_module(module)\r\n\r\n        if move_to_device:\r\n            module = self._move_model_to_device(model=module, optimizers=list(optimizers))\r\n\r\n        if optimizers:\r\n            module, optimizers, scheduler = self._strategy.setup_module_and_optimizers(  # type: ignore[assignment]\r\n                module, list(optimizers), scheduler\r\n            )\r\n        else:\r\n            module = self._strategy.setup_module(module)\r\n\r\n        if compile_kwargs is not None:\r\n            module = _to_compiled(module, compile_kwargs)\r\n        module = _FabricModule(module, self._strategy, original_module=original_module)\r\n\r\n        _update_properties(\r\n            module, device=self.device if move_to_device else next(module.parameters(), torch.tensor(0)).device\r\n        )\r\n\r\n        optimizers = [_FabricOptimizer(optimizer, self._strategy, self._callbacks) for optimizer in optimizers]\r\n\r\n        self._models_setup += 1\r\n\r\n        if hasattr(original_module, \"_fabric\"):  # this is probably a LightningModule\r\n            original_module._fabric = self\r\n            original_module._fabric_optimizers = optimizers\r\n            if original_module not in self._callbacks:\r\n                self._callbacks.append(original_module)\r\n\r\n        self.call(\"on_after_setup\", fabric=self, module=module)\r\n\r\n        if optimizers:\r\n            return (module, *optimizers, scheduler) if scheduler is not None else (module, *optimizers)\r\n        return module", "code_tokens": ["def", "setup", "(", "self", ",", "module", ":", "nn", ".", "Module", ",", "*", "optimizers", ":", "Optimizer", ",", "scheduler", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "move_to_device", ":", "bool", "=", "True", ",", "_reapply_compile", ":", "bool", "=", "True", ",", ")", "-", ">", "Any", ":", "#", "no", "specific", "return", "because", "the", "way", "we", "want", "our", "API", "to", "look", "does", "not", "play", "well", "with", "mypy", "rSTRING", "self", ".", "_validate_setup", "(", "module", ",", "optimizers", ")", "module", ",", "compile_kwargs", "=", "_unwrap_compiled", "(", "module", ")", "if", "_reapply_compile", "else", "(", "module", ",", "None", ")", "original_module", "=", "module", "module", "=", "self", ".", "_precision", ".", "convert_module", "(", "module", ")", "if", "move_to_device", ":", "module", "=", "self", ".", "_move_model_to_device", "(", "model", "=", "module", ",", "optimizers", "=", "list", "(", "optimizers", ")", ")", "if", "optimizers", ":", "module", ",", "optimizers", ",", "scheduler", "=", "self", ".", "_strategy", ".", "setup_module_and_optimizers", "(", "#", "type", ":", "ignore", "[", "assignment", "]", "module", ",", "list", "(", "optimizers", ")", ",", "scheduler", ")", "else", ":", "module", "=", "self", ".", "_strategy", ".", "setup_module", "(", "module", ")", "if", "compile_kwargs", "is", "not", "None", ":", "module", "=", "_to_compiled", "(", "module", ",", "compile_kwargs", ")", "module", "=", "_FabricModule", "(", "module", ",", "self", ".", "_strategy", ",", "original_module", "=", "original_module", ")", "_update_properties", "(", "module", ",", "device", "=", "self", ".", "device", "if", "move_to_device", "else", "next", "(", "module", ".", "parameters", "(", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", ".", "device", ")", "optimizers", "=", "[", "_FabricOptimizer", "(", "optimizer", ",", "self", ".", "_strategy", ",", "self", ".", "_callbacks", ")", "for", "optimizer", "in", "optimizers", "]", "self", ".", "_models_setup", "+", "=", "1", "if", "hasattr", "(", "original_module", ",", "STRING", ")", ":", "#", "this", "is", "probably", "a", "LightningModule", "original_module", ".", "_fabric", "=", "self", "original_module", ".", "_fabric_optimizers", "=", "optimizers", "if", "original_module", "not", "in", "self", ".", "_callbacks", ":", "self", ".", "_callbacks", ".", "append", "(", "original_module", ")", "self", ".", "call", "(", "STRING", ",", "fabric", "=", "self", ",", "module", "=", "module", ")", "if", "optimizers", ":", "return", "(", "module", ",", "*", "optimizers", ",", "scheduler", ")", "if", "scheduler", "is", "not", "None", "else", "(", "module", ",", "*", "optimizers", ")", "return", "module"], "docstring": "Basic usage With multiple optimizers and scheduler Model only Let accelerator/plugin wrap and connect the models and optimizers Update the _DeviceDtypeModuleMixin's device parameter NOTE: for sharded strategies or manual device placement, there's no single root device join both types in a tuple for API convenience", "docstring_tokens": ["basic", "usage", "with", "multiple", "optimizers", "and", "scheduler", "model", "only", "let", "accelerator", "plugin", "wrap", "and", "connect", "the", "models", "and", "optimizers", "update", "the", "_devicedtypemodulemixin", "s", "device", "parameter", "note", "for", "sharded", "strategies", "or", "manual", "device", "placement", "there", "s", "no", "single", "root", "device", "join", "both", "types", "in", "a", "tuple", "for", "api", "convenience"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 228, "end_line": 312, "has_examples": true, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_6", "original_string": "def setup_module(\r\n        self, module: nn.Module, move_to_device: bool = True, _reapply_compile: bool = True\r\n    ) -> _FabricModule:\r\n        r\"\"\"Set up a model for accelerated training or inference.\r\n\r\n        This is the same as calling ``.setup(model)`` with no optimizers. It is useful for inference or for certain\r\n        strategies like `FSDP` that require setting up the module before the optimizer can be created and set up.\r\n        See also :meth:`setup_optimizers`.\r\n\r\n        Args:\r\n            module: A :class:`torch.nn.Module` to set up.\r\n            move_to_device: If set ``True`` (default), moves the model to the correct device. Set this to ``False``\r\n                and alternatively use :meth:`to_device` manually.\r\n            _reapply_compile: If ``True`` (default), and the model was ``torch.compile``d before, the\r\n                corresponding :class:`~torch._dynamo.OptimizedModule` wrapper will be removed and reapplied with the\r\n                same settings after the model was set up by the strategy (e.g., after the model was wrapped by DDP,\r\n                FSDP etc.). Set it to ``False`` if compiling DDP/FSDP is causing issues.\r\n\r\n        Returns:\r\n            The wrapped model as a :class:`~lightning.fabric.wrappers._FabricModule`.\r\n\r\n        Example::\r\n\r\n            model = fabric.setup_module(model)\r\n\r\n            optimizer = torch.optim.Adam(model.parameters())\r\n            optimizer = fabric.setup_optimizers(optimizer)\r\n\r\n        \"\"\"\r\n        self._validate_setup_module(module)\r\n        module, compile_kwargs = _unwrap_compiled(module) if _reapply_compile else (module, None)\r\n        original_module = module\r\n\r\n        module = self._precision.convert_module(module)\r\n\r\n        if move_to_device:\r\n            module = self._move_model_to_device(model=module, optimizers=[])\r\n\r\n        module = self._strategy.setup_module(module)\r\n\r\n        if compile_kwargs is not None:\r\n            module = _to_compiled(module, compile_kwargs)\r\n        module = _FabricModule(module, self._strategy, original_module=original_module)\r\n\r\n        _update_properties(\r\n            module, device=self.device if move_to_device else next(module.parameters(), torch.tensor(0)).device\r\n        )\r\n\r\n        if hasattr(original_module, \"_fabric\"):  # this is probably a LightningModule\r\n            original_module._fabric = self\r\n            if original_module not in self._callbacks:\r\n                self._callbacks.append(original_module)\r\n\r\n        self._models_setup += 1\r\n        return module", "language": "python", "code": "def setup_module(\r\n        self, module: nn.Module, move_to_device: bool = True, _reapply_compile: bool = True\r\n    ) -> _FabricModule:\r\n        r\"\"\"Set up a model for accelerated training or inference.\r\n\r\n        This is the same as calling ``.setup(model)`` with no optimizers. It is useful for inference or for certain\r\n        strategies like `FSDP` that require setting up the module before the optimizer can be created and set up.\r\n        See also :meth:`setup_optimizers`.\r\n\r\n        Args:\r\n            module: A :class:`torch.nn.Module` to set up.\r\n            move_to_device: If set ``True`` (default), moves the model to the correct device. Set this to ``False``\r\n                and alternatively use :meth:`to_device` manually.\r\n            _reapply_compile: If ``True`` (default), and the model was ``torch.compile``d before, the\r\n                corresponding :class:`~torch._dynamo.OptimizedModule` wrapper will be removed and reapplied with the\r\n                same settings after the model was set up by the strategy (e.g., after the model was wrapped by DDP,\r\n                FSDP etc.). Set it to ``False`` if compiling DDP/FSDP is causing issues.\r\n\r\n        Returns:\r\n            The wrapped model as a :class:`~lightning.fabric.wrappers._FabricModule`.\r\n\r\n        Example::\r\n\r\n            model = fabric.setup_module(model)\r\n\r\n            optimizer = torch.optim.Adam(model.parameters())\r\n            optimizer = fabric.setup_optimizers(optimizer)\r\n\r\n        \"\"\"\r\n        self._validate_setup_module(module)\r\n        module, compile_kwargs = _unwrap_compiled(module) if _reapply_compile else (module, None)\r\n        original_module = module\r\n\r\n        module = self._precision.convert_module(module)\r\n\r\n        if move_to_device:\r\n            module = self._move_model_to_device(model=module, optimizers=[])\r\n\r\n        module = self._strategy.setup_module(module)\r\n\r\n        if compile_kwargs is not None:\r\n            module = _to_compiled(module, compile_kwargs)\r\n        module = _FabricModule(module, self._strategy, original_module=original_module)\r\n\r\n        _update_properties(\r\n            module, device=self.device if move_to_device else next(module.parameters(), torch.tensor(0)).device\r\n        )\r\n\r\n        if hasattr(original_module, \"_fabric\"):  # this is probably a LightningModule\r\n            original_module._fabric = self\r\n            if original_module not in self._callbacks:\r\n                self._callbacks.append(original_module)\r\n\r\n        self._models_setup += 1\r\n        return module", "code_tokens": ["def", "setup_module", "(", "self", ",", "module", ":", "nn", ".", "Module", ",", "move_to_device", ":", "bool", "=", "True", ",", "_reapply_compile", ":", "bool", "=", "True", ")", "-", ">", "_FabricModule", ":", "rSTRING", "self", ".", "_validate_setup_module", "(", "module", ")", "module", ",", "compile_kwargs", "=", "_unwrap_compiled", "(", "module", ")", "if", "_reapply_compile", "else", "(", "module", ",", "None", ")", "original_module", "=", "module", "module", "=", "self", ".", "_precision", ".", "convert_module", "(", "module", ")", "if", "move_to_device", ":", "module", "=", "self", ".", "_move_model_to_device", "(", "model", "=", "module", ",", "optimizers", "=", "[", "]", ")", "module", "=", "self", ".", "_strategy", ".", "setup_module", "(", "module", ")", "if", "compile_kwargs", "is", "not", "None", ":", "module", "=", "_to_compiled", "(", "module", ",", "compile_kwargs", ")", "module", "=", "_FabricModule", "(", "module", ",", "self", ".", "_strategy", ",", "original_module", "=", "original_module", ")", "_update_properties", "(", "module", ",", "device", "=", "self", ".", "device", "if", "move_to_device", "else", "next", "(", "module", ".", "parameters", "(", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", ".", "device", ")", "if", "hasattr", "(", "original_module", ",", "STRING", ")", ":", "#", "this", "is", "probably", "a", "LightningModule", "original_module", ".", "_fabric", "=", "self", "if", "original_module", "not", "in", "self", ".", "_callbacks", ":", "self", ".", "_callbacks", ".", "append", "(", "original_module", ")", "self", ".", "_models_setup", "+", "=", "1", "return", "module"], "docstring": "Set up model first (useful for FSDP) Then create and set up optimizer Let strategy wrap and connect the module alone Update the _DeviceDtypeModuleMixin's device parameter NOTE: for sharded strategies or manual device placement, there's no single root device", "docstring_tokens": ["set", "up", "model", "first", "useful", "for", "fsdp", "then", "create", "and", "set", "up", "optimizer", "let", "strategy", "wrap", "and", "connect", "the", "module", "alone", "update", "the", "_devicedtypemodulemixin", "s", "device", "parameter", "note", "for", "sharded", "strategies", "or", "manual", "device", "placement", "there", "s", "no", "single", "root", "device"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 314, "end_line": 373, "has_examples": true, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_7", "original_string": "def setup_optimizers(self, *optimizers: Optimizer) -> Union[_FabricOptimizer, tuple[_FabricOptimizer, ...]]:\r\n        r\"\"\"Set up one or more optimizers for accelerated training.\r\n\r\n        Some strategies do not allow setting up model and optimizer independently. For them, you should call\r\n        ``.setup(model, optimizer, ...)`` instead to jointly set them up.\r\n\r\n        Args:\r\n            *optimizers: One or more optimizers to set up. Must provide at least one optimizer.\r\n\r\n        Returns:\r\n            If a single optimizer is passed, returns the wrapped optimizer. If multiple optimizers are passed,\r\n            returns a tuple of wrapped optimizers in the same order they were passed in.\r\n\r\n        Raises:\r\n            RuntimeError: If using DeepSpeed or XLA strategies, which require joint model-optimizer setup.\r\n\r\n        Note:\r\n            This method cannot be used with DeepSpeed or XLA strategies. Use :meth:`setup` instead for those strategies.\r\n\r\n        Example::\r\n\r\n            optimizer = fabric.setup_optimizers(optimizer)\r\n\r\n            opt1, opt2 = fabric.setup_optimizers(opt1, opt2)\r\n\r\n        \"\"\"\r\n        self._validate_setup_optimizers(optimizers)\r\n        optimizers = [self._strategy.setup_optimizer(optimizer) for optimizer in optimizers]\r\n        optimizers = [\r\n            _FabricOptimizer(optimizer=optimizer, strategy=self._strategy, callbacks=self._callbacks)\r\n            for optimizer in optimizers\r\n        ]\r\n        return optimizers[0] if len(optimizers) == 1 else tuple(optimizers)", "language": "python", "code": "def setup_optimizers(self, *optimizers: Optimizer) -> Union[_FabricOptimizer, tuple[_FabricOptimizer, ...]]:\r\n        r\"\"\"Set up one or more optimizers for accelerated training.\r\n\r\n        Some strategies do not allow setting up model and optimizer independently. For them, you should call\r\n        ``.setup(model, optimizer, ...)`` instead to jointly set them up.\r\n\r\n        Args:\r\n            *optimizers: One or more optimizers to set up. Must provide at least one optimizer.\r\n\r\n        Returns:\r\n            If a single optimizer is passed, returns the wrapped optimizer. If multiple optimizers are passed,\r\n            returns a tuple of wrapped optimizers in the same order they were passed in.\r\n\r\n        Raises:\r\n            RuntimeError: If using DeepSpeed or XLA strategies, which require joint model-optimizer setup.\r\n\r\n        Note:\r\n            This method cannot be used with DeepSpeed or XLA strategies. Use :meth:`setup` instead for those strategies.\r\n\r\n        Example::\r\n\r\n            optimizer = fabric.setup_optimizers(optimizer)\r\n\r\n            opt1, opt2 = fabric.setup_optimizers(opt1, opt2)\r\n\r\n        \"\"\"\r\n        self._validate_setup_optimizers(optimizers)\r\n        optimizers = [self._strategy.setup_optimizer(optimizer) for optimizer in optimizers]\r\n        optimizers = [\r\n            _FabricOptimizer(optimizer=optimizer, strategy=self._strategy, callbacks=self._callbacks)\r\n            for optimizer in optimizers\r\n        ]\r\n        return optimizers[0] if len(optimizers) == 1 else tuple(optimizers)", "code_tokens": ["def", "setup_optimizers", "(", "self", ",", "*", "optimizers", ":", "Optimizer", ")", "-", ">", "Union", "[", "_FabricOptimizer", ",", "tuple", "[", "_FabricOptimizer", ",", ".", ".", ".", "]", "]", ":", "rSTRING", "self", ".", "_validate_setup_optimizers", "(", "optimizers", ")", "optimizers", "=", "[", "self", ".", "_strategy", ".", "setup_optimizer", "(", "optimizer", ")", "for", "optimizer", "in", "optimizers", "]", "optimizers", "=", "[", "_FabricOptimizer", "(", "optimizer", "=", "optimizer", ",", "strategy", "=", "self", ".", "_strategy", ",", "callbacks", "=", "self", ".", "_callbacks", ")", "for", "optimizer", "in", "optimizers", "]", "return", "optimizers", "[", "0", "]", "if", "len", "(", "optimizers", ")", "=", "=", "1", "else", "tuple", "(", "optimizers", ")"], "docstring": "Single optimizer Multiple optimizers", "docstring_tokens": ["single", "optimizer", "multiple", "optimizers"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 375, "end_line": 409, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_8", "original_string": "def setup_dataloaders(\r\n        self, *dataloaders: DataLoader, use_distributed_sampler: bool = True, move_to_device: bool = True\r\n    ) -> Union[DataLoader, list[DataLoader]]:\r\n        r\"\"\"Set up one or multiple dataloaders for accelerated training. If you need different settings for each\r\n        dataloader, call this method individually for each one.\r\n\r\n        Args:\r\n            *dataloaders: One or more PyTorch :class:`~torch.utils.data.DataLoader` instances to set up.\r\n            use_distributed_sampler: If set ``True`` (default), automatically wraps or replaces the sampler on the\r\n                dataloader(s) for distributed training. If you have a custom sampler defined, set this argument\r\n                to ``False``.\r\n            move_to_device: If set ``True`` (default), moves the data returned by the dataloader(s) automatically to\r\n                the correct device. Set this to ``False`` and alternatively use :meth:`to_device` manually on the\r\n                returned data.\r\n\r\n        Returns:\r\n            If a single dataloader is passed, returns the wrapped dataloader. If multiple dataloaders are passed,\r\n            returns a list of wrapped dataloaders in the same order they were passed in.\r\n\r\n        Example::\r\n\r\n            train_loader = fabric.setup_dataloaders(train_loader)\r\n\r\n            train_loader, val_loader = fabric.setup_dataloaders(train_loader, val_loader)\r\n\r\n        \"\"\"\r\n        self._validate_setup_dataloaders(dataloaders)\r\n        dataloaders = [\r\n            self._setup_dataloader(\r\n                dataloader, use_distributed_sampler=use_distributed_sampler, move_to_device=move_to_device\r\n            )\r\n            for dataloader in dataloaders\r\n        ]\r\n        return dataloaders[0] if len(dataloaders) == 1 else dataloaders", "language": "python", "code": "def setup_dataloaders(\r\n        self, *dataloaders: DataLoader, use_distributed_sampler: bool = True, move_to_device: bool = True\r\n    ) -> Union[DataLoader, list[DataLoader]]:\r\n        r\"\"\"Set up one or multiple dataloaders for accelerated training. If you need different settings for each\r\n        dataloader, call this method individually for each one.\r\n\r\n        Args:\r\n            *dataloaders: One or more PyTorch :class:`~torch.utils.data.DataLoader` instances to set up.\r\n            use_distributed_sampler: If set ``True`` (default), automatically wraps or replaces the sampler on the\r\n                dataloader(s) for distributed training. If you have a custom sampler defined, set this argument\r\n                to ``False``.\r\n            move_to_device: If set ``True`` (default), moves the data returned by the dataloader(s) automatically to\r\n                the correct device. Set this to ``False`` and alternatively use :meth:`to_device` manually on the\r\n                returned data.\r\n\r\n        Returns:\r\n            If a single dataloader is passed, returns the wrapped dataloader. If multiple dataloaders are passed,\r\n            returns a list of wrapped dataloaders in the same order they were passed in.\r\n\r\n        Example::\r\n\r\n            train_loader = fabric.setup_dataloaders(train_loader)\r\n\r\n            train_loader, val_loader = fabric.setup_dataloaders(train_loader, val_loader)\r\n\r\n        \"\"\"\r\n        self._validate_setup_dataloaders(dataloaders)\r\n        dataloaders = [\r\n            self._setup_dataloader(\r\n                dataloader, use_distributed_sampler=use_distributed_sampler, move_to_device=move_to_device\r\n            )\r\n            for dataloader in dataloaders\r\n        ]\r\n        return dataloaders[0] if len(dataloaders) == 1 else dataloaders", "code_tokens": ["def", "setup_dataloaders", "(", "self", ",", "*", "dataloaders", ":", "DataLoader", ",", "use_distributed_sampler", ":", "bool", "=", "True", ",", "move_to_device", ":", "bool", "=", "True", ")", "-", ">", "Union", "[", "DataLoader", ",", "list", "[", "DataLoader", "]", "]", ":", "rSTRING", "self", ".", "_validate_setup_dataloaders", "(", "dataloaders", ")", "dataloaders", "=", "[", "self", ".", "_setup_dataloader", "(", "dataloader", ",", "use_distributed_sampler", "=", "use_distributed_sampler", ",", "move_to_device", "=", "move_to_device", ")", "for", "dataloader", "in", "dataloaders", "]", "return", "dataloaders", "[", "0", "]", "if", "len", "(", "dataloaders", ")", "=", "=", "1", "else", "dataloaders"], "docstring": "Single dataloader Multiple dataloaders", "docstring_tokens": ["single", "dataloader", "multiple", "dataloaders"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 411, "end_line": 446, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_9", "original_string": "def _setup_dataloader(\r\n        self, dataloader: DataLoader, use_distributed_sampler: bool = True, move_to_device: bool = True\r\n    ) -> DataLoader:\r\n        r\"\"\"Set up a single dataloader for accelerated training.\r\n\r\n        Args:\r\n            dataloader: The dataloader to accelerate.\r\n            use_distributed_sampler: If set ``True`` (default), automatically wraps or replaces the sampler on the\r\n                dataloader for distributed training. If you have a custom sampler defined, set this argument to\r\n                ``False``.\r\n            move_to_device: If set ``True`` (default), moves the data returned by the dataloader automatically to\r\n                the correct device. Set this to ``False`` and alternatively use :meth:`to_device` manually on the\r\n                returned data.\r\n\r\n        Returns:\r\n            The wrapped dataloader.\r\n\r\n        \"\"\"\r\n        if use_distributed_sampler and self._requires_distributed_sampler(dataloader):\r\n            sampler = self._get_distributed_sampler(dataloader, **self._strategy.distributed_sampler_kwargs)\r\n\r\n            dataloader = _update_dataloader(dataloader, sampler)\r\n\r\n        _auto_add_worker_init_fn(dataloader, self.global_rank)\r\n\r\n        dataloader = self._strategy.process_dataloader(dataloader)\r\n        device = self.device if move_to_device and not isinstance(self._strategy, XLAStrategy) else None\r\n        fabric_dataloader = _FabricDataLoader(dataloader=dataloader, device=device)\r\n        fabric_dataloader = cast(DataLoader, fabric_dataloader)\r\n        return fabric_dataloader", "language": "python", "code": "def _setup_dataloader(\r\n        self, dataloader: DataLoader, use_distributed_sampler: bool = True, move_to_device: bool = True\r\n    ) -> DataLoader:\r\n        r\"\"\"Set up a single dataloader for accelerated training.\r\n\r\n        Args:\r\n            dataloader: The dataloader to accelerate.\r\n            use_distributed_sampler: If set ``True`` (default), automatically wraps or replaces the sampler on the\r\n                dataloader for distributed training. If you have a custom sampler defined, set this argument to\r\n                ``False``.\r\n            move_to_device: If set ``True`` (default), moves the data returned by the dataloader automatically to\r\n                the correct device. Set this to ``False`` and alternatively use :meth:`to_device` manually on the\r\n                returned data.\r\n\r\n        Returns:\r\n            The wrapped dataloader.\r\n\r\n        \"\"\"\r\n        if use_distributed_sampler and self._requires_distributed_sampler(dataloader):\r\n            sampler = self._get_distributed_sampler(dataloader, **self._strategy.distributed_sampler_kwargs)\r\n\r\n            dataloader = _update_dataloader(dataloader, sampler)\r\n\r\n        _auto_add_worker_init_fn(dataloader, self.global_rank)\r\n\r\n        dataloader = self._strategy.process_dataloader(dataloader)\r\n        device = self.device if move_to_device and not isinstance(self._strategy, XLAStrategy) else None\r\n        fabric_dataloader = _FabricDataLoader(dataloader=dataloader, device=device)\r\n        fabric_dataloader = cast(DataLoader, fabric_dataloader)\r\n        return fabric_dataloader", "code_tokens": ["def", "_setup_dataloader", "(", "self", ",", "dataloader", ":", "DataLoader", ",", "use_distributed_sampler", ":", "bool", "=", "True", ",", "move_to_device", ":", "bool", "=", "True", ")", "-", ">", "DataLoader", ":", "rSTRING", "if", "use_distributed_sampler", "and", "self", ".", "_requires_distributed_sampler", "(", "dataloader", ")", ":", "sampler", "=", "self", ".", "_get_distributed_sampler", "(", "dataloader", ",", "*", "*", "self", ".", "_strategy", ".", "distributed_sampler_kwargs", ")", "dataloader", "=", "_update_dataloader", "(", "dataloader", ",", "sampler", ")", "_auto_add_worker_init_fn", "(", "dataloader", ",", "self", ".", "global_rank", ")", "dataloader", "=", "self", ".", "_strategy", ".", "process_dataloader", "(", "dataloader", ")", "device", "=", "self", ".", "device", "if", "move_to_device", "and", "not", "isinstance", "(", "self", ".", "_strategy", ",", "XLAStrategy", ")", "else", "None", "fabric_dataloader", "=", "_FabricDataLoader", "(", "dataloader", "=", "dataloader", ",", "device", "=", "device", ")", "fabric_dataloader", "=", "cast", "(", "DataLoader", ",", "fabric_dataloader", ")", "return", "fabric_dataloader"], "docstring": "the dataloader needs to be re-instantiated because we want to update the sampler add worker_init_fn for correct seeding in worker processes", "docstring_tokens": ["the", "dataloader", "needs", "to", "be", "re", "instantiated", "because", "we", "want", "to", "update", "the", "sampler", "add", "worker_init_fn", "for", "correct", "seeding", "in", "worker", "processes"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 448, "end_line": 479, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_10", "original_string": "def backward(self, tensor: Tensor, *args: Any, model: Optional[_FabricModule] = None, **kwargs: Any) -> None:\r\n        r\"\"\"Replaces ``loss.backward()`` in your training loop. Handles precision automatically for you.\r\n\r\n        Args:\r\n            tensor: The tensor (loss) to back-propagate gradients from.\r\n            *args: Optional positional arguments passed to the underlying backward function.\r\n            model: Optional model instance for plugins that require the model for backward(). Required when using\r\n                DeepSpeed strategy with multiple models.\r\n            **kwargs: Optional named keyword arguments passed to the underlying backward function.\r\n\r\n        Note:\r\n            When using ``strategy=\"deepspeed\"`` and multiple models were set up, it is required to pass in the\r\n            model as argument here.\r\n\r\n        Example::\r\n\r\n            loss = criterion(output, target)\r\n            fabric.backward(loss)\r\n\r\n            fabric.backward(loss, model=model)\r\n\r\n        \"\"\"\r\n        module = model._forward_module if model is not None else model\r\n        module, _ = _unwrap_compiled(module)\r\n        if isinstance(self._strategy, DeepSpeedStrategy):\r\n            if model is None:\r\n                if self._models_setup == 0:\r\n                    raise RuntimeError(\"No models were set up for backward. Did you forget to call `fabric.setup()`?\")\r\n                if self._models_setup > 1:\r\n                    raise ValueError(\r\n                        \"When using multiple models + deepspeed, please provide the model used to perform\"\r\n                        \" the optimization: `self.backward(loss, model=model)`\"\r\n                    )\r\n                module = self._strategy.model\r\n            else:\r\n                self._strategy._deepspeed_engine = module\r\n\r\n        lightning.fabric.wrappers._in_fabric_backward = True\r\n        try:\r\n            self._strategy.backward(tensor, module, *args, **kwargs)\r\n        finally:\r\n            lightning.fabric.wrappers._in_fabric_backward = False", "language": "python", "code": "def backward(self, tensor: Tensor, *args: Any, model: Optional[_FabricModule] = None, **kwargs: Any) -> None:\r\n        r\"\"\"Replaces ``loss.backward()`` in your training loop. Handles precision automatically for you.\r\n\r\n        Args:\r\n            tensor: The tensor (loss) to back-propagate gradients from.\r\n            *args: Optional positional arguments passed to the underlying backward function.\r\n            model: Optional model instance for plugins that require the model for backward(). Required when using\r\n                DeepSpeed strategy with multiple models.\r\n            **kwargs: Optional named keyword arguments passed to the underlying backward function.\r\n\r\n        Note:\r\n            When using ``strategy=\"deepspeed\"`` and multiple models were set up, it is required to pass in the\r\n            model as argument here.\r\n\r\n        Example::\r\n\r\n            loss = criterion(output, target)\r\n            fabric.backward(loss)\r\n\r\n            fabric.backward(loss, model=model)\r\n\r\n        \"\"\"\r\n        module = model._forward_module if model is not None else model\r\n        module, _ = _unwrap_compiled(module)\r\n        if isinstance(self._strategy, DeepSpeedStrategy):\r\n            if model is None:\r\n                if self._models_setup == 0:\r\n                    raise RuntimeError(\"No models were set up for backward. Did you forget to call `fabric.setup()`?\")\r\n                if self._models_setup > 1:\r\n                    raise ValueError(\r\n                        \"When using multiple models + deepspeed, please provide the model used to perform\"\r\n                        \" the optimization: `self.backward(loss, model=model)`\"\r\n                    )\r\n                module = self._strategy.model\r\n            else:\r\n                self._strategy._deepspeed_engine = module\r\n\r\n        lightning.fabric.wrappers._in_fabric_backward = True\r\n        try:\r\n            self._strategy.backward(tensor, module, *args, **kwargs)\r\n        finally:\r\n            lightning.fabric.wrappers._in_fabric_backward = False", "code_tokens": ["def", "backward", "(", "self", ",", "tensor", ":", "Tensor", ",", "*", "args", ":", "Any", ",", "model", ":", "Optional", "[", "_FabricModule", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "rSTRING", "module", "=", "model", ".", "_forward_module", "if", "model", "is", "not", "None", "else", "model", "module", ",", "_", "=", "_unwrap_compiled", "(", "module", ")", "if", "isinstance", "(", "self", ".", "_strategy", ",", "DeepSpeedStrategy", ")", ":", "if", "model", "is", "None", ":", "if", "self", ".", "_models_setup", "=", "=", "0", ":", "raise", "RuntimeError", "(", "STRING", ")", "if", "self", ".", "_models_setup", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "module", "=", "self", ".", "_strategy", ".", "model", "else", ":", "self", ".", "_strategy", ".", "_deepspeed_engine", "=", "module", "lightning", ".", "fabric", ".", "wrappers", ".", "_in_fabric_backward", "=", "True", "try", ":", "self", ".", "_strategy", ".", "backward", "(", "tensor", ",", "module", ",", "*", "args", ",", "*", "*", "kwargs", ")", "finally", ":", "lightning", ".", "fabric", ".", "wrappers", ".", "_in_fabric_backward", "=", "False"], "docstring": "With DeepSpeed and multiple models requires to attach the current `DeepSpeedEngine` for the `_FabricOptimizer.step` call.", "docstring_tokens": ["with", "deepspeed", "and", "multiple", "models", "requires", "to", "attach", "the", "current", "deepspeedengine", "for", "the", "_fabricoptimizer", "step", "call"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 481, "end_line": 524, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_11", "original_string": "def clip_gradients(\r\n        self,\r\n        module: Union[torch.nn.Module, _FabricModule],\r\n        optimizer: Union[Optimizer, _FabricOptimizer],\r\n        clip_val: Optional[Union[float, int]] = None,\r\n        max_norm: Optional[Union[float, int]] = None,\r\n        norm_type: Union[float, int] = 2.0,\r\n        error_if_nonfinite: bool = True,\r\n    ) -> Optional[torch.Tensor]:\r\n        \"\"\"Clip the gradients of the model to a given max value or max norm.\r\n\r\n        Args:\r\n            module: The module whose parameters should be clipped.\r\n            optimizer: The optimizer referencing the parameters to be clipped.\r\n            clip_val: If passed, gradients will be clipped to this value. Cannot be used together with ``max_norm``.\r\n            max_norm: If passed, clips the gradients in such a way that the p-norm of the resulting parameters is\r\n                no larger than the given value. Cannot be used together with ``clip_val``.\r\n            norm_type: The type of norm if ``max_norm`` was passed. Can be ``'inf'`` for infinity norm.\r\n                Defaults to 2-norm.\r\n            error_if_nonfinite: An error is raised if the total norm of the gradients is NaN or infinite.\r\n                Only applies when ``max_norm`` is used.\r\n\r\n        Returns:\r\n            The total norm of the gradients (before clipping was applied) as a scalar tensor if ``max_norm`` was\r\n            passed, otherwise ``None``.\r\n\r\n        Raises:\r\n            ValueError: If both ``clip_val`` and ``max_norm`` are provided, or if neither is provided.\r\n\r\n        Example::\r\n\r\n            fabric.clip_gradients(model, optimizer, clip_val=1.0)\r\n\r\n            total_norm = fabric.clip_gradients(model, optimizer, max_norm=1.0)\r\n\r\n        \"\"\"\r\n        if clip_val is not None and max_norm is not None:\r\n            raise ValueError(\r\n                \"Only one of `clip_val` or `max_norm` can be set as this specifies the underlying clipping algorithm!\"\r\n            )\r\n\r\n        if clip_val is not None:\r\n            self.strategy.clip_gradients_value(_unwrap_objects(module), _unwrap_objects(optimizer), clip_val=clip_val)\r\n            return None\r\n        if max_norm is not None:\r\n            return self.strategy.clip_gradients_norm(\r\n                _unwrap_objects(module),\r\n                _unwrap_objects(optimizer),\r\n                max_norm=max_norm,\r\n                norm_type=norm_type,\r\n                error_if_nonfinite=error_if_nonfinite,\r\n            )\r\n        raise ValueError(\"You have to specify either `clip_val` or `max_norm` to do gradient clipping!\")", "language": "python", "code": "def clip_gradients(\r\n        self,\r\n        module: Union[torch.nn.Module, _FabricModule],\r\n        optimizer: Union[Optimizer, _FabricOptimizer],\r\n        clip_val: Optional[Union[float, int]] = None,\r\n        max_norm: Optional[Union[float, int]] = None,\r\n        norm_type: Union[float, int] = 2.0,\r\n        error_if_nonfinite: bool = True,\r\n    ) -> Optional[torch.Tensor]:\r\n        \"\"\"Clip the gradients of the model to a given max value or max norm.\r\n\r\n        Args:\r\n            module: The module whose parameters should be clipped.\r\n            optimizer: The optimizer referencing the parameters to be clipped.\r\n            clip_val: If passed, gradients will be clipped to this value. Cannot be used together with ``max_norm``.\r\n            max_norm: If passed, clips the gradients in such a way that the p-norm of the resulting parameters is\r\n                no larger than the given value. Cannot be used together with ``clip_val``.\r\n            norm_type: The type of norm if ``max_norm`` was passed. Can be ``'inf'`` for infinity norm.\r\n                Defaults to 2-norm.\r\n            error_if_nonfinite: An error is raised if the total norm of the gradients is NaN or infinite.\r\n                Only applies when ``max_norm`` is used.\r\n\r\n        Returns:\r\n            The total norm of the gradients (before clipping was applied) as a scalar tensor if ``max_norm`` was\r\n            passed, otherwise ``None``.\r\n\r\n        Raises:\r\n            ValueError: If both ``clip_val`` and ``max_norm`` are provided, or if neither is provided.\r\n\r\n        Example::\r\n\r\n            fabric.clip_gradients(model, optimizer, clip_val=1.0)\r\n\r\n            total_norm = fabric.clip_gradients(model, optimizer, max_norm=1.0)\r\n\r\n        \"\"\"\r\n        if clip_val is not None and max_norm is not None:\r\n            raise ValueError(\r\n                \"Only one of `clip_val` or `max_norm` can be set as this specifies the underlying clipping algorithm!\"\r\n            )\r\n\r\n        if clip_val is not None:\r\n            self.strategy.clip_gradients_value(_unwrap_objects(module), _unwrap_objects(optimizer), clip_val=clip_val)\r\n            return None\r\n        if max_norm is not None:\r\n            return self.strategy.clip_gradients_norm(\r\n                _unwrap_objects(module),\r\n                _unwrap_objects(optimizer),\r\n                max_norm=max_norm,\r\n                norm_type=norm_type,\r\n                error_if_nonfinite=error_if_nonfinite,\r\n            )\r\n        raise ValueError(\"You have to specify either `clip_val` or `max_norm` to do gradient clipping!\")", "code_tokens": ["def", "clip_gradients", "(", "self", ",", "module", ":", "Union", "[", "torch", ".", "nn", ".", "Module", ",", "_FabricModule", "]", ",", "optimizer", ":", "Union", "[", "Optimizer", ",", "_FabricOptimizer", "]", ",", "clip_val", ":", "Optional", "[", "Union", "[", "float", ",", "int", "]", "]", "=", "None", ",", "max_norm", ":", "Optional", "[", "Union", "[", "float", ",", "int", "]", "]", "=", "None", ",", "norm_type", ":", "Union", "[", "float", ",", "int", "]", "=", "2", ".", "0", ",", "error_if_nonfinite", ":", "bool", "=", "True", ",", ")", "-", ">", "Optional", "[", "torch", ".", "Tensor", "]", ":", "STRING", "if", "clip_val", "is", "not", "None", "and", "max_norm", "is", "not", "None", ":", "raise", "ValueError", "(", "STRING", ")", "if", "clip_val", "is", "not", "None", ":", "self", ".", "strategy", ".", "clip_gradients_value", "(", "_unwrap_objects", "(", "module", ")", ",", "_unwrap_objects", "(", "optimizer", ")", ",", "clip_val", "=", "clip_val", ")", "return", "None", "if", "max_norm", "is", "not", "None", ":", "return", "self", ".", "strategy", ".", "clip_gradients_norm", "(", "_unwrap_objects", "(", "module", ")", ",", "_unwrap_objects", "(", "optimizer", ")", ",", "max_norm", "=", "max_norm", ",", "norm_type", "=", "norm_type", ",", "error_if_nonfinite", "=", "error_if_nonfinite", ",", ")", "raise", "ValueError", "(", "STRING", ")"], "docstring": "Clip by value Clip by norm", "docstring_tokens": ["clip", "by", "value", "clip", "by", "norm"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 526, "end_line": 580, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_12", "original_string": "def no_backward_sync(self, module: _FabricModule, enabled: bool = True) -> AbstractContextManager:\r\n        r\"\"\"Skip gradient synchronization during backward to avoid redundant communication overhead.\r\n\r\n        Use this context manager when performing gradient accumulation to speed up training with multiple devices.\r\n        Both the model's ``.forward()`` and the ``fabric.backward()`` call need to run under this context.\r\n\r\n        Args:\r\n            module: The module for which to control the gradient synchronization. Must be a module that was\r\n                set up with :meth:`setup` or :meth:`setup_module`.\r\n            enabled: Whether the context manager is enabled or not. ``True`` means skip the sync, ``False`` means do not\r\n                skip.\r\n\r\n        Returns:\r\n            A context manager that controls gradient synchronization.\r\n\r\n        Raises:\r\n            TypeError: If the module was not set up with Fabric first.\r\n\r\n        Note:\r\n            For strategies that don't support gradient sync control, a warning is emitted and the context manager\r\n            becomes a no-op. For single-device strategies, it is always a no-op.\r\n\r\n        Example::\r\n\r\n            for batch_idx, batch in enumerate(dataloader):\r\n                with fabric.no_backward_sync(model, enabled=(batch_idx % 8 != 0)):\r\n                    output = model(batch)\r\n                    loss = criterion(output, target)\r\n                    fabric.backward(loss)\r\n\r\n                if batch_idx % 8 == 0:\r\n                    optimizer.step()\r\n                    optimizer.zero_grad()\r\n\r\n        \"\"\"\r\n        module, _ = _unwrap_compiled(module)\r\n        if not isinstance(module, _FabricModule):\r\n            raise TypeError(\r\n                \"You need to set up the model first before you can call `fabric.no_backward_sync()`:\"\r\n                \" `model = fabric.setup(model, ...)`\"\r\n            )\r\n        if isinstance(self._strategy, (SingleDeviceStrategy, XLAStrategy)):\r\n            return nullcontext()\r\n        if self._strategy._backward_sync_control is None:\r\n            rank_zero_warn(\r\n                f\"The `{self._strategy.__class__.__name__}` does not support skipping the gradient synchronization.\"\r\n                f\" Remove `.no_backward_sync()` from your code or choose a different strategy.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n            return nullcontext()\r\n\r\n        forward_module, _ = _unwrap_compiled(module._forward_module)\r\n        return self._strategy._backward_sync_control.no_backward_sync(forward_module, enabled)", "language": "python", "code": "def no_backward_sync(self, module: _FabricModule, enabled: bool = True) -> AbstractContextManager:\r\n        r\"\"\"Skip gradient synchronization during backward to avoid redundant communication overhead.\r\n\r\n        Use this context manager when performing gradient accumulation to speed up training with multiple devices.\r\n        Both the model's ``.forward()`` and the ``fabric.backward()`` call need to run under this context.\r\n\r\n        Args:\r\n            module: The module for which to control the gradient synchronization. Must be a module that was\r\n                set up with :meth:`setup` or :meth:`setup_module`.\r\n            enabled: Whether the context manager is enabled or not. ``True`` means skip the sync, ``False`` means do not\r\n                skip.\r\n\r\n        Returns:\r\n            A context manager that controls gradient synchronization.\r\n\r\n        Raises:\r\n            TypeError: If the module was not set up with Fabric first.\r\n\r\n        Note:\r\n            For strategies that don't support gradient sync control, a warning is emitted and the context manager\r\n            becomes a no-op. For single-device strategies, it is always a no-op.\r\n\r\n        Example::\r\n\r\n            for batch_idx, batch in enumerate(dataloader):\r\n                with fabric.no_backward_sync(model, enabled=(batch_idx % 8 != 0)):\r\n                    output = model(batch)\r\n                    loss = criterion(output, target)\r\n                    fabric.backward(loss)\r\n\r\n                if batch_idx % 8 == 0:\r\n                    optimizer.step()\r\n                    optimizer.zero_grad()\r\n\r\n        \"\"\"\r\n        module, _ = _unwrap_compiled(module)\r\n        if not isinstance(module, _FabricModule):\r\n            raise TypeError(\r\n                \"You need to set up the model first before you can call `fabric.no_backward_sync()`:\"\r\n                \" `model = fabric.setup(model, ...)`\"\r\n            )\r\n        if isinstance(self._strategy, (SingleDeviceStrategy, XLAStrategy)):\r\n            return nullcontext()\r\n        if self._strategy._backward_sync_control is None:\r\n            rank_zero_warn(\r\n                f\"The `{self._strategy.__class__.__name__}` does not support skipping the gradient synchronization.\"\r\n                f\" Remove `.no_backward_sync()` from your code or choose a different strategy.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n            return nullcontext()\r\n\r\n        forward_module, _ = _unwrap_compiled(module._forward_module)\r\n        return self._strategy._backward_sync_control.no_backward_sync(forward_module, enabled)", "code_tokens": ["def", "no_backward_sync", "(", "self", ",", "module", ":", "_FabricModule", ",", "enabled", ":", "bool", "=", "True", ")", "-", ">", "AbstractContextManager", ":", "rSTRING", "module", ",", "_", "=", "_unwrap_compiled", "(", "module", ")", "if", "not", "isinstance", "(", "module", ",", "_FabricModule", ")", ":", "raise", "TypeError", "(", "STRING", "STRING", ")", "if", "isinstance", "(", "self", ".", "_strategy", ",", "(", "SingleDeviceStrategy", ",", "XLAStrategy", ")", ")", ":", "return", "nullcontext", "(", ")", "if", "self", ".", "_strategy", ".", "_backward_sync_control", "is", "None", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "return", "nullcontext", "(", ")", "forward_module", ",", "_", "=", "_unwrap_compiled", "(", "module", ".", "_forward_module", ")", "return", "self", ".", "_strategy", ".", "_backward_sync_control", ".", "no_backward_sync", "(", "forward_module", ",", "enabled", ")"], "docstring": "Accumulate gradients over 8 batches", "docstring_tokens": ["accumulate", "gradients", "over", "8", "batches"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 732, "end_line": 785, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_13", "original_string": "def save(\r\n        self,\r\n        path: Union[str, Path],\r\n        state: dict[str, Union[nn.Module, Optimizer, Any]],\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        r\"\"\"Save checkpoint contents to a file.\r\n\r\n        How and which processes save gets determined by the `strategy`. For example, the `ddp` strategy\r\n        saves checkpoints only on process 0, while the `fsdp` strategy saves files from every rank.\r\n        This method must be called on all processes!\r\n\r\n        Args:\r\n            path: A path to where the file(s) should be saved.\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            filter: An optional dictionary containing filter callables that return a boolean indicating whether the\r\n                given item should be saved (``True``) or filtered out (``False``). Each filter key should match a\r\n                state key, where its filter will be applied to the ``state_dict`` generated.\r\n\r\n        Raises:\r\n            TypeError: If filter is not a dictionary or contains non-callable values.\r\n            ValueError: If filter keys don't match state keys.\r\n\r\n        Example::\r\n\r\n            state = {\"model\": model, \"optimizer\": optimizer, \"epoch\": epoch}\r\n            fabric.save(\"checkpoint.pth\", state)\r\n\r\n            def param_filter(name, param):\r\n                return \"bias\" not in name  # Save only non-bias parameters\r\n\r\n            fabric.save(\"checkpoint.pth\", state, filter={\"model\": param_filter})\r\n\r\n        \"\"\"\r\n        if filter is not None:\r\n            if not isinstance(filter, dict):\r\n                raise TypeError(f\"Filter should be a dictionary, given {filter!r}\")\r\n            if not set(filter).issubset(state):\r\n                raise ValueError(\r\n                    f\"The filter keys {filter.keys() - state} are not present in the state keys {set(state)}.\"\r\n                )\r\n            for k, v in filter.items():\r\n                if not callable(v):\r\n                    raise TypeError(f\"Expected `fabric.save(filter=...)` for key {k!r} to be a callable, given {v!r}\")\r\n        self._strategy.save_checkpoint(path=path, state=_unwrap_objects(state), filter=filter)\r\n        self.barrier()", "language": "python", "code": "def save(\r\n        self,\r\n        path: Union[str, Path],\r\n        state: dict[str, Union[nn.Module, Optimizer, Any]],\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        r\"\"\"Save checkpoint contents to a file.\r\n\r\n        How and which processes save gets determined by the `strategy`. For example, the `ddp` strategy\r\n        saves checkpoints only on process 0, while the `fsdp` strategy saves files from every rank.\r\n        This method must be called on all processes!\r\n\r\n        Args:\r\n            path: A path to where the file(s) should be saved.\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            filter: An optional dictionary containing filter callables that return a boolean indicating whether the\r\n                given item should be saved (``True``) or filtered out (``False``). Each filter key should match a\r\n                state key, where its filter will be applied to the ``state_dict`` generated.\r\n\r\n        Raises:\r\n            TypeError: If filter is not a dictionary or contains non-callable values.\r\n            ValueError: If filter keys don't match state keys.\r\n\r\n        Example::\r\n\r\n            state = {\"model\": model, \"optimizer\": optimizer, \"epoch\": epoch}\r\n            fabric.save(\"checkpoint.pth\", state)\r\n\r\n            def param_filter(name, param):\r\n                return \"bias\" not in name  # Save only non-bias parameters\r\n\r\n            fabric.save(\"checkpoint.pth\", state, filter={\"model\": param_filter})\r\n\r\n        \"\"\"\r\n        if filter is not None:\r\n            if not isinstance(filter, dict):\r\n                raise TypeError(f\"Filter should be a dictionary, given {filter!r}\")\r\n            if not set(filter).issubset(state):\r\n                raise ValueError(\r\n                    f\"The filter keys {filter.keys() - state} are not present in the state keys {set(state)}.\"\r\n                )\r\n            for k, v in filter.items():\r\n                if not callable(v):\r\n                    raise TypeError(f\"Expected `fabric.save(filter=...)` for key {k!r} to be a callable, given {v!r}\")\r\n        self._strategy.save_checkpoint(path=path, state=_unwrap_objects(state), filter=filter)\r\n        self.barrier()", "code_tokens": ["def", "save", "(", "self", ",", "path", ":", "Union", "[", "str", ",", "Path", "]", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "nn", ".", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "rSTRING", "if", "filter", "is", "not", "None", ":", "if", "not", "isinstance", "(", "filter", ",", "dict", ")", ":", "raise", "TypeError", "(", "fSTRING", ")", "if", "not", "set", "(", "filter", ")", ".", "issubset", "(", "state", ")", ":", "raise", "ValueError", "(", "fSTRING", ")", "for", "k", ",", "v", "in", "filter", ".", "items", "(", ")", ":", "if", "not", "callable", "(", "v", ")", ":", "raise", "TypeError", "(", "fSTRING", ")", "self", ".", "_strategy", ".", "save_checkpoint", "(", "path", "=", "path", ",", "state", "=", "_unwrap_objects", "(", "state", ")", ",", "filter", "=", "filter", ")", "self", ".", "barrier", "(", ")"], "docstring": "With filter", "docstring_tokens": ["with", "filter"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 819, "end_line": 866, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_14", "original_string": "def load(\r\n        self,\r\n        path: Union[str, Path],\r\n        state: Optional[dict[str, Union[nn.Module, Optimizer, Any]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load a checkpoint from a file and restore the state of objects (modules, optimizers, etc.)\r\n\r\n        How and which processes load gets determined by the `strategy`.\r\n        This method must be called on all processes!\r\n\r\n        Args:\r\n            path: A path to where the file is located.\r\n            state: A dictionary of objects whose state will be restored in-place from the checkpoint path.\r\n                If no state is given, then the checkpoint will be returned in full.\r\n            strict: Whether to enforce that the keys in `state` match the keys in the checkpoint.\r\n\r\n        Returns:\r\n            The remaining items that were not restored into the given state dictionary. If no state dictionary is\r\n            given, the full checkpoint will be returned.\r\n\r\n        Example::\r\n\r\n            checkpoint = fabric.load(\"checkpoint.pth\")\r\n\r\n            state = {\"model\": model, \"optimizer\": optimizer}\r\n            remainder = fabric.load(\"checkpoint.pth\", state)\r\n            epoch = remainder.get(\"epoch\", 0)\r\n\r\n        \"\"\"\r\n        unwrapped_state = _unwrap_objects(state)\r\n        remainder = self._strategy.load_checkpoint(path=path, state=unwrapped_state, strict=strict)\r\n        self.barrier()\r\n        if state is not None:\r\n            for k in list(unwrapped_state.keys()):\r\n                obj, _ = _unwrap_compiled(state[k])\r\n                if isinstance(obj, (_FabricModule, _FabricOptimizer, _FabricDataLoader)):\r\n                    continue\r\n                state[k] = unwrapped_state[k]\r\n        return remainder", "language": "python", "code": "def load(\r\n        self,\r\n        path: Union[str, Path],\r\n        state: Optional[dict[str, Union[nn.Module, Optimizer, Any]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load a checkpoint from a file and restore the state of objects (modules, optimizers, etc.)\r\n\r\n        How and which processes load gets determined by the `strategy`.\r\n        This method must be called on all processes!\r\n\r\n        Args:\r\n            path: A path to where the file is located.\r\n            state: A dictionary of objects whose state will be restored in-place from the checkpoint path.\r\n                If no state is given, then the checkpoint will be returned in full.\r\n            strict: Whether to enforce that the keys in `state` match the keys in the checkpoint.\r\n\r\n        Returns:\r\n            The remaining items that were not restored into the given state dictionary. If no state dictionary is\r\n            given, the full checkpoint will be returned.\r\n\r\n        Example::\r\n\r\n            checkpoint = fabric.load(\"checkpoint.pth\")\r\n\r\n            state = {\"model\": model, \"optimizer\": optimizer}\r\n            remainder = fabric.load(\"checkpoint.pth\", state)\r\n            epoch = remainder.get(\"epoch\", 0)\r\n\r\n        \"\"\"\r\n        unwrapped_state = _unwrap_objects(state)\r\n        remainder = self._strategy.load_checkpoint(path=path, state=unwrapped_state, strict=strict)\r\n        self.barrier()\r\n        if state is not None:\r\n            for k in list(unwrapped_state.keys()):\r\n                obj, _ = _unwrap_compiled(state[k])\r\n                if isinstance(obj, (_FabricModule, _FabricOptimizer, _FabricDataLoader)):\r\n                    continue\r\n                state[k] = unwrapped_state[k]\r\n        return remainder", "code_tokens": ["def", "load", "(", "self", ",", "path", ":", "Union", "[", "str", ",", "Path", "]", ",", "state", ":", "Optional", "[", "dict", "[", "str", ",", "Union", "[", "nn", ".", "Module", ",", "Optimizer", ",", "Any", "]", "]", "]", "=", "None", ",", "strict", ":", "bool", "=", "True", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "unwrapped_state", "=", "_unwrap_objects", "(", "state", ")", "remainder", "=", "self", ".", "_strategy", ".", "load_checkpoint", "(", "path", "=", "path", ",", "state", "=", "unwrapped_state", ",", "strict", "=", "strict", ")", "self", ".", "barrier", "(", ")", "if", "state", "is", "not", "None", ":", "for", "k", "in", "list", "(", "unwrapped_state", ".", "keys", "(", ")", ")", ":", "obj", ",", "_", "=", "_unwrap_compiled", "(", "state", "[", "k", "]", ")", "if", "isinstance", "(", "obj", ",", "(", "_FabricModule", ",", "_FabricOptimizer", ",", "_FabricDataLoader", ")", ")", ":", "continue", "state", "[", "k", "]", "=", "unwrapped_state", "[", "k", "]", "return", "remainder"], "docstring": "Load full checkpoint Load into existing objects We need to unwrap objects (see above) but this creates a new dictionary. In-place updates (for user metadata) wouldn't show up in the original dict, so we need to copy the data back.", "docstring_tokens": ["load", "full", "checkpoint", "load", "into", "existing", "objects", "we", "need", "to", "unwrap", "objects", "see", "above", "but", "this", "creates", "a", "new", "dictionary", "in", "place", "updates", "for", "user", "metadata", "wouldn", "t", "show", "up", "in", "the", "original", "dict", "so", "we", "need", "to", "copy", "the", "data", "back"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 868, "end_line": 911, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\fabric.py", "func_name": "function_15", "original_string": "def seed_everything(seed: Optional[int] = None, workers: Optional[bool] = None, verbose: bool = True) -> int:\r\n        r\"\"\"Helper function to seed everything without explicitly importing Lightning.\r\n\r\n        See :func:`~lightning.fabric.utilities.seed.seed_everything` for more details.\r\n\r\n        \"\"\"\r\n        if workers is None:\r\n            workers = True\r\n        return seed_everything(seed=seed, workers=workers, verbose=verbose)", "language": "python", "code": "def seed_everything(seed: Optional[int] = None, workers: Optional[bool] = None, verbose: bool = True) -> int:\r\n        r\"\"\"Helper function to seed everything without explicitly importing Lightning.\r\n\r\n        See :func:`~lightning.fabric.utilities.seed.seed_everything` for more details.\r\n\r\n        \"\"\"\r\n        if workers is None:\r\n            workers = True\r\n        return seed_everything(seed=seed, workers=workers, verbose=verbose)", "code_tokens": ["def", "seed_everything", "(", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "workers", ":", "Optional", "[", "bool", "]", "=", "None", ",", "verbose", ":", "bool", "=", "True", ")", "-", ">", "int", ":", "rSTRING", "if", "workers", "is", "None", ":", "workers", "=", "True", "return", "seed_everything", "(", "seed", "=", "seed", ",", "workers", "=", "workers", ",", "verbose", "=", "verbose", ")"], "docstring": "Lightning sets `workers=False` by default to avoid breaking reproducibility, but since this is a new release, we can afford to do it.", "docstring_tokens": ["lightning", "sets", "workers", "false", "by", "default", "to", "avoid", "breaking", "reproducibility", "but", "since", "this", "is", "a", "new", "release", "we", "can", "afford", "to", "do", "it"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\fabric.py", "start_line": 1054, "end_line": 1064, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\wrappers.py", "func_name": "function_16", "original_string": "def __init__(self, optimizer: Optimizer, strategy: Strategy, callbacks: Optional[list[Callable]] = None) -> None:\r\n        \"\"\"FabricOptimizer is a thin wrapper around the :class:`~torch.optim.Optimizer` that delegates the optimizer\r\n        step calls to the strategy.\r\n\r\n        The underlying wrapped optimizer object can be accessed via the property :attr:`optimizer`.\r\n\r\n        Args:\r\n            optimizer: The optimizer to wrap\r\n            strategy: Reference to the strategy for handling the optimizer step\r\n\r\n        \"\"\"\r\n        self._optimizer = optimizer\r\n        self._strategy = strategy\r\n        self._callbacks = callbacks or []\r\n        self.__class__ = type(\"Fabric\" + optimizer.__class__.__name__, (self.__class__, optimizer.__class__), {})", "language": "python", "code": "def __init__(self, optimizer: Optimizer, strategy: Strategy, callbacks: Optional[list[Callable]] = None) -> None:\r\n        \"\"\"FabricOptimizer is a thin wrapper around the :class:`~torch.optim.Optimizer` that delegates the optimizer\r\n        step calls to the strategy.\r\n\r\n        The underlying wrapped optimizer object can be accessed via the property :attr:`optimizer`.\r\n\r\n        Args:\r\n            optimizer: The optimizer to wrap\r\n            strategy: Reference to the strategy for handling the optimizer step\r\n\r\n        \"\"\"\r\n        self._optimizer = optimizer\r\n        self._strategy = strategy\r\n        self._callbacks = callbacks or []\r\n        self.__class__ = type(\"Fabric\" + optimizer.__class__.__name__, (self.__class__, optimizer.__class__), {})", "code_tokens": ["def", "__init__", "(", "self", ",", "optimizer", ":", "Optimizer", ",", "strategy", ":", "Strategy", ",", "callbacks", ":", "Optional", "[", "list", "[", "Callable", "]", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "self", ".", "_optimizer", "=", "optimizer", "self", ".", "_strategy", "=", "strategy", "self", ".", "_callbacks", "=", "callbacks", "or", "[", "]", "self", ".", "__class__", "=", "type", "(", "STRING", "+", "optimizer", ".", "__class__", ".", "__name__", ",", "(", "self", ".", "__class__", ",", "optimizer", ".", "__class__", ")", ",", "{", "}", ")"], "docstring": "imitate the class of the wrapped object to make isinstance checks work", "docstring_tokens": ["imitate", "the", "class", "of", "the", "wrapped", "object", "to", "make", "isinstance", "checks", "work"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\wrappers.py", "start_line": 52, "end_line": 67, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\wrappers.py", "func_name": "function_17", "original_string": "def _capture_compile_kwargs(compile_fn: Callable) -> Callable:\r\n    \"\"\"Wraps the ``torch.compile`` function and captures the compile arguments.\r\n\r\n    We extract the compile arguments so that we can reapply ``torch.compile`` in ``Fabric.setup()`` with the\r\n    same arguments as the user passed to the original call. The arguments get stored in a dictionary\r\n    ``_compile_kwargs`` on the returned compiled module.\r\n\r\n    \"\"\"\r\n\r\n    @wraps(compile_fn)\r\n    def _capture(*args: Any, **kwargs: Any) -> Any:\r\n        if not args or not isinstance(args[0], nn.Module):\r\n            return compile_fn(*args, **kwargs)\r\n\r\n        model = args[0]\r\n        compiled_model = compile_fn(model, **kwargs)\r\n        compiled_model._compile_kwargs = deepcopy(kwargs)\r\n        return compiled_model\r\n\r\n    return _capture", "language": "python", "code": "def _capture_compile_kwargs(compile_fn: Callable) -> Callable:\r\n    \"\"\"Wraps the ``torch.compile`` function and captures the compile arguments.\r\n\r\n    We extract the compile arguments so that we can reapply ``torch.compile`` in ``Fabric.setup()`` with the\r\n    same arguments as the user passed to the original call. The arguments get stored in a dictionary\r\n    ``_compile_kwargs`` on the returned compiled module.\r\n\r\n    \"\"\"\r\n\r\n    @wraps(compile_fn)\r\n    def _capture(*args: Any, **kwargs: Any) -> Any:\r\n        if not args or not isinstance(args[0], nn.Module):\r\n            return compile_fn(*args, **kwargs)\r\n\r\n        model = args[0]\r\n        compiled_model = compile_fn(model, **kwargs)\r\n        compiled_model._compile_kwargs = deepcopy(kwargs)\r\n        return compiled_model\r\n\r\n    return _capture", "code_tokens": ["def", "_capture_compile_kwargs", "(", "compile_fn", ":", "Callable", ")", "-", ">", "Callable", ":", "STRING", "@", "wraps", "(", "compile_fn", ")", "def", "_capture", "(", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "if", "not", "args", "or", "not", "isinstance", "(", "args", "[", "0", "]", ",", "nn", ".", "Module", ")", ":", "return", "compile_fn", "(", "*", "args", ",", "*", "*", "kwargs", ")", "model", "=", "args", "[", "0", "]", "compiled_model", "=", "compile_fn", "(", "model", ",", "*", "*", "kwargs", ")", "compiled_model", ".", "_compile_kwargs", "=", "deepcopy", "(", "kwargs", ")", "return", "compiled_model", "return", "_capture"], "docstring": "either torch.compile is being applied as a decorator or we're compiling something else", "docstring_tokens": ["either", "torch", "compile", "is", "being", "applied", "as", "a", "decorator", "or", "we", "re", "compiling", "something", "else"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\wrappers.py", "start_line": 390, "end_line": 412, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\accelerators\\cuda.py", "func_name": "function_18", "original_string": "def find_usable_cuda_devices(num_devices: int = -1) -> list[int]:\r\n    \"\"\"Returns a list of all available and usable CUDA GPU devices.\r\n\r\n    A GPU is considered usable if we can successfully move a tensor to the device, and this is what this function\r\n    tests for each GPU on the system until the target number of usable devices is found.\r\n\r\n    A subset of GPUs on the system might be used by other processes, and if the GPU is configured to operate in\r\n    'exclusive' mode (configurable by the admin), then only one process is allowed to occupy it.\r\n\r\n    Args:\r\n        num_devices: The number of devices you want to request. By default, this function will return as many as there\r\n            are usable CUDA GPU devices available.\r\n\r\n    Warning:\r\n        If multiple processes call this function at the same time, there can be race conditions in the case where\r\n        both processes determine that the device is unoccupied, leading into one of them crashing later on.\r\n\r\n    \"\"\"\r\n    if num_devices == 0:\r\n        return []\r\n    visible_devices = _get_all_visible_cuda_devices()\r\n    if not visible_devices:\r\n        raise ValueError(\r\n            f\"You requested to find {num_devices} devices but there are no visible CUDA devices on this machine.\"\r\n        )\r\n    if num_devices > len(visible_devices):\r\n        raise ValueError(\r\n            f\"You requested to find {num_devices} devices but this machine only has {len(visible_devices)} GPUs.\"\r\n        )\r\n\r\n    available_devices = []\r\n    unavailable_devices = []\r\n\r\n    for gpu_idx in visible_devices:\r\n        try:\r\n            torch.tensor(0, device=torch.device(\"cuda\", gpu_idx))\r\n        except RuntimeError:\r\n            unavailable_devices.append(gpu_idx)\r\n            continue\r\n\r\n        available_devices.append(gpu_idx)\r\n        if len(available_devices) == num_devices:\r\n            break\r\n\r\n    if num_devices != -1 and len(available_devices) != num_devices:\r\n        raise RuntimeError(\r\n            f\"You requested to find {num_devices} devices but only {len(available_devices)} are currently available.\"\r\n            f\" The devices {unavailable_devices} are occupied by other processes and can't be used at the moment.\"\r\n        )\r\n    return available_devices", "language": "python", "code": "def find_usable_cuda_devices(num_devices: int = -1) -> list[int]:\r\n    \"\"\"Returns a list of all available and usable CUDA GPU devices.\r\n\r\n    A GPU is considered usable if we can successfully move a tensor to the device, and this is what this function\r\n    tests for each GPU on the system until the target number of usable devices is found.\r\n\r\n    A subset of GPUs on the system might be used by other processes, and if the GPU is configured to operate in\r\n    'exclusive' mode (configurable by the admin), then only one process is allowed to occupy it.\r\n\r\n    Args:\r\n        num_devices: The number of devices you want to request. By default, this function will return as many as there\r\n            are usable CUDA GPU devices available.\r\n\r\n    Warning:\r\n        If multiple processes call this function at the same time, there can be race conditions in the case where\r\n        both processes determine that the device is unoccupied, leading into one of them crashing later on.\r\n\r\n    \"\"\"\r\n    if num_devices == 0:\r\n        return []\r\n    visible_devices = _get_all_visible_cuda_devices()\r\n    if not visible_devices:\r\n        raise ValueError(\r\n            f\"You requested to find {num_devices} devices but there are no visible CUDA devices on this machine.\"\r\n        )\r\n    if num_devices > len(visible_devices):\r\n        raise ValueError(\r\n            f\"You requested to find {num_devices} devices but this machine only has {len(visible_devices)} GPUs.\"\r\n        )\r\n\r\n    available_devices = []\r\n    unavailable_devices = []\r\n\r\n    for gpu_idx in visible_devices:\r\n        try:\r\n            torch.tensor(0, device=torch.device(\"cuda\", gpu_idx))\r\n        except RuntimeError:\r\n            unavailable_devices.append(gpu_idx)\r\n            continue\r\n\r\n        available_devices.append(gpu_idx)\r\n        if len(available_devices) == num_devices:\r\n            break\r\n\r\n    if num_devices != -1 and len(available_devices) != num_devices:\r\n        raise RuntimeError(\r\n            f\"You requested to find {num_devices} devices but only {len(available_devices)} are currently available.\"\r\n            f\" The devices {unavailable_devices} are occupied by other processes and can't be used at the moment.\"\r\n        )\r\n    return available_devices", "code_tokens": ["def", "find_usable_cuda_devices", "(", "num_devices", ":", "int", "=", "-", "1", ")", "-", ">", "list", "[", "int", "]", ":", "STRING", "if", "num_devices", "=", "=", "0", ":", "return", "[", "]", "visible_devices", "=", "_get_all_visible_cuda_devices", "(", ")", "if", "not", "visible_devices", ":", "raise", "ValueError", "(", "fSTRING", ")", "if", "num_devices", ">", "len", "(", "visible_devices", ")", ":", "raise", "ValueError", "(", "fSTRING", ")", "available_devices", "=", "[", "]", "unavailable_devices", "=", "[", "]", "for", "gpu_idx", "in", "visible_devices", ":", "try", ":", "torch", ".", "tensor", "(", "0", ",", "device", "=", "torch", ".", "device", "(", "STRING", ",", "gpu_idx", ")", ")", "except", "RuntimeError", ":", "unavailable_devices", ".", "append", "(", "gpu_idx", ")", "continue", "available_devices", ".", "append", "(", "gpu_idx", ")", "if", "len", "(", "available_devices", ")", "=", "=", "num_devices", ":", "break", "if", "num_devices", "!", "=", "-", "1", "and", "len", "(", "available_devices", ")", "!", "=", "num_devices", ":", "raise", "RuntimeError", "(", "fSTRING", "fSTRING", ")", "return", "available_devices"], "docstring": "exit early if we found the right number of GPUs", "docstring_tokens": ["exit", "early", "if", "we", "found", "the", "right", "number", "of", "gpus"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\accelerators\\cuda.py", "start_line": 78, "end_line": 128, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\accelerators\\cuda.py", "func_name": "function_19", "original_string": "def is_cuda_available() -> bool:\r\n    \"\"\"Returns a bool indicating if CUDA is currently available.\"\"\"\r\n    return torch.cuda.is_available()", "language": "python", "code": "def is_cuda_available() -> bool:\r\n    \"\"\"Returns a bool indicating if CUDA is currently available.\"\"\"\r\n    return torch.cuda.is_available()", "code_tokens": ["def", "is_cuda_available", "(", ")", "-", ">", "bool", ":", "STRING", "return", "torch", ".", "cuda", ".", "is_available", "(", ")"], "docstring": "We set `PYTORCH_NVML_BASED_CUDA_CHECK=1` in lightning.fabric.__init__.py", "docstring_tokens": ["we", "set", "pytorch_nvml_based_cuda_check", "1", "in", "lightning", "fabric", "__init__", "py"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\accelerators\\cuda.py", "start_line": 147, "end_line": 150, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\accelerators\\xla.py", "func_name": "function_20", "original_string": "def get_parallel_devices(devices: Union[int, list[int]]) -> list[torch.device]:\r\n        \"\"\"Gets parallel devices for the Accelerator.\"\"\"\r\n        devices = _parse_tpu_devices(devices)\r\n        if isinstance(devices, int):\r\n            return [torch.device(\"xla\", i) for i in range(devices)]\r\n        return [torch.device(\"xla\", devices[0])]\r", "language": "python", "code": "def get_parallel_devices(devices: Union[int, list[int]]) -> list[torch.device]:\r\n        \"\"\"Gets parallel devices for the Accelerator.\"\"\"\r\n        devices = _parse_tpu_devices(devices)\r\n        if isinstance(devices, int):\r\n            return [torch.device(\"xla\", i) for i in range(devices)]\r\n        return [torch.device(\"xla\", devices[0])]\r", "code_tokens": ["def", "get_parallel_devices", "(", "devices", ":", "Union", "[", "int", ",", "list", "[", "int", "]", "]", ")", "-", ">", "list", "[", "torch", ".", "device", "]", ":", "STRING", "devices", "=", "_parse_tpu_devices", "(", "devices", ")", "if", "isinstance", "(", "devices", ",", "int", ")", ":", "return", "[", "torch", ".", "device", "(", "STRING", ",", "i", ")", "for", "i", "in", "range", "(", "devices", ")", "]", "return", "[", "torch", ".", "device", "(", "STRING", ",", "devices", "[", "0", "]", ")", "]"], "docstring": "list of devices is not supported, just a specific index, fine to access [0]", "docstring_tokens": ["list", "of", "devices", "is", "not", "supported", "just", "a", "specific", "index", "fine", "to", "access", "0"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\accelerators\\xla.py", "start_line": 55, "end_line": 64, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\loggers\\csv_logs.py", "func_name": "function_21", "original_string": "def log_dir(self) -> str:\r\n        \"\"\"The log directory for this run.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        return os.path.join(self._root_dir, self.name, version)", "language": "python", "code": "def log_dir(self) -> str:\r\n        \"\"\"The log directory for this run.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        return os.path.join(self._root_dir, self.name, version)", "code_tokens": ["def", "log_dir", "(", "self", ")", "-", ">", "str", ":", "STRING", "version", "=", "self", ".", "version", "if", "isinstance", "(", "self", ".", "version", ",", "str", ")", "else", "fSTRING", "return", "os", ".", "path", ".", "join", "(", "self", ".", "_root_dir", ",", "self", ".", "name", ",", "version", ")"], "docstring": "create a pseudo standard path", "docstring_tokens": ["create", "a", "pseudo", "standard", "path"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\loggers\\csv_logs.py", "start_line": 110, "end_line": 119, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\loggers\\csv_logs.py", "func_name": "function_22", "original_string": "def save(self) -> None:\r\n        \"\"\"Save recorded metrics into files.\"\"\"\r\n        if not self.metrics:\r\n            return\r\n\r\n        new_keys = self._record_new_keys()\r\n        file_exists = self._fs.isfile(self.metrics_file_path)\r\n\r\n        if new_keys and file_exists:\r\n            self._rewrite_with_new_header(self.metrics_keys)\r\n\r\n        with self._fs.open(self.metrics_file_path, mode=(\"a\" if file_exists else \"w\"), newline=\"\") as file:\r\n            writer = csv.DictWriter(file, fieldnames=self.metrics_keys)\r\n            if not file_exists:\r\n                writer.writeheader()\r\n            writer.writerows(self.metrics)\r\n\r\n        self.metrics = []  # reset\r", "language": "python", "code": "def save(self) -> None:\r\n        \"\"\"Save recorded metrics into files.\"\"\"\r\n        if not self.metrics:\r\n            return\r\n\r\n        new_keys = self._record_new_keys()\r\n        file_exists = self._fs.isfile(self.metrics_file_path)\r\n\r\n        if new_keys and file_exists:\r\n            self._rewrite_with_new_header(self.metrics_keys)\r\n\r\n        with self._fs.open(self.metrics_file_path, mode=(\"a\" if file_exists else \"w\"), newline=\"\") as file:\r\n            writer = csv.DictWriter(file, fieldnames=self.metrics_keys)\r\n            if not file_exists:\r\n                writer.writeheader()\r\n            writer.writerows(self.metrics)\r\n\r\n        self.metrics = []  # reset\r", "code_tokens": ["def", "save", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "metrics", ":", "return", "new_keys", "=", "self", ".", "_record_new_keys", "(", ")", "file_exists", "=", "self", ".", "_fs", ".", "isfile", "(", "self", ".", "metrics_file_path", ")", "if", "new_keys", "and", "file_exists", ":", "self", ".", "_rewrite_with_new_header", "(", "self", ".", "metrics_keys", ")", "with", "self", ".", "_fs", ".", "open", "(", "self", ".", "metrics_file_path", ",", "mode", "=", "(", "STRING", "if", "file_exists", "else", "STRING", ")", ",", "newline", "=", "STRING", ")", "as", "file", ":", "writer", "=", "csv", ".", "DictWriter", "(", "file", ",", "fieldnames", "=", "self", ".", "metrics_keys", ")", "if", "not", "file_exists", ":", "writer", ".", "writeheader", "(", ")", "writer", ".", "writerows", "(", "self", ".", "metrics", ")", "self", ".", "metrics", "=", "[", "]", "#", "reset"], "docstring": "we need to re-write the file if the keys (header) change only write the header if we're writing a fresh file", "docstring_tokens": ["we", "need", "to", "re", "write", "the", "file", "if", "the", "keys", "header", "change", "only", "write", "the", "header", "if", "we", "re", "writing", "a", "fresh", "file"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\loggers\\csv_logs.py", "start_line": 227, "end_line": 246, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\loggers\\tensorboard.py", "func_name": "function_23", "original_string": "def log_hyperparams(\r\n        self,\r\n        params: Union[dict[str, Any], Namespace],\r\n        metrics: Optional[dict[str, Any]] = None,\r\n        step: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Record hyperparameters. TensorBoard logs with and without saved hyperparameters are incompatible, the\r\n        hyperparameters are then not displayed in the TensorBoard. Please delete or move the previously saved logs to\r\n        display the new ones with hyperparameters.\r\n\r\n        Args:\r\n            params: A dictionary-like container with the hyperparameters\r\n            metrics: Dictionary with metric names as keys and measured quantities as values\r\n            step: Optional global step number for the logged metrics\r\n\r\n        \"\"\"\r\n        params = _convert_params(params)\r\n\r\n        params = _flatten_dict(params)\r\n        params = self._sanitize_params(params)\r\n\r\n        if metrics is None:\r\n            if self._default_hp_metric:\r\n                metrics = {\"hp_metric\": -1}\r\n        elif not isinstance(metrics, dict):\r\n            metrics = {\"hp_metric\": metrics}\r\n\r\n        if metrics:\r\n            self.log_metrics(metrics, step)\r\n\r\n            if _TENSORBOARD_AVAILABLE:\r\n                from torch.utils.tensorboard.summary import hparams\r\n            else:\r\n                from tensorboardX.summary import hparams  # type: ignore[no-redef]\r\n\r\n            exp, ssi, sei = hparams(params, metrics)\r\n            writer = self.experiment._get_file_writer()\r\n            writer.add_summary(exp, step)\r\n            writer.add_summary(ssi, step)\r\n            writer.add_summary(sei, step)", "language": "python", "code": "def log_hyperparams(\r\n        self,\r\n        params: Union[dict[str, Any], Namespace],\r\n        metrics: Optional[dict[str, Any]] = None,\r\n        step: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Record hyperparameters. TensorBoard logs with and without saved hyperparameters are incompatible, the\r\n        hyperparameters are then not displayed in the TensorBoard. Please delete or move the previously saved logs to\r\n        display the new ones with hyperparameters.\r\n\r\n        Args:\r\n            params: A dictionary-like container with the hyperparameters\r\n            metrics: Dictionary with metric names as keys and measured quantities as values\r\n            step: Optional global step number for the logged metrics\r\n\r\n        \"\"\"\r\n        params = _convert_params(params)\r\n\r\n        params = _flatten_dict(params)\r\n        params = self._sanitize_params(params)\r\n\r\n        if metrics is None:\r\n            if self._default_hp_metric:\r\n                metrics = {\"hp_metric\": -1}\r\n        elif not isinstance(metrics, dict):\r\n            metrics = {\"hp_metric\": metrics}\r\n\r\n        if metrics:\r\n            self.log_metrics(metrics, step)\r\n\r\n            if _TENSORBOARD_AVAILABLE:\r\n                from torch.utils.tensorboard.summary import hparams\r\n            else:\r\n                from tensorboardX.summary import hparams  # type: ignore[no-redef]\r\n\r\n            exp, ssi, sei = hparams(params, metrics)\r\n            writer = self.experiment._get_file_writer()\r\n            writer.add_summary(exp, step)\r\n            writer.add_summary(ssi, step)\r\n            writer.add_summary(sei, step)", "code_tokens": ["def", "log_hyperparams", "(", "self", ",", "params", ":", "Union", "[", "dict", "[", "str", ",", "Any", "]", ",", "Namespace", "]", ",", "metrics", ":", "Optional", "[", "dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "step", ":", "Optional", "[", "int", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "params", "=", "_convert_params", "(", "params", ")", "params", "=", "_flatten_dict", "(", "params", ")", "params", "=", "self", ".", "_sanitize_params", "(", "params", ")", "if", "metrics", "is", "None", ":", "if", "self", ".", "_default_hp_metric", ":", "metrics", "=", "{", "STRING", ":", "-", "1", "}", "elif", "not", "isinstance", "(", "metrics", ",", "dict", ")", ":", "metrics", "=", "{", "STRING", ":", "metrics", "}", "if", "metrics", ":", "self", ".", "log_metrics", "(", "metrics", ",", "step", ")", "if", "_TENSORBOARD_AVAILABLE", ":", "from", "torch", ".", "utils", ".", "tensorboard", ".", "summary", "import", "hparams", "else", ":", "from", "tensorboardX", ".", "summary", "import", "hparams", "#", "type", ":", "ignore", "[", "no", "-", "redef", "]", "exp", ",", "ssi", ",", "sei", "=", "hparams", "(", "params", ",", "metrics", ")", "writer", "=", "self", ".", "experiment", ".", "_get_file_writer", "(", ")", "writer", ".", "add_summary", "(", "exp", ",", "step", ")", "writer", ".", "add_summary", "(", "ssi", ",", "step", ")", "writer", ".", "add_summary", "(", "sei", ",", "step", ")"], "docstring": "format params into the suitable for tensorboard", "docstring_tokens": ["format", "params", "into", "the", "suitable", "for", "tensorboard"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\loggers\\tensorboard.py", "start_line": 221, "end_line": 261, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\environments\\lsf.py", "func_name": "function_24", "original_string": "def _read_hosts() -> list[str]:\r\n        \"\"\"Read compute hosts that are a part of the compute job.\r\n\r\n        LSF uses the Job Step Manager (JSM) to manage job steps. Job steps are executed by the JSM from \"launch\" nodes.\r\n        Each job is assigned a launch node. This launch node will be the first node in the list contained in\r\n        ``LSB_DJOB_RANKFILE``.\r\n\r\n        \"\"\"\r\n        var = \"LSB_DJOB_RANKFILE\"\r\n        rankfile = os.environ.get(var)\r\n        if rankfile is None:\r\n            raise ValueError(\"Did not find the environment variable `LSB_DJOB_RANKFILE`\")\r\n        if not rankfile:\r\n            raise ValueError(\"The environment variable `LSB_DJOB_RANKFILE` is empty\")\r\n\r\n        fs = get_filesystem(rankfile)\r\n        with fs.open(rankfile, \"r\") as f:\r\n            ret = [line.strip() for line in f]\r\n        return ret[1:]", "language": "python", "code": "def _read_hosts() -> list[str]:\r\n        \"\"\"Read compute hosts that are a part of the compute job.\r\n\r\n        LSF uses the Job Step Manager (JSM) to manage job steps. Job steps are executed by the JSM from \"launch\" nodes.\r\n        Each job is assigned a launch node. This launch node will be the first node in the list contained in\r\n        ``LSB_DJOB_RANKFILE``.\r\n\r\n        \"\"\"\r\n        var = \"LSB_DJOB_RANKFILE\"\r\n        rankfile = os.environ.get(var)\r\n        if rankfile is None:\r\n            raise ValueError(\"Did not find the environment variable `LSB_DJOB_RANKFILE`\")\r\n        if not rankfile:\r\n            raise ValueError(\"The environment variable `LSB_DJOB_RANKFILE` is empty\")\r\n\r\n        fs = get_filesystem(rankfile)\r\n        with fs.open(rankfile, \"r\") as f:\r\n            ret = [line.strip() for line in f]\r\n        return ret[1:]", "code_tokens": ["def", "_read_hosts", "(", ")", "-", ">", "list", "[", "str", "]", ":", "STRING", "var", "=", "STRING", "rankfile", "=", "os", ".", "environ", ".", "get", "(", "var", ")", "if", "rankfile", "is", "None", ":", "raise", "ValueError", "(", "STRING", ")", "if", "not", "rankfile", ":", "raise", "ValueError", "(", "STRING", ")", "fs", "=", "get_filesystem", "(", "rankfile", ")", "with", "fs", ".", "open", "(", "rankfile", ",", "STRING", ")", "as", "f", ":", "ret", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "return", "ret", "[", "1", ":", "]"], "docstring": "remove the launch node (i.e. the first node in LSB_DJOB_RANKFILE) from the list", "docstring_tokens": ["remove", "the", "launch", "node", "i", "e", "the", "first", "node", "in", "lsb_djob_rankfile", "from", "the", "list"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\environments\\lsf.py", "start_line": 152, "end_line": 171, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\environments\\lsf.py", "func_name": "function_25", "original_string": "def _get_main_port() -> int:\r\n        \"\"\"A helper function for accessing the main port.\r\n\r\n        Uses the LSF job ID so all ranks can compute the main port.\r\n\r\n        \"\"\"\r\n        if \"MASTER_PORT\" in os.environ:\r\n            log.debug(f\"Using externally specified main port: {os.environ['MASTER_PORT']}\")\r\n            return int(os.environ[\"MASTER_PORT\"])\r\n        if \"LSB_JOBID\" in os.environ:\r\n            port = int(os.environ[\"LSB_JOBID\"])\r\n            port = port % 1000 + 10000\r\n            log.debug(f\"calculated LSF main port: {port}\")\r\n            return port\r\n        raise ValueError(\"Could not find job id in environment variable LSB_JOBID\")", "language": "python", "code": "def _get_main_port() -> int:\r\n        \"\"\"A helper function for accessing the main port.\r\n\r\n        Uses the LSF job ID so all ranks can compute the main port.\r\n\r\n        \"\"\"\r\n        if \"MASTER_PORT\" in os.environ:\r\n            log.debug(f\"Using externally specified main port: {os.environ['MASTER_PORT']}\")\r\n            return int(os.environ[\"MASTER_PORT\"])\r\n        if \"LSB_JOBID\" in os.environ:\r\n            port = int(os.environ[\"LSB_JOBID\"])\r\n            port = port % 1000 + 10000\r\n            log.debug(f\"calculated LSF main port: {port}\")\r\n            return port\r\n        raise ValueError(\"Could not find job id in environment variable LSB_JOBID\")", "code_tokens": ["def", "_get_main_port", "(", ")", "-", ">", "int", ":", "STRING", "if", "STRING", "in", "os", ".", "environ", ":", "log", ".", "debug", "(", "fSTRING", ")", "return", "int", "(", "os", ".", "environ", "[", "STRING", "]", ")", "if", "STRING", "in", "os", ".", "environ", ":", "port", "=", "int", "(", "os", ".", "environ", "[", "STRING", "]", ")", "port", "=", "port", "%", "1000", "+", "10000", "log", ".", "debug", "(", "fSTRING", ")", "return", "port", "raise", "ValueError", "(", "STRING", ")"], "docstring": "check for user-specified main port all ports should be in the 10k+ range", "docstring_tokens": ["check", "for", "user", "specified", "main", "port", "all", "ports", "should", "be", "in", "the", "10k", "range"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\environments\\lsf.py", "start_line": 183, "end_line": 199, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\environments\\torchelastic.py", "func_name": "function_26", "original_string": "def detect() -> bool:\r\n        \"\"\"Returns ``True`` if the current process was launched using the torchelastic command.\"\"\"\r\n        return torch.distributed.is_available() and torch.distributed.is_torchelastic_launched()", "language": "python", "code": "def detect() -> bool:\r\n        \"\"\"Returns ``True`` if the current process was launched using the torchelastic command.\"\"\"\r\n        return torch.distributed.is_available() and torch.distributed.is_torchelastic_launched()", "code_tokens": ["def", "detect", "(", ")", "-", ">", "bool", ":", "STRING", "return", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_torchelastic_launched", "(", ")"], "docstring": "if not available (for example on MacOS), `is_torchelastic_launched` is not defined", "docstring_tokens": ["if", "not", "available", "for", "example", "on", "macos", "is_torchelastic_launched", "is", "not", "defined"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\environments\\torchelastic.py", "start_line": 55, "end_line": 58, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\io\\torch_io.py", "func_name": "function_27", "original_string": "def load_checkpoint(\r\n        self, path: _PATH, map_location: Optional[Callable] = lambda storage, loc: storage\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Loads checkpoint using :func:`torch.load`, with additional handling for ``fsspec`` remote loading of files.\r\n\r\n        Args:\r\n            path: Path to checkpoint\r\n            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage\r\n                locations.\r\n\r\n        Returns: The loaded checkpoint.\r\n\r\n        Raises:\r\n            FileNotFoundError: If ``path`` is not found by the ``fsspec`` filesystem\r\n\r\n        \"\"\"\r\n\r\n        fs = get_filesystem(path)\r\n        if not fs.exists(path):\r\n            raise FileNotFoundError(f\"Checkpoint file not found: {path}\")\r\n\r\n        return pl_load(path, map_location=map_location)", "language": "python", "code": "def load_checkpoint(\r\n        self, path: _PATH, map_location: Optional[Callable] = lambda storage, loc: storage\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Loads checkpoint using :func:`torch.load`, with additional handling for ``fsspec`` remote loading of files.\r\n\r\n        Args:\r\n            path: Path to checkpoint\r\n            map_location: a function, :class:`torch.device`, string or a dict specifying how to remap storage\r\n                locations.\r\n\r\n        Returns: The loaded checkpoint.\r\n\r\n        Raises:\r\n            FileNotFoundError: If ``path`` is not found by the ``fsspec`` filesystem\r\n\r\n        \"\"\"\r\n\r\n        fs = get_filesystem(path)\r\n        if not fs.exists(path):\r\n            raise FileNotFoundError(f\"Checkpoint file not found: {path}\")\r\n\r\n        return pl_load(path, map_location=map_location)", "code_tokens": ["def", "load_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "map_location", ":", "Optional", "[", "Callable", "]", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "fs", "=", "get_filesystem", "(", "path", ")", "if", "not", "fs", ".", "exists", "(", "path", ")", ":", "raise", "FileNotFoundError", "(", "fSTRING", ")", "return", "pl_load", "(", "path", ",", "map_location", "=", "map_location", ")"], "docstring": "Try to read the checkpoint at `path`. If not exist, do not restore checkpoint.", "docstring_tokens": ["try", "to", "read", "the", "checkpoint", "at", "path", "if", "not", "exist", "do", "not", "restore", "checkpoint"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\io\\torch_io.py", "start_line": 60, "end_line": 82, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\io\\xla.py", "func_name": "function_28", "original_string": "def save_checkpoint(self, checkpoint: dict[str, Any], path: _PATH, storage_options: Optional[Any] = None) -> None:\r\n        \"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\r\n\r\n        Args:\r\n            checkpoint: dict containing model and trainer state\r\n            path: write-target path\r\n            storage_options: not used in ``XLACheckpointIO.save_checkpoint``\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``storage_options`` arg is passed in\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`Trainer.save_checkpoint(..., storage_options=...)` with `storage_options` arg\"\r\n                f\" is not supported for `{self.__class__.__name__}`. Please implement your custom `CheckpointIO`\"\r\n                \" to define how you'd like to use `storage_options`.\"\r\n            )\r\n        fs = get_filesystem(path)\r\n        fs.makedirs(os.path.dirname(path), exist_ok=True)\r\n        if RequirementCache(\"omegaconf\"):\r\n            from omegaconf import DictConfig, ListConfig, OmegaConf\r\n\r\n            checkpoint = apply_to_collection(checkpoint, (DictConfig, ListConfig), OmegaConf.to_container)\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        cpu_data = xm._maybe_convert_to_cpu(checkpoint, convert=True)\r\n        log.debug(f\"Saving checkpoint: {path}\")\r\n        torch.save(cpu_data, path)", "language": "python", "code": "def save_checkpoint(self, checkpoint: dict[str, Any], path: _PATH, storage_options: Optional[Any] = None) -> None:\r\n        \"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\r\n\r\n        Args:\r\n            checkpoint: dict containing model and trainer state\r\n            path: write-target path\r\n            storage_options: not used in ``XLACheckpointIO.save_checkpoint``\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``storage_options`` arg is passed in\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`Trainer.save_checkpoint(..., storage_options=...)` with `storage_options` arg\"\r\n                f\" is not supported for `{self.__class__.__name__}`. Please implement your custom `CheckpointIO`\"\r\n                \" to define how you'd like to use `storage_options`.\"\r\n            )\r\n        fs = get_filesystem(path)\r\n        fs.makedirs(os.path.dirname(path), exist_ok=True)\r\n        if RequirementCache(\"omegaconf\"):\r\n            from omegaconf import DictConfig, ListConfig, OmegaConf\r\n\r\n            checkpoint = apply_to_collection(checkpoint, (DictConfig, ListConfig), OmegaConf.to_container)\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        cpu_data = xm._maybe_convert_to_cpu(checkpoint, convert=True)\r\n        log.debug(f\"Saving checkpoint: {path}\")\r\n        torch.save(cpu_data, path)", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ",", "path", ":", "_PATH", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "if", "storage_options", "is", "not", "None", ":", "raise", "TypeError", "(", "STRING", "fSTRING", "STRING", ")", "fs", "=", "get_filesystem", "(", "path", ")", "fs", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ",", "exist_ok", "=", "True", ")", "if", "RequirementCache", "(", "STRING", ")", ":", "from", "omegaconf", "import", "DictConfig", ",", "ListConfig", ",", "OmegaConf", "checkpoint", "=", "apply_to_collection", "(", "checkpoint", ",", "(", "DictConfig", ",", "ListConfig", ")", ",", "OmegaConf", ".", "to_container", ")", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "cpu_data", "=", "xm", ".", "_maybe_convert_to_cpu", "(", "checkpoint", ",", "convert", "=", "True", ")", "log", ".", "debug", "(", "fSTRING", ")", "torch", ".", "save", "(", "cpu_data", ",", "path", ")"], "docstring": "workaround for https://github.com/pytorch/xla/issues/2773", "docstring_tokens": ["workaround", "for", "https", "github", "com", "pytorch", "xla", "issues", "2773"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\io\\xla.py", "start_line": 43, "end_line": 73, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\precision\\bitsandbytes.py", "func_name": "function_29", "original_string": "def quantize_(self, weight: Optional[torch.Tensor] = None, device: Optional[torch.device] = None) -> None:\r\n            \"\"\"Inplace quantize.\"\"\"\r\n            if weight is None:\r\n                weight = self.weight.data\r\n            if weight.data.dtype == torch.int8:\r\n                return\r\n            assert isinstance(self.weight, bnb.nn.Int8Params)\r\n            self.weight = self.quantize(self.weight, weight, device)", "language": "python", "code": "def quantize_(self, weight: Optional[torch.Tensor] = None, device: Optional[torch.device] = None) -> None:\r\n            \"\"\"Inplace quantize.\"\"\"\r\n            if weight is None:\r\n                weight = self.weight.data\r\n            if weight.data.dtype == torch.int8:\r\n                return\r\n            assert isinstance(self.weight, bnb.nn.Int8Params)\r\n            self.weight = self.quantize(self.weight, weight, device)", "code_tokens": ["def", "quantize_", "(", "self", ",", "weight", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "if", "weight", "is", "None", ":", "weight", "=", "self", ".", "weight", ".", "data", "if", "weight", ".", "data", ".", "dtype", "=", "=", "torch", ".", "int8", ":", "return", "assert", "isinstance", "(", "self", ".", "weight", ",", "bnb", ".", "nn", ".", "Int8Params", ")", "self", ".", "weight", "=", "self", ".", "quantize", "(", "self", ".", "weight", ",", "weight", ",", "device", ")"], "docstring": "already quantized", "docstring_tokens": ["already", "quantized"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\precision\\bitsandbytes.py", "start_line": 236, "end_line": 244, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\plugins\\precision\\bitsandbytes.py", "func_name": "function_30", "original_string": "def quantize_(self, weight: Optional[torch.Tensor] = None, device: Optional[torch.device] = None) -> None:\r\n            \"\"\"Inplace quantize.\"\"\"\r\n            if weight is None:\r\n                weight = self.weight.data\r\n            if weight.data.dtype == torch.uint8:\r\n                return\r\n            assert isinstance(self.weight, bnb.nn.Params4bit)\r\n            self.weight = self.quantize(self.weight, weight, device)\r\n            self.weight.bnb_quantized = True", "language": "python", "code": "def quantize_(self, weight: Optional[torch.Tensor] = None, device: Optional[torch.device] = None) -> None:\r\n            \"\"\"Inplace quantize.\"\"\"\r\n            if weight is None:\r\n                weight = self.weight.data\r\n            if weight.data.dtype == torch.uint8:\r\n                return\r\n            assert isinstance(self.weight, bnb.nn.Params4bit)\r\n            self.weight = self.quantize(self.weight, weight, device)\r\n            self.weight.bnb_quantized = True", "code_tokens": ["def", "quantize_", "(", "self", ",", "weight", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "if", "weight", "is", "None", ":", "weight", "=", "self", ".", "weight", ".", "data", "if", "weight", ".", "data", ".", "dtype", "=", "=", "torch", ".", "uint8", ":", "return", "assert", "isinstance", "(", "self", ".", "weight", ",", "bnb", ".", "nn", ".", "Params4bit", ")", "self", ".", "weight", "=", "self", ".", "quantize", "(", "self", ".", "weight", ",", "weight", ",", "device", ")", "self", ".", "weight", ".", "bnb_quantized", "=", "True"], "docstring": "already quantized", "docstring_tokens": ["already", "quantized"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\plugins\\precision\\bitsandbytes.py", "start_line": 323, "end_line": 332, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\ddp.py", "func_name": "function_31", "original_string": "def setup_module(self, module: Module) -> DistributedDataParallel:\r\n        \"\"\"Wraps the model into a :class:`~torch.nn.parallel.distributed.DistributedDataParallel` module.\"\"\"\r\n        device_ids = self._determine_ddp_device_ids()\r\n        ctx = torch.cuda.stream(torch.cuda.Stream()) if device_ids is not None else nullcontext()\r\n        with ctx:\r\n            return DistributedDataParallel(module=module, device_ids=device_ids, **self._ddp_kwargs)", "language": "python", "code": "def setup_module(self, module: Module) -> DistributedDataParallel:\r\n        \"\"\"Wraps the model into a :class:`~torch.nn.parallel.distributed.DistributedDataParallel` module.\"\"\"\r\n        device_ids = self._determine_ddp_device_ids()\r\n        ctx = torch.cuda.stream(torch.cuda.Stream()) if device_ids is not None else nullcontext()\r\n        with ctx:\r\n            return DistributedDataParallel(module=module, device_ids=device_ids, **self._ddp_kwargs)", "code_tokens": ["def", "setup_module", "(", "self", ",", "module", ":", "Module", ")", "-", ">", "DistributedDataParallel", ":", "STRING", "device_ids", "=", "self", ".", "_determine_ddp_device_ids", "(", ")", "ctx", "=", "torch", ".", "cuda", ".", "stream", "(", "torch", ".", "cuda", ".", "Stream", "(", ")", ")", "if", "device_ids", "is", "not", "None", "else", "nullcontext", "(", ")", "with", "ctx", ":", "return", "DistributedDataParallel", "(", "module", "=", "module", ",", "device_ids", "=", "device_ids", ",", "*", "*", "self", ".", "_ddp_kwargs", ")"], "docstring": "https://pytorch.org/docs/stable/notes/cuda.html#id5", "docstring_tokens": ["https", "pytorch", "org", "docs", "stable", "notes", "cuda", "html", "id5"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\ddp.py", "start_line": 123, "end_line": 129, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "func_name": "function_32", "original_string": "def __init__(\r\n        self,\r\n        accelerator: Optional[Accelerator] = None,\r\n        zero_optimization: bool = True,\r\n        stage: int = 2,\r\n        remote_device: Optional[str] = None,\r\n        offload_optimizer: bool = False,\r\n        offload_parameters: bool = False,\r\n        offload_params_device: str = \"cpu\",\r\n        nvme_path: str = \"/local_nvme\",\r\n        params_buffer_count: int = 5,\r\n        params_buffer_size: int = 100_000_000,\r\n        max_in_cpu: int = 1_000_000_000,\r\n        offload_optimizer_device: str = \"cpu\",\r\n        optimizer_buffer_count: int = 4,\r\n        block_size: int = 1048576,\r\n        queue_depth: int = 8,\r\n        single_submit: bool = False,\r\n        overlap_events: bool = True,\r\n        thread_count: int = 1,\r\n        pin_memory: bool = False,\r\n        sub_group_size: int = 1_000_000_000_000,\r\n        contiguous_gradients: bool = True,\r\n        overlap_comm: bool = True,\r\n        allgather_partitions: bool = True,\r\n        reduce_scatter: bool = True,\r\n        allgather_bucket_size: int = 200_000_000,\r\n        reduce_bucket_size: int = 200_000_000,\r\n        zero_allow_untested_optimizer: bool = True,\r\n        logging_batch_size_per_gpu: Optional[int] = None,\r\n        config: Optional[Union[_PATH, dict[str, Any]]] = None,\r\n        logging_level: int = logging.WARN,\r\n        parallel_devices: Optional[list[torch.device]] = None,\r\n        cluster_environment: Optional[ClusterEnvironment] = None,\r\n        loss_scale: float = 0,\r\n        initial_scale_power: int = 16,\r\n        loss_scale_window: int = 1000,\r\n        hysteresis: int = 2,\r\n        min_loss_scale: int = 1,\r\n        partition_activations: bool = False,\r\n        cpu_checkpointing: bool = False,\r\n        contiguous_memory_optimization: bool = False,\r\n        synchronize_checkpoint_boundary: bool = False,\r\n        load_full_weights: bool = False,\r\n        precision: Optional[Precision] = None,\r\n        process_group_backend: Optional[str] = None,\r\n        timeout: Optional[timedelta] = default_pg_timeout,\r\n        exclude_frozen_parameters: bool = False,\r\n    ) -> None:\r\n        \"\"\"Provides capabilities to run training using the DeepSpeed library, with training optimizations for large\r\n        billion parameter models. `For more information: https://pytorch-\r\n        lightning.readthedocs.io/en/stable/advanced/model_parallel.html#deepspeed`.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        Defaults have been set to enable ZeRO-Offload and some have been taken from the link below.\r\n        These defaults have been set generally, but may require tuning for optimum performance based on your model size.\r\n        `For more information: https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training`.\r\n\r\n        Arguments:\r\n\r\n            zero_optimization: Enable ZeRO optimization. This is compatible with either ``precision=\"16-mixed\"`` or\r\n                ``precision=\"bf16-mixed\"``.\r\n\r\n            stage: Different stages of the ZeRO Optimizer. 0 is disabled,\r\n                1 is optimizer state partitioning, 2 is optimizer+gradient state partitioning,\r\n                3 is optimizer+gradient_parameter partitioning using the infinity engine.\r\n\r\n            remote_device: Device to instantiate the model on initially (``cpu`` or ``nvme``). Defaults to GPU.\r\n\r\n            offload_optimizer: Enable offloading optimizer memory and computation to CPU or NVMe\r\n                based on ``offload_optimizer_device``.\r\n\r\n            offload_parameters: When using ZeRO Stage 3, Enable offloading parameter memory and computation\r\n                to CPU or NVMe based on ``offload_params_device``.\r\n\r\n            offload_params_device: When offloading parameters choose the device to offload to, ``cpu`` or ``nvme``.\r\n\r\n            offload_optimizer_device: When offloading optimizer state choose the device to offload to,\r\n                ``cpu`` or ``nvme``.\r\n\r\n            params_buffer_count: Number of buffers in buffer pool for\r\n                parameter offloading when ``offload_params_device`` is ``nvme``.\r\n\r\n            params_buffer_size: Size of buffers in buffer pool for parameter offloading\r\n                when ``offload_params_device`` is ``nvme``.\r\n\r\n            max_in_cpu: Number of parameter elements to maintain in CPU memory when offloading to NVMe is enabled.\r\n\r\n            nvme_path: Filesystem path for NVMe device for optimizer/parameter state offloading.\r\n\r\n            optimizer_buffer_count: Number of buffers in buffer pool for optimizer state offloading\r\n                when ``offload_optimizer_device`` is set to ``nvme``.\r\n                This should be at least the number of states maintained per parameter by the optimizer.\r\n                For example, Adam optimizer has 4 states (parameter, gradient, momentum, and variance).\r\n\r\n            block_size: When using NVMe Offloading, the I/O block size in bytes.\r\n\r\n            queue_depth: When using NVMe Offloading, the I/O queue depth.\r\n\r\n            single_submit: When using NVMe Offloading,\r\n                submit requests to storage device as multiple individual requests,\r\n                as opposed to one block of requests.\r\n\r\n            overlap_events: When using NVMe Offloading,\r\n                submit requests to storage device in an overlapped fashion\r\n                without waiting for completion of earlier requests.\r\n\r\n            thread_count: When using NVMe Offloading,\r\n                Intra-request parallelism for each read/write submitted by a user thread.\r\n\r\n            pin_memory: When using ZeRO stage 3, pin optimizer state memory on CPU.\r\n                This could boost throughput at the cost of extra memory overhead.\r\n\r\n            sub_group_size: When using ZeRO stage 3, defines the number of parameters\r\n                within a sub group to offload at a time.\r\n                Smaller numbers require more communication, but improve memory efficiency.\r\n\r\n            contiguous_gradients: Copies gradients to a continuous buffer as they are produced.\r\n                Avoids memory fragmentation during backwards. Useful when training large models.\r\n\r\n            overlap_comm: Overlap the reduction (synchronization) of gradients with the backwards computation.\r\n                This is a speed optimization when training across multiple GPUs/machines.\r\n\r\n            allgather_partitions: All gather updated parameters at the end of training step,\r\n                instead of using a series of broadcast collectives.\r\n\r\n            reduce_scatter: Use reduce/scatter instead of allreduce to average gradients.\r\n\r\n            allgather_bucket_size: Number of elements to allgather at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            reduce_bucket_size: Number of elements to reduce at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            zero_allow_untested_optimizer: Allow untested optimizers to be used with ZeRO. Currently only Adam is a\r\n                DeepSpeed supported optimizer when using ZeRO.\r\n\r\n            logging_batch_size_per_gpu: Config used in DeepSpeed to calculate verbose timing for logging\r\n                on a per sample per second basis (only displayed if logging=logging.INFO).\r\n                To obtain accurate logs when using datasets that do not support batch samplers,\r\n                set this to the actual per gpu batch size.\r\n\r\n            config: Pass in a deepspeed formatted config dict,\r\n                or path to a deepspeed config: https://www.deepspeed.ai/docs/config-json.\r\n                All defaults will be ignored if a config is passed in.\r\n\r\n            logging_level: Set logging level for deepspeed.\r\n\r\n            loss_scale: Loss scaling value for FP16 training.\r\n                0.0 results in dynamic loss scaling, otherwise static.\r\n\r\n            initial_scale_power: Power of the initial dynamic loss scale value. Loss scale is computed\r\n                by ``2^initial_scale_power``.\r\n\r\n            loss_scale_window: Window in which to raise/lower the dynamic FP16 loss scaling value.\r\n\r\n            hysteresis: FP16 Delay shift in Dynamic Loss scaling.\r\n\r\n            min_loss_scale: The minimum FP16 dynamic loss scaling value.\r\n\r\n            partition_activations: Enables partition activation when used with ZeRO stage 3 and model parallelism.\r\n                Still requires you to wrap your forward functions in deepspeed.checkpointing.checkpoint.\r\n                See `deepspeed tutorial\r\n                <https://www.deepspeed.ai/tutorials/megatron/#deepspeed-activation-checkpoints-optional>`_.\r\n\r\n            cpu_checkpointing: Offloads partitioned activations to CPU if ``partition_activations`` is enabled.\r\n\r\n            contiguous_memory_optimization: Copies partitioned activations so that they are contiguous in memory.\r\n                Not supported by all models.\r\n\r\n            synchronize_checkpoint_boundary: Insert :func:`torch.cuda.synchronize` at each checkpoint boundary.\r\n\r\n            load_full_weights: True when loading a single checkpoint file containing the model state dict\r\n                when using ZeRO Stage 3. This differs from the DeepSpeed checkpoint which contains shards\r\n                per worker.\r\n\r\n            exclude_frozen_parameters: Exclude frozen parameters when saving checkpoints.\r\n\r\n        \"\"\"\r\n        if not _DEEPSPEED_AVAILABLE:\r\n            raise ImportError(\r\n                \"To use the `DeepSpeedStrategy`, you must have DeepSpeed installed.\"\r\n                \" Install it by running `pip install -U deepspeed`.\"\r\n            )\r\n\r\n        if _TORCH_GREATER_EQUAL_2_6 and not _DEEPSPEED_GREATER_EQUAL_0_16:\r\n            import deepspeed\r\n\r\n            deepspeed_version = deepspeed.__version__\r\n\r\n            raise ImportError(\r\n                f\"PyTorch >= 2.6 requires DeepSpeed >= 0.16.0. \"\r\n                f\"Detected DeepSpeed version: {deepspeed_version}. \"\r\n                \"Please upgrade by running `pip install -U 'deepspeed>=0.16.0'`.\"\r\n            )\r\n\r\n        super().__init__(\r\n            accelerator=accelerator,\r\n            parallel_devices=parallel_devices,\r\n            cluster_environment=cluster_environment,\r\n            precision=precision,\r\n            process_group_backend=process_group_backend,\r\n        )\r\n        self._backward_sync_control = None  # DeepSpeed handles gradient accumulation internally\r\n        self._timeout: Optional[timedelta] = timeout\r\n\r\n        self.config = self._load_config(config)\r\n        if self.config is None:\r\n            self.config = self._create_default_config(\r\n                zero_optimization,\r\n                zero_allow_untested_optimizer,\r\n                logging_batch_size_per_gpu,\r\n                offload_optimizer=offload_optimizer,\r\n                offload_parameters=offload_parameters,\r\n                nvme_path=nvme_path,\r\n                offload_params_device=offload_params_device,\r\n                params_buffer_count=params_buffer_count,\r\n                params_buffer_size=params_buffer_size,\r\n                max_in_cpu=max_in_cpu,\r\n                pin_memory=pin_memory,\r\n                offload_optimizer_device=offload_optimizer_device,\r\n                optimizer_buffer_count=optimizer_buffer_count,\r\n                block_size=block_size,\r\n                queue_depth=queue_depth,\r\n                single_submit=single_submit,\r\n                overlap_events=overlap_events,\r\n                thread_count=thread_count,\r\n                partition_activations=partition_activations,\r\n                cpu_checkpointing=cpu_checkpointing,\r\n                contiguous_memory_optimization=contiguous_memory_optimization,\r\n                synchronize_checkpoint_boundary=synchronize_checkpoint_boundary,\r\n                stage=stage,\r\n                contiguous_gradients=contiguous_gradients,\r\n                overlap_comm=overlap_comm,\r\n                allgather_partitions=allgather_partitions,\r\n                reduce_scatter=reduce_scatter,\r\n                allgather_bucket_size=allgather_bucket_size,\r\n                reduce_bucket_size=reduce_bucket_size,\r\n                sub_group_size=sub_group_size,\r\n            )\r\n\r\n        import deepspeed\r\n\r\n        self._config_initialized = False\r\n        deepspeed.utils.logging.logger.setLevel(logging_level)\r\n\r\n        self.remote_device = remote_device\r\n        self.load_full_weights = load_full_weights\r\n        self.exclude_frozen_parameters = exclude_frozen_parameters\r\n\r\n        self.loss_scale = loss_scale\r\n        self.initial_scale_power = initial_scale_power\r\n        self.loss_scale_window = loss_scale_window\r\n        self.hysteresis = hysteresis\r\n        self.min_loss_scale = min_loss_scale\r\n\r\n        self._deepspeed_engine: Optional[DeepSpeedEngine] = None", "language": "python", "code": "def __init__(\r\n        self,\r\n        accelerator: Optional[Accelerator] = None,\r\n        zero_optimization: bool = True,\r\n        stage: int = 2,\r\n        remote_device: Optional[str] = None,\r\n        offload_optimizer: bool = False,\r\n        offload_parameters: bool = False,\r\n        offload_params_device: str = \"cpu\",\r\n        nvme_path: str = \"/local_nvme\",\r\n        params_buffer_count: int = 5,\r\n        params_buffer_size: int = 100_000_000,\r\n        max_in_cpu: int = 1_000_000_000,\r\n        offload_optimizer_device: str = \"cpu\",\r\n        optimizer_buffer_count: int = 4,\r\n        block_size: int = 1048576,\r\n        queue_depth: int = 8,\r\n        single_submit: bool = False,\r\n        overlap_events: bool = True,\r\n        thread_count: int = 1,\r\n        pin_memory: bool = False,\r\n        sub_group_size: int = 1_000_000_000_000,\r\n        contiguous_gradients: bool = True,\r\n        overlap_comm: bool = True,\r\n        allgather_partitions: bool = True,\r\n        reduce_scatter: bool = True,\r\n        allgather_bucket_size: int = 200_000_000,\r\n        reduce_bucket_size: int = 200_000_000,\r\n        zero_allow_untested_optimizer: bool = True,\r\n        logging_batch_size_per_gpu: Optional[int] = None,\r\n        config: Optional[Union[_PATH, dict[str, Any]]] = None,\r\n        logging_level: int = logging.WARN,\r\n        parallel_devices: Optional[list[torch.device]] = None,\r\n        cluster_environment: Optional[ClusterEnvironment] = None,\r\n        loss_scale: float = 0,\r\n        initial_scale_power: int = 16,\r\n        loss_scale_window: int = 1000,\r\n        hysteresis: int = 2,\r\n        min_loss_scale: int = 1,\r\n        partition_activations: bool = False,\r\n        cpu_checkpointing: bool = False,\r\n        contiguous_memory_optimization: bool = False,\r\n        synchronize_checkpoint_boundary: bool = False,\r\n        load_full_weights: bool = False,\r\n        precision: Optional[Precision] = None,\r\n        process_group_backend: Optional[str] = None,\r\n        timeout: Optional[timedelta] = default_pg_timeout,\r\n        exclude_frozen_parameters: bool = False,\r\n    ) -> None:\r\n        \"\"\"Provides capabilities to run training using the DeepSpeed library, with training optimizations for large\r\n        billion parameter models. `For more information: https://pytorch-\r\n        lightning.readthedocs.io/en/stable/advanced/model_parallel.html#deepspeed`.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        Defaults have been set to enable ZeRO-Offload and some have been taken from the link below.\r\n        These defaults have been set generally, but may require tuning for optimum performance based on your model size.\r\n        `For more information: https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training`.\r\n\r\n        Arguments:\r\n\r\n            zero_optimization: Enable ZeRO optimization. This is compatible with either ``precision=\"16-mixed\"`` or\r\n                ``precision=\"bf16-mixed\"``.\r\n\r\n            stage: Different stages of the ZeRO Optimizer. 0 is disabled,\r\n                1 is optimizer state partitioning, 2 is optimizer+gradient state partitioning,\r\n                3 is optimizer+gradient_parameter partitioning using the infinity engine.\r\n\r\n            remote_device: Device to instantiate the model on initially (``cpu`` or ``nvme``). Defaults to GPU.\r\n\r\n            offload_optimizer: Enable offloading optimizer memory and computation to CPU or NVMe\r\n                based on ``offload_optimizer_device``.\r\n\r\n            offload_parameters: When using ZeRO Stage 3, Enable offloading parameter memory and computation\r\n                to CPU or NVMe based on ``offload_params_device``.\r\n\r\n            offload_params_device: When offloading parameters choose the device to offload to, ``cpu`` or ``nvme``.\r\n\r\n            offload_optimizer_device: When offloading optimizer state choose the device to offload to,\r\n                ``cpu`` or ``nvme``.\r\n\r\n            params_buffer_count: Number of buffers in buffer pool for\r\n                parameter offloading when ``offload_params_device`` is ``nvme``.\r\n\r\n            params_buffer_size: Size of buffers in buffer pool for parameter offloading\r\n                when ``offload_params_device`` is ``nvme``.\r\n\r\n            max_in_cpu: Number of parameter elements to maintain in CPU memory when offloading to NVMe is enabled.\r\n\r\n            nvme_path: Filesystem path for NVMe device for optimizer/parameter state offloading.\r\n\r\n            optimizer_buffer_count: Number of buffers in buffer pool for optimizer state offloading\r\n                when ``offload_optimizer_device`` is set to ``nvme``.\r\n                This should be at least the number of states maintained per parameter by the optimizer.\r\n                For example, Adam optimizer has 4 states (parameter, gradient, momentum, and variance).\r\n\r\n            block_size: When using NVMe Offloading, the I/O block size in bytes.\r\n\r\n            queue_depth: When using NVMe Offloading, the I/O queue depth.\r\n\r\n            single_submit: When using NVMe Offloading,\r\n                submit requests to storage device as multiple individual requests,\r\n                as opposed to one block of requests.\r\n\r\n            overlap_events: When using NVMe Offloading,\r\n                submit requests to storage device in an overlapped fashion\r\n                without waiting for completion of earlier requests.\r\n\r\n            thread_count: When using NVMe Offloading,\r\n                Intra-request parallelism for each read/write submitted by a user thread.\r\n\r\n            pin_memory: When using ZeRO stage 3, pin optimizer state memory on CPU.\r\n                This could boost throughput at the cost of extra memory overhead.\r\n\r\n            sub_group_size: When using ZeRO stage 3, defines the number of parameters\r\n                within a sub group to offload at a time.\r\n                Smaller numbers require more communication, but improve memory efficiency.\r\n\r\n            contiguous_gradients: Copies gradients to a continuous buffer as they are produced.\r\n                Avoids memory fragmentation during backwards. Useful when training large models.\r\n\r\n            overlap_comm: Overlap the reduction (synchronization) of gradients with the backwards computation.\r\n                This is a speed optimization when training across multiple GPUs/machines.\r\n\r\n            allgather_partitions: All gather updated parameters at the end of training step,\r\n                instead of using a series of broadcast collectives.\r\n\r\n            reduce_scatter: Use reduce/scatter instead of allreduce to average gradients.\r\n\r\n            allgather_bucket_size: Number of elements to allgather at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            reduce_bucket_size: Number of elements to reduce at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            zero_allow_untested_optimizer: Allow untested optimizers to be used with ZeRO. Currently only Adam is a\r\n                DeepSpeed supported optimizer when using ZeRO.\r\n\r\n            logging_batch_size_per_gpu: Config used in DeepSpeed to calculate verbose timing for logging\r\n                on a per sample per second basis (only displayed if logging=logging.INFO).\r\n                To obtain accurate logs when using datasets that do not support batch samplers,\r\n                set this to the actual per gpu batch size.\r\n\r\n            config: Pass in a deepspeed formatted config dict,\r\n                or path to a deepspeed config: https://www.deepspeed.ai/docs/config-json.\r\n                All defaults will be ignored if a config is passed in.\r\n\r\n            logging_level: Set logging level for deepspeed.\r\n\r\n            loss_scale: Loss scaling value for FP16 training.\r\n                0.0 results in dynamic loss scaling, otherwise static.\r\n\r\n            initial_scale_power: Power of the initial dynamic loss scale value. Loss scale is computed\r\n                by ``2^initial_scale_power``.\r\n\r\n            loss_scale_window: Window in which to raise/lower the dynamic FP16 loss scaling value.\r\n\r\n            hysteresis: FP16 Delay shift in Dynamic Loss scaling.\r\n\r\n            min_loss_scale: The minimum FP16 dynamic loss scaling value.\r\n\r\n            partition_activations: Enables partition activation when used with ZeRO stage 3 and model parallelism.\r\n                Still requires you to wrap your forward functions in deepspeed.checkpointing.checkpoint.\r\n                See `deepspeed tutorial\r\n                <https://www.deepspeed.ai/tutorials/megatron/#deepspeed-activation-checkpoints-optional>`_.\r\n\r\n            cpu_checkpointing: Offloads partitioned activations to CPU if ``partition_activations`` is enabled.\r\n\r\n            contiguous_memory_optimization: Copies partitioned activations so that they are contiguous in memory.\r\n                Not supported by all models.\r\n\r\n            synchronize_checkpoint_boundary: Insert :func:`torch.cuda.synchronize` at each checkpoint boundary.\r\n\r\n            load_full_weights: True when loading a single checkpoint file containing the model state dict\r\n                when using ZeRO Stage 3. This differs from the DeepSpeed checkpoint which contains shards\r\n                per worker.\r\n\r\n            exclude_frozen_parameters: Exclude frozen parameters when saving checkpoints.\r\n\r\n        \"\"\"\r\n        if not _DEEPSPEED_AVAILABLE:\r\n            raise ImportError(\r\n                \"To use the `DeepSpeedStrategy`, you must have DeepSpeed installed.\"\r\n                \" Install it by running `pip install -U deepspeed`.\"\r\n            )\r\n\r\n        if _TORCH_GREATER_EQUAL_2_6 and not _DEEPSPEED_GREATER_EQUAL_0_16:\r\n            import deepspeed\r\n\r\n            deepspeed_version = deepspeed.__version__\r\n\r\n            raise ImportError(\r\n                f\"PyTorch >= 2.6 requires DeepSpeed >= 0.16.0. \"\r\n                f\"Detected DeepSpeed version: {deepspeed_version}. \"\r\n                \"Please upgrade by running `pip install -U 'deepspeed>=0.16.0'`.\"\r\n            )\r\n\r\n        super().__init__(\r\n            accelerator=accelerator,\r\n            parallel_devices=parallel_devices,\r\n            cluster_environment=cluster_environment,\r\n            precision=precision,\r\n            process_group_backend=process_group_backend,\r\n        )\r\n        self._backward_sync_control = None  # DeepSpeed handles gradient accumulation internally\r\n        self._timeout: Optional[timedelta] = timeout\r\n\r\n        self.config = self._load_config(config)\r\n        if self.config is None:\r\n            self.config = self._create_default_config(\r\n                zero_optimization,\r\n                zero_allow_untested_optimizer,\r\n                logging_batch_size_per_gpu,\r\n                offload_optimizer=offload_optimizer,\r\n                offload_parameters=offload_parameters,\r\n                nvme_path=nvme_path,\r\n                offload_params_device=offload_params_device,\r\n                params_buffer_count=params_buffer_count,\r\n                params_buffer_size=params_buffer_size,\r\n                max_in_cpu=max_in_cpu,\r\n                pin_memory=pin_memory,\r\n                offload_optimizer_device=offload_optimizer_device,\r\n                optimizer_buffer_count=optimizer_buffer_count,\r\n                block_size=block_size,\r\n                queue_depth=queue_depth,\r\n                single_submit=single_submit,\r\n                overlap_events=overlap_events,\r\n                thread_count=thread_count,\r\n                partition_activations=partition_activations,\r\n                cpu_checkpointing=cpu_checkpointing,\r\n                contiguous_memory_optimization=contiguous_memory_optimization,\r\n                synchronize_checkpoint_boundary=synchronize_checkpoint_boundary,\r\n                stage=stage,\r\n                contiguous_gradients=contiguous_gradients,\r\n                overlap_comm=overlap_comm,\r\n                allgather_partitions=allgather_partitions,\r\n                reduce_scatter=reduce_scatter,\r\n                allgather_bucket_size=allgather_bucket_size,\r\n                reduce_bucket_size=reduce_bucket_size,\r\n                sub_group_size=sub_group_size,\r\n            )\r\n\r\n        import deepspeed\r\n\r\n        self._config_initialized = False\r\n        deepspeed.utils.logging.logger.setLevel(logging_level)\r\n\r\n        self.remote_device = remote_device\r\n        self.load_full_weights = load_full_weights\r\n        self.exclude_frozen_parameters = exclude_frozen_parameters\r\n\r\n        self.loss_scale = loss_scale\r\n        self.initial_scale_power = initial_scale_power\r\n        self.loss_scale_window = loss_scale_window\r\n        self.hysteresis = hysteresis\r\n        self.min_loss_scale = min_loss_scale\r\n\r\n        self._deepspeed_engine: Optional[DeepSpeedEngine] = None", "code_tokens": ["def", "__init__", "(", "self", ",", "accelerator", ":", "Optional", "[", "Accelerator", "]", "=", "None", ",", "zero_optimization", ":", "bool", "=", "True", ",", "stage", ":", "int", "=", "2", ",", "remote_device", ":", "Optional", "[", "str", "]", "=", "None", ",", "offload_optimizer", ":", "bool", "=", "False", ",", "offload_parameters", ":", "bool", "=", "False", ",", "offload_params_device", ":", "str", "=", "STRING", ",", "nvme_path", ":", "str", "=", "STRING", ",", "params_buffer_count", ":", "int", "=", "5", ",", "params_buffer_size", ":", "int", "=", "100_000_000", ",", "max_in_cpu", ":", "int", "=", "1_000_000_000", ",", "offload_optimizer_device", ":", "str", "=", "STRING", ",", "optimizer_buffer_count", ":", "int", "=", "4", ",", "block_size", ":", "int", "=", "1048576", ",", "queue_depth", ":", "int", "=", "8", ",", "single_submit", ":", "bool", "=", "False", ",", "overlap_events", ":", "bool", "=", "True", ",", "thread_count", ":", "int", "=", "1", ",", "pin_memory", ":", "bool", "=", "False", ",", "sub_group_size", ":", "int", "=", "1_000_000_000_000", ",", "contiguous_gradients", ":", "bool", "=", "True", ",", "overlap_comm", ":", "bool", "=", "True", ",", "allgather_partitions", ":", "bool", "=", "True", ",", "reduce_scatter", ":", "bool", "=", "True", ",", "allgather_bucket_size", ":", "int", "=", "200_000_000", ",", "reduce_bucket_size", ":", "int", "=", "200_000_000", ",", "zero_allow_untested_optimizer", ":", "bool", "=", "True", ",", "logging_batch_size_per_gpu", ":", "Optional", "[", "int", "]", "=", "None", ",", "config", ":", "Optional", "[", "Union", "[", "_PATH", ",", "dict", "[", "str", ",", "Any", "]", "]", "]", "=", "None", ",", "logging_level", ":", "int", "=", "logging", ".", "WARN", ",", "parallel_devices", ":", "Optional", "[", "list", "[", "torch", ".", "device", "]", "]", "=", "None", ",", "cluster_environment", ":", "Optional", "[", "ClusterEnvironment", "]", "=", "None", ",", "loss_scale", ":", "float", "=", "0", ",", "initial_scale_power", ":", "int", "=", "16", ",", "loss_scale_window", ":", "int", "=", "1000", ",", "hysteresis", ":", "int", "=", "2", ",", "min_loss_scale", ":", "int", "=", "1", ",", "partition_activations", ":", "bool", "=", "False", ",", "cpu_checkpointing", ":", "bool", "=", "False", ",", "contiguous_memory_optimization", ":", "bool", "=", "False", ",", "synchronize_checkpoint_boundary", ":", "bool", "=", "False", ",", "load_full_weights", ":", "bool", "=", "False", ",", "precision", ":", "Optional", "[", "Precision", "]", "=", "None", ",", "process_group_backend", ":", "Optional", "[", "str", "]", "=", "None", ",", "timeout", ":", "Optional", "[", "timedelta", "]", "=", "default_pg_timeout", ",", "exclude_frozen_parameters", ":", "bool", "=", "False", ",", ")", "-", ">", "None", ":", "STRING", "if", "not", "_DEEPSPEED_AVAILABLE", ":", "raise", "ImportError", "(", "STRING", "STRING", ")", "if", "_TORCH_GREATER_EQUAL_2_6", "and", "not", "_DEEPSPEED_GREATER_EQUAL_0_16", ":", "import", "deepspeed", "deepspeed_version", "=", "deepspeed", ".", "__version__", "raise", "ImportError", "(", "fSTRING", "fSTRING", "STRING", ")", "super", "(", ")", ".", "__init__", "(", "accelerator", "=", "accelerator", ",", "parallel_devices", "=", "parallel_devices", ",", "cluster_environment", "=", "cluster_environment", ",", "precision", "=", "precision", ",", "process_group_backend", "=", "process_group_backend", ",", ")", "self", ".", "_backward_sync_control", "=", "None", "#", "DeepSpeed", "handles", "gradient", "accumulation", "internally", "self", ".", "_timeout", ":", "Optional", "[", "timedelta", "]", "=", "timeout", "self", ".", "config", "=", "self", ".", "_load_config", "(", "config", ")", "if", "self", ".", "config", "is", "None", ":", "self", ".", "config", "=", "self", ".", "_create_default_config", "(", "zero_optimization", ",", "zero_allow_untested_optimizer", ",", "logging_batch_size_per_gpu", ",", "offload_optimizer", "=", "offload_optimizer", ",", "offload_parameters", "=", "offload_parameters", ",", "nvme_path", "=", "nvme_path", ",", "offload_params_device", "=", "offload_params_device", ",", "params_buffer_count", "=", "params_buffer_count", ",", "params_buffer_size", "=", "params_buffer_size", ",", "max_in_cpu", "=", "max_in_cpu", ",", "pin_memory", "=", "pin_memory", ",", "offload_optimizer_device", "=", "offload_optimizer_device", ",", "optimizer_buffer_count", "=", "optimizer_buffer_count", ",", "block_size", "=", "block_size", ",", "queue_depth", "=", "queue_depth", ",", "single_submit", "=", "single_submit", ",", "overlap_events", "=", "overlap_events", ",", "thread_count", "=", "thread_count", ",", "partition_activations", "=", "partition_activations", ",", "cpu_checkpointing", "=", "cpu_checkpointing", ",", "contiguous_memory_optimization", "=", "contiguous_memory_optimization", ","], "docstring": "Starting with PyTorch 2.6, `torch.load` defaults to `weights_only=True` when loading full checkpoints. DeepSpeed added support for this behavior in version 0.16.0. User has not overridden config, set defaults default FP16 parameters.", "docstring_tokens": ["starting", "with", "pytorch", "2", "6", "torch", "load", "defaults", "to", "weights_only", "true", "when", "loading", "full", "checkpoints", "deepspeed", "added", "support", "for", "this", "behavior", "in", "version", "0", "16", "0", "user", "has", "not", "overridden", "config", "set", "defaults", "default", "fp16", "parameters"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "start_line": 57, "end_line": 318, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "func_name": "function_33", "original_string": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state in a checkpoint directory.\r\n\r\n        Args:\r\n            path: A path to where the files should be saved\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            storage_options: Unused by this strategy, since it doesn't use a ``CheckpointIO`` plugin.\r\n            filter: Unsupported.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If the unused ``storage_options`` gets passed.\r\n            ValueError:\r\n                When no :class:`deepspeed.DeepSpeedEngine` objects were found in the state, or when multiple\r\n                :class:`deepspeed.DeepSpeedEngine` objects were found.\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`DeepSpeedStrategy.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                \" `DeepSpeedStrategy` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None:\r\n            raise TypeError(\r\n                \"`DeepSpeedStrategy.save_checkpoint(..., filter=...)` is not supported because\"\r\n                \" `DeepSpeedStrategy` manages the state serialization internally.\"\r\n            )\r\n\r\n        engines = _get_deepspeed_engines_from_state(state)\r\n        if len(engines) == 0:\r\n            raise ValueError(\r\n                \"Could not find a DeepSpeed model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(engines) > 1:\r\n            raise ValueError(\r\n                \"Found multiple DeepSpeed engine modules in the given state. Saving checkpoints with DeepSpeed is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        engine = engines[0]\r\n\r\n        path = self.broadcast(path)\r\n\r\n        excluded_objects = (engine, engine.optimizer) if engine.optimizer is not None else (engine,)\r\n        state = {k: v for k, v in state.items() if v not in excluded_objects}\r\n        _validate_state_keys(state)\r\n        state = self._convert_stateful_objects_in_state(state, filter={})\r\n        engine.save_checkpoint(\r\n            path, client_state=state, tag=\"checkpoint\", exclude_frozen_parameters=self.exclude_frozen_parameters\r\n        )", "language": "python", "code": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state in a checkpoint directory.\r\n\r\n        Args:\r\n            path: A path to where the files should be saved\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            storage_options: Unused by this strategy, since it doesn't use a ``CheckpointIO`` plugin.\r\n            filter: Unsupported.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If the unused ``storage_options`` gets passed.\r\n            ValueError:\r\n                When no :class:`deepspeed.DeepSpeedEngine` objects were found in the state, or when multiple\r\n                :class:`deepspeed.DeepSpeedEngine` objects were found.\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`DeepSpeedStrategy.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                \" `DeepSpeedStrategy` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None:\r\n            raise TypeError(\r\n                \"`DeepSpeedStrategy.save_checkpoint(..., filter=...)` is not supported because\"\r\n                \" `DeepSpeedStrategy` manages the state serialization internally.\"\r\n            )\r\n\r\n        engines = _get_deepspeed_engines_from_state(state)\r\n        if len(engines) == 0:\r\n            raise ValueError(\r\n                \"Could not find a DeepSpeed model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(engines) > 1:\r\n            raise ValueError(\r\n                \"Found multiple DeepSpeed engine modules in the given state. Saving checkpoints with DeepSpeed is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        engine = engines[0]\r\n\r\n        path = self.broadcast(path)\r\n\r\n        excluded_objects = (engine, engine.optimizer) if engine.optimizer is not None else (engine,)\r\n        state = {k: v for k, v in state.items() if v not in excluded_objects}\r\n        _validate_state_keys(state)\r\n        state = self._convert_stateful_objects_in_state(state, filter={})\r\n        engine.save_checkpoint(\r\n            path, client_state=state, tag=\"checkpoint\", exclude_frozen_parameters=self.exclude_frozen_parameters\r\n        )", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "storage_options", "is", "not", "None", ":", "raise", "TypeError", "(", "STRING", "STRING", ")", "if", "filter", "is", "not", "None", ":", "raise", "TypeError", "(", "STRING", "STRING", ")", "engines", "=", "_get_deepspeed_engines_from_state", "(", "state", ")", "if", "len", "(", "engines", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "if", "len", "(", "engines", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "engine", "=", "engines", "[", "0", "]", "path", "=", "self", ".", "broadcast", "(", "path", ")", "excluded_objects", "=", "(", "engine", ",", "engine", ".", "optimizer", ")", "if", "engine", ".", "optimizer", "is", "not", "None", "else", "(", "engine", ",", ")", "state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", "if", "v", "not", "in", "excluded_objects", "}", "_validate_state_keys", "(", "state", ")", "state", "=", "self", ".", "_convert_stateful_objects_in_state", "(", "state", ",", "filter", "=", "{", "}", ")", "engine", ".", "save_checkpoint", "(", "path", ",", "client_state", "=", "state", ",", "tag", "=", "STRING", ",", "exclude_frozen_parameters", "=", "self", ".", "exclude_frozen_parameters", ")"], "docstring": "broadcast the path from rank 0 to ensure all the states are saved in a common path split the checkpoint into two parts: 1) the deepspeed engine encapsulating both the model and optionally the optimizer(s) 2) the rest of the user's state, which in deepspeed is called `client state` there might be other stateful objects unrelated to the deepspeed engine - convert them to a state_dict use deepspeed's internal checkpointing function to handle partitioned weights across processes", "docstring_tokens": ["broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "saved", "in", "a", "common", "path", "split", "the", "checkpoint", "into", "two", "parts", "1", "the", "deepspeed", "engine", "encapsulating", "both", "the", "model", "and", "optionally", "the", "optimizer", "s", "2", "the", "rest", "of", "the", "user", "s", "state", "which", "in", "deepspeed", "is", "called", "client", "state", "there", "might", "be", "other", "stateful", "objects", "unrelated", "to", "the", "deepspeed", "engine", "convert", "them", "to", "a", "state_dict", "use", "deepspeed", "s", "internal", "checkpointing", "function", "to", "handle", "partitioned", "weights", "across", "processes"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "start_line": 403, "end_line": 467, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "func_name": "function_34", "original_string": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\r\n\r\n        Args:\r\n            path: A path to where the file is located\r\n            state: A dictionary of objects whose state will be restored in-place from the checkpoint path.\r\n                This should contain exactly one model, and the model must already be set up by DeepSpeed.\r\n            strict: Whether to enforce that the keys in `state` match the keys in the checkpoint.\r\n\r\n        Returns:\r\n            Dictionary with the state inside DeepSpeed's engine\r\n\r\n        Raises:\r\n            ValueError:\r\n                If no state is provided, when no :class:`deepspeed.DeepSpeedEngine` objects were found in the\r\n                state, or when multiple :class:`deepspeed.DeepSpeedEngine` objects were found.\r\n            RuntimeError:\r\n                If DeepSpeed was unable to load the checkpoint due to missing files or because the checkpoint is\r\n                not in the expected DeepSpeed format.\r\n\r\n        \"\"\"\r\n        if isinstance(state, (Module, Optimizer)) or self.load_full_weights and self.zero_stage_3:\r\n            path = self.broadcast(path)\r\n            return super().load_checkpoint(path=path, state=state, strict=strict)\r\n\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got DeepSpeedStrategy.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                f\" a model instance to reload is required. Pass it in like so:\"\r\n                \" DeepSpeedStrategy.load_checkpoint(..., state={'model': model, ...})\"\r\n            )\r\n        _validate_checkpoint_directory(path)\r\n\r\n        engines = _get_deepspeed_engines_from_state(state)\r\n        if len(engines) == 0:\r\n            raise ValueError(\r\n                \"Could not find a DeepSpeed model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n            )\r\n        if len(engines) > 1:\r\n            raise ValueError(\r\n                \"Found multiple DeepSpeed engine modules in the given state. Saving and loading checkpoints\"\r\n                \" with DeepSpeed is currently limited to a single model per checkpoint. To load multiple model\"\r\n                \" states, call the load method for each model checkpoint separately.\"\r\n            )\r\n        engine = engines[0]\r\n\r\n        from deepspeed.runtime.base_optimizer import DeepSpeedOptimizer\r\n\r\n        optimzer_state_requested = any(isinstance(item, (Optimizer, DeepSpeedOptimizer)) for item in state.values())\r\n\r\n        torch.cuda.empty_cache()\r\n        _, client_state = engine.load_checkpoint(\r\n            path,\r\n            tag=\"checkpoint\",\r\n            load_optimizer_states=optimzer_state_requested,\r\n            load_lr_scheduler_states=False,\r\n            load_module_strict=strict,\r\n        )\r\n\r\n        if client_state is None:\r\n            raise RuntimeError(\r\n                \"DeepSpeed was unable to load the checkpoint. Ensure you passed in a DeepSpeed compatible checkpoint\"\r\n                \" or a single checkpoint file by setting `DeepSpeedStrategy(..., load_full_weights=True)`.\"\r\n            )\r\n\r\n        keys = set(client_state) & set(state) - {\"optimizer\", \"lr_scheduler\"}\r\n        _move_state_into(source=client_state, destination=state, keys=keys)\r\n        return client_state", "language": "python", "code": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\r\n\r\n        Args:\r\n            path: A path to where the file is located\r\n            state: A dictionary of objects whose state will be restored in-place from the checkpoint path.\r\n                This should contain exactly one model, and the model must already be set up by DeepSpeed.\r\n            strict: Whether to enforce that the keys in `state` match the keys in the checkpoint.\r\n\r\n        Returns:\r\n            Dictionary with the state inside DeepSpeed's engine\r\n\r\n        Raises:\r\n            ValueError:\r\n                If no state is provided, when no :class:`deepspeed.DeepSpeedEngine` objects were found in the\r\n                state, or when multiple :class:`deepspeed.DeepSpeedEngine` objects were found.\r\n            RuntimeError:\r\n                If DeepSpeed was unable to load the checkpoint due to missing files or because the checkpoint is\r\n                not in the expected DeepSpeed format.\r\n\r\n        \"\"\"\r\n        if isinstance(state, (Module, Optimizer)) or self.load_full_weights and self.zero_stage_3:\r\n            path = self.broadcast(path)\r\n            return super().load_checkpoint(path=path, state=state, strict=strict)\r\n\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got DeepSpeedStrategy.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                f\" a model instance to reload is required. Pass it in like so:\"\r\n                \" DeepSpeedStrategy.load_checkpoint(..., state={'model': model, ...})\"\r\n            )\r\n        _validate_checkpoint_directory(path)\r\n\r\n        engines = _get_deepspeed_engines_from_state(state)\r\n        if len(engines) == 0:\r\n            raise ValueError(\r\n                \"Could not find a DeepSpeed model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n            )\r\n        if len(engines) > 1:\r\n            raise ValueError(\r\n                \"Found multiple DeepSpeed engine modules in the given state. Saving and loading checkpoints\"\r\n                \" with DeepSpeed is currently limited to a single model per checkpoint. To load multiple model\"\r\n                \" states, call the load method for each model checkpoint separately.\"\r\n            )\r\n        engine = engines[0]\r\n\r\n        from deepspeed.runtime.base_optimizer import DeepSpeedOptimizer\r\n\r\n        optimzer_state_requested = any(isinstance(item, (Optimizer, DeepSpeedOptimizer)) for item in state.values())\r\n\r\n        torch.cuda.empty_cache()\r\n        _, client_state = engine.load_checkpoint(\r\n            path,\r\n            tag=\"checkpoint\",\r\n            load_optimizer_states=optimzer_state_requested,\r\n            load_lr_scheduler_states=False,\r\n            load_module_strict=strict,\r\n        )\r\n\r\n        if client_state is None:\r\n            raise RuntimeError(\r\n                \"DeepSpeed was unable to load the checkpoint. Ensure you passed in a DeepSpeed compatible checkpoint\"\r\n                \" or a single checkpoint file by setting `DeepSpeedStrategy(..., load_full_weights=True)`.\"\r\n            )\r\n\r\n        keys = set(client_state) & set(state) - {\"optimizer\", \"lr_scheduler\"}\r\n        _move_state_into(source=client_state, destination=state, keys=keys)\r\n        return client_state", "code_tokens": ["def", "load_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "Optional", "[", "Union", "[", "Module", ",", "Optimizer", ",", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", "]", "]", "=", "None", ",", "strict", ":", "bool", "=", "True", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "isinstance", "(", "state", ",", "(", "Module", ",", "Optimizer", ")", ")", "or", "self", ".", "load_full_weights", "and", "self", ".", "zero_stage_3", ":", "path", "=", "self", ".", "broadcast", "(", "path", ")", "return", "super", "(", ")", ".", "load_checkpoint", "(", "path", "=", "path", ",", "state", "=", "state", ",", "strict", "=", "strict", ")", "if", "not", "state", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", "STRING", ")", "_validate_checkpoint_directory", "(", "path", ")", "engines", "=", "_get_deepspeed_engines_from_state", "(", "state", ")", "if", "len", "(", "engines", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "if", "len", "(", "engines", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "engine", "=", "engines", "[", "0", "]", "from", "deepspeed", ".", "runtime", ".", "base_optimizer", "import", "DeepSpeedOptimizer", "optimzer_state_requested", "=", "any", "(", "isinstance", "(", "item", ",", "(", "Optimizer", ",", "DeepSpeedOptimizer", ")", ")", "for", "item", "in", "state", ".", "values", "(", ")", ")", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "_", ",", "client_state", "=", "engine", ".", "load_checkpoint", "(", "path", ",", "tag", "=", "STRING", ",", "load_optimizer_states", "=", "optimzer_state_requested", ",", "load_lr_scheduler_states", "=", "False", ",", "load_module_strict", "=", "strict", ",", ")", "if", "client_state", "is", "None", ":", "raise", "RuntimeError", "(", "STRING", "STRING", ")", "keys", "=", "set", "(", "client_state", ")", "&", "set", "(", "state", ")", "-", "{", "STRING", ",", "STRING", "}", "_move_state_into", "(", "source", "=", "client_state", ",", "destination", "=", "state", ",", "keys", "=", "keys", ")", "return", "client_state"], "docstring": "This code path to enables loading a checkpoint from a non-deepspeed checkpoint or from a consolidated checkpoint `Engine.load_checkpoint` adds useless keys 'optimizer' and 'lr_scheduler' to the client state; remove them to avoid name collision with user state", "docstring_tokens": ["this", "code", "path", "to", "enables", "loading", "a", "checkpoint", "from", "a", "non", "deepspeed", "checkpoint", "or", "from", "a", "consolidated", "checkpoint", "engine", "load_checkpoint", "adds", "useless", "keys", "optimizer", "and", "lr_scheduler", "to", "the", "client", "state", "remove", "them", "to", "avoid", "name", "collision", "with", "user", "state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "start_line": 470, "end_line": 548, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "func_name": "function_35", "original_string": "def _restore_zero_state(self, module: Module, ckpt: Mapping[str, Any]) -> None:\r\n        \"\"\"Overrides the normal load_state_dict behaviour in PyTorch to ensure we gather parameters that may be sharded\r\n        across processes before loading the state dictionary when using ZeRO stage 3. This is then automatically synced\r\n        across processes.\r\n\r\n        Args:\r\n            ckpt: The ckpt file.\r\n\r\n        \"\"\"\r\n        import deepspeed\r\n\r\n        def load(module: torch.nn.Module, prefix: str = \"\") -> None:\r\n            missing_keys: list[str] = []\r\n            unexpected_keys: list[str] = []\r\n            error_msgs: list[str] = []\r\n            state_dict = ckpt[\"state_dict\"]\r\n\r\n            metadata = getattr(state_dict, \"_metadata\", None)\r\n            state_dict = state_dict.copy()\r\n            if metadata is not None:\r\n                state_dict._metadata = metadata\r\n\r\n            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\r\n            with deepspeed.zero.GatheredParameters(list(module.parameters(recurse=False)), modifier_rank=0):\r\n                if self.is_global_zero:\r\n                    module._load_from_state_dict(\r\n                        state_dict=state_dict,\r\n                        prefix=prefix,\r\n                        local_metadata=local_metadata,\r\n                        strict=True,\r\n                        missing_keys=missing_keys,\r\n                        unexpected_keys=unexpected_keys,\r\n                        error_msgs=error_msgs,\r\n                    )\r\n\r\n            for name, child in module._modules.items():\r\n                if child is not None:\r\n                    load(child, prefix + name + \".\")\r\n\r\n        load(module, prefix=\"\")", "language": "python", "code": "def _restore_zero_state(self, module: Module, ckpt: Mapping[str, Any]) -> None:\r\n        \"\"\"Overrides the normal load_state_dict behaviour in PyTorch to ensure we gather parameters that may be sharded\r\n        across processes before loading the state dictionary when using ZeRO stage 3. This is then automatically synced\r\n        across processes.\r\n\r\n        Args:\r\n            ckpt: The ckpt file.\r\n\r\n        \"\"\"\r\n        import deepspeed\r\n\r\n        def load(module: torch.nn.Module, prefix: str = \"\") -> None:\r\n            missing_keys: list[str] = []\r\n            unexpected_keys: list[str] = []\r\n            error_msgs: list[str] = []\r\n            state_dict = ckpt[\"state_dict\"]\r\n\r\n            metadata = getattr(state_dict, \"_metadata\", None)\r\n            state_dict = state_dict.copy()\r\n            if metadata is not None:\r\n                state_dict._metadata = metadata\r\n\r\n            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\r\n            with deepspeed.zero.GatheredParameters(list(module.parameters(recurse=False)), modifier_rank=0):\r\n                if self.is_global_zero:\r\n                    module._load_from_state_dict(\r\n                        state_dict=state_dict,\r\n                        prefix=prefix,\r\n                        local_metadata=local_metadata,\r\n                        strict=True,\r\n                        missing_keys=missing_keys,\r\n                        unexpected_keys=unexpected_keys,\r\n                        error_msgs=error_msgs,\r\n                    )\r\n\r\n            for name, child in module._modules.items():\r\n                if child is not None:\r\n                    load(child, prefix + name + \".\")\r\n\r\n        load(module, prefix=\"\")", "code_tokens": ["def", "_restore_zero_state", "(", "self", ",", "module", ":", "Module", ",", "ckpt", ":", "Mapping", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "STRING", "import", "deepspeed", "def", "load", "(", "module", ":", "torch", ".", "nn", ".", "Module", ",", "prefix", ":", "str", "=", "STRING", ")", "-", ">", "None", ":", "missing_keys", ":", "list", "[", "str", "]", "=", "[", "]", "unexpected_keys", ":", "list", "[", "str", "]", "=", "[", "]", "error_msgs", ":", "list", "[", "str", "]", "=", "[", "]", "state_dict", "=", "ckpt", "[", "STRING", "]", "metadata", "=", "getattr", "(", "state_dict", ",", "STRING", ",", "None", ")", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "if", "metadata", "is", "not", "None", ":", "state_dict", ".", "_metadata", "=", "metadata", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "with", "deepspeed", ".", "zero", ".", "GatheredParameters", "(", "list", "(", "module", ".", "parameters", "(", "recurse", "=", "False", ")", ")", ",", "modifier_rank", "=", "0", ")", ":", "if", "self", ".", "is_global_zero", ":", "module", ".", "_load_from_state_dict", "(", "state_dict", "=", "state_dict", ",", "prefix", "=", "prefix", ",", "local_metadata", "=", "local_metadata", ",", "strict", "=", "True", ",", "missing_keys", "=", "missing_keys", ",", "unexpected_keys", "=", "unexpected_keys", ",", "error_msgs", "=", "error_msgs", ",", ")", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "if", "child", "is", "not", "None", ":", "load", "(", "child", ",", "prefix", "+", "name", "+", "STRING", ")", "load", "(", "module", ",", "prefix", "=", "STRING", ")"], "docstring": "copy state_dict so _load_from_state_dict can modify it because zero3 puts placeholders in model params, this context manager gathers (unpartitions) the params of the current layer, then loads from the state dict and then re-partitions them again", "docstring_tokens": ["copy", "state_dict", "so", "_load_from_state_dict", "can", "modify", "it", "because", "zero3", "puts", "placeholders", "in", "model", "params", "this", "context", "manager", "gathers", "unpartitions", "the", "params", "of", "the", "current", "layer", "then", "loads", "from", "the", "state", "dict", "and", "then", "re", "partitions", "them", "again"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "start_line": 781, "end_line": 824, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "func_name": "function_36", "original_string": "def _validate_checkpoint_directory(path: _PATH) -> None:\r\n    \"\"\"Validates that the path points to a DeepSpeed checkpoint directory and suggests fixes for user error.\"\"\"\r\n\r\n    path = Path(path)\r\n    path_is_ds_checkpoint = _is_deepspeed_checkpoint(path)\r\n    default_message = f\"The provided path is not a valid DeepSpeed checkpoint: {path}\"\r\n\r\n    if not path_is_ds_checkpoint:\r\n        parent_is_ds_checkpoint = _is_deepspeed_checkpoint(path.parent)\r\n        if parent_is_ds_checkpoint:\r\n            raise FileNotFoundError(\r\n                f\"{default_message}. It looks like you passed the path to a subfolder.\"\r\n                f\" Try to load using this parent directory instead: {path.parent}\"\r\n            )\r\n        parent_parent_is_ds_checkpoint = path.is_file() and _is_deepspeed_checkpoint(path.parent.parent)\r\n        if parent_parent_is_ds_checkpoint:\r\n            raise FileNotFoundError(\r\n                f\"{default_message}. It looks like you passed the path to a file inside a DeepSpeed checkpoint folder.\"\r\n                f\" Try to load using this parent directory instead: {path.parent.parent}\"\r\n            )\r\n        raise FileNotFoundError(default_message)", "language": "python", "code": "def _validate_checkpoint_directory(path: _PATH) -> None:\r\n    \"\"\"Validates that the path points to a DeepSpeed checkpoint directory and suggests fixes for user error.\"\"\"\r\n\r\n    path = Path(path)\r\n    path_is_ds_checkpoint = _is_deepspeed_checkpoint(path)\r\n    default_message = f\"The provided path is not a valid DeepSpeed checkpoint: {path}\"\r\n\r\n    if not path_is_ds_checkpoint:\r\n        parent_is_ds_checkpoint = _is_deepspeed_checkpoint(path.parent)\r\n        if parent_is_ds_checkpoint:\r\n            raise FileNotFoundError(\r\n                f\"{default_message}. It looks like you passed the path to a subfolder.\"\r\n                f\" Try to load using this parent directory instead: {path.parent}\"\r\n            )\r\n        parent_parent_is_ds_checkpoint = path.is_file() and _is_deepspeed_checkpoint(path.parent.parent)\r\n        if parent_parent_is_ds_checkpoint:\r\n            raise FileNotFoundError(\r\n                f\"{default_message}. It looks like you passed the path to a file inside a DeepSpeed checkpoint folder.\"\r\n                f\" Try to load using this parent directory instead: {path.parent.parent}\"\r\n            )\r\n        raise FileNotFoundError(default_message)", "code_tokens": ["def", "_validate_checkpoint_directory", "(", "path", ":", "_PATH", ")", "-", ">", "None", ":", "STRING", "path", "=", "Path", "(", "path", ")", "path_is_ds_checkpoint", "=", "_is_deepspeed_checkpoint", "(", "path", ")", "default_message", "=", "fSTRING", "if", "not", "path_is_ds_checkpoint", ":", "parent_is_ds_checkpoint", "=", "_is_deepspeed_checkpoint", "(", "path", ".", "parent", ")", "if", "parent_is_ds_checkpoint", ":", "raise", "FileNotFoundError", "(", "fSTRING", "fSTRING", ")", "parent_parent_is_ds_checkpoint", "=", "path", ".", "is_file", "(", ")", "and", "_is_deepspeed_checkpoint", "(", "path", ".", "parent", ".", "parent", ")", "if", "parent_parent_is_ds_checkpoint", ":", "raise", "FileNotFoundError", "(", "fSTRING", "fSTRING", ")", "raise", "FileNotFoundError", "(", "default_message", ")"], "docstring": "Case 1: User may have accidentally passed the subfolder \"checkpoint\" Case 2: User may have accidentally passed the path to a file inside the \"checkpoint\" subfolder", "docstring_tokens": ["case", "1", "user", "may", "have", "accidentally", "passed", "the", "subfolder", "checkpoint", "case", "2", "user", "may", "have", "accidentally", "passed", "the", "path", "to", "a", "file", "inside", "the", "checkpoint", "subfolder"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\deepspeed.py", "start_line": 891, "end_line": 923, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_37", "original_string": "def setup_module(self, module: Module) -> Module:\r\n        \"\"\"Wraps the model into a :class:`~torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel`\r\n        module.\"\"\"\r\n        from torch.distributed.fsdp import FullyShardedDataParallel\r\n\r\n        if any(isinstance(mod, FullyShardedDataParallel) for mod in module.modules()):\r\n            if _has_meta_device_parameters_or_buffers(module):\r\n                rank_zero_warn(\r\n                    \"The model is already wrapped in `FSDP` but there are still parameters on the meta device.\"\r\n                )\r\n            if \"auto_wrap_policy\" in self._fsdp_kwargs:\r\n                rank_zero_warn(\r\n                    \"A FSDP `auto_wrap_policy` is set, but the model is already wrapped. The policy will be ignored.\"\r\n                )\r\n                del self._fsdp_kwargs[\"auto_wrap_policy\"]\r\n        else:\r\n            module = FullyShardedDataParallel(\r\n                module=module,\r\n                cpu_offload=self.cpu_offload,\r\n                mixed_precision=self.mixed_precision_config,\r\n                sharding_strategy=self.sharding_strategy,\r\n                device_id=self.root_device.index,\r\n                **self._fsdp_kwargs,\r\n            )\r\n\r\n        _move_torchmetrics_to_device(module, self.root_device)\r\n\r\n        _setup_activation_checkpointing(module, self._activation_checkpointing_kwargs)\r\n\r\n        return module", "language": "python", "code": "def setup_module(self, module: Module) -> Module:\r\n        \"\"\"Wraps the model into a :class:`~torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel`\r\n        module.\"\"\"\r\n        from torch.distributed.fsdp import FullyShardedDataParallel\r\n\r\n        if any(isinstance(mod, FullyShardedDataParallel) for mod in module.modules()):\r\n            if _has_meta_device_parameters_or_buffers(module):\r\n                rank_zero_warn(\r\n                    \"The model is already wrapped in `FSDP` but there are still parameters on the meta device.\"\r\n                )\r\n            if \"auto_wrap_policy\" in self._fsdp_kwargs:\r\n                rank_zero_warn(\r\n                    \"A FSDP `auto_wrap_policy` is set, but the model is already wrapped. The policy will be ignored.\"\r\n                )\r\n                del self._fsdp_kwargs[\"auto_wrap_policy\"]\r\n        else:\r\n            module = FullyShardedDataParallel(\r\n                module=module,\r\n                cpu_offload=self.cpu_offload,\r\n                mixed_precision=self.mixed_precision_config,\r\n                sharding_strategy=self.sharding_strategy,\r\n                device_id=self.root_device.index,\r\n                **self._fsdp_kwargs,\r\n            )\r\n\r\n        _move_torchmetrics_to_device(module, self.root_device)\r\n\r\n        _setup_activation_checkpointing(module, self._activation_checkpointing_kwargs)\r\n\r\n        return module", "code_tokens": ["def", "setup_module", "(", "self", ",", "module", ":", "Module", ")", "-", ">", "Module", ":", "STRING", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "if", "any", "(", "isinstance", "(", "mod", ",", "FullyShardedDataParallel", ")", "for", "mod", "in", "module", ".", "modules", "(", ")", ")", ":", "if", "_has_meta_device_parameters_or_buffers", "(", "module", ")", ":", "rank_zero_warn", "(", "STRING", ")", "if", "STRING", "in", "self", ".", "_fsdp_kwargs", ":", "rank_zero_warn", "(", "STRING", ")", "del", "self", ".", "_fsdp_kwargs", "[", "STRING", "]", "else", ":", "module", "=", "FullyShardedDataParallel", "(", "module", "=", "module", ",", "cpu_offload", "=", "self", ".", "cpu_offload", ",", "mixed_precision", "=", "self", ".", "mixed_precision_config", ",", "sharding_strategy", "=", "self", ".", "sharding_strategy", ",", "device_id", "=", "self", ".", "root_device", ".", "index", ",", "*", "*", "self", ".", "_fsdp_kwargs", ",", ")", "_move_torchmetrics_to_device", "(", "module", ",", "self", ".", "root_device", ")", "_setup_activation_checkpointing", "(", "module", ",", "self", ".", "_activation_checkpointing_kwargs", ")", "return", "module"], "docstring": "The user has wrapped their submodules manually, don't apply the auto wrap policy. activation checkpointing needs to be set up after wrapping the model", "docstring_tokens": ["the", "user", "has", "wrapped", "their", "submodules", "manually", "don", "t", "apply", "the", "auto", "wrap", "policy", "activation", "checkpointing", "needs", "to", "be", "set", "up", "after", "wrapping", "the", "model"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 280, "end_line": 311, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_38", "original_string": "def setup_optimizer(self, optimizer: Optimizer) -> Optimizer:\r\n        \"\"\"Set up an optimizer for a model wrapped with FSDP.\r\n\r\n        This setup method doesn't modify the optimizer or wrap the optimizer. The only thing it currently does is verify\r\n        that the optimizer was created after the model was wrapped with :meth:`setup_module` with a reference to the\r\n        flattened parameters.\r\n\r\n        \"\"\"\r\n        if self._fsdp_kwargs.get(\"use_orig_params\"):\r\n            return super().setup_optimizer(optimizer)\r\n        if not _optimizer_has_flat_params(optimizer):\r\n            raise ValueError(\r\n                \"The optimizer does not seem to reference any FSDP parameters. HINT: Make sure to create the optimizer\"\r\n                \" after setting up the model.\"\r\n            )\r\n        return optimizer", "language": "python", "code": "def setup_optimizer(self, optimizer: Optimizer) -> Optimizer:\r\n        \"\"\"Set up an optimizer for a model wrapped with FSDP.\r\n\r\n        This setup method doesn't modify the optimizer or wrap the optimizer. The only thing it currently does is verify\r\n        that the optimizer was created after the model was wrapped with :meth:`setup_module` with a reference to the\r\n        flattened parameters.\r\n\r\n        \"\"\"\r\n        if self._fsdp_kwargs.get(\"use_orig_params\"):\r\n            return super().setup_optimizer(optimizer)\r\n        if not _optimizer_has_flat_params(optimizer):\r\n            raise ValueError(\r\n                \"The optimizer does not seem to reference any FSDP parameters. HINT: Make sure to create the optimizer\"\r\n                \" after setting up the model.\"\r\n            )\r\n        return optimizer", "code_tokens": ["def", "setup_optimizer", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "Optimizer", ":", "STRING", "if", "self", ".", "_fsdp_kwargs", ".", "get", "(", "STRING", ")", ":", "return", "super", "(", ")", ".", "setup_optimizer", "(", "optimizer", ")", "if", "not", "_optimizer_has_flat_params", "(", "optimizer", ")", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "return", "optimizer"], "docstring": "We avoid this limitation by setting `use_orig_params=True`", "docstring_tokens": ["we", "avoid", "this", "limitation", "by", "setting", "use_orig_params", "true"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 314, "end_line": 330, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_39", "original_string": "def clip_gradients_norm(\r\n        self,\r\n        module: Module,\r\n        optimizer: Optimizer,\r\n        max_norm: Union[float, int],\r\n        norm_type: Union[float, int] = 2.0,\r\n        error_if_nonfinite: bool = True,\r\n    ) -> Tensor:\r\n        \"\"\"Clip gradients by norm.\"\"\"\r\n        from torch.distributed.fsdp.fully_sharded_data_parallel import FullyShardedDataParallel\r\n\r\n        if not isinstance(module, FullyShardedDataParallel):\r\n            raise TypeError(\r\n                \"Gradient clipping with FSDP is only possible if the module passed to\"\r\n                f\" `{type(self).__name__}.clip_gradients_norm` is wrapped in `FullyShardedDataParallel`.\"\r\n                f\" Got: {module.__class__.__name__}.\"\r\n            )\r\n        self.precision.unscale_gradients(optimizer)\r\n        return module.clip_grad_norm_(max_norm=max_norm, norm_type=norm_type)", "language": "python", "code": "def clip_gradients_norm(\r\n        self,\r\n        module: Module,\r\n        optimizer: Optimizer,\r\n        max_norm: Union[float, int],\r\n        norm_type: Union[float, int] = 2.0,\r\n        error_if_nonfinite: bool = True,\r\n    ) -> Tensor:\r\n        \"\"\"Clip gradients by norm.\"\"\"\r\n        from torch.distributed.fsdp.fully_sharded_data_parallel import FullyShardedDataParallel\r\n\r\n        if not isinstance(module, FullyShardedDataParallel):\r\n            raise TypeError(\r\n                \"Gradient clipping with FSDP is only possible if the module passed to\"\r\n                f\" `{type(self).__name__}.clip_gradients_norm` is wrapped in `FullyShardedDataParallel`.\"\r\n                f\" Got: {module.__class__.__name__}.\"\r\n            )\r\n        self.precision.unscale_gradients(optimizer)\r\n        return module.clip_grad_norm_(max_norm=max_norm, norm_type=norm_type)", "code_tokens": ["def", "clip_gradients_norm", "(", "self", ",", "module", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "max_norm", ":", "Union", "[", "float", ",", "int", "]", ",", "norm_type", ":", "Union", "[", "float", ",", "int", "]", "=", "2", ".", "0", ",", "error_if_nonfinite", ":", "bool", "=", "True", ",", ")", "-", ">", "Tensor", ":", "STRING", "from", "torch", ".", "distributed", ".", "fsdp", ".", "fully_sharded_data_parallel", "import", "FullyShardedDataParallel", "if", "not", "isinstance", "(", "module", ",", "FullyShardedDataParallel", ")", ":", "raise", "TypeError", "(", "STRING", "fSTRING", "fSTRING", ")", "self", ".", "precision", ".", "unscale_gradients", "(", "optimizer", ")", "return", "module", ".", "clip_grad_norm_", "(", "max_norm", "=", "max_norm", ",", "norm_type", "=", "norm_type", ")"], "docstring": "the root must be wrapped", "docstring_tokens": ["the", "root", "must", "be", "wrapped"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 391, "end_line": 410, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_40", "original_string": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state to a checkpoint on disk.\r\n\r\n        If the state-dict-type is ``'full'``, the checkpoint will be written to a single file containing the weights,\r\n        optimizer state and other metadata. If the state-dict-type is ``'sharded'``, the checkpoint gets saved as a\r\n        directory containing one file per process, with model- and optimizer shards stored per file. Additionally, it\r\n        creates a metadata file `meta.pt` with the rest of the user's state (only saved from rank 0).\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`FSDPStrategy.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                \" `FSDPStrategy` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None and self._state_dict_type == \"sharded\":\r\n            raise NotImplementedError(\r\n                \"FSDP doesn't support loading sharded filtered checkpoints, so saving them is disabled.\"\r\n            )\r\n\r\n        path = Path(self.broadcast(path))\r\n        if path.is_dir() and self._state_dict_type == \"full\" and not _is_sharded_checkpoint(path):\r\n            raise IsADirectoryError(f\"The checkpoint path exists and is a directory: {path}\")\r\n\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n        modules = [module for module in state.values() if _has_fsdp_modules(module)]\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a FSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple FSDP models in the given state. Saving checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        module = modules[0]\r\n\r\n        if self._state_dict_type == \"sharded\":\r\n            if path.is_file():\r\n                path.unlink()\r\n            path.mkdir(parents=True, exist_ok=True)\r\n\r\n            state_dict_ctx = _get_sharded_state_dict_context(module)\r\n\r\n            converted_state: dict[str, Any] = {}\r\n            metadata: dict[str, Any] = {}\r\n            with state_dict_ctx:\r\n                for key, obj in state.items():\r\n                    converted: Any\r\n                    if isinstance(obj, Module):\r\n                        converted = obj.state_dict()\r\n                        target_dict = converted_state\r\n                    elif isinstance(obj, Optimizer):\r\n                        converted = FSDP.optim_state_dict(module, obj)\r\n                        target_dict = converted_state\r\n                    else:  # everything not a module or optimizer is considered metadata\r\n                        converted = obj.state_dict() if isinstance(obj, _Stateful) else obj\r\n                        target_dict = metadata\r\n                    _apply_filter(key, filter or {}, converted, target_dict)\r\n\r\n            _distributed_checkpoint_save(converted_state, path)\r\n\r\n            if self.global_rank == 0:\r\n                torch.save(metadata, path / _METADATA_FILENAME)\r\n\r\n        elif self._state_dict_type == \"full\":\r\n            if _is_sharded_checkpoint(path):\r\n                shutil.rmtree(path)\r\n\r\n            state_dict_ctx = _get_full_state_dict_context(module, world_size=self.world_size)\r\n            full_state: dict[str, Any] = {}\r\n            with state_dict_ctx:\r\n                for key, obj in state.items():\r\n                    if isinstance(obj, Module):\r\n                        converted = obj.state_dict()\r\n                    elif isinstance(obj, Optimizer):\r\n                        converted = FSDP.optim_state_dict(module, obj)\r\n                    else:  # everything not a module or optimizer is considered metadata\r\n                        converted = obj.state_dict() if isinstance(obj, _Stateful) else obj\r\n                    _apply_filter(key, filter or {}, converted, full_state)\r\n\r\n            if self.global_rank == 0:\r\n                torch.save(full_state, path)\r\n        else:\r\n            raise ValueError(f\"Unknown state_dict_type: {self._state_dict_type}\")", "language": "python", "code": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state to a checkpoint on disk.\r\n\r\n        If the state-dict-type is ``'full'``, the checkpoint will be written to a single file containing the weights,\r\n        optimizer state and other metadata. If the state-dict-type is ``'sharded'``, the checkpoint gets saved as a\r\n        directory containing one file per process, with model- and optimizer shards stored per file. Additionally, it\r\n        creates a metadata file `meta.pt` with the rest of the user's state (only saved from rank 0).\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`FSDPStrategy.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                \" `FSDPStrategy` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None and self._state_dict_type == \"sharded\":\r\n            raise NotImplementedError(\r\n                \"FSDP doesn't support loading sharded filtered checkpoints, so saving them is disabled.\"\r\n            )\r\n\r\n        path = Path(self.broadcast(path))\r\n        if path.is_dir() and self._state_dict_type == \"full\" and not _is_sharded_checkpoint(path):\r\n            raise IsADirectoryError(f\"The checkpoint path exists and is a directory: {path}\")\r\n\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n        modules = [module for module in state.values() if _has_fsdp_modules(module)]\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a FSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple FSDP models in the given state. Saving checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        module = modules[0]\r\n\r\n        if self._state_dict_type == \"sharded\":\r\n            if path.is_file():\r\n                path.unlink()\r\n            path.mkdir(parents=True, exist_ok=True)\r\n\r\n            state_dict_ctx = _get_sharded_state_dict_context(module)\r\n\r\n            converted_state: dict[str, Any] = {}\r\n            metadata: dict[str, Any] = {}\r\n            with state_dict_ctx:\r\n                for key, obj in state.items():\r\n                    converted: Any\r\n                    if isinstance(obj, Module):\r\n                        converted = obj.state_dict()\r\n                        target_dict = converted_state\r\n                    elif isinstance(obj, Optimizer):\r\n                        converted = FSDP.optim_state_dict(module, obj)\r\n                        target_dict = converted_state\r\n                    else:  # everything not a module or optimizer is considered metadata\r\n                        converted = obj.state_dict() if isinstance(obj, _Stateful) else obj\r\n                        target_dict = metadata\r\n                    _apply_filter(key, filter or {}, converted, target_dict)\r\n\r\n            _distributed_checkpoint_save(converted_state, path)\r\n\r\n            if self.global_rank == 0:\r\n                torch.save(metadata, path / _METADATA_FILENAME)\r\n\r\n        elif self._state_dict_type == \"full\":\r\n            if _is_sharded_checkpoint(path):\r\n                shutil.rmtree(path)\r\n\r\n            state_dict_ctx = _get_full_state_dict_context(module, world_size=self.world_size)\r\n            full_state: dict[str, Any] = {}\r\n            with state_dict_ctx:\r\n                for key, obj in state.items():\r\n                    if isinstance(obj, Module):\r\n                        converted = obj.state_dict()\r\n                    elif isinstance(obj, Optimizer):\r\n                        converted = FSDP.optim_state_dict(module, obj)\r\n                    else:  # everything not a module or optimizer is considered metadata\r\n                        converted = obj.state_dict() if isinstance(obj, _Stateful) else obj\r\n                    _apply_filter(key, filter or {}, converted, full_state)\r\n\r\n            if self.global_rank == 0:\r\n                torch.save(full_state, path)\r\n        else:\r\n            raise ValueError(f\"Unknown state_dict_type: {self._state_dict_type}\")", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "storage_options", "is", "not", "None", ":", "raise", "TypeError", "(", "STRING", "STRING", ")", "if", "filter", "is", "not", "None", "and", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "raise", "NotImplementedError", "(", "STRING", ")", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "if", "path", ".", "is_dir", "(", ")", "and", "self", ".", "_state_dict_type", "=", "=", "STRING", "and", "not", "_is_sharded_checkpoint", "(", "path", ")", ":", "raise", "IsADirectoryError", "(", "fSTRING", ")", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "as", "FSDP", "modules", "=", "[", "module", "for", "module", "in", "state", ".", "values", "(", ")", "if", "_has_fsdp_modules", "(", "module", ")", "]", "if", "len", "(", "modules", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "if", "len", "(", "modules", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "module", "=", "modules", "[", "0", "]", "if", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "if", "path", ".", "is_file", "(", ")", ":", "path", ".", "unlink", "(", ")", "path", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "state_dict_ctx", "=", "_get_sharded_state_dict_context", "(", "module", ")", "converted_state", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "metadata", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "with", "state_dict_ctx", ":", "for", "key", ",", "obj", "in", "state", ".", "items", "(", ")", ":", "converted", ":", "Any", "if", "isinstance", "(", "obj", ",", "Module", ")", ":", "converted", "=", "obj", ".", "state_dict", "(", ")", "target_dict", "=", "converted_state", "elif", "isinstance", "(", "obj", ",", "Optimizer", ")", ":", "converted", "=", "FSDP", ".", "optim_state_dict", "(", "module", ",", "obj", ")", "target_dict", "=", "converted_state", "else", ":", "#", "everything", "not", "a", "module", "or", "optimizer", "is", "considered", "metadata", "converted", "=", "obj", ".", "state_dict", "(", ")", "if", "isinstance", "(", "obj", ",", "_Stateful", ")", "else", "obj", "target_dict", "=", "metadata", "_apply_filter", "(", "key", ",", "filter", "or", "{", "}", ",", "converted", ",", "target_dict", ")", "_distributed_checkpoint_save", "(", "converted_state", ",", "path", ")", "if", "self", ".", "global_rank", "=", "=", "0", ":", "torch", ".", "save", "(", "metadata", ",", "path", "/", "_METADATA_FILENAME", ")", "elif", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "if", "_is_sharded_checkpoint", "(", "path", ")", ":", "shutil", ".", "rmtree", "(", "path", ")", "state_dict_ctx", "=", "_get_full_state_dict_context", "(", "module", ",", "world_size", "=", "self", ".", "world_size", ")", "full_state", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "with", "state_dict_ctx", ":", "for", "key", ",", "obj", "in", "state", ".", "items", "(", ")", ":", "if", "isinstance", "(", "obj", ",", "Module", ")", ":", "converted", "=", "obj", ".", "state_dict", "(", ")", "elif", "isinstance", "(", "obj", ",", "Optimizer", ")", ":", "converted", "=", "FSDP", ".", "optim_state_dict", "(", "module", ",", "obj", ")", "else", ":", "#", "everything", "not", "a", "module", "or", "optimizer", "is", "considered", "metadata", "converted", "=", "obj", ".", "state_dict", "(", ")", "if", "isinstance", "(", "obj", ",", "_Stateful", ")", "else", "obj", "_apply_filter", "(", "key", ",", "filter", "or", "{", "}", ",", "converted", ",", "full_state", ")", "if", "self", "."], "docstring": "https://github.com/pytorch/pytorch/issues/105379 broadcast the path from rank 0 to ensure all the states are saved in a common path replace the modules and optimizer objects in the state with their local state dict and separate the user's metadata", "docstring_tokens": ["https", "github", "com", "pytorch", "pytorch", "issues", "105379", "broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "saved", "in", "a", "common", "path", "replace", "the", "modules", "and", "optimizer", "objects", "in", "the", "state", "with", "their", "local", "state", "dict", "and", "separate", "the", "user", "s", "metadata"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 413, "end_line": 510, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_41", "original_string": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got FSDPStrategy.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                f\" a model instance to reload is required. Pass it in like so:\"\r\n                \" FSDPStrategy.load_checkpoint(..., state={'model': model, ...})\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, Module):\r\n            from lightning.fabric.strategies.model_parallel import _load_raw_module_state_from_path\r\n\r\n            _load_raw_module_state_from_path(path, module=state, world_size=self.world_size, strict=strict)\r\n            return {}\r\n\r\n        if isinstance(state, Optimizer):\r\n            raise NotImplementedError(\r\n                \"Loading a single optimizer object from a checkpoint is not supported yet with the FSDP strategy.\"\r\n            )\r\n\r\n        from torch.distributed.checkpoint.optimizer import load_sharded_optimizer_state_dict\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n        modules = {key: module for key, module in state.items() if _has_fsdp_modules(module)}\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a FSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n            )\r\n        optimizers = {key: optim for key, optim in state.items() if isinstance(optim, Optimizer)}\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple FSDP models in the given state. Loading checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To load multiple models, call the\"\r\n                \" load method for each model separately with a different path.\"\r\n            )\r\n        module_key, module = list(modules.items())[0]\r\n\r\n        if _is_sharded_checkpoint(path):\r\n            state_dict_ctx = _get_sharded_state_dict_context(module)\r\n\r\n            with state_dict_ctx:\r\n                module_state = {module_key: module.state_dict()}\r\n                _distributed_checkpoint_load(module_state, path)\r\n                module.load_state_dict(module_state[module_key], strict=strict)\r\n\r\n                if optimizers:\r\n                    from torch.distributed.checkpoint import FileSystemReader\r\n\r\n                    reader = FileSystemReader(path=path)\r\n                    for optim_key, optim in optimizers.items():\r\n                        optim_state = load_sharded_optimizer_state_dict(\r\n                            model_state_dict=module_state[module_key],\r\n                            optimizer_key=optim_key,\r\n                            storage_reader=reader,\r\n                        )\r\n                        flattened_osd = FSDP.optim_state_dict_to_load(\r\n                            optim_state_dict=optim_state[optim_key],\r\n                            model=module,\r\n                            optim=optim,\r\n                        )\r\n                        optim.load_state_dict(flattened_osd)\r\n\r\n            metadata = torch.load(path / _METADATA_FILENAME)\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, metadata.keys(), strict=strict)\r\n            for key in requested_metadata_keys:\r\n                if key not in metadata:\r\n                    continue\r\n                state[key] = metadata.pop(key)\r\n\r\n            return metadata\r\n\r\n        if _is_full_checkpoint(path):\r\n            checkpoint = _lazy_load(path)\r\n\r\n            from lightning.fabric.strategies.model_parallel import (\r\n                _load_raw_module_state,\r\n                _rekey_optimizer_state_if_needed,\r\n            )\r\n\r\n            _load_raw_module_state(checkpoint.pop(module_key), module=module, world_size=self.world_size, strict=strict)\r\n\r\n            if isinstance(state, Module):\r\n                return {}\r\n\r\n            checkpoint = _materialize_tensors(checkpoint)\r\n\r\n            for optim_key, optim in optimizers.items():\r\n                with _get_full_state_dict_context(module, world_size=self.world_size, rank0_only=False):\r\n                    temp_state_dict = _rekey_optimizer_state_if_needed(checkpoint.pop(optim_key), module)\r\n                    optim_state_dict = FSDP.optim_state_dict_to_load(\r\n                        optim_state_dict=temp_state_dict,\r\n                        model=module,\r\n                        optim=optim,\r\n                    )\r\n                    optim.load_state_dict(optim_state_dict)\r\n\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, checkpoint.keys(), strict=strict)\r\n\r\n            _move_state_into(source=checkpoint, destination=state, keys=requested_metadata_keys)\r\n\r\n            return checkpoint\r\n\r\n        raise ValueError(\r\n            f\"The path {str(path)!r} does not point to a valid checkpoint. Make sure the path points to either a\"\r\n            \" directory with FSDP checkpoint shards, or a single file with a full checkpoint.\"\r\n        )", "language": "python", "code": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got FSDPStrategy.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                f\" a model instance to reload is required. Pass it in like so:\"\r\n                \" FSDPStrategy.load_checkpoint(..., state={'model': model, ...})\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, Module):\r\n            from lightning.fabric.strategies.model_parallel import _load_raw_module_state_from_path\r\n\r\n            _load_raw_module_state_from_path(path, module=state, world_size=self.world_size, strict=strict)\r\n            return {}\r\n\r\n        if isinstance(state, Optimizer):\r\n            raise NotImplementedError(\r\n                \"Loading a single optimizer object from a checkpoint is not supported yet with the FSDP strategy.\"\r\n            )\r\n\r\n        from torch.distributed.checkpoint.optimizer import load_sharded_optimizer_state_dict\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n        modules = {key: module for key, module in state.items() if _has_fsdp_modules(module)}\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a FSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n            )\r\n        optimizers = {key: optim for key, optim in state.items() if isinstance(optim, Optimizer)}\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple FSDP models in the given state. Loading checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To load multiple models, call the\"\r\n                \" load method for each model separately with a different path.\"\r\n            )\r\n        module_key, module = list(modules.items())[0]\r\n\r\n        if _is_sharded_checkpoint(path):\r\n            state_dict_ctx = _get_sharded_state_dict_context(module)\r\n\r\n            with state_dict_ctx:\r\n                module_state = {module_key: module.state_dict()}\r\n                _distributed_checkpoint_load(module_state, path)\r\n                module.load_state_dict(module_state[module_key], strict=strict)\r\n\r\n                if optimizers:\r\n                    from torch.distributed.checkpoint import FileSystemReader\r\n\r\n                    reader = FileSystemReader(path=path)\r\n                    for optim_key, optim in optimizers.items():\r\n                        optim_state = load_sharded_optimizer_state_dict(\r\n                            model_state_dict=module_state[module_key],\r\n                            optimizer_key=optim_key,\r\n                            storage_reader=reader,\r\n                        )\r\n                        flattened_osd = FSDP.optim_state_dict_to_load(\r\n                            optim_state_dict=optim_state[optim_key],\r\n                            model=module,\r\n                            optim=optim,\r\n                        )\r\n                        optim.load_state_dict(flattened_osd)\r\n\r\n            metadata = torch.load(path / _METADATA_FILENAME)\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, metadata.keys(), strict=strict)\r\n            for key in requested_metadata_keys:\r\n                if key not in metadata:\r\n                    continue\r\n                state[key] = metadata.pop(key)\r\n\r\n            return metadata\r\n\r\n        if _is_full_checkpoint(path):\r\n            checkpoint = _lazy_load(path)\r\n\r\n            from lightning.fabric.strategies.model_parallel import (\r\n                _load_raw_module_state,\r\n                _rekey_optimizer_state_if_needed,\r\n            )\r\n\r\n            _load_raw_module_state(checkpoint.pop(module_key), module=module, world_size=self.world_size, strict=strict)\r\n\r\n            if isinstance(state, Module):\r\n                return {}\r\n\r\n            checkpoint = _materialize_tensors(checkpoint)\r\n\r\n            for optim_key, optim in optimizers.items():\r\n                with _get_full_state_dict_context(module, world_size=self.world_size, rank0_only=False):\r\n                    temp_state_dict = _rekey_optimizer_state_if_needed(checkpoint.pop(optim_key), module)\r\n                    optim_state_dict = FSDP.optim_state_dict_to_load(\r\n                        optim_state_dict=temp_state_dict,\r\n                        model=module,\r\n                        optim=optim,\r\n                    )\r\n                    optim.load_state_dict(optim_state_dict)\r\n\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, checkpoint.keys(), strict=strict)\r\n\r\n            _move_state_into(source=checkpoint, destination=state, keys=requested_metadata_keys)\r\n\r\n            return checkpoint\r\n\r\n        raise ValueError(\r\n            f\"The path {str(path)!r} does not point to a valid checkpoint. Make sure the path points to either a\"\r\n            \" directory with FSDP checkpoint shards, or a single file with a full checkpoint.\"\r\n        )", "code_tokens": ["def", "load_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "Optional", "[", "Union", "[", "Module", ",", "Optimizer", ",", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", "]", "]", "=", "None", ",", "strict", ":", "bool", "=", "True", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "state", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", "STRING", ")", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "if", "isinstance", "(", "state", ",", "Module", ")", ":", "from", "lightning", ".", "fabric", ".", "strategies", ".", "model_parallel", "import", "_load_raw_module_state_from_path", "_load_raw_module_state_from_path", "(", "path", ",", "module", "=", "state", ",", "world_size", "=", "self", ".", "world_size", ",", "strict", "=", "strict", ")", "return", "{", "}", "if", "isinstance", "(", "state", ",", "Optimizer", ")", ":", "raise", "NotImplementedError", "(", "STRING", ")", "from", "torch", ".", "distributed", ".", "checkpoint", ".", "optimizer", "import", "load_sharded_optimizer_state_dict", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "as", "FSDP", "modules", "=", "{", "key", ":", "module", "for", "key", ",", "module", "in", "state", ".", "items", "(", ")", "if", "_has_fsdp_modules", "(", "module", ")", "}", "if", "len", "(", "modules", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "optimizers", "=", "{", "key", ":", "optim", "for", "key", ",", "optim", "in", "state", ".", "items", "(", ")", "if", "isinstance", "(", "optim", ",", "Optimizer", ")", "}", "if", "len", "(", "modules", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "module_key", ",", "module", "=", "list", "(", "modules", ".", "items", "(", ")", ")", "[", "0", "]", "if", "_is_sharded_checkpoint", "(", "path", ")", ":", "state_dict_ctx", "=", "_get_sharded_state_dict_context", "(", "module", ")", "with", "state_dict_ctx", ":", "module_state", "=", "{", "module_key", ":", "module", ".", "state_dict", "(", ")", "}", "_distributed_checkpoint_load", "(", "module_state", ",", "path", ")", "module", ".", "load_state_dict", "(", "module_state", "[", "module_key", "]", ",", "strict", "=", "strict", ")", "if", "optimizers", ":", "from", "torch", ".", "distributed", ".", "checkpoint", "import", "FileSystemReader", "reader", "=", "FileSystemReader", "(", "path", "=", "path", ")", "for", "optim_key", ",", "optim", "in", "optimizers", ".", "items", "(", ")", ":", "optim_state", "=", "load_sharded_optimizer_state_dict", "(", "model_state_dict", "=", "module_state", "[", "module_key", "]", ",", "optimizer_key", "=", "optim_key", ",", "storage_reader", "=", "reader", ",", ")", "flattened_osd", "=", "FSDP", ".", "optim_state_dict_to_load", "(", "optim_state_dict", "=", "optim_state", "[", "optim_key", "]", ",", "model", "=", "module", ",", "optim", "=", "optim", ",", ")", "optim", ".", "load_state_dict", "(", "flattened_osd", ")", "metadata", "=", "torch", ".", "load", "(", "path", "/", "_METADATA_FILENAME", ")", "requested_metadata_keys", "=", "state", ".", "keys", "(", ")", "-", "modules", ".", "keys", "(", ")", "-", "optimizers", ".", "keys", "(", ")", "_validate_keys_for_strict_loading", "(", "requested_metadata_keys", ",", "metadata", ".", "keys", "(", ")", ",", "strict", "=", "strict", ")", "for", "key", "in", "requested_metadata_keys", ":", "if", "key", "not", "in", "metadata", ":", "continue", "state", "[", "key", "]", "=", "metadata", ".", "pop", "(", "key", ")", "return", "metadata", "if", "_is_full_checkpoint", "(", "path", ")", ":", "checkpoint", "=", "_lazy_load", "(", "path", ")", "from", "lightning", ".", "fabric", ".", "strategies", ".", "model_parallel", "import", "(", "_load_raw_module_state", ",", "_rekey_optimizer_state_if_needed", ",", ")", "_load_raw_module_state", "(", "checkpoint", ".", "pop", "(", "module_key", ")", ",", "module", "=", "module", ",", "world_size", "=", "self", ".", "world_size", ",", "strict", "=", "strict", ")", "if", "isinstance", "(", "state", ",", "Module", ")", ":", "return", "{", "}", "checkpoint", "=", "_materialize_tensors", "(", "checkpoint", ")", "for", "optim_key", ",", "optim", "in", "optimizers", ".", "items", "(", ")", ":", "with", "_get_full_state_dict_context", "("], "docstring": "broadcast the path from rank 0 to ensure all the states are loaded from a common path TODO: replace with newer APIs https://github.com/pytorch/pytorch/issues/119800#issuecomment-1942156271 the optimizer states must be loaded separately Load metadata (anything not a module or optimizer) return the remaining metadata that wasn't requested as part of `state` Materialize lazy tensors if there are any left in the checkpoint The `torch.Optimizer.load_state_dict` method can't load lazy tensors because of deepcopy pickle issues Load optimizer states rank0_only should be false because we need to load the optimizer state on all ranks Load metadata (anything not a module or optimizer) return the remaining metadata that wasn't requested as part of `state`", "docstring_tokens": ["broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "loaded", "from", "a", "common", "path", "todo", "replace", "with", "newer", "apis", "https", "github", "com", "pytorch", "pytorch", "issues", "119800", "issuecomment", "1942156271", "the", "optimizer", "states", "must", "be", "loaded", "separately", "load", "metadata", "anything", "not", "a", "module", "or", "optimizer", "return", "the", "remaining", "metadata", "that", "wasn", "t", "requested", "as", "part", "of", "state", "materialize", "lazy", "tensors", "if", "there", "are", "any", "left", "in", "the", "checkpoint", "the", "torch", "optimizer", "load_state_dict", "method", "can", "t", "load", "lazy", "tensors", "because", "of", "deepcopy", "pickle", "issues", "load", "optimizer", "states", "rank0_only", "should", "be", "false", "because", "we", "need", "to", "load", "the", "optimizer", "state", "on", "all", "ranks", "load", "metadata", "anything", "not", "a", "module", "or", "optimizer", "return", "the", "remaining", "metadata", "that", "wasn", "t", "requested", "as", "part", "of", "state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 513, "end_line": 640, "has_examples": false, "num_comments": 10, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\fsdp.py", "func_name": "function_42", "original_string": "def no_backward_sync(self, module: Module, enabled: bool) -> AbstractContextManager:\r\n        \"\"\"Blocks gradient synchronization inside the :class:`~torch.distributed.fsdp.FullyShardedDataParallel`\r\n        wrapper.\"\"\"\r\n        if not enabled:\r\n            return nullcontext()\r\n        from torch.distributed.fsdp.fully_sharded_data_parallel import FullyShardedDataParallel\r\n\r\n        if not isinstance(module, FullyShardedDataParallel):\r\n            raise TypeError(\r\n                \"Blocking backward sync is only possible if the module passed to\"\r\n                f\" `{type(self).__name__}.no_backward_sync` is wrapped in `FullyShardedDataParallel`.\"\r\n                f\" Got: {module.__class__.__name__}.\"\r\n            )\r\n        return module.no_sync()", "language": "python", "code": "def no_backward_sync(self, module: Module, enabled: bool) -> AbstractContextManager:\r\n        \"\"\"Blocks gradient synchronization inside the :class:`~torch.distributed.fsdp.FullyShardedDataParallel`\r\n        wrapper.\"\"\"\r\n        if not enabled:\r\n            return nullcontext()\r\n        from torch.distributed.fsdp.fully_sharded_data_parallel import FullyShardedDataParallel\r\n\r\n        if not isinstance(module, FullyShardedDataParallel):\r\n            raise TypeError(\r\n                \"Blocking backward sync is only possible if the module passed to\"\r\n                f\" `{type(self).__name__}.no_backward_sync` is wrapped in `FullyShardedDataParallel`.\"\r\n                f\" Got: {module.__class__.__name__}.\"\r\n            )\r\n        return module.no_sync()", "code_tokens": ["def", "no_backward_sync", "(", "self", ",", "module", ":", "Module", ",", "enabled", ":", "bool", ")", "-", ">", "AbstractContextManager", ":", "STRING", "if", "not", "enabled", ":", "return", "nullcontext", "(", ")", "from", "torch", ".", "distributed", ".", "fsdp", ".", "fully_sharded_data_parallel", "import", "FullyShardedDataParallel", "if", "not", "isinstance", "(", "module", ",", "FullyShardedDataParallel", ")", ":", "raise", "TypeError", "(", "STRING", "fSTRING", "fSTRING", ")", "return", "module", ".", "no_sync", "(", ")"], "docstring": "the root must be wrapped", "docstring_tokens": ["the", "root", "must", "be", "wrapped"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\fsdp.py", "start_line": 745, "end_line": 759, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "func_name": "function_43", "original_string": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state to a checkpoint on disk.\r\n\r\n        If distributed checkpointing is enabled (default), the checkpoint gets saved as a directory containing one file\r\n        per process, with model- and optimizer shards stored per file. Additionally, it creates a metadata file\r\n        `meta.pt` with the rest of the user's state (only saved from rank 0).\r\n        If distributed checkpointing is disabled (``save_distributed_checkpoint=False``), the checkpoint will be\r\n        written to a single file containing the weights, optimizer state and other metadata.\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                f\"`{type(self).__name__}.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                f\" `{type(self).__name__}` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None and self._save_distributed_checkpoint:\r\n            raise NotImplementedError(\r\n                f\"{type(self).__name__} doesn't support loading distributed filtered checkpoints,\"\r\n                \" so saving them is disabled.\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n        _save_checkpoint(\r\n            path=path,\r\n            state=state,\r\n            full_state_dict=(not self._save_distributed_checkpoint),\r\n            rank=self.global_rank,\r\n            filter=filter,\r\n        )", "language": "python", "code": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state to a checkpoint on disk.\r\n\r\n        If distributed checkpointing is enabled (default), the checkpoint gets saved as a directory containing one file\r\n        per process, with model- and optimizer shards stored per file. Additionally, it creates a metadata file\r\n        `meta.pt` with the rest of the user's state (only saved from rank 0).\r\n        If distributed checkpointing is disabled (``save_distributed_checkpoint=False``), the checkpoint will be\r\n        written to a single file containing the weights, optimizer state and other metadata.\r\n\r\n        \"\"\"\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                f\"`{type(self).__name__}.save_checkpoint(..., storage_options=...)` is not supported because\"\r\n                f\" `{type(self).__name__}` does not use the `CheckpointIO`.\"\r\n            )\r\n        if filter is not None and self._save_distributed_checkpoint:\r\n            raise NotImplementedError(\r\n                f\"{type(self).__name__} doesn't support loading distributed filtered checkpoints,\"\r\n                \" so saving them is disabled.\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n        _save_checkpoint(\r\n            path=path,\r\n            state=state,\r\n            full_state_dict=(not self._save_distributed_checkpoint),\r\n            rank=self.global_rank,\r\n            filter=filter,\r\n        )", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "storage_options", "is", "not", "None", ":", "raise", "TypeError", "(", "fSTRING", "fSTRING", ")", "if", "filter", "is", "not", "None", "and", "self", ".", "_save_distributed_checkpoint", ":", "raise", "NotImplementedError", "(", "fSTRING", "STRING", ")", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "_save_checkpoint", "(", "path", "=", "path", ",", "state", "=", "state", ",", "full_state_dict", "=", "(", "not", "self", ".", "_save_distributed_checkpoint", ")", ",", "rank", "=", "self", ".", "global_rank", ",", "filter", "=", "filter", ",", ")"], "docstring": "https://github.com/pytorch/pytorch/issues/105379 broadcast the path from rank 0 to ensure all the states are saved in a common path", "docstring_tokens": ["https", "github", "com", "pytorch", "pytorch", "issues", "105379", "broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "saved", "in", "a", "common", "path"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "start_line": 234, "end_line": 269, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "func_name": "function_44", "original_string": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got {type(self).__name__}.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                \" a model instance to reload is required. Pass it in like so:\"\r\n                f\" {type(self).__name__}.load_checkpoint(..., state={{'model': model, ...}})\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, Module):\r\n            _load_raw_module_state_from_path(path, module=state, world_size=self.world_size, strict=strict)\r\n            return {}\r\n\r\n        if isinstance(state, Optimizer):\r\n            raise NotImplementedError(\r\n                f\"Loading a single optimizer object from a checkpoint is not supported yet with {type(self).__name__}.\"\r\n            )\r\n\r\n        return _load_checkpoint(path=path, state=state, strict=strict)", "language": "python", "code": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Load the contents from a checkpoint and restore the state of the given objects.\"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got {type(self).__name__}.load_checkpoint(..., state={state!r}) but a state with at least \"\r\n                \" a model instance to reload is required. Pass it in like so:\"\r\n                f\" {type(self).__name__}.load_checkpoint(..., state={{'model': model, ...}})\"\r\n            )\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, Module):\r\n            _load_raw_module_state_from_path(path, module=state, world_size=self.world_size, strict=strict)\r\n            return {}\r\n\r\n        if isinstance(state, Optimizer):\r\n            raise NotImplementedError(\r\n                f\"Loading a single optimizer object from a checkpoint is not supported yet with {type(self).__name__}.\"\r\n            )\r\n\r\n        return _load_checkpoint(path=path, state=state, strict=strict)", "code_tokens": ["def", "load_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "Optional", "[", "Union", "[", "Module", ",", "Optimizer", ",", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", "]", "]", "=", "None", ",", "strict", ":", "bool", "=", "True", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "state", ":", "raise", "ValueError", "(", "fSTRING", "STRING", "fSTRING", ")", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "if", "isinstance", "(", "state", ",", "Module", ")", ":", "_load_raw_module_state_from_path", "(", "path", ",", "module", "=", "state", ",", "world_size", "=", "self", ".", "world_size", ",", "strict", "=", "strict", ")", "return", "{", "}", "if", "isinstance", "(", "state", ",", "Optimizer", ")", ":", "raise", "NotImplementedError", "(", "fSTRING", ")", "return", "_load_checkpoint", "(", "path", "=", "path", ",", "state", "=", "state", ",", "strict", "=", "strict", ")"], "docstring": "broadcast the path from rank 0 to ensure all the states are loaded from a common path", "docstring_tokens": ["broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "loaded", "from", "a", "common", "path"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "start_line": 272, "end_line": 297, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "func_name": "function_45", "original_string": "def _load_raw_module_state_from_path(path: Path, module: Module, world_size: int, strict: bool = True) -> None:\r\n    \"\"\"Loads the state dict from a file path into the FSDP module.\"\"\"\r\n    if not _is_full_checkpoint(path):\r\n        raise ValueError(\r\n            \"Failed to load checkpoint directly into the model. The given path must be a single file containing the\"\r\n            f\" full state dict: {path}\"\r\n        )\r\n    state_dict = torch.load(path, mmap=True, map_location=\"cpu\") if _TORCH_GREATER_EQUAL_2_3 else _lazy_load(path)\r\n    _load_raw_module_state(state_dict=state_dict, module=module, world_size=world_size, strict=strict)", "language": "python", "code": "def _load_raw_module_state_from_path(path: Path, module: Module, world_size: int, strict: bool = True) -> None:\r\n    \"\"\"Loads the state dict from a file path into the FSDP module.\"\"\"\r\n    if not _is_full_checkpoint(path):\r\n        raise ValueError(\r\n            \"Failed to load checkpoint directly into the model. The given path must be a single file containing the\"\r\n            f\" full state dict: {path}\"\r\n        )\r\n    state_dict = torch.load(path, mmap=True, map_location=\"cpu\") if _TORCH_GREATER_EQUAL_2_3 else _lazy_load(path)\r\n    _load_raw_module_state(state_dict=state_dict, module=module, world_size=world_size, strict=strict)", "code_tokens": ["def", "_load_raw_module_state_from_path", "(", "path", ":", "Path", ",", "module", ":", "Module", ",", "world_size", ":", "int", ",", "strict", ":", "bool", "=", "True", ")", "-", ">", "None", ":", "STRING", "if", "not", "_is_full_checkpoint", "(", "path", ")", ":", "raise", "ValueError", "(", "STRING", "fSTRING", ")", "state_dict", "=", "torch", ".", "load", "(", "path", ",", "mmap", "=", "True", ",", "map_location", "=", "STRING", ")", "if", "_TORCH_GREATER_EQUAL_2_3", "else", "_lazy_load", "(", "path", ")", "_load_raw_module_state", "(", "state_dict", "=", "state_dict", ",", "module", "=", "module", ",", "world_size", "=", "world_size", ",", "strict", "=", "strict", ")"], "docstring": "Use `lazy_load`/`mmap` instead to avoid storing a copy of the full checkpoint per rank", "docstring_tokens": ["use", "lazy_load", "mmap", "instead", "to", "avoid", "storing", "a", "copy", "of", "the", "full", "checkpoint", "per", "rank"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "start_line": 529, "end_line": 538, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "func_name": "function_46", "original_string": "def _load_raw_module_state(\r\n    state_dict: dict[str, Any], module: Module, world_size: int = 1, strict: bool = True\r\n) -> None:\r\n    \"\"\"Loads the state dict into the module by gathering all weights first and then and writing back to each shard.\"\"\"\r\n    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n    if _has_dtensor_modules(module):\r\n        from torch.distributed.checkpoint.state_dict import StateDictOptions, set_model_state_dict\r\n\r\n        state_dict_options = StateDictOptions(\r\n            broadcast_from_rank0=True,\r\n            full_state_dict=True,\r\n            strict=False,\r\n        )\r\n\r\n        for submodule_name, submodule in module.named_modules():\r\n            for param_name, _ in _named_parameters_and_buffers_to_load(submodule):\r\n                full_param_name = f\"{submodule_name}{'.' if submodule_name else ''}{param_name}\"\r\n                if full_param_name not in state_dict:\r\n                    if not strict:\r\n                        continue\r\n                    raise KeyError(\r\n                        f\"The model contains a key '{full_param_name}' that does not exist in the loaded checkpoint.\"\r\n                        \" To disable strict loading, set `strict=False`.\"\r\n                    )\r\n                local_state_dict = {param_name: state_dict[full_param_name]}\r\n                set_model_state_dict(submodule, local_state_dict, options=state_dict_options)\r\n\r\n    elif isinstance(module, FSDP):\r\n        with _get_full_state_dict_context(module, world_size=world_size, rank0_only=False):\r\n            module.load_state_dict(state_dict, strict=strict)\r\n    else:\r\n        module.load_state_dict(state_dict, strict=strict)", "language": "python", "code": "def _load_raw_module_state(\r\n    state_dict: dict[str, Any], module: Module, world_size: int = 1, strict: bool = True\r\n) -> None:\r\n    \"\"\"Loads the state dict into the module by gathering all weights first and then and writing back to each shard.\"\"\"\r\n    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n\r\n    if _has_dtensor_modules(module):\r\n        from torch.distributed.checkpoint.state_dict import StateDictOptions, set_model_state_dict\r\n\r\n        state_dict_options = StateDictOptions(\r\n            broadcast_from_rank0=True,\r\n            full_state_dict=True,\r\n            strict=False,\r\n        )\r\n\r\n        for submodule_name, submodule in module.named_modules():\r\n            for param_name, _ in _named_parameters_and_buffers_to_load(submodule):\r\n                full_param_name = f\"{submodule_name}{'.' if submodule_name else ''}{param_name}\"\r\n                if full_param_name not in state_dict:\r\n                    if not strict:\r\n                        continue\r\n                    raise KeyError(\r\n                        f\"The model contains a key '{full_param_name}' that does not exist in the loaded checkpoint.\"\r\n                        \" To disable strict loading, set `strict=False`.\"\r\n                    )\r\n                local_state_dict = {param_name: state_dict[full_param_name]}\r\n                set_model_state_dict(submodule, local_state_dict, options=state_dict_options)\r\n\r\n    elif isinstance(module, FSDP):\r\n        with _get_full_state_dict_context(module, world_size=world_size, rank0_only=False):\r\n            module.load_state_dict(state_dict, strict=strict)\r\n    else:\r\n        module.load_state_dict(state_dict, strict=strict)", "code_tokens": ["def", "_load_raw_module_state", "(", "state_dict", ":", "dict", "[", "str", ",", "Any", "]", ",", "module", ":", "Module", ",", "world_size", ":", "int", "=", "1", ",", "strict", ":", "bool", "=", "True", ")", "-", ">", "None", ":", "STRING", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "as", "FSDP", "if", "_has_dtensor_modules", "(", "module", ")", ":", "from", "torch", ".", "distributed", ".", "checkpoint", ".", "state_dict", "import", "StateDictOptions", ",", "set_model_state_dict", "state_dict_options", "=", "StateDictOptions", "(", "broadcast_from_rank0", "=", "True", ",", "full_state_dict", "=", "True", ",", "strict", "=", "False", ",", ")", "for", "submodule_name", ",", "submodule", "in", "module", ".", "named_modules", "(", ")", ":", "for", "param_name", ",", "_", "in", "_named_parameters_and_buffers_to_load", "(", "submodule", ")", ":", "full_param_name", "=", "fSTRING", "if", "full_param_name", "not", "in", "state_dict", ":", "if", "not", "strict", ":", "continue", "raise", "KeyError", "(", "fSTRING", "STRING", ")", "local_state_dict", "=", "{", "param_name", ":", "state_dict", "[", "full_param_name", "]", "}", "set_model_state_dict", "(", "submodule", ",", "local_state_dict", ",", "options", "=", "state_dict_options", ")", "elif", "isinstance", "(", "module", ",", "FSDP", ")", ":", "with", "_get_full_state_dict_context", "(", "module", ",", "world_size", "=", "world_size", ",", "rank0_only", "=", "False", ")", ":", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "else", ":", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")"], "docstring": "must be set False to allow loading each param separately below", "docstring_tokens": ["must", "be", "set", "false", "to", "allow", "loading", "each", "param", "separately", "below"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\model_parallel.py", "start_line": 541, "end_line": 574, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\strategy.py", "func_name": "function_47", "original_string": "def get_optimizer_state(self, optimizer: Optimizer) -> dict[str, Tensor]:\r\n        \"\"\"Returns state of an optimizer.\r\n\r\n        Allows for syncing/collating optimizer state from processes in custom plugins.\r\n\r\n        \"\"\"\r\n        if hasattr(optimizer, \"consolidate_state_dict\"):\r\n            optimizer.consolidate_state_dict()\r\n            return optimizer.state_dict() if self.is_global_zero else {}\r\n\r\n        return optimizer.state_dict()", "language": "python", "code": "def get_optimizer_state(self, optimizer: Optimizer) -> dict[str, Tensor]:\r\n        \"\"\"Returns state of an optimizer.\r\n\r\n        Allows for syncing/collating optimizer state from processes in custom plugins.\r\n\r\n        \"\"\"\r\n        if hasattr(optimizer, \"consolidate_state_dict\"):\r\n            optimizer.consolidate_state_dict()\r\n            return optimizer.state_dict() if self.is_global_zero else {}\r\n\r\n        return optimizer.state_dict()", "code_tokens": ["def", "get_optimizer_state", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "dict", "[", "str", ",", "Tensor", "]", ":", "STRING", "if", "hasattr", "(", "optimizer", ",", "STRING", ")", ":", "optimizer", ".", "consolidate_state_dict", "(", ")", "return", "optimizer", ".", "state_dict", "(", ")", "if", "self", ".", "is_global_zero", "else", "{", "}", "return", "optimizer", ".", "state_dict", "(", ")"], "docstring": "there are optimizers like PyTorch's ZeroRedundancyOptimizer that shard their states, and to avoid OOM we consolidate the full state on rank 0 only for optimizers that are not sharded, we return the state dict on all ranks", "docstring_tokens": ["there", "are", "optimizers", "like", "pytorch", "s", "zeroredundancyoptimizer", "that", "shard", "their", "states", "and", "to", "avoid", "oom", "we", "consolidate", "the", "full", "state", "on", "rank", "0", "only", "for", "optimizers", "that", "are", "not", "sharded", "we", "return", "the", "state", "dict", "on", "all", "ranks"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\strategy.py", "start_line": 292, "end_line": 305, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\xla.py", "func_name": "function_48", "original_string": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state as a checkpoint file.\r\n\r\n        Args:\r\n            path: A path to where the file(s) should be saved\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            storage_options: Additional options for the ``CheckpointIO`` plugin\r\n            filter: An optional dictionary of the same format as ``state`` mapping keys to callables that return a\r\n                boolean indicating whether the given parameter should be saved (``True``) or filtered out (``False``).\r\n\r\n        \"\"\"\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        xm.mark_step()\r\n        super().save_checkpoint(path, state, storage_options=storage_options, filter=filter)", "language": "python", "code": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state as a checkpoint file.\r\n\r\n        Args:\r\n            path: A path to where the file(s) should be saved\r\n            state: A dictionary with contents to be saved. If the dict contains modules or optimizers, their\r\n                state-dict will be retrieved and converted automatically.\r\n            storage_options: Additional options for the ``CheckpointIO`` plugin\r\n            filter: An optional dictionary of the same format as ``state`` mapping keys to callables that return a\r\n                boolean indicating whether the given parameter should be saved (``True``) or filtered out (``False``).\r\n\r\n        \"\"\"\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        xm.mark_step()\r\n        super().save_checkpoint(path, state, storage_options=storage_options, filter=filter)", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "xm", ".", "mark_step", "(", ")", "super", "(", ")", ".", "save_checkpoint", "(", "path", ",", "state", ",", "storage_options", "=", "storage_options", ",", "filter", "=", "filter", ")"], "docstring": "sync any pending lazy tensors on all ranks before saving to prevent potential collective hangs save on global rank zero only", "docstring_tokens": ["sync", "any", "pending", "lazy", "tensors", "on", "all", "ranks", "before", "saving", "to", "prevent", "potential", "collective", "hangs", "save", "on", "global", "rank", "zero", "only"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\xla.py", "start_line": 275, "end_line": 298, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\xla_fsdp.py", "func_name": "function_49", "original_string": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state in the provided checkpoint directory.\r\n\r\n        If the user specifies sharded checkpointing, the directory will contain one file per process, with model- and\r\n        optimizer shards stored per file. If the user specifies full checkpointing, the directory will contain a\r\n        consolidated checkpoint combining all of the sharded checkpoints.\r\n\r\n        \"\"\"\r\n        path = Path(self.broadcast(path))\r\n        if path.is_dir() and any(path.iterdir()):\r\n            raise FileExistsError(f\"The checkpoint directory already exists and is not empty: {path}\")\r\n        from torch_xla.distributed.fsdp import XlaFullyShardedDataParallel as XLAFSDP\r\n\r\n        modules = [module for module in state.values() if isinstance(module, XLAFSDP)]\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a XLAFSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple XLAFSDP modules in the given state. Saving checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        xm.mark_step()\r\n\r\n        parallel_devices = self.parallel_devices\r\n        assert parallel_devices is not None\r\n        if self._sequential_save:\r\n            for rank in range(len(parallel_devices)):\r\n                if rank == self.local_rank:\r\n                    self._save_checkpoint_shard(path, state, storage_options, filter)\r\n                self.barrier(f\"wait-for-{rank}-save\")\r\n        else:\r\n            self._save_checkpoint_shard(path, state, storage_options, filter)\r\n\r\n        if self._state_dict_type == \"full\":\r\n            ckpt_prefix = str(path / \"checkpoint\")\r\n            ckpt_suffix = \"_rank-*-of-*.pth\"\r\n            if len(parallel_devices) != self.world_size:  # multihost\r\n                raise OSError(\r\n                    \"Multihost setups do not have a shared filesystem, so the checkpoint shards cannot be consolidated\"\r\n                    \" into a single checkpoint after saving them. Please switch to\"\r\n                    \" `XLAFSDPStrategy(state_dict_type='sharded')`. TIP: You can consolidate them manually by getting\"\r\n                    \" them together into a single directory and running `python -m\"\r\n                    f\" torch_xla.distributed.fsdp.consolidate_sharded_ckpts --ckpt_prefix {ckpt_prefix!r} --ckpt_suffix\"\r\n                    f\" {ckpt_suffix!r} --save_path 'path/to/consolidated.ckpt'`.\"\r\n                )\r\n\r\n            from torch_xla.distributed.fsdp import consolidate_sharded_model_checkpoints\r\n\r\n            self.barrier(\"before_ckpt_consolidation\")\r\n            if self.is_global_zero:\r\n                save_path = path.parent / \"consolidated.ckpt\"\r\n                consolidate_sharded_model_checkpoints(ckpt_prefix, ckpt_suffix, str(save_path))\r\n                self.checkpoint_io.remove_checkpoint(path)\r\n                get_filesystem(save_path).mv(str(save_path), str(path))\r\n            self.barrier(\"after_ckpt_consolidation\")", "language": "python", "code": "def save_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: dict[str, Union[Module, Optimizer, Any]],\r\n        storage_options: Optional[Any] = None,\r\n        filter: Optional[dict[str, Callable[[str, Any], bool]]] = None,\r\n    ) -> None:\r\n        \"\"\"Save model, optimizer, and other state in the provided checkpoint directory.\r\n\r\n        If the user specifies sharded checkpointing, the directory will contain one file per process, with model- and\r\n        optimizer shards stored per file. If the user specifies full checkpointing, the directory will contain a\r\n        consolidated checkpoint combining all of the sharded checkpoints.\r\n\r\n        \"\"\"\r\n        path = Path(self.broadcast(path))\r\n        if path.is_dir() and any(path.iterdir()):\r\n            raise FileExistsError(f\"The checkpoint directory already exists and is not empty: {path}\")\r\n        from torch_xla.distributed.fsdp import XlaFullyShardedDataParallel as XLAFSDP\r\n\r\n        modules = [module for module in state.values() if isinstance(module, XLAFSDP)]\r\n        if len(modules) == 0:\r\n            raise ValueError(\r\n                \"Could not find a XLAFSDP model in the provided checkpoint state. Please provide the model as\"\r\n                \" part of the state like so: `save_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                \" you set up the model (and optimizers if any) through the strategy before saving the checkpoint.\"\r\n            )\r\n        if len(modules) > 1:\r\n            raise ValueError(\r\n                \"Found multiple XLAFSDP modules in the given state. Saving checkpoints with FSDP is\"\r\n                \" currently limited to a single model per checkpoint. To save multiple models, call the\"\r\n                \" save method for each model separately with a different path.\"\r\n            )\r\n        import torch_xla.core.xla_model as xm\r\n\r\n        xm.mark_step()\r\n\r\n        parallel_devices = self.parallel_devices\r\n        assert parallel_devices is not None\r\n        if self._sequential_save:\r\n            for rank in range(len(parallel_devices)):\r\n                if rank == self.local_rank:\r\n                    self._save_checkpoint_shard(path, state, storage_options, filter)\r\n                self.barrier(f\"wait-for-{rank}-save\")\r\n        else:\r\n            self._save_checkpoint_shard(path, state, storage_options, filter)\r\n\r\n        if self._state_dict_type == \"full\":\r\n            ckpt_prefix = str(path / \"checkpoint\")\r\n            ckpt_suffix = \"_rank-*-of-*.pth\"\r\n            if len(parallel_devices) != self.world_size:  # multihost\r\n                raise OSError(\r\n                    \"Multihost setups do not have a shared filesystem, so the checkpoint shards cannot be consolidated\"\r\n                    \" into a single checkpoint after saving them. Please switch to\"\r\n                    \" `XLAFSDPStrategy(state_dict_type='sharded')`. TIP: You can consolidate them manually by getting\"\r\n                    \" them together into a single directory and running `python -m\"\r\n                    f\" torch_xla.distributed.fsdp.consolidate_sharded_ckpts --ckpt_prefix {ckpt_prefix!r} --ckpt_suffix\"\r\n                    f\" {ckpt_suffix!r} --save_path 'path/to/consolidated.ckpt'`.\"\r\n                )\r\n\r\n            from torch_xla.distributed.fsdp import consolidate_sharded_model_checkpoints\r\n\r\n            self.barrier(\"before_ckpt_consolidation\")\r\n            if self.is_global_zero:\r\n                save_path = path.parent / \"consolidated.ckpt\"\r\n                consolidate_sharded_model_checkpoints(ckpt_prefix, ckpt_suffix, str(save_path))\r\n                self.checkpoint_io.remove_checkpoint(path)\r\n                get_filesystem(save_path).mv(str(save_path), str(path))\r\n            self.barrier(\"after_ckpt_consolidation\")", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ",", "filter", ":", "Optional", "[", "dict", "[", "str", ",", "Callable", "[", "[", "str", ",", "Any", "]", ",", "bool", "]", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "if", "path", ".", "is_dir", "(", ")", "and", "any", "(", "path", ".", "iterdir", "(", ")", ")", ":", "raise", "FileExistsError", "(", "fSTRING", ")", "from", "torch_xla", ".", "distributed", ".", "fsdp", "import", "XlaFullyShardedDataParallel", "as", "XLAFSDP", "modules", "=", "[", "module", "for", "module", "in", "state", ".", "values", "(", ")", "if", "isinstance", "(", "module", ",", "XLAFSDP", ")", "]", "if", "len", "(", "modules", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "if", "len", "(", "modules", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "xm", ".", "mark_step", "(", ")", "parallel_devices", "=", "self", ".", "parallel_devices", "assert", "parallel_devices", "is", "not", "None", "if", "self", ".", "_sequential_save", ":", "for", "rank", "in", "range", "(", "len", "(", "parallel_devices", ")", ")", ":", "if", "rank", "=", "=", "self", ".", "local_rank", ":", "self", ".", "_save_checkpoint_shard", "(", "path", ",", "state", ",", "storage_options", ",", "filter", ")", "self", ".", "barrier", "(", "fSTRING", ")", "else", ":", "self", ".", "_save_checkpoint_shard", "(", "path", ",", "state", ",", "storage_options", ",", "filter", ")", "if", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "ckpt_prefix", "=", "str", "(", "path", "/", "STRING", ")", "ckpt_suffix", "=", "STRING", "if", "len", "(", "parallel_devices", ")", "!", "=", "self", ".", "world_size", ":", "#", "multihost", "raise", "OSError", "(", "STRING", "STRING", "STRING", "STRING", "fSTRING", "fSTRING", ")", "from", "torch_xla", ".", "distributed", ".", "fsdp", "import", "consolidate_sharded_model_checkpoints", "self", ".", "barrier", "(", "STRING", ")", "if", "self", ".", "is_global_zero", ":", "save_path", "=", "path", ".", "parent", "/", "STRING", "consolidate_sharded_model_checkpoints", "(", "ckpt_prefix", ",", "ckpt_suffix", ",", "str", "(", "save_path", ")", ")", "self", ".", "checkpoint_io", ".", "remove_checkpoint", "(", "path", ")", "get_filesystem", "(", "save_path", ")", ".", "mv", "(", "str", "(", "save_path", ")", ",", "str", "(", "path", ")", ")", "self", ".", "barrier", "(", "STRING", ")"], "docstring": "broadcast the path from rank 0 to ensure all the states are saved in a common path ensure model parameters are updated each host runs this in parallel, but the ranks in the host run it sequentially save consolidated checkpoint separate to the shards remove the shards directory mv the consolidated checkpoint where the user would expect it", "docstring_tokens": ["broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "saved", "in", "a", "common", "path", "ensure", "model", "parameters", "are", "updated", "each", "host", "runs", "this", "in", "parallel", "but", "the", "ranks", "in", "the", "host", "run", "it", "sequentially", "save", "consolidated", "checkpoint", "separate", "to", "the", "shards", "remove", "the", "shards", "directory", "mv", "the", "consolidated", "checkpoint", "where", "the", "user", "would", "expect", "it"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\xla_fsdp.py", "start_line": 409, "end_line": 482, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\xla_fsdp.py", "func_name": "function_50", "original_string": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Given a folder, load the contents from a checkpoint and restore the state of the given objects.\r\n\r\n        The strategy currently only supports saving and loading sharded checkpoints which are stored in form of a\r\n        directory of multiple files rather than a single file.\r\n\r\n        \"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got `XLAFSDPStrategy.load_checkpoint(..., state={state!r})` but a state with at least \"\r\n                \" a model instance to reload is required. Pass it in like so:\"\r\n                \" `FSDPStrategy.load_checkpoint(..., state={'model': model, ...})`\"\r\n            )\r\n\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, (Module, Optimizer)):\r\n            raise NotImplementedError(\r\n                \"Loading a single module or optimizer object from a checkpoint\"\r\n                \" is not supported yet with the XLAFSDP strategy.\"\r\n            )\r\n\r\n        from torch_xla.distributed.fsdp import XlaFullyShardedDataParallel as XLAFSDP\r\n\r\n        modules = {key: module for key, module in state.items() if isinstance(module, XLAFSDP)}\r\n        optimizers = {key: optim for key, optim in state.items() if isinstance(optim, Optimizer)}\r\n        if self._state_dict_type == \"sharded\":\r\n            file = path / f\"checkpoint_rank-{self.global_rank:08d}-of-{self.world_size:08d}.pth\"\r\n            if not file.is_file():\r\n                raise ValueError(\r\n                    f\"The path {str(file)!r} does not point to valid sharded checkpoints. Make sure the path points to\"\r\n                    \" a directory with XLAFSDP checkpoint shards.\"\r\n                )\r\n            if len(modules) == 0:\r\n                raise ValueError(\r\n                    \"Could not find a XLAFSDP model in the provided checkpoint state. Please provide the model as\"\r\n                    \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                    \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n                )\r\n            if len(modules) > 1:\r\n                raise ValueError(\r\n                    \"Found multiple XLAFSDP modules in the given state. Loading checkpoints with FSDP is\"\r\n                    \" currently limited to a single model per checkpoint. To load multiple models, call the\"\r\n                    \" load method for each model separately with a different path.\"\r\n                )\r\n\r\n            _, module = list(modules.items())[0]\r\n            sharded_ckpt = torch.load(file)\r\n\r\n            module.load_state_dict(sharded_ckpt[\"model\"], strict=strict)\r\n            for opt_key, opt in optimizers.items():\r\n                opt.load_state_dict(sharded_ckpt[opt_key])\r\n\r\n            loaded_metadata_keys = sharded_ckpt.keys() - modules.keys() - optimizers.keys()\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, loaded_metadata_keys, strict=strict)\r\n            for key in requested_metadata_keys:\r\n                if key in loaded_metadata_keys:\r\n                    state[key] = sharded_ckpt[key]\r\n                    loaded_metadata_keys.remove(key)\r\n\r\n            metadata = {}\r\n            if len(loaded_metadata_keys):\r\n                for key in loaded_metadata_keys:\r\n                    metadata[key] = sharded_ckpt[key]\r\n\r\n            if \"shard_metadata\" in metadata:\r\n                metadata.pop(\"shard_metadata\")\r\n\r\n            return metadata\r\n\r\n        if self._state_dict_type == \"full\":\r\n            if not path.is_file():\r\n                raise ValueError(\r\n                    f\"The path {str(path)!r} does not point to a valid full checkpoint. Make sure the path points to a\"\r\n                    \" directory with a full XLAFSDP checkpoint.\"\r\n                )\r\n            if len(optimizers) > 0 or len(state.keys() - modules.keys() - optimizers.keys()) > 0:\r\n                rank_zero_warn(\r\n                    \"Loading a full checkpoint will only load the full model.\"\r\n                    \" The optimizer and any additional metadata are not included.\"\r\n                )\r\n            if len(modules) > 0:\r\n                raise ValueError(\r\n                    \"Found a XLAFSDP model in the provided checkpoint state.\"\r\n                    \" Please provide the model without any XLAFSDP wrapper.\"\r\n                )\r\n            if \"model\" not in state or not isinstance(model := state[\"model\"], torch.nn.Module):\r\n                raise NotImplementedError(\"XLAFSDP only supports a single model instance with 'model' as the key.\")\r\n            full_ckpt = torch.load(path)\r\n            model.load_state_dict(full_ckpt.pop(\"model\"), strict=strict)\r\n            return full_ckpt\r\n\r\n        raise ValueError(f\"Unknown state_dict_type: {self._state_dict_type}\")", "language": "python", "code": "def load_checkpoint(\r\n        self,\r\n        path: _PATH,\r\n        state: Optional[Union[Module, Optimizer, dict[str, Union[Module, Optimizer, Any]]]] = None,\r\n        strict: bool = True,\r\n    ) -> dict[str, Any]:\r\n        \"\"\"Given a folder, load the contents from a checkpoint and restore the state of the given objects.\r\n\r\n        The strategy currently only supports saving and loading sharded checkpoints which are stored in form of a\r\n        directory of multiple files rather than a single file.\r\n\r\n        \"\"\"\r\n        if not state:\r\n            raise ValueError(\r\n                f\"Got `XLAFSDPStrategy.load_checkpoint(..., state={state!r})` but a state with at least \"\r\n                \" a model instance to reload is required. Pass it in like so:\"\r\n                \" `FSDPStrategy.load_checkpoint(..., state={'model': model, ...})`\"\r\n            )\r\n\r\n        path = Path(self.broadcast(path))\r\n\r\n        if isinstance(state, (Module, Optimizer)):\r\n            raise NotImplementedError(\r\n                \"Loading a single module or optimizer object from a checkpoint\"\r\n                \" is not supported yet with the XLAFSDP strategy.\"\r\n            )\r\n\r\n        from torch_xla.distributed.fsdp import XlaFullyShardedDataParallel as XLAFSDP\r\n\r\n        modules = {key: module for key, module in state.items() if isinstance(module, XLAFSDP)}\r\n        optimizers = {key: optim for key, optim in state.items() if isinstance(optim, Optimizer)}\r\n        if self._state_dict_type == \"sharded\":\r\n            file = path / f\"checkpoint_rank-{self.global_rank:08d}-of-{self.world_size:08d}.pth\"\r\n            if not file.is_file():\r\n                raise ValueError(\r\n                    f\"The path {str(file)!r} does not point to valid sharded checkpoints. Make sure the path points to\"\r\n                    \" a directory with XLAFSDP checkpoint shards.\"\r\n                )\r\n            if len(modules) == 0:\r\n                raise ValueError(\r\n                    \"Could not find a XLAFSDP model in the provided checkpoint state. Please provide the model as\"\r\n                    \" part of the state like so: `load_checkpoint(..., state={'model': model, ...})`. Make sure\"\r\n                    \" you set up the model (and optimizers if any) through the strategy before loading the checkpoint.\"\r\n                )\r\n            if len(modules) > 1:\r\n                raise ValueError(\r\n                    \"Found multiple XLAFSDP modules in the given state. Loading checkpoints with FSDP is\"\r\n                    \" currently limited to a single model per checkpoint. To load multiple models, call the\"\r\n                    \" load method for each model separately with a different path.\"\r\n                )\r\n\r\n            _, module = list(modules.items())[0]\r\n            sharded_ckpt = torch.load(file)\r\n\r\n            module.load_state_dict(sharded_ckpt[\"model\"], strict=strict)\r\n            for opt_key, opt in optimizers.items():\r\n                opt.load_state_dict(sharded_ckpt[opt_key])\r\n\r\n            loaded_metadata_keys = sharded_ckpt.keys() - modules.keys() - optimizers.keys()\r\n            requested_metadata_keys = state.keys() - modules.keys() - optimizers.keys()\r\n            _validate_keys_for_strict_loading(requested_metadata_keys, loaded_metadata_keys, strict=strict)\r\n            for key in requested_metadata_keys:\r\n                if key in loaded_metadata_keys:\r\n                    state[key] = sharded_ckpt[key]\r\n                    loaded_metadata_keys.remove(key)\r\n\r\n            metadata = {}\r\n            if len(loaded_metadata_keys):\r\n                for key in loaded_metadata_keys:\r\n                    metadata[key] = sharded_ckpt[key]\r\n\r\n            if \"shard_metadata\" in metadata:\r\n                metadata.pop(\"shard_metadata\")\r\n\r\n            return metadata\r\n\r\n        if self._state_dict_type == \"full\":\r\n            if not path.is_file():\r\n                raise ValueError(\r\n                    f\"The path {str(path)!r} does not point to a valid full checkpoint. Make sure the path points to a\"\r\n                    \" directory with a full XLAFSDP checkpoint.\"\r\n                )\r\n            if len(optimizers) > 0 or len(state.keys() - modules.keys() - optimizers.keys()) > 0:\r\n                rank_zero_warn(\r\n                    \"Loading a full checkpoint will only load the full model.\"\r\n                    \" The optimizer and any additional metadata are not included.\"\r\n                )\r\n            if len(modules) > 0:\r\n                raise ValueError(\r\n                    \"Found a XLAFSDP model in the provided checkpoint state.\"\r\n                    \" Please provide the model without any XLAFSDP wrapper.\"\r\n                )\r\n            if \"model\" not in state or not isinstance(model := state[\"model\"], torch.nn.Module):\r\n                raise NotImplementedError(\"XLAFSDP only supports a single model instance with 'model' as the key.\")\r\n            full_ckpt = torch.load(path)\r\n            model.load_state_dict(full_ckpt.pop(\"model\"), strict=strict)\r\n            return full_ckpt\r\n\r\n        raise ValueError(f\"Unknown state_dict_type: {self._state_dict_type}\")", "code_tokens": ["def", "load_checkpoint", "(", "self", ",", "path", ":", "_PATH", ",", "state", ":", "Optional", "[", "Union", "[", "Module", ",", "Optimizer", ",", "dict", "[", "str", ",", "Union", "[", "Module", ",", "Optimizer", ",", "Any", "]", "]", "]", "]", "=", "None", ",", "strict", ":", "bool", "=", "True", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "state", ":", "raise", "ValueError", "(", "fSTRING", "STRING", "STRING", ")", "path", "=", "Path", "(", "self", ".", "broadcast", "(", "path", ")", ")", "if", "isinstance", "(", "state", ",", "(", "Module", ",", "Optimizer", ")", ")", ":", "raise", "NotImplementedError", "(", "STRING", "STRING", ")", "from", "torch_xla", ".", "distributed", ".", "fsdp", "import", "XlaFullyShardedDataParallel", "as", "XLAFSDP", "modules", "=", "{", "key", ":", "module", "for", "key", ",", "module", "in", "state", ".", "items", "(", ")", "if", "isinstance", "(", "module", ",", "XLAFSDP", ")", "}", "optimizers", "=", "{", "key", ":", "optim", "for", "key", ",", "optim", "in", "state", ".", "items", "(", ")", "if", "isinstance", "(", "optim", ",", "Optimizer", ")", "}", "if", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "file", "=", "path", "/", "fSTRING", "if", "not", "file", ".", "is_file", "(", ")", ":", "raise", "ValueError", "(", "fSTRING", "STRING", ")", "if", "len", "(", "modules", ")", "=", "=", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "if", "len", "(", "modules", ")", ">", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", "STRING", ")", "_", ",", "module", "=", "list", "(", "modules", ".", "items", "(", ")", ")", "[", "0", "]", "sharded_ckpt", "=", "torch", ".", "load", "(", "file", ")", "module", ".", "load_state_dict", "(", "sharded_ckpt", "[", "STRING", "]", ",", "strict", "=", "strict", ")", "for", "opt_key", ",", "opt", "in", "optimizers", ".", "items", "(", ")", ":", "opt", ".", "load_state_dict", "(", "sharded_ckpt", "[", "opt_key", "]", ")", "loaded_metadata_keys", "=", "sharded_ckpt", ".", "keys", "(", ")", "-", "modules", ".", "keys", "(", ")", "-", "optimizers", ".", "keys", "(", ")", "requested_metadata_keys", "=", "state", ".", "keys", "(", ")", "-", "modules", ".", "keys", "(", ")", "-", "optimizers", ".", "keys", "(", ")", "_validate_keys_for_strict_loading", "(", "requested_metadata_keys", ",", "loaded_metadata_keys", ",", "strict", "=", "strict", ")", "for", "key", "in", "requested_metadata_keys", ":", "if", "key", "in", "loaded_metadata_keys", ":", "state", "[", "key", "]", "=", "sharded_ckpt", "[", "key", "]", "loaded_metadata_keys", ".", "remove", "(", "key", ")", "metadata", "=", "{", "}", "if", "len", "(", "loaded_metadata_keys", ")", ":", "for", "key", "in", "loaded_metadata_keys", ":", "metadata", "[", "key", "]", "=", "sharded_ckpt", "[", "key", "]", "if", "STRING", "in", "metadata", ":", "metadata", ".", "pop", "(", "STRING", ")", "return", "metadata", "if", "self", ".", "_state_dict_type", "=", "=", "STRING", ":", "if", "not", "path", ".", "is_file", "(", ")", ":", "raise", "ValueError", "(", "fSTRING", "STRING", ")", "if", "len", "(", "optimizers", ")", ">", "0", "or", "len", "(", "state", ".", "keys", "(", ")", "-", "modules", ".", "keys", "(", ")", "-", "optimizers", ".", "keys", "(", ")", ")", ">", "0", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "if", "len", "(", "modules", ")", ">", "0", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "if", "STRING", "not", "in", "state", "or", "not", "isinstance", "(", "model", ":", "=", "state", "[", "STRING", "]", ",", "torch", ".", "nn", ".", "Module", ")", ":", "raise", "NotImplementedError", "(", "STRING", ")", "full_ckpt", "=", "torch", ".", "load", "(", "path", ")", "model", ".", "load_state_dict", "(", "full_ckpt", ".", "pop", "(", "STRING", ")", ",", "strict", "=", "strict", ")", "return", "full_ckpt", "raise", "ValueError", "(", "fSTRING", ")"], "docstring": "broadcast the path from rank 0 to ensure all the states are loaded from a common path Load anything leftover from sharded_ckpt remove \"shard_metadata\" that is loaded in", "docstring_tokens": ["broadcast", "the", "path", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "loaded", "from", "a", "common", "path", "load", "anything", "leftover", "from", "sharded_ckpt", "remove", "shard_metadata", "that", "is", "loaded", "in"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\xla_fsdp.py", "start_line": 513, "end_line": 614, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\launchers\\multiprocessing.py", "func_name": "function_51", "original_string": "def launch(self, function: Callable, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._start_method in (\"fork\", \"forkserver\"):\r\n            _check_bad_cuda_fork()\r\n        if self._start_method == \"spawn\":\r\n            _check_missing_main_guard()\r\n\r\n        assert self._strategy.cluster_environment is not None\r\n        os.environ[\"MASTER_PORT\"] = str(self._strategy.cluster_environment.main_port)\r\n\r\n        context = mp.get_context(self._start_method)\r\n        return_queue = context.SimpleQueue()\r\n\r\n        if self._start_method == \"spawn\":\r\n            global_states = _GlobalStateSnapshot.capture()\r\n            process_args = [function, args, kwargs, return_queue, global_states]\r\n        else:\r\n            process_args = [function, args, kwargs, return_queue]\r\n\r\n        mp.start_processes(\r\n            self._wrapping_function,\r\n            args=process_args,\r\n            nprocs=self._strategy.num_processes,\r\n            start_method=self._start_method,\r\n        )\r\n        return return_queue.get()", "language": "python", "code": "def launch(self, function: Callable, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._start_method in (\"fork\", \"forkserver\"):\r\n            _check_bad_cuda_fork()\r\n        if self._start_method == \"spawn\":\r\n            _check_missing_main_guard()\r\n\r\n        assert self._strategy.cluster_environment is not None\r\n        os.environ[\"MASTER_PORT\"] = str(self._strategy.cluster_environment.main_port)\r\n\r\n        context = mp.get_context(self._start_method)\r\n        return_queue = context.SimpleQueue()\r\n\r\n        if self._start_method == \"spawn\":\r\n            global_states = _GlobalStateSnapshot.capture()\r\n            process_args = [function, args, kwargs, return_queue, global_states]\r\n        else:\r\n            process_args = [function, args, kwargs, return_queue]\r\n\r\n        mp.start_processes(\r\n            self._wrapping_function,\r\n            args=process_args,\r\n            nprocs=self._strategy.num_processes,\r\n            start_method=self._start_method,\r\n        )\r\n        return return_queue.get()", "code_tokens": ["def", "launch", "(", "self", ",", "function", ":", "Callable", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "if", "self", ".", "_start_method", "in", "(", "STRING", ",", "STRING", ")", ":", "_check_bad_cuda_fork", "(", ")", "if", "self", ".", "_start_method", "=", "=", "STRING", ":", "_check_missing_main_guard", "(", ")", "assert", "self", ".", "_strategy", ".", "cluster_environment", "is", "not", "None", "os", ".", "environ", "[", "STRING", "]", "=", "str", "(", "self", ".", "_strategy", ".", "cluster_environment", ".", "main_port", ")", "context", "=", "mp", ".", "get_context", "(", "self", ".", "_start_method", ")", "return_queue", "=", "context", ".", "SimpleQueue", "(", ")", "if", "self", ".", "_start_method", "=", "=", "STRING", ":", "global_states", "=", "_GlobalStateSnapshot", ".", "capture", "(", ")", "process_args", "=", "[", "function", ",", "args", ",", "kwargs", ",", "return_queue", ",", "global_states", "]", "else", ":", "process_args", "=", "[", "function", ",", "args", ",", "kwargs", ",", "return_queue", "]", "mp", ".", "start_processes", "(", "self", ".", "_wrapping_function", ",", "args", "=", "process_args", ",", "nprocs", "=", "self", ".", "_strategy", ".", "num_processes", ",", "start_method", "=", "self", ".", "_start_method", ",", ")", "return", "return_queue", ".", "get", "(", ")"], "docstring": "The default cluster environment in Lightning chooses a random free port number This needs to be done in the main process here before starting processes to ensure each rank will connect through the same port", "docstring_tokens": ["the", "default", "cluster", "environment", "in", "lightning", "chooses", "a", "random", "free", "port", "number", "this", "needs", "to", "be", "done", "in", "the", "main", "process", "here", "before", "starting", "processes", "to", "ensure", "each", "rank", "will", "connect", "through", "the", "same", "port"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\launchers\\multiprocessing.py", "start_line": 84, "end_line": 122, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\launchers\\multiprocessing.py", "func_name": "function_52", "original_string": "def _check_missing_main_guard() -> None:\r\n    \"\"\"Raises an exception if the ``__name__ == \"__main__\"`` guard is missing.\"\"\"\r\n    if not getattr(mp.current_process(), \"_inheriting\", False):\r\n        return\r\n    message = dedent(\r\n        \"\"\"\r\n        Launching multiple processes with the 'spawn' start method requires that your script guards the main\r\n        function with an `if __name__ == \\\"__main__\\\"` clause. For example:\r\n\r\n        def main():\r\n            ...\r\n\r\n        if __name__ == \"__main__\":\r\n            main()\r\n\r\n        Alternatively, you can run with `strategy=\"ddp\"` to avoid this error.\r\n        \"\"\"\r\n    )\r\n    raise RuntimeError(message)", "language": "python", "code": "def _check_missing_main_guard() -> None:\r\n    \"\"\"Raises an exception if the ``__name__ == \"__main__\"`` guard is missing.\"\"\"\r\n    if not getattr(mp.current_process(), \"_inheriting\", False):\r\n        return\r\n    message = dedent(\r\n        \"\"\"\r\n        Launching multiple processes with the 'spawn' start method requires that your script guards the main\r\n        function with an `if __name__ == \\\"__main__\\\"` clause. For example:\r\n\r\n        def main():\r\n            ...\r\n\r\n        if __name__ == \"__main__\":\r\n            main()\r\n\r\n        Alternatively, you can run with `strategy=\"ddp\"` to avoid this error.\r\n        \"\"\"\r\n    )\r\n    raise RuntimeError(message)", "code_tokens": ["def", "_check_missing_main_guard", "(", ")", "-", ">", "None", ":", "STRING", "if", "not", "getattr", "(", "mp", ".", "current_process", "(", ")", ",", "STRING", ",", "False", ")", ":", "return", "message", "=", "dedent", "(", "STRING", ")", "raise", "RuntimeError", "(", "message", ")"], "docstring": "Put your code here", "docstring_tokens": ["put", "your", "code", "here"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\launchers\\multiprocessing.py", "start_line": 229, "end_line": 248, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\strategies\\launchers\\xla.py", "func_name": "function_53", "original_string": "def launch(self, function: Callable, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        return_queue: Union[queue.Queue, mp.SimpleQueue]\r\n        return_queue = mp.Manager().Queue()\r\n\r\n        import torch_xla.distributed.xla_multiprocessing as xmp\r\n\r\n        spawn_kwargs = {}\r\n        nprocs = self._strategy.num_processes\r\n        if nprocs == 1:\r\n            spawn_kwargs[\"nprocs\"] = nprocs\r\n\r\n        xmp.spawn(\r\n            self._wrapping_function,\r\n            args=(function, args, kwargs, return_queue),\r\n            start_method=self._start_method,\r\n            **spawn_kwargs,\r\n        )\r\n        return return_queue.get()", "language": "python", "code": "def launch(self, function: Callable, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        return_queue: Union[queue.Queue, mp.SimpleQueue]\r\n        return_queue = mp.Manager().Queue()\r\n\r\n        import torch_xla.distributed.xla_multiprocessing as xmp\r\n\r\n        spawn_kwargs = {}\r\n        nprocs = self._strategy.num_processes\r\n        if nprocs == 1:\r\n            spawn_kwargs[\"nprocs\"] = nprocs\r\n\r\n        xmp.spawn(\r\n            self._wrapping_function,\r\n            args=(function, args, kwargs, return_queue),\r\n            start_method=self._start_method,\r\n            **spawn_kwargs,\r\n        )\r\n        return return_queue.get()", "code_tokens": ["def", "launch", "(", "self", ",", "function", ":", "Callable", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "return_queue", ":", "Union", "[", "queue", ".", "Queue", ",", "mp", ".", "SimpleQueue", "]", "return_queue", "=", "mp", ".", "Manager", "(", ")", ".", "Queue", "(", ")", "import", "torch_xla", ".", "distributed", ".", "xla_multiprocessing", "as", "xmp", "spawn_kwargs", "=", "{", "}", "nprocs", "=", "self", ".", "_strategy", ".", "num_processes", "if", "nprocs", "=", "=", "1", ":", "spawn_kwargs", "[", "STRING", "]", "=", "nprocs", "xmp", ".", "spawn", "(", "self", ".", "_wrapping_function", ",", "args", "=", "(", "function", ",", "args", ",", "kwargs", ",", "return_queue", ")", ",", "start_method", "=", "self", ".", "_start_method", ",", "*", "*", "spawn_kwargs", ",", ")", "return", "return_queue", ".", "get", "(", ")"], "docstring": "avoid warning: \"Unsupported nprocs\". If it's 1, it will call the launched function directly. otherwise it will use all devices", "docstring_tokens": ["avoid", "warning", "unsupported", "nprocs", "if", "it", "s", "1", "it", "will", "call", "the", "launched", "function", "directly", "otherwise", "it", "will", "use", "all", "devices"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\strategies\\launchers\\xla.py", "start_line": 58, "end_line": 88, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\apply_func.py", "func_name": "function_54", "original_string": "def move_data_to_device(batch: Any, device: _DEVICE) -> Any:\r\n    \"\"\"Transfers a collection of data to the given device. Any object that defines a method ``to(device)`` will be\r\n    moved and all other objects in the collection will be left untouched.\r\n\r\n    Args:\r\n        batch: A tensor or collection of tensors or anything that has a method ``.to(...)``.\r\n            See :func:`apply_to_collection` for a list of supported collection types.\r\n        device: The device to which the data should be moved\r\n\r\n    Return:\r\n        the same collection but with all contained tensors residing on the new device.\r\n\r\n    See Also:\r\n        - :meth:`torch.Tensor.to`\r\n        - :class:`torch.device`\r\n\r\n    \"\"\"\r\n    if isinstance(device, str):\r\n        device = torch.device(device)\r\n\r\n    def batch_to(data: Any) -> Any:\r\n        kwargs = {}\r\n        if isinstance(data, Tensor) and isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES:\r\n            kwargs[\"non_blocking\"] = True\r\n        data_output = data.to(device, **kwargs)\r\n        if data_output is not None:\r\n            return data_output\r\n        return data\r\n\r\n    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)", "language": "python", "code": "def move_data_to_device(batch: Any, device: _DEVICE) -> Any:\r\n    \"\"\"Transfers a collection of data to the given device. Any object that defines a method ``to(device)`` will be\r\n    moved and all other objects in the collection will be left untouched.\r\n\r\n    Args:\r\n        batch: A tensor or collection of tensors or anything that has a method ``.to(...)``.\r\n            See :func:`apply_to_collection` for a list of supported collection types.\r\n        device: The device to which the data should be moved\r\n\r\n    Return:\r\n        the same collection but with all contained tensors residing on the new device.\r\n\r\n    See Also:\r\n        - :meth:`torch.Tensor.to`\r\n        - :class:`torch.device`\r\n\r\n    \"\"\"\r\n    if isinstance(device, str):\r\n        device = torch.device(device)\r\n\r\n    def batch_to(data: Any) -> Any:\r\n        kwargs = {}\r\n        if isinstance(data, Tensor) and isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES:\r\n            kwargs[\"non_blocking\"] = True\r\n        data_output = data.to(device, **kwargs)\r\n        if data_output is not None:\r\n            return data_output\r\n        return data\r\n\r\n    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)", "code_tokens": ["def", "move_data_to_device", "(", "batch", ":", "Any", ",", "device", ":", "_DEVICE", ")", "-", ">", "Any", ":", "STRING", "if", "isinstance", "(", "device", ",", "str", ")", ":", "device", "=", "torch", ".", "device", "(", "device", ")", "def", "batch_to", "(", "data", ":", "Any", ")", "-", ">", "Any", ":", "kwargs", "=", "{", "}", "if", "isinstance", "(", "data", ",", "Tensor", ")", "and", "isinstance", "(", "device", ",", "torch", ".", "device", ")", "and", "device", ".", "type", "not", "in", "_BLOCKING_DEVICE_TYPES", ":", "kwargs", "[", "STRING", "]", "=", "True", "data_output", "=", "data", ".", "to", "(", "device", ",", "*", "*", "kwargs", ")", "if", "data_output", "is", "not", "None", ":", "return", "data_output", "return", "data", "return", "apply_to_collection", "(", "batch", ",", "dtype", "=", "_TransferableDataType", ",", "function", "=", "batch_to", ")"], "docstring": "Don't issue non-blocking transfers to CPU Same with MPS due to a race condition bug: https://github.com/pytorch/pytorch/issues/83015 user wrongly implemented the `_TransferableDataType` and forgot to return `self`.", "docstring_tokens": ["don", "t", "issue", "non", "blocking", "transfers", "to", "cpu", "same", "with", "mps", "due", "to", "a", "race", "condition", "bug", "https", "github", "com", "pytorch", "pytorch", "issues", "83015", "user", "wrongly", "implemented", "the", "_transferabledatatype", "and", "forgot", "to", "return", "self"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\apply_func.py", "start_line": 77, "end_line": 109, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "func_name": "function_55", "original_string": "def _load(\r\n    path_or_url: Union[IO, _PATH],\r\n    map_location: _MAP_LOCATION_TYPE = None,\r\n    weights_only: bool = False,\r\n) -> Any:\r\n    \"\"\"Loads a checkpoint.\r\n\r\n    Args:\r\n        path_or_url: Path or URL of the checkpoint.\r\n        map_location: a function, ``torch.device``, string or a dict specifying how to remap storage locations.\r\n\r\n    \"\"\"\r\n    if not isinstance(path_or_url, (str, Path)):\r\n        return torch.load(\r\n            path_or_url,\r\n            map_location=map_location,  # type: ignore[arg-type] # upstream annotation is not correct\r\n            weights_only=weights_only,\r\n        )\r\n    if str(path_or_url).startswith(\"http\"):\r\n        return torch.hub.load_state_dict_from_url(\r\n            str(path_or_url),\r\n            map_location=map_location,  # type: ignore[arg-type]\r\n            weights_only=weights_only,\r\n        )\r\n    fs = get_filesystem(path_or_url)\r\n    with fs.open(path_or_url, \"rb\") as f:\r\n        return torch.load(\r\n            f,\r\n            map_location=map_location,  # type: ignore[arg-type]\r\n            weights_only=weights_only,\r\n        )", "language": "python", "code": "def _load(\r\n    path_or_url: Union[IO, _PATH],\r\n    map_location: _MAP_LOCATION_TYPE = None,\r\n    weights_only: bool = False,\r\n) -> Any:\r\n    \"\"\"Loads a checkpoint.\r\n\r\n    Args:\r\n        path_or_url: Path or URL of the checkpoint.\r\n        map_location: a function, ``torch.device``, string or a dict specifying how to remap storage locations.\r\n\r\n    \"\"\"\r\n    if not isinstance(path_or_url, (str, Path)):\r\n        return torch.load(\r\n            path_or_url,\r\n            map_location=map_location,  # type: ignore[arg-type] # upstream annotation is not correct\r\n            weights_only=weights_only,\r\n        )\r\n    if str(path_or_url).startswith(\"http\"):\r\n        return torch.hub.load_state_dict_from_url(\r\n            str(path_or_url),\r\n            map_location=map_location,  # type: ignore[arg-type]\r\n            weights_only=weights_only,\r\n        )\r\n    fs = get_filesystem(path_or_url)\r\n    with fs.open(path_or_url, \"rb\") as f:\r\n        return torch.load(\r\n            f,\r\n            map_location=map_location,  # type: ignore[arg-type]\r\n            weights_only=weights_only,\r\n        )", "code_tokens": ["def", "_load", "(", "path_or_url", ":", "Union", "[", "IO", ",", "_PATH", "]", ",", "map_location", ":", "_MAP_LOCATION_TYPE", "=", "None", ",", "weights_only", ":", "bool", "=", "False", ",", ")", "-", ">", "Any", ":", "STRING", "if", "not", "isinstance", "(", "path_or_url", ",", "(", "str", ",", "Path", ")", ")", ":", "return", "torch", ".", "load", "(", "path_or_url", ",", "map_location", "=", "map_location", ",", "#", "type", ":", "ignore", "[", "arg", "-", "type", "]", "#", "upstream", "annotation", "is", "not", "correct", "weights_only", "=", "weights_only", ",", ")", "if", "str", "(", "path_or_url", ")", ".", "startswith", "(", "STRING", ")", ":", "return", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "str", "(", "path_or_url", ")", ",", "map_location", "=", "map_location", ",", "#", "type", ":", "ignore", "[", "arg", "-", "type", "]", "weights_only", "=", "weights_only", ",", ")", "fs", "=", "get_filesystem", "(", "path_or_url", ")", "with", "fs", ".", "open", "(", "path_or_url", ",", "STRING", ")", "as", "f", ":", "return", "torch", ".", "load", "(", "f", ",", "map_location", "=", "map_location", ",", "#", "type", ":", "ignore", "[", "arg", "-", "type", "]", "weights_only", "=", "weights_only", ",", ")"], "docstring": "any sort of BytesIO or similar", "docstring_tokens": ["any", "sort", "of", "bytesio", "or", "similar"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "start_line": 33, "end_line": 64, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "func_name": "function_56", "original_string": "def _atomic_save(checkpoint: dict[str, Any], filepath: Union[str, Path]) -> None:\r\n    \"\"\"Saves a checkpoint atomically, avoiding the creation of incomplete checkpoints.\r\n\r\n    Args:\r\n        checkpoint: The object to save.\r\n            Built to be used with the ``dump_checkpoint`` method, but can deal with anything which ``torch.save``\r\n            accepts.\r\n        filepath: The path to which the checkpoint will be saved.\r\n            This points to the file that the checkpoint will be stored in.\r\n\r\n    \"\"\"\r\n    bytesbuffer = io.BytesIO()\r\n    log.debug(f\"Saving checkpoint: {filepath}\")\r\n    torch.save(checkpoint, bytesbuffer)\r\n\r\n    try:\r\n        fs, urlpath = fsspec.core.url_to_fs(str(filepath))\r\n        with fs.transaction, fs.open(urlpath, \"wb\") as f:\r\n            f.write(bytesbuffer.getvalue())\r\n    except PermissionError as e:\r\n        if isinstance(e.__context__, OSError) and getattr(e.__context__, \"errno\", None) == errno.EXDEV:\r\n            raise RuntimeError(\r\n                'Upgrade fsspec to enable cross-device local checkpoints: pip install \"fsspec[http]>=2025.5.0\"',\r\n            ) from e", "language": "python", "code": "def _atomic_save(checkpoint: dict[str, Any], filepath: Union[str, Path]) -> None:\r\n    \"\"\"Saves a checkpoint atomically, avoiding the creation of incomplete checkpoints.\r\n\r\n    Args:\r\n        checkpoint: The object to save.\r\n            Built to be used with the ``dump_checkpoint`` method, but can deal with anything which ``torch.save``\r\n            accepts.\r\n        filepath: The path to which the checkpoint will be saved.\r\n            This points to the file that the checkpoint will be stored in.\r\n\r\n    \"\"\"\r\n    bytesbuffer = io.BytesIO()\r\n    log.debug(f\"Saving checkpoint: {filepath}\")\r\n    torch.save(checkpoint, bytesbuffer)\r\n\r\n    try:\r\n        fs, urlpath = fsspec.core.url_to_fs(str(filepath))\r\n        with fs.transaction, fs.open(urlpath, \"wb\") as f:\r\n            f.write(bytesbuffer.getvalue())\r\n    except PermissionError as e:\r\n        if isinstance(e.__context__, OSError) and getattr(e.__context__, \"errno\", None) == errno.EXDEV:\r\n            raise RuntimeError(\r\n                'Upgrade fsspec to enable cross-device local checkpoints: pip install \"fsspec[http]>=2025.5.0\"',\r\n            ) from e", "code_tokens": ["def", "_atomic_save", "(", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ",", "filepath", ":", "Union", "[", "str", ",", "Path", "]", ")", "-", ">", "None", ":", "STRING", "bytesbuffer", "=", "io", ".", "BytesIO", "(", ")", "log", ".", "debug", "(", "fSTRING", ")", "torch", ".", "save", "(", "checkpoint", ",", "bytesbuffer", ")", "try", ":", "fs", ",", "urlpath", "=", "fsspec", ".", "core", ".", "url_to_fs", "(", "str", "(", "filepath", ")", ")", "with", "fs", ".", "transaction", ",", "fs", ".", "open", "(", "urlpath", ",", "STRING", ")", "as", "f", ":", "f", ".", "write", "(", "bytesbuffer", ".", "getvalue", "(", ")", ")", "except", "PermissionError", "as", "e", ":", "if", "isinstance", "(", "e", ".", "__context__", ",", "OSError", ")", "and", "getattr", "(", "e", ".", "__context__", ",", "STRING", ",", "None", ")", "=", "=", "errno", ".", "EXDEV", ":", "raise", "RuntimeError", "(", "STRING", ",", ")", "from", "e"], "docstring": "We use a transaction here to avoid file corruption if the save gets interrupted", "docstring_tokens": ["we", "use", "a", "transaction", "here", "to", "avoid", "file", "corruption", "if", "the", "save", "gets", "interrupted"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "start_line": 72, "end_line": 96, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "func_name": "function_57", "original_string": "def _is_dir(fs: AbstractFileSystem, path: Union[str, Path], strict: bool = False) -> bool:\r\n    \"\"\"Check if a path is directory-like.\r\n\r\n    This function determines if a given path is considered directory-like, taking into account the behavior\r\n    specific to object storage platforms. For other filesystems, it behaves similarly to the standard `fs.isdir`\r\n    method.\r\n\r\n    Args:\r\n        fs: The filesystem to check the path against.\r\n        path: The path or URL to be checked.\r\n        strict: A flag specific to Object Storage platforms. If set to ``False``, any non-existing path is considered\r\n            as a valid directory-like path. In such cases, the directory (and any non-existing parent directories)\r\n            will be created on the fly. Defaults to False.\r\n\r\n    \"\"\"\r\n    if _is_object_storage(fs):\r\n        if strict:\r\n            return fs.isdir(path)\r\n\r\n        return not fs.isfile(path)\r\n\r\n    return fs.isdir(path)", "language": "python", "code": "def _is_dir(fs: AbstractFileSystem, path: Union[str, Path], strict: bool = False) -> bool:\r\n    \"\"\"Check if a path is directory-like.\r\n\r\n    This function determines if a given path is considered directory-like, taking into account the behavior\r\n    specific to object storage platforms. For other filesystems, it behaves similarly to the standard `fs.isdir`\r\n    method.\r\n\r\n    Args:\r\n        fs: The filesystem to check the path against.\r\n        path: The path or URL to be checked.\r\n        strict: A flag specific to Object Storage platforms. If set to ``False``, any non-existing path is considered\r\n            as a valid directory-like path. In such cases, the directory (and any non-existing parent directories)\r\n            will be created on the fly. Defaults to False.\r\n\r\n    \"\"\"\r\n    if _is_object_storage(fs):\r\n        if strict:\r\n            return fs.isdir(path)\r\n\r\n        return not fs.isfile(path)\r\n\r\n    return fs.isdir(path)", "code_tokens": ["def", "_is_dir", "(", "fs", ":", "AbstractFileSystem", ",", "path", ":", "Union", "[", "str", ",", "Path", "]", ",", "strict", ":", "bool", "=", "False", ")", "-", ">", "bool", ":", "STRING", "if", "_is_object_storage", "(", "fs", ")", ":", "if", "strict", ":", "return", "fs", ".", "isdir", "(", "path", ")", "return", "not", "fs", ".", "isfile", "(", "path", ")", "return", "fs", ".", "isdir", "(", "path", ")"], "docstring": "Object storage fsspec's are inconsistent with other file systems because they do not have real directories, see for instance https://gcsfs.readthedocs.io/en/latest/api.html?highlight=makedirs#gcsfs.core.GCSFileSystem.mkdir In particular, `fs.makedirs` is a no-op so we use `strict=False` to consider any path as valid, except if the path already exists but is a file Check if the path is not already taken by a file. If not, it is considered a valid directory-like path because the directory (and all non-existing parent directories) will be created on the fly.", "docstring_tokens": ["object", "storage", "fsspec", "s", "are", "inconsistent", "with", "other", "file", "systems", "because", "they", "do", "not", "have", "real", "directories", "see", "for", "instance", "https", "gcsfs", "readthedocs", "io", "en", "latest", "api", "html", "highlight", "makedirs", "gcsfs", "core", "gcsfilesystem", "mkdir", "in", "particular", "fs", "makedirs", "is", "a", "no", "op", "so", "we", "use", "strict", "false", "to", "consider", "any", "path", "as", "valid", "except", "if", "the", "path", "already", "exists", "but", "is", "a", "file", "check", "if", "the", "path", "is", "not", "already", "taken", "by", "a", "file", "if", "not", "it", "is", "considered", "a", "valid", "directory", "like", "path", "because", "the", "directory", "and", "all", "non", "existing", "parent", "directories", "will", "be", "created", "on", "the", "fly"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\cloud_io.py", "start_line": 121, "end_line": 148, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_58", "original_string": "def sized_len(dataloader: object) -> Optional[int]:\r\n    \"\"\"Try to get the length of an object, return ``None`` otherwise.\"\"\"\r\n    try:\r\n        length = len(dataloader)  # type: ignore [arg-type]\r\n    except (TypeError, NotImplementedError):\r\n        length = None\r\n    return length", "language": "python", "code": "def sized_len(dataloader: object) -> Optional[int]:\r\n    \"\"\"Try to get the length of an object, return ``None`` otherwise.\"\"\"\r\n    try:\r\n        length = len(dataloader)  # type: ignore [arg-type]\r\n    except (TypeError, NotImplementedError):\r\n        length = None\r\n    return length", "code_tokens": ["def", "sized_len", "(", "dataloader", ":", "object", ")", "-", ">", "Optional", "[", "int", "]", ":", "STRING", "try", ":", "length", "=", "len", "(", "dataloader", ")", "#", "type", ":", "ignore", "[", "arg", "-", "type", "]", "except", "(", "TypeError", ",", "NotImplementedError", ")", ":", "length", "=", "None", "return", "length"], "docstring": "try getting the length", "docstring_tokens": ["try", "getting", "the", "length"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 47, "end_line": 54, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_59", "original_string": "def _dataloader_init_kwargs_resolve_sampler(\r\n    dataloader: DataLoader,\r\n    sampler: Union[Sampler, Iterable],\r\n) -> dict[str, Any]:\r\n    \"\"\"This function is used to handle the sampler, batch_sampler arguments associated within a DataLoader for its re-\r\n    instantiation.\"\"\"\r\n    batch_sampler = getattr(dataloader, \"batch_sampler\")\r\n\r\n    if batch_sampler is not None and type(batch_sampler) is not BatchSampler:\r\n        batch_sampler_cls = type(batch_sampler)\r\n        if hasattr(batch_sampler, \"__pl_saved_args\"):\r\n            args = batch_sampler.__pl_saved_args\r\n            kwargs = batch_sampler.__pl_saved_kwargs\r\n            default_kwargs = batch_sampler.__pl_saved_default_kwargs\r\n            arg_names = batch_sampler.__pl_saved_arg_names\r\n\r\n            success, args, kwargs = _replace_value_in_saved_args(\r\n                \"sampler\", sampler, args, kwargs, default_kwargs, arg_names\r\n            )\r\n            if not success:\r\n                raise TypeError(\r\n                    \"Trying to inject a modified sampler into the batch sampler; however, it seems the class \"\r\n                    f\"`{batch_sampler_cls.__qualname__}` does not have an argument called `sampler.` To mitigate \"\r\n                    \"this, expose an argument `sampler` in the `__init__` method of your custom class.\"\r\n                )\r\n\r\n            batch_sampler = _reinstantiate_wrapped_cls(batch_sampler, *args, **kwargs)\r\n        elif hasattr(batch_sampler, \"batch_size\") and hasattr(batch_sampler, \"drop_last\"):\r\n            try:\r\n                batch_sampler = batch_sampler_cls(\r\n                    sampler,\r\n                    batch_size=batch_sampler.batch_size,\r\n                    drop_last=batch_sampler.drop_last,\r\n                )\r\n            except TypeError as ex:\r\n                import re\r\n\r\n                match = re.match(r\".*__init__\\(\\) (got multiple values)|(missing \\d required)\", str(ex))\r\n                if not match:\r\n                    raise\r\n\r\n                raise TypeError(\r\n                    \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                    \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                    \" or set`.setup_dataloaders(..., use_distributed_sampler=False)`. If you choose the latter, you\"\r\n                    \" will be responsible for handling the distributed sampling within your batch sampler.\"\r\n                ) from ex\r\n        else:\r\n            raise TypeError(\r\n                \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                \" or set`.setup_dataloaders(..., use_distributed_sampler=False)`. If you choose the latter, you\"\r\n                \" will be responsible for handling the distributed sampling within your batch sampler.\"\r\n            )\r\n\r\n        return {\r\n            \"sampler\": None,\r\n            \"shuffle\": False,\r\n            \"batch_sampler\": batch_sampler,\r\n            \"batch_size\": 1,\r\n            \"drop_last\": False,\r\n        }\r\n\r\n    return {\"sampler\": sampler, \"shuffle\": False, \"batch_sampler\": None}", "language": "python", "code": "def _dataloader_init_kwargs_resolve_sampler(\r\n    dataloader: DataLoader,\r\n    sampler: Union[Sampler, Iterable],\r\n) -> dict[str, Any]:\r\n    \"\"\"This function is used to handle the sampler, batch_sampler arguments associated within a DataLoader for its re-\r\n    instantiation.\"\"\"\r\n    batch_sampler = getattr(dataloader, \"batch_sampler\")\r\n\r\n    if batch_sampler is not None and type(batch_sampler) is not BatchSampler:\r\n        batch_sampler_cls = type(batch_sampler)\r\n        if hasattr(batch_sampler, \"__pl_saved_args\"):\r\n            args = batch_sampler.__pl_saved_args\r\n            kwargs = batch_sampler.__pl_saved_kwargs\r\n            default_kwargs = batch_sampler.__pl_saved_default_kwargs\r\n            arg_names = batch_sampler.__pl_saved_arg_names\r\n\r\n            success, args, kwargs = _replace_value_in_saved_args(\r\n                \"sampler\", sampler, args, kwargs, default_kwargs, arg_names\r\n            )\r\n            if not success:\r\n                raise TypeError(\r\n                    \"Trying to inject a modified sampler into the batch sampler; however, it seems the class \"\r\n                    f\"`{batch_sampler_cls.__qualname__}` does not have an argument called `sampler.` To mitigate \"\r\n                    \"this, expose an argument `sampler` in the `__init__` method of your custom class.\"\r\n                )\r\n\r\n            batch_sampler = _reinstantiate_wrapped_cls(batch_sampler, *args, **kwargs)\r\n        elif hasattr(batch_sampler, \"batch_size\") and hasattr(batch_sampler, \"drop_last\"):\r\n            try:\r\n                batch_sampler = batch_sampler_cls(\r\n                    sampler,\r\n                    batch_size=batch_sampler.batch_size,\r\n                    drop_last=batch_sampler.drop_last,\r\n                )\r\n            except TypeError as ex:\r\n                import re\r\n\r\n                match = re.match(r\".*__init__\\(\\) (got multiple values)|(missing \\d required)\", str(ex))\r\n                if not match:\r\n                    raise\r\n\r\n                raise TypeError(\r\n                    \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                    \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                    \" or set`.setup_dataloaders(..., use_distributed_sampler=False)`. If you choose the latter, you\"\r\n                    \" will be responsible for handling the distributed sampling within your batch sampler.\"\r\n                ) from ex\r\n        else:\r\n            raise TypeError(\r\n                \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                \" or set`.setup_dataloaders(..., use_distributed_sampler=False)`. If you choose the latter, you\"\r\n                \" will be responsible for handling the distributed sampling within your batch sampler.\"\r\n            )\r\n\r\n        return {\r\n            \"sampler\": None,\r\n            \"shuffle\": False,\r\n            \"batch_sampler\": batch_sampler,\r\n            \"batch_size\": 1,\r\n            \"drop_last\": False,\r\n        }\r\n\r\n    return {\"sampler\": sampler, \"shuffle\": False, \"batch_sampler\": None}", "code_tokens": ["def", "_dataloader_init_kwargs_resolve_sampler", "(", "dataloader", ":", "DataLoader", ",", "sampler", ":", "Union", "[", "Sampler", ",", "Iterable", "]", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "batch_sampler", "=", "getattr", "(", "dataloader", ",", "STRING", ")", "if", "batch_sampler", "is", "not", "None", "and", "type", "(", "batch_sampler", ")", "is", "not", "BatchSampler", ":", "batch_sampler_cls", "=", "type", "(", "batch_sampler", ")", "if", "hasattr", "(", "batch_sampler", ",", "STRING", ")", ":", "args", "=", "batch_sampler", ".", "__pl_saved_args", "kwargs", "=", "batch_sampler", ".", "__pl_saved_kwargs", "default_kwargs", "=", "batch_sampler", ".", "__pl_saved_default_kwargs", "arg_names", "=", "batch_sampler", ".", "__pl_saved_arg_names", "success", ",", "args", ",", "kwargs", "=", "_replace_value_in_saved_args", "(", "STRING", ",", "sampler", ",", "args", ",", "kwargs", ",", "default_kwargs", ",", "arg_names", ")", "if", "not", "success", ":", "raise", "TypeError", "(", "STRING", "fSTRING", "STRING", ")", "batch_sampler", "=", "_reinstantiate_wrapped_cls", "(", "batch_sampler", ",", "*", "args", ",", "*", "*", "kwargs", ")", "elif", "hasattr", "(", "batch_sampler", ",", "STRING", ")", "and", "hasattr", "(", "batch_sampler", ",", "STRING", ")", ":", "try", ":", "batch_sampler", "=", "batch_sampler_cls", "(", "sampler", ",", "batch_size", "=", "batch_sampler", ".", "batch_size", ",", "drop_last", "=", "batch_sampler", ".", "drop_last", ",", ")", "except", "TypeError", "as", "ex", ":", "import", "re", "match", "=", "re", ".", "match", "(", "rSTRING", ",", "str", "(", "ex", ")", ")", "if", "not", "match", ":", "raise", "raise", "TypeError", "(", "STRING", "STRING", "STRING", "STRING", ")", "from", "ex", "else", ":", "raise", "TypeError", "(", "STRING", "STRING", "STRING", "STRING", ")", "return", "{", "STRING", ":", "None", ",", "STRING", ":", "False", ",", "STRING", ":", "batch_sampler", ",", "STRING", ":", "1", ",", "STRING", ":", "False", ",", "}", "return", "{", "STRING", ":", "sampler", ",", "STRING", ":", "False", ",", "STRING", ":", "None", "}"], "docstring": "This is a PyTorch `BatchSampler` subclass for which we captured the init args This is a sampler for which we could not capture the init args, but it kinda looks like a batch sampler even if it does not inherit from PyTorch's interface. an unexpected `TypeError`, continue failure There could either be too few or too many arguments. Customizing the message based on this doesn't make much sense since our MisconfigurationException is going to be raised from the original one. The sampler is not a PyTorch `BatchSampler`, we don't know how to inject a custom sampler", "docstring_tokens": ["this", "is", "a", "pytorch", "batchsampler", "subclass", "for", "which", "we", "captured", "the", "init", "args", "this", "is", "a", "sampler", "for", "which", "we", "could", "not", "capture", "the", "init", "args", "but", "it", "kinda", "looks", "like", "a", "batch", "sampler", "even", "if", "it", "does", "not", "inherit", "from", "pytorch", "s", "interface", "an", "unexpected", "typeerror", "continue", "failure", "there", "could", "either", "be", "too", "few", "or", "too", "many", "arguments", "customizing", "the", "message", "based", "on", "this", "doesn", "t", "make", "much", "sense", "since", "our", "misconfigurationexception", "is", "going", "to", "be", "raised", "from", "the", "original", "one", "the", "sampler", "is", "not", "a", "pytorch", "batchsampler", "we", "don", "t", "know", "how", "to", "inject", "a", "custom", "sampler"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 172, "end_line": 242, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_60", "original_string": "def _wrap_init_method(init: Callable, store_explicit_arg: Optional[str] = None) -> Callable:\r\n    \"\"\"Wraps the ``__init__`` method of classes (currently :class:`~torch.utils.data.DataLoader` and\r\n    :class:`~torch.utils.data.BatchSampler`) in order to enable re-instantiation of custom subclasses.\"\"\"\r\n\r\n    @functools.wraps(init)\r\n    def wrapper(obj: Any, *args: Any, **kwargs: Any) -> None:\r\n        old_inside_init = getattr(obj, \"__pl_inside_init\", False)\r\n        object.__setattr__(obj, \"__pl_inside_init\", True)\r\n        params = inspect.signature(init).parameters\r\n\r\n        parameters_defaults = OrderedDict(\r\n            (param.name, param.default)\r\n            for param in params.values()\r\n            if param.name != \"self\" and param.kind not in (param.VAR_POSITIONAL, param.VAR_KEYWORD)\r\n        )\r\n\r\n        param_names = tuple(parameters_defaults)[: len(args)]\r\n\r\n        default_kwargs = {\r\n            name: value\r\n            for name, value in parameters_defaults.items()\r\n            if name not in kwargs and name not in param_names and value != inspect.Parameter.empty\r\n        }\r\n\r\n        if not hasattr(obj, \"__pl_saved_args\"):\r\n            object.__setattr__(obj, \"__pl_saved_args\", args)\r\n            object.__setattr__(obj, \"__pl_saved_kwargs\", kwargs)\r\n            object.__setattr__(obj, \"__pl_saved_arg_names\", param_names)\r\n            object.__setattr__(obj, \"__pl_saved_default_kwargs\", default_kwargs)\r\n\r\n        if store_explicit_arg is not None:\r\n            if store_explicit_arg in param_names:\r\n                object.__setattr__(obj, f\"__{store_explicit_arg}\", args[param_names.index(store_explicit_arg)])\r\n            elif store_explicit_arg in kwargs:\r\n                object.__setattr__(obj, f\"__{store_explicit_arg}\", kwargs[store_explicit_arg])\r\n\r\n        init(obj, *args, **kwargs)\r\n        object.__setattr__(obj, \"__pl_inside_init\", old_inside_init)\r\n\r\n    return wrapper", "language": "python", "code": "def _wrap_init_method(init: Callable, store_explicit_arg: Optional[str] = None) -> Callable:\r\n    \"\"\"Wraps the ``__init__`` method of classes (currently :class:`~torch.utils.data.DataLoader` and\r\n    :class:`~torch.utils.data.BatchSampler`) in order to enable re-instantiation of custom subclasses.\"\"\"\r\n\r\n    @functools.wraps(init)\r\n    def wrapper(obj: Any, *args: Any, **kwargs: Any) -> None:\r\n        old_inside_init = getattr(obj, \"__pl_inside_init\", False)\r\n        object.__setattr__(obj, \"__pl_inside_init\", True)\r\n        params = inspect.signature(init).parameters\r\n\r\n        parameters_defaults = OrderedDict(\r\n            (param.name, param.default)\r\n            for param in params.values()\r\n            if param.name != \"self\" and param.kind not in (param.VAR_POSITIONAL, param.VAR_KEYWORD)\r\n        )\r\n\r\n        param_names = tuple(parameters_defaults)[: len(args)]\r\n\r\n        default_kwargs = {\r\n            name: value\r\n            for name, value in parameters_defaults.items()\r\n            if name not in kwargs and name not in param_names and value != inspect.Parameter.empty\r\n        }\r\n\r\n        if not hasattr(obj, \"__pl_saved_args\"):\r\n            object.__setattr__(obj, \"__pl_saved_args\", args)\r\n            object.__setattr__(obj, \"__pl_saved_kwargs\", kwargs)\r\n            object.__setattr__(obj, \"__pl_saved_arg_names\", param_names)\r\n            object.__setattr__(obj, \"__pl_saved_default_kwargs\", default_kwargs)\r\n\r\n        if store_explicit_arg is not None:\r\n            if store_explicit_arg in param_names:\r\n                object.__setattr__(obj, f\"__{store_explicit_arg}\", args[param_names.index(store_explicit_arg)])\r\n            elif store_explicit_arg in kwargs:\r\n                object.__setattr__(obj, f\"__{store_explicit_arg}\", kwargs[store_explicit_arg])\r\n\r\n        init(obj, *args, **kwargs)\r\n        object.__setattr__(obj, \"__pl_inside_init\", old_inside_init)\r\n\r\n    return wrapper", "code_tokens": ["def", "_wrap_init_method", "(", "init", ":", "Callable", ",", "store_explicit_arg", ":", "Optional", "[", "str", "]", "=", "None", ")", "-", ">", "Callable", ":", "STRING", "@", "functools", ".", "wraps", "(", "init", ")", "def", "wrapper", "(", "obj", ":", "Any", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "old_inside_init", "=", "getattr", "(", "obj", ",", "STRING", ",", "False", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "True", ")", "params", "=", "inspect", ".", "signature", "(", "init", ")", ".", "parameters", "parameters_defaults", "=", "OrderedDict", "(", "(", "param", ".", "name", ",", "param", ".", "default", ")", "for", "param", "in", "params", ".", "values", "(", ")", "if", "param", ".", "name", "!", "=", "STRING", "and", "param", ".", "kind", "not", "in", "(", "param", ".", "VAR_POSITIONAL", ",", "param", ".", "VAR_KEYWORD", ")", ")", "param_names", "=", "tuple", "(", "parameters_defaults", ")", "[", ":", "len", "(", "args", ")", "]", "default_kwargs", "=", "{", "name", ":", "value", "for", "name", ",", "value", "in", "parameters_defaults", ".", "items", "(", ")", "if", "name", "not", "in", "kwargs", "and", "name", "not", "in", "param_names", "and", "value", "!", "=", "inspect", ".", "Parameter", ".", "empty", "}", "if", "not", "hasattr", "(", "obj", ",", "STRING", ")", ":", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "args", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "kwargs", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "param_names", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "default_kwargs", ")", "if", "store_explicit_arg", "is", "not", "None", ":", "if", "store_explicit_arg", "in", "param_names", ":", "object", ".", "__setattr__", "(", "obj", ",", "fSTRING", ",", "args", "[", "param_names", ".", "index", "(", "store_explicit_arg", ")", "]", ")", "elif", "store_explicit_arg", "in", "kwargs", ":", "object", ".", "__setattr__", "(", "obj", ",", "fSTRING", ",", "kwargs", "[", "store_explicit_arg", "]", ")", "init", "(", "obj", ",", "*", "args", ",", "*", "*", "kwargs", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "old_inside_init", ")", "return", "wrapper"], "docstring": "We need to inspect `init`, as inspecting `obj.__init__` can lead to inspecting the wrong function with multiple inheritance We want to use the latest possible value for explicit argument (i.e. ideally what gets passed to base class) so that we can be sure, that it will not get changed anymore. That is why we are setting this in every `__init__`", "docstring_tokens": ["we", "need", "to", "inspect", "init", "as", "inspecting", "obj", "__init__", "can", "lead", "to", "inspecting", "the", "wrong", "function", "with", "multiple", "inheritance", "we", "want", "to", "use", "the", "latest", "possible", "value", "for", "explicit", "argument", "i", "e", "ideally", "what", "gets", "passed", "to", "base", "class", "so", "that", "we", "can", "be", "sure", "that", "it", "will", "not", "get", "changed", "anymore", "that", "is", "why", "we", "are", "setting", "this", "in", "every", "__init__"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 283, "end_line": 327, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_61", "original_string": "def _wrap_attr_method(method: Callable, tag: _WrapAttrTag) -> Callable:\r\n    \"\"\"Wraps the ``__setattr__`` or ``__delattr__`` method of classes (currently :class:`~torch.utils.data.DataLoader`\r\n    and :class:`~torch.utils.data.BatchSampler`) in order to enable re- instantiation of custom subclasses.\"\"\"\r\n\r\n    @functools.wraps(method)\r\n    def wrapper(obj: Any, *args: Any) -> None:\r\n        name, *_ = args\r\n        prev_call_name, prev_call_method = getattr(obj, \"__pl_current_call\", (None, \"method\"))\r\n        first_call = not (prev_call_name == name and prev_call_method == tag)\r\n\r\n        object.__setattr__(obj, \"__pl_current_call\", (name, tag))\r\n\r\n        method(obj, *args)\r\n        if first_call and not getattr(obj, \"__pl_inside_init\", True):\r\n            attrs_record = getattr(obj, \"__pl_attrs_record\", [])\r\n            attrs_record.append((args, tag))\r\n            object.__setattr__(obj, \"__pl_attrs_record\", attrs_record)\r\n        object.__setattr__(obj, \"__pl_current_call\", (prev_call_name, prev_call_method))\r\n\r\n    return wrapper", "language": "python", "code": "def _wrap_attr_method(method: Callable, tag: _WrapAttrTag) -> Callable:\r\n    \"\"\"Wraps the ``__setattr__`` or ``__delattr__`` method of classes (currently :class:`~torch.utils.data.DataLoader`\r\n    and :class:`~torch.utils.data.BatchSampler`) in order to enable re- instantiation of custom subclasses.\"\"\"\r\n\r\n    @functools.wraps(method)\r\n    def wrapper(obj: Any, *args: Any) -> None:\r\n        name, *_ = args\r\n        prev_call_name, prev_call_method = getattr(obj, \"__pl_current_call\", (None, \"method\"))\r\n        first_call = not (prev_call_name == name and prev_call_method == tag)\r\n\r\n        object.__setattr__(obj, \"__pl_current_call\", (name, tag))\r\n\r\n        method(obj, *args)\r\n        if first_call and not getattr(obj, \"__pl_inside_init\", True):\r\n            attrs_record = getattr(obj, \"__pl_attrs_record\", [])\r\n            attrs_record.append((args, tag))\r\n            object.__setattr__(obj, \"__pl_attrs_record\", attrs_record)\r\n        object.__setattr__(obj, \"__pl_current_call\", (prev_call_name, prev_call_method))\r\n\r\n    return wrapper", "code_tokens": ["def", "_wrap_attr_method", "(", "method", ":", "Callable", ",", "tag", ":", "_WrapAttrTag", ")", "-", ">", "Callable", ":", "STRING", "@", "functools", ".", "wraps", "(", "method", ")", "def", "wrapper", "(", "obj", ":", "Any", ",", "*", "args", ":", "Any", ")", "-", ">", "None", ":", "name", ",", "*", "_", "=", "args", "prev_call_name", ",", "prev_call_method", "=", "getattr", "(", "obj", ",", "STRING", ",", "(", "None", ",", "STRING", ")", ")", "first_call", "=", "not", "(", "prev_call_name", "=", "=", "name", "and", "prev_call_method", "=", "=", "tag", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "(", "name", ",", "tag", ")", ")", "method", "(", "obj", ",", "*", "args", ")", "if", "first_call", "and", "not", "getattr", "(", "obj", ",", "STRING", ",", "True", ")", ":", "attrs_record", "=", "getattr", "(", "obj", ",", "STRING", ",", "[", "]", ")", "attrs_record", ".", "append", "(", "(", "args", ",", "tag", ")", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "attrs_record", ")", "object", ".", "__setattr__", "(", "obj", ",", "STRING", ",", "(", "prev_call_name", ",", "prev_call_method", ")", ")", "return", "wrapper"], "docstring": "First, let's find out if we're the first in inheritance chain calling the patched method. Then mark the current called method call original method and save the value it was called with to the internal list, if we're outside of __init__ and the original call did not fail and we're the first call", "docstring_tokens": ["first", "let", "s", "find", "out", "if", "we", "re", "the", "first", "in", "inheritance", "chain", "calling", "the", "patched", "method", "then", "mark", "the", "current", "called", "method", "call", "original", "method", "and", "save", "the", "value", "it", "was", "called", "with", "to", "the", "internal", "list", "if", "we", "re", "outside", "of", "__init__", "and", "the", "original", "call", "did", "not", "fail", "and", "we", "re", "the", "first", "call"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 330, "end_line": 354, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_62", "original_string": "def _replace_dunder_methods(base_cls: type, store_explicit_arg: Optional[str] = None) -> Generator[None, None, None]:\r\n    \"\"\"This context manager is used to add support for re-instantiation of custom (subclasses) of `base_cls`.\r\n\r\n    It patches the ``__init__``, ``__setattr__`` and ``__delattr__`` methods.\r\n\r\n    \"\"\"\r\n    classes = get_all_subclasses(base_cls) | {base_cls}\r\n    for cls in classes:\r\n        if \"__init__\" in cls.__dict__:\r\n            cls.__old__init__ = cls.__init__  # type: ignore[misc]\r\n            cls.__init__ = _wrap_init_method(cls.__init__, store_explicit_arg)  # type: ignore[misc]\r\n\r\n        for patch_fn_name, tag in ((\"__setattr__\", _WrapAttrTag.SET), (\"__delattr__\", _WrapAttrTag.DEL)):\r\n            if patch_fn_name in cls.__dict__ or cls is base_cls:\r\n                saved_name = f\"__old{patch_fn_name}\"\r\n                setattr(cls, saved_name, getattr(cls, patch_fn_name))\r\n                setattr(cls, patch_fn_name, _wrap_attr_method(getattr(cls, patch_fn_name), tag))\r\n    yield\r\n    for cls in classes:\r\n        for patched_name in (\"__setattr__\", \"__delattr__\", \"__init__\"):\r\n            if f\"__old{patched_name}\" in cls.__dict__:\r\n                setattr(cls, patched_name, getattr(cls, f\"__old{patched_name}\"))\r\n                delattr(cls, f\"__old{patched_name}\")", "language": "python", "code": "def _replace_dunder_methods(base_cls: type, store_explicit_arg: Optional[str] = None) -> Generator[None, None, None]:\r\n    \"\"\"This context manager is used to add support for re-instantiation of custom (subclasses) of `base_cls`.\r\n\r\n    It patches the ``__init__``, ``__setattr__`` and ``__delattr__`` methods.\r\n\r\n    \"\"\"\r\n    classes = get_all_subclasses(base_cls) | {base_cls}\r\n    for cls in classes:\r\n        if \"__init__\" in cls.__dict__:\r\n            cls.__old__init__ = cls.__init__  # type: ignore[misc]\r\n            cls.__init__ = _wrap_init_method(cls.__init__, store_explicit_arg)  # type: ignore[misc]\r\n\r\n        for patch_fn_name, tag in ((\"__setattr__\", _WrapAttrTag.SET), (\"__delattr__\", _WrapAttrTag.DEL)):\r\n            if patch_fn_name in cls.__dict__ or cls is base_cls:\r\n                saved_name = f\"__old{patch_fn_name}\"\r\n                setattr(cls, saved_name, getattr(cls, patch_fn_name))\r\n                setattr(cls, patch_fn_name, _wrap_attr_method(getattr(cls, patch_fn_name), tag))\r\n    yield\r\n    for cls in classes:\r\n        for patched_name in (\"__setattr__\", \"__delattr__\", \"__init__\"):\r\n            if f\"__old{patched_name}\" in cls.__dict__:\r\n                setattr(cls, patched_name, getattr(cls, f\"__old{patched_name}\"))\r\n                delattr(cls, f\"__old{patched_name}\")", "code_tokens": ["def", "_replace_dunder_methods", "(", "base_cls", ":", "type", ",", "store_explicit_arg", ":", "Optional", "[", "str", "]", "=", "None", ")", "-", ">", "Generator", "[", "None", ",", "None", ",", "None", "]", ":", "STRING", "classes", "=", "get_all_subclasses", "(", "base_cls", ")", "|", "{", "base_cls", "}", "for", "cls", "in", "classes", ":", "if", "STRING", "in", "cls", ".", "__dict__", ":", "cls", ".", "__old__init__", "=", "cls", ".", "__init__", "#", "type", ":", "ignore", "[", "misc", "]", "cls", ".", "__init__", "=", "_wrap_init_method", "(", "cls", ".", "__init__", ",", "store_explicit_arg", ")", "#", "type", ":", "ignore", "[", "misc", "]", "for", "patch_fn_name", ",", "tag", "in", "(", "(", "STRING", ",", "_WrapAttrTag", ".", "SET", ")", ",", "(", "STRING", ",", "_WrapAttrTag", ".", "DEL", ")", ")", ":", "if", "patch_fn_name", "in", "cls", ".", "__dict__", "or", "cls", "is", "base_cls", ":", "saved_name", "=", "fSTRING", "setattr", "(", "cls", ",", "saved_name", ",", "getattr", "(", "cls", ",", "patch_fn_name", ")", ")", "setattr", "(", "cls", ",", "patch_fn_name", ",", "_wrap_attr_method", "(", "getattr", "(", "cls", ",", "patch_fn_name", ")", ",", "tag", ")", ")", "yield", "for", "cls", "in", "classes", ":", "for", "patched_name", "in", "(", "STRING", ",", "STRING", ",", "STRING", ")", ":", "if", "fSTRING", "in", "cls", ".", "__dict__", ":", "setattr", "(", "cls", ",", "patched_name", ",", "getattr", "(", "cls", ",", "fSTRING", ")", ")", "delattr", "(", "cls", ",", "fSTRING", ")"], "docstring": "Check that __init__ belongs to the class https://stackoverflow.com/a/5253424 we want at least one setattr/delattr in the chain to be patched and it can happen, that none of the subclasses implement `__setattr__`/`__delattr__`. Therefore, we are always patching the `base_cls` Check that __old__{init,setattr,delattr} belongs to the class https://stackoverflow.com/a/5253424", "docstring_tokens": ["check", "that", "__init__", "belongs", "to", "the", "class", "https", "stackoverflow", "com", "a", "5253424", "we", "want", "at", "least", "one", "setattr", "delattr", "in", "the", "chain", "to", "be", "patched", "and", "it", "can", "happen", "that", "none", "of", "the", "subclasses", "implement", "__setattr__", "__delattr__", "therefore", "we", "are", "always", "patching", "the", "base_cls", "check", "that", "__old__", "init", "setattr", "delattr", "belongs", "to", "the", "class", "https", "stackoverflow", "com", "a", "5253424"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 358, "end_line": 386, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\data.py", "func_name": "function_63", "original_string": "def _set_sampler_epoch(dataloader: object, epoch: int) -> None:\r\n    \"\"\"Calls the ``set_epoch`` method on either the sampler of the given dataloader.\r\n\r\n    Every PyTorch dataloader has either a sampler or a batch sampler. If the sampler is wrapped by a\r\n    :class:`~torch.utils.data.distributed.DistributedSampler`, ``set_epoch`` must be called at the beginning\r\n    of every epoch to ensure shuffling applies a new ordering. This has no effect if shuffling is off.\r\n\r\n    \"\"\"\r\n    objects: dict[int, Any] = {}\r\n    if (sampler := getattr(dataloader, \"sampler\", None)) is not None:\r\n        objects[id(sampler)] = sampler\r\n    if (batch_sampler := getattr(dataloader, \"batch_sampler\", None)) is not None and (\r\n        sampler := getattr(batch_sampler, \"sampler\", None)\r\n    ) is not None:\r\n        objects[id(sampler)] = sampler\r\n    for obj in objects.values():\r\n        set_epoch = getattr(obj, \"set_epoch\", None)\r\n        if callable(set_epoch):\r\n            set_epoch(epoch)", "language": "python", "code": "def _set_sampler_epoch(dataloader: object, epoch: int) -> None:\r\n    \"\"\"Calls the ``set_epoch`` method on either the sampler of the given dataloader.\r\n\r\n    Every PyTorch dataloader has either a sampler or a batch sampler. If the sampler is wrapped by a\r\n    :class:`~torch.utils.data.distributed.DistributedSampler`, ``set_epoch`` must be called at the beginning\r\n    of every epoch to ensure shuffling applies a new ordering. This has no effect if shuffling is off.\r\n\r\n    \"\"\"\r\n    objects: dict[int, Any] = {}\r\n    if (sampler := getattr(dataloader, \"sampler\", None)) is not None:\r\n        objects[id(sampler)] = sampler\r\n    if (batch_sampler := getattr(dataloader, \"batch_sampler\", None)) is not None and (\r\n        sampler := getattr(batch_sampler, \"sampler\", None)\r\n    ) is not None:\r\n        objects[id(sampler)] = sampler\r\n    for obj in objects.values():\r\n        set_epoch = getattr(obj, \"set_epoch\", None)\r\n        if callable(set_epoch):\r\n            set_epoch(epoch)", "code_tokens": ["def", "_set_sampler_epoch", "(", "dataloader", ":", "object", ",", "epoch", ":", "int", ")", "-", ">", "None", ":", "STRING", "objects", ":", "dict", "[", "int", ",", "Any", "]", "=", "{", "}", "if", "(", "sampler", ":", "=", "getattr", "(", "dataloader", ",", "STRING", ",", "None", ")", ")", "is", "not", "None", ":", "objects", "[", "id", "(", "sampler", ")", "]", "=", "sampler", "if", "(", "batch_sampler", ":", "=", "getattr", "(", "dataloader", ",", "STRING", ",", "None", ")", ")", "is", "not", "None", "and", "(", "sampler", ":", "=", "getattr", "(", "batch_sampler", ",", "STRING", ",", "None", ")", ")", "is", "not", "None", ":", "objects", "[", "id", "(", "sampler", ")", "]", "=", "sampler", "for", "obj", "in", "objects", ".", "values", "(", ")", ":", "set_epoch", "=", "getattr", "(", "obj", ",", "STRING", ",", "None", ")", "if", "callable", "(", "set_epoch", ")", ":", "set_epoch", "(", "epoch", ")"], "docstring": "cannot use a set because samplers might be unhashable: use a dict based on the id to drop duplicates check dataloader.sampler check dataloader.batch_sampler.sampler", "docstring_tokens": ["cannot", "use", "a", "set", "because", "samplers", "might", "be", "unhashable", "use", "a", "dict", "based", "on", "the", "id", "to", "drop", "duplicates", "check", "dataloader", "sampler", "check", "dataloader", "batch_sampler", "sampler"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\data.py", "start_line": 414, "end_line": 435, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\device_dtype_mixin.py", "func_name": "function_64", "original_string": "def to(self, *args: Any, **kwargs: Any) -> Self:\r\n        \"\"\"See :meth:`torch.nn.Module.to`.\"\"\"\r\n        device, dtype = torch._C._nn._parse_to(*args, **kwargs)[:2]\r\n        _update_properties(self, device=device, dtype=dtype)\r\n        return super().to(*args, **kwargs)", "language": "python", "code": "def to(self, *args: Any, **kwargs: Any) -> Self:\r\n        \"\"\"See :meth:`torch.nn.Module.to`.\"\"\"\r\n        device, dtype = torch._C._nn._parse_to(*args, **kwargs)[:2]\r\n        _update_properties(self, device=device, dtype=dtype)\r\n        return super().to(*args, **kwargs)", "code_tokens": ["def", "to", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Self", ":", "STRING", "device", ",", "dtype", "=", "torch", ".", "_C", ".", "_nn", ".", "_parse_to", "(", "*", "args", ",", "*", "*", "kwargs", ")", "[", ":", "2", "]", "_update_properties", "(", "self", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "return", "super", "(", ")", ".", "to", "(", "*", "args", ",", "*", "*", "kwargs", ")"], "docstring": "this converts `str` device to `torch.device`", "docstring_tokens": ["this", "converts", "str", "device", "to", "torch", "device"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\device_dtype_mixin.py", "start_line": 53, "end_line": 58, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\device_parser.py", "func_name": "function_65", "original_string": "def _determine_root_gpu_device(gpus: list[_DEVICE]) -> Optional[_DEVICE]:\r\n    \"\"\"\r\n    Args:\r\n        gpus: Non-empty list of ints representing which GPUs to use\r\n\r\n    Returns:\r\n        Designated root GPU device id\r\n\r\n    Raises:\r\n        TypeError:\r\n            If ``gpus`` is not a list\r\n        AssertionError:\r\n            If GPU list is empty\r\n    \"\"\"\r\n    if gpus is None:\r\n        return None\r\n\r\n    if not isinstance(gpus, list):\r\n        raise TypeError(\"GPUs should be a list\")\r\n\r\n    assert len(gpus) > 0, \"GPUs should be a non-empty list\"\r\n\r\n    return gpus[0]", "language": "python", "code": "def _determine_root_gpu_device(gpus: list[_DEVICE]) -> Optional[_DEVICE]:\r\n    \"\"\"\r\n    Args:\r\n        gpus: Non-empty list of ints representing which GPUs to use\r\n\r\n    Returns:\r\n        Designated root GPU device id\r\n\r\n    Raises:\r\n        TypeError:\r\n            If ``gpus`` is not a list\r\n        AssertionError:\r\n            If GPU list is empty\r\n    \"\"\"\r\n    if gpus is None:\r\n        return None\r\n\r\n    if not isinstance(gpus, list):\r\n        raise TypeError(\"GPUs should be a list\")\r\n\r\n    assert len(gpus) > 0, \"GPUs should be a non-empty list\"\r\n\r\n    return gpus[0]", "code_tokens": ["def", "_determine_root_gpu_device", "(", "gpus", ":", "list", "[", "_DEVICE", "]", ")", "-", ">", "Optional", "[", "_DEVICE", "]", ":", "STRING", "if", "gpus", "is", "None", ":", "return", "None", "if", "not", "isinstance", "(", "gpus", ",", "list", ")", ":", "raise", "TypeError", "(", "STRING", ")", "assert", "len", "(", "gpus", ")", ">", "0", ",", "STRING", "return", "gpus", "[", "0", "]"], "docstring": "set root gpu", "docstring_tokens": ["set", "root", "gpu"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\device_parser.py", "start_line": 22, "end_line": 45, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\device_parser.py", "func_name": "function_66", "original_string": "def _parse_gpu_ids(\r\n    gpus: Optional[Union[int, str, list[int]]],\r\n    include_cuda: bool = False,\r\n    include_mps: bool = False,\r\n) -> Optional[list[int]]:\r\n    \"\"\"Parses the GPU IDs given in the format as accepted by the :class:`~lightning.pytorch.trainer.trainer.Trainer`.\r\n\r\n    Args:\r\n        gpus: An int -1 or string '-1' indicate that all available GPUs should be used.\r\n            A list of unique ints or a string containing a list of comma separated unique integers\r\n            indicates specific GPUs to use.\r\n            An int of 0 means that no GPUs should be used.\r\n            Any int N > 0 indicates that GPUs [0..N) should be used.\r\n        include_cuda: A boolean value indicating whether to include CUDA devices for GPU parsing.\r\n        include_mps: A boolean value indicating whether to include MPS devices for GPU parsing.\r\n\r\n    Returns:\r\n        A list of GPUs to be used or ``None`` if no GPUs were requested\r\n\r\n    Raises:\r\n        MisconfigurationException:\r\n            If no GPUs are available but the value of gpus variable indicates request for GPUs\r\n\r\n    .. note::\r\n        ``include_cuda`` and ``include_mps`` default to ``False`` so that you only\r\n        have to specify which device type to use and all other devices are not disabled.\r\n\r\n    \"\"\"\r\n    _check_data_type(gpus)\r\n\r\n    if gpus is None or (isinstance(gpus, int) and gpus == 0) or str(gpus).strip() in (\"0\", \"[]\"):\r\n        return None\r\n\r\n    gpus = _normalize_parse_gpu_string_input(gpus)\r\n    gpus = _normalize_parse_gpu_input_to_list(gpus, include_cuda=include_cuda, include_mps=include_mps)\r\n    if not gpus:\r\n        raise MisconfigurationException(\"GPUs requested but none are available.\")\r\n\r\n    if (\r\n        torch.distributed.is_available()\r\n        and torch.distributed.is_torchelastic_launched()\r\n        and len(gpus) != 1\r\n        and len(_get_all_available_gpus(include_cuda=include_cuda, include_mps=include_mps)) == 1\r\n    ):\r\n        return gpus\r\n\r\n    _check_unique(gpus)\r\n\r\n    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)", "language": "python", "code": "def _parse_gpu_ids(\r\n    gpus: Optional[Union[int, str, list[int]]],\r\n    include_cuda: bool = False,\r\n    include_mps: bool = False,\r\n) -> Optional[list[int]]:\r\n    \"\"\"Parses the GPU IDs given in the format as accepted by the :class:`~lightning.pytorch.trainer.trainer.Trainer`.\r\n\r\n    Args:\r\n        gpus: An int -1 or string '-1' indicate that all available GPUs should be used.\r\n            A list of unique ints or a string containing a list of comma separated unique integers\r\n            indicates specific GPUs to use.\r\n            An int of 0 means that no GPUs should be used.\r\n            Any int N > 0 indicates that GPUs [0..N) should be used.\r\n        include_cuda: A boolean value indicating whether to include CUDA devices for GPU parsing.\r\n        include_mps: A boolean value indicating whether to include MPS devices for GPU parsing.\r\n\r\n    Returns:\r\n        A list of GPUs to be used or ``None`` if no GPUs were requested\r\n\r\n    Raises:\r\n        MisconfigurationException:\r\n            If no GPUs are available but the value of gpus variable indicates request for GPUs\r\n\r\n    .. note::\r\n        ``include_cuda`` and ``include_mps`` default to ``False`` so that you only\r\n        have to specify which device type to use and all other devices are not disabled.\r\n\r\n    \"\"\"\r\n    _check_data_type(gpus)\r\n\r\n    if gpus is None or (isinstance(gpus, int) and gpus == 0) or str(gpus).strip() in (\"0\", \"[]\"):\r\n        return None\r\n\r\n    gpus = _normalize_parse_gpu_string_input(gpus)\r\n    gpus = _normalize_parse_gpu_input_to_list(gpus, include_cuda=include_cuda, include_mps=include_mps)\r\n    if not gpus:\r\n        raise MisconfigurationException(\"GPUs requested but none are available.\")\r\n\r\n    if (\r\n        torch.distributed.is_available()\r\n        and torch.distributed.is_torchelastic_launched()\r\n        and len(gpus) != 1\r\n        and len(_get_all_available_gpus(include_cuda=include_cuda, include_mps=include_mps)) == 1\r\n    ):\r\n        return gpus\r\n\r\n    _check_unique(gpus)\r\n\r\n    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)", "code_tokens": ["def", "_parse_gpu_ids", "(", "gpus", ":", "Optional", "[", "Union", "[", "int", ",", "str", ",", "list", "[", "int", "]", "]", "]", ",", "include_cuda", ":", "bool", "=", "False", ",", "include_mps", ":", "bool", "=", "False", ",", ")", "-", ">", "Optional", "[", "list", "[", "int", "]", "]", ":", "STRING", "_check_data_type", "(", "gpus", ")", "if", "gpus", "is", "None", "or", "(", "isinstance", "(", "gpus", ",", "int", ")", "and", "gpus", "=", "=", "0", ")", "or", "str", "(", "gpus", ")", ".", "strip", "(", ")", "in", "(", "STRING", ",", "STRING", ")", ":", "return", "None", "gpus", "=", "_normalize_parse_gpu_string_input", "(", "gpus", ")", "gpus", "=", "_normalize_parse_gpu_input_to_list", "(", "gpus", ",", "include_cuda", "=", "include_cuda", ",", "include_mps", "=", "include_mps", ")", "if", "not", "gpus", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "if", "(", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_torchelastic_launched", "(", ")", "and", "len", "(", "gpus", ")", "!", "=", "1", "and", "len", "(", "_get_all_available_gpus", "(", "include_cuda", "=", "include_cuda", ",", "include_mps", "=", "include_mps", ")", ")", "=", "=", "1", ")", ":", "return", "gpus", "_check_unique", "(", "gpus", ")", "return", "_sanitize_gpu_ids", "(", "gpus", ",", "include_cuda", "=", "include_cuda", ",", "include_mps", "=", "include_mps", ")"], "docstring": "Check that gpus param is None, Int, String or Sequence of Ints Handle the case when no GPUs are requested We know the user requested GPUs therefore if some of the requested GPUs are not available an exception is thrown. Omit sanity check on torchelastic because by default it shows one visible GPU per process Check that GPUs are unique. Duplicate GPUs are not supported by the backend.", "docstring_tokens": ["check", "that", "gpus", "param", "is", "none", "int", "string", "or", "sequence", "of", "ints", "handle", "the", "case", "when", "no", "gpus", "are", "requested", "we", "know", "the", "user", "requested", "gpus", "therefore", "if", "some", "of", "the", "requested", "gpus", "are", "not", "available", "an", "exception", "is", "thrown", "omit", "sanity", "check", "on", "torchelastic", "because", "by", "default", "it", "shows", "one", "visible", "gpu", "per", "process", "check", "that", "gpus", "are", "unique", "duplicate", "gpus", "are", "not", "supported", "by", "the", "backend"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\device_parser.py", "start_line": 48, "end_line": 102, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\distributed.py", "func_name": "function_67", "original_string": "def is_shared_filesystem(strategy: \"Strategy\", path: Optional[_PATH] = None, timeout: int = 3) -> bool:\r\n    \"\"\"Checks whether the filesystem under the given path is shared across all processes.\r\n\r\n    This function should only be used in a context where distributed is initialized.\r\n\r\n    Args:\r\n        strategy: The strategy being used, either from Fabric (``fabric.strategy``) or from Trainer\r\n            (``trainer.strategy``).\r\n        path: The path to check. Defaults to the current working directory. The user must have permissions to write\r\n            to this path or the parent folder, and the filesystem must be writable.\r\n        timeout: If any of the processes can't list the file created by rank 0 within this many seconds, the\r\n            filesystem is determined to be not shared.\r\n\r\n    \"\"\"\r\n    if path is not None and not _is_local_file_protocol(path):\r\n        return True\r\n\r\n    path = Path(Path.cwd() if path is None else path).resolve()\r\n\r\n    if not hasattr(strategy, \"world_size\") or strategy.world_size == 1:\r\n        return True\r\n\r\n    rank_zero_path = strategy.broadcast(path)\r\n    if not strategy.reduce_boolean_decision(rank_zero_path == path, all=True):\r\n        return False\r\n\r\n    if not strategy.reduce_boolean_decision(path.exists(), all=True):\r\n        raise FileNotFoundError(\r\n            f\"Unable to determine if the path belongs to a shared filesystem. The path does not exist: {path}\"\r\n        )\r\n\r\n    path = path.parent if path.is_file() else path\r\n    check_file = path / \".lightning_shared_fs_check\"\r\n    check_file.unlink(missing_ok=True)\r\n\r\n    strategy.barrier()\r\n    if strategy.is_global_zero:\r\n        check_file.touch()\r\n        found = True\r\n    else:\r\n        start = time.perf_counter()\r\n        found = False\r\n        while not found and (time.perf_counter() - start) < timeout:\r\n            found = check_file.exists()\r\n    strategy.barrier()\r\n\r\n    all_found = strategy.reduce_boolean_decision(found, all=True)\r\n\r\n    with contextlib.suppress(OSError):  # handle race condition on deletion\r\n        check_file.unlink()\r\n\r\n    return all_found", "language": "python", "code": "def is_shared_filesystem(strategy: \"Strategy\", path: Optional[_PATH] = None, timeout: int = 3) -> bool:\r\n    \"\"\"Checks whether the filesystem under the given path is shared across all processes.\r\n\r\n    This function should only be used in a context where distributed is initialized.\r\n\r\n    Args:\r\n        strategy: The strategy being used, either from Fabric (``fabric.strategy``) or from Trainer\r\n            (``trainer.strategy``).\r\n        path: The path to check. Defaults to the current working directory. The user must have permissions to write\r\n            to this path or the parent folder, and the filesystem must be writable.\r\n        timeout: If any of the processes can't list the file created by rank 0 within this many seconds, the\r\n            filesystem is determined to be not shared.\r\n\r\n    \"\"\"\r\n    if path is not None and not _is_local_file_protocol(path):\r\n        return True\r\n\r\n    path = Path(Path.cwd() if path is None else path).resolve()\r\n\r\n    if not hasattr(strategy, \"world_size\") or strategy.world_size == 1:\r\n        return True\r\n\r\n    rank_zero_path = strategy.broadcast(path)\r\n    if not strategy.reduce_boolean_decision(rank_zero_path == path, all=True):\r\n        return False\r\n\r\n    if not strategy.reduce_boolean_decision(path.exists(), all=True):\r\n        raise FileNotFoundError(\r\n            f\"Unable to determine if the path belongs to a shared filesystem. The path does not exist: {path}\"\r\n        )\r\n\r\n    path = path.parent if path.is_file() else path\r\n    check_file = path / \".lightning_shared_fs_check\"\r\n    check_file.unlink(missing_ok=True)\r\n\r\n    strategy.barrier()\r\n    if strategy.is_global_zero:\r\n        check_file.touch()\r\n        found = True\r\n    else:\r\n        start = time.perf_counter()\r\n        found = False\r\n        while not found and (time.perf_counter() - start) < timeout:\r\n            found = check_file.exists()\r\n    strategy.barrier()\r\n\r\n    all_found = strategy.reduce_boolean_decision(found, all=True)\r\n\r\n    with contextlib.suppress(OSError):  # handle race condition on deletion\r\n        check_file.unlink()\r\n\r\n    return all_found", "code_tokens": ["def", "is_shared_filesystem", "(", "strategy", ":", "STRING", ",", "path", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "timeout", ":", "int", "=", "3", ")", "-", ">", "bool", ":", "STRING", "if", "path", "is", "not", "None", "and", "not", "_is_local_file_protocol", "(", "path", ")", ":", "return", "True", "path", "=", "Path", "(", "Path", ".", "cwd", "(", ")", "if", "path", "is", "None", "else", "path", ")", ".", "resolve", "(", ")", "if", "not", "hasattr", "(", "strategy", ",", "STRING", ")", "or", "strategy", ".", "world_size", "=", "=", "1", ":", "return", "True", "rank_zero_path", "=", "strategy", ".", "broadcast", "(", "path", ")", "if", "not", "strategy", ".", "reduce_boolean_decision", "(", "rank_zero_path", "=", "=", "path", ",", "all", "=", "True", ")", ":", "return", "False", "if", "not", "strategy", ".", "reduce_boolean_decision", "(", "path", ".", "exists", "(", ")", ",", "all", "=", "True", ")", ":", "raise", "FileNotFoundError", "(", "fSTRING", ")", "path", "=", "path", ".", "parent", "if", "path", ".", "is_file", "(", ")", "else", "path", "check_file", "=", "path", "/", "STRING", "check_file", ".", "unlink", "(", "missing_ok", "=", "True", ")", "strategy", ".", "barrier", "(", ")", "if", "strategy", ".", "is_global_zero", ":", "check_file", ".", "touch", "(", ")", "found", "=", "True", "else", ":", "start", "=", "time", ".", "perf_counter", "(", ")", "found", "=", "False", "while", "not", "found", "and", "(", "time", ".", "perf_counter", "(", ")", "-", "start", ")", "<", "timeout", ":", "found", "=", "check_file", ".", "exists", "(", ")", "strategy", ".", "barrier", "(", ")", "all_found", "=", "strategy", ".", "reduce_boolean_decision", "(", "found", ",", "all", "=", "True", ")", "with", "contextlib", ".", "suppress", "(", "OSError", ")", ":", "#", "handle", "race", "condition", "on", "deletion", "check_file", ".", "unlink", "(", ")", "return", "all_found"], "docstring": "Fast path: Any non-local filesystem is considered shared (e.g., S3) Fast path: Only distributed strategies can detect shared filesystems Fast path: If the path is not the same on all ranks we know it's not a shared filesystem Rank 0 creates the file All other ranks will wait until they find the file or timeout", "docstring_tokens": ["fast", "path", "any", "non", "local", "filesystem", "is", "considered", "shared", "e", "g", "s3", "fast", "path", "only", "distributed", "strategies", "can", "detect", "shared", "filesystems", "fast", "path", "if", "the", "path", "is", "not", "the", "same", "on", "all", "ranks", "we", "know", "it", "s", "not", "a", "shared", "filesystem", "rank", "0", "creates", "the", "file", "all", "other", "ranks", "will", "wait", "until", "they", "find", "the", "file", "or", "timeout"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\distributed.py", "start_line": 43, "end_line": 99, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\distributed.py", "func_name": "function_68", "original_string": "def _gather_all_tensors(result: Tensor, group: Optional[Any] = None) -> list[Tensor]:\r\n    \"\"\"Function to gather all tensors from several DDP processes onto a list that is broadcasted to all processes.\r\n\r\n    Works on tensors that have the same number of dimensions, but where each dimension may differ. In this case\r\n    tensors are padded, gathered and then trimmed to secure equal workload for all processes.\r\n\r\n    Args:\r\n        result: The value to sync\r\n        group: The process group to gather results from. Defaults to all processes (world)\r\n\r\n    Return:\r\n        gathered_result: List with size equal to the process group where\r\n            gathered_result[i] corresponds to result tensor from process i\r\n\r\n    \"\"\"\r\n    if group is None:\r\n        group = torch.distributed.group.WORLD\r\n\r\n    result = result.contiguous()\r\n\r\n    world_size = torch.distributed.get_world_size(group)\r\n    torch.distributed.barrier(group=group)\r\n\r\n    if result.ndim == 0:\r\n        return _simple_gather_all_tensors(result, group, world_size)\r\n\r\n    local_size = torch.tensor(result.shape, device=result.device)\r\n    local_sizes = [torch.zeros_like(local_size) for _ in range(world_size)]\r\n    torch.distributed.all_gather(local_sizes, local_size, group=group)\r\n    max_size = torch.stack(local_sizes).max(dim=0).values\r\n    all_sizes_equal = all(all(ls == max_size) for ls in local_sizes)\r\n\r\n    if all_sizes_equal:\r\n        return _simple_gather_all_tensors(result, group, world_size)\r\n\r\n    pad_dims = []\r\n    pad_by = (max_size - local_size).detach().cpu()\r\n    for val in reversed(pad_by):\r\n        pad_dims.append(0)\r\n        pad_dims.append(val.item())\r\n    result_padded = F.pad(result, pad_dims)\r\n    gathered_result = [torch.zeros_like(result_padded) for _ in range(world_size)]\r\n    torch.distributed.all_gather(gathered_result, result_padded, group)\r\n    for idx, item_size in enumerate(local_sizes):\r\n        slice_param = [slice(dim_size) for dim_size in item_size]\r\n        gathered_result[idx] = gathered_result[idx][slice_param]\r\n    return gathered_result", "language": "python", "code": "def _gather_all_tensors(result: Tensor, group: Optional[Any] = None) -> list[Tensor]:\r\n    \"\"\"Function to gather all tensors from several DDP processes onto a list that is broadcasted to all processes.\r\n\r\n    Works on tensors that have the same number of dimensions, but where each dimension may differ. In this case\r\n    tensors are padded, gathered and then trimmed to secure equal workload for all processes.\r\n\r\n    Args:\r\n        result: The value to sync\r\n        group: The process group to gather results from. Defaults to all processes (world)\r\n\r\n    Return:\r\n        gathered_result: List with size equal to the process group where\r\n            gathered_result[i] corresponds to result tensor from process i\r\n\r\n    \"\"\"\r\n    if group is None:\r\n        group = torch.distributed.group.WORLD\r\n\r\n    result = result.contiguous()\r\n\r\n    world_size = torch.distributed.get_world_size(group)\r\n    torch.distributed.barrier(group=group)\r\n\r\n    if result.ndim == 0:\r\n        return _simple_gather_all_tensors(result, group, world_size)\r\n\r\n    local_size = torch.tensor(result.shape, device=result.device)\r\n    local_sizes = [torch.zeros_like(local_size) for _ in range(world_size)]\r\n    torch.distributed.all_gather(local_sizes, local_size, group=group)\r\n    max_size = torch.stack(local_sizes).max(dim=0).values\r\n    all_sizes_equal = all(all(ls == max_size) for ls in local_sizes)\r\n\r\n    if all_sizes_equal:\r\n        return _simple_gather_all_tensors(result, group, world_size)\r\n\r\n    pad_dims = []\r\n    pad_by = (max_size - local_size).detach().cpu()\r\n    for val in reversed(pad_by):\r\n        pad_dims.append(0)\r\n        pad_dims.append(val.item())\r\n    result_padded = F.pad(result, pad_dims)\r\n    gathered_result = [torch.zeros_like(result_padded) for _ in range(world_size)]\r\n    torch.distributed.all_gather(gathered_result, result_padded, group)\r\n    for idx, item_size in enumerate(local_sizes):\r\n        slice_param = [slice(dim_size) for dim_size in item_size]\r\n        gathered_result[idx] = gathered_result[idx][slice_param]\r\n    return gathered_result", "code_tokens": ["def", "_gather_all_tensors", "(", "result", ":", "Tensor", ",", "group", ":", "Optional", "[", "Any", "]", "=", "None", ")", "-", ">", "list", "[", "Tensor", "]", ":", "STRING", "if", "group", "is", "None", ":", "group", "=", "torch", ".", "distributed", ".", "group", ".", "WORLD", "result", "=", "result", ".", "contiguous", "(", ")", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "group", ")", "torch", ".", "distributed", ".", "barrier", "(", "group", "=", "group", ")", "if", "result", ".", "ndim", "=", "=", "0", ":", "return", "_simple_gather_all_tensors", "(", "result", ",", "group", ",", "world_size", ")", "local_size", "=", "torch", ".", "tensor", "(", "result", ".", "shape", ",", "device", "=", "result", ".", "device", ")", "local_sizes", "=", "[", "torch", ".", "zeros_like", "(", "local_size", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "torch", ".", "distributed", ".", "all_gather", "(", "local_sizes", ",", "local_size", ",", "group", "=", "group", ")", "max_size", "=", "torch", ".", "stack", "(", "local_sizes", ")", ".", "max", "(", "dim", "=", "0", ")", ".", "values", "all_sizes_equal", "=", "all", "(", "all", "(", "ls", "=", "=", "max_size", ")", "for", "ls", "in", "local_sizes", ")", "if", "all_sizes_equal", ":", "return", "_simple_gather_all_tensors", "(", "result", ",", "group", ",", "world_size", ")", "pad_dims", "=", "[", "]", "pad_by", "=", "(", "max_size", "-", "local_size", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "for", "val", "in", "reversed", "(", "pad_by", ")", ":", "pad_dims", ".", "append", "(", "0", ")", "pad_dims", ".", "append", "(", "val", ".", "item", "(", ")", ")", "result_padded", "=", "F", ".", "pad", "(", "result", ",", "pad_dims", ")", "gathered_result", "=", "[", "torch", ".", "zeros_like", "(", "result_padded", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "torch", ".", "distributed", ".", "all_gather", "(", "gathered_result", ",", "result_padded", ",", "group", ")", "for", "idx", ",", "item_size", "in", "enumerate", "(", "local_sizes", ")", ":", "slice_param", "=", "[", "slice", "(", "dim_size", ")", "for", "dim_size", "in", "item_size", "]", "gathered_result", "[", "idx", "]", "=", "gathered_result", "[", "idx", "]", "[", "slice_param", "]", "return", "gathered_result"], "docstring": "Convert tensors to contiguous format If the tensor is scalar, things are easy 1. Gather sizes of all tensors 2. If shapes are all the same, then do a simple gather: 3. If not, we need to pad each local tensor to maximum size, gather and then truncate", "docstring_tokens": ["convert", "tensors", "to", "contiguous", "format", "if", "the", "tensor", "is", "scalar", "things", "are", "easy", "1", "gather", "sizes", "of", "all", "tensors", "2", "if", "shapes", "are", "all", "the", "same", "then", "do", "a", "simple", "gather", "3", "if", "not", "we", "need", "to", "pad", "each", "local", "tensor", "to", "maximum", "size", "gather", "and", "then", "truncate"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\distributed.py", "start_line": 102, "end_line": 153, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\distributed.py", "func_name": "function_69", "original_string": "def _sync_ddp(result: Tensor, group: Optional[Any] = None, reduce_op: Optional[Union[ReduceOp, str]] = None) -> Tensor:\r\n    \"\"\"Reduces a tensor across several distributed processes.\r\n\r\n    This operation is performed in-place, meaning the result will be placed back into the input tensor on all processes.\r\n\r\n    Args:\r\n        result: The value to sync and reduce (typically tensor or number)\r\n        group: The process group to gather results from. Defaults to all processes (world)\r\n        reduce_op: The reduction operation. Defaults to sum.\r\n            Can also be a string of 'avg', 'mean' to calculate the mean during reduction.\r\n\r\n    Return:\r\n        The reduced value.\r\n\r\n    \"\"\"\r\n    divide_by_world_size = False\r\n    group = torch.distributed.group.WORLD if group is None else group\r\n\r\n    op: Optional[ReduceOp]\r\n    if isinstance(reduce_op, str):\r\n        reduce_op = \"avg\" if reduce_op == \"mean\" else reduce_op\r\n        if reduce_op.lower() == \"avg\" and torch.distributed.get_backend(group) == \"gloo\":\r\n            op = ReduceOp.SUM  # type: ignore[assignment]\r\n            divide_by_world_size = True\r\n        else:\r\n            op = getattr(ReduceOp, reduce_op.upper())\r\n    else:\r\n        op = reduce_op\r\n\r\n    if (\r\n        package_available(\"habana_frameworks\")\r\n        and os.environ.get(\"HCCL_DISTRIBUTED_BACKEND\") == \"1\"\r\n        and result.type()\r\n        in (\r\n            \"torch.LongTensor\",\r\n            \"torch.hpu.LongTensor\",\r\n        )\r\n    ):\r\n        rank_zero_info(\"Long tensor unsupported on HPU, casting to float\")\r\n        result = result.float()\r\n\r\n    torch.distributed.barrier(group=group)\r\n    torch.distributed.all_reduce(result, op=op, group=group, async_op=False)\r\n    world_size = torch.distributed.get_world_size(group)\r\n\r\n    if not divide_by_world_size:\r\n        return result\r\n    if not torch.is_floating_point(result):\r\n        return result.copy_(result / world_size)\r\n    return result.div_(world_size)", "language": "python", "code": "def _sync_ddp(result: Tensor, group: Optional[Any] = None, reduce_op: Optional[Union[ReduceOp, str]] = None) -> Tensor:\r\n    \"\"\"Reduces a tensor across several distributed processes.\r\n\r\n    This operation is performed in-place, meaning the result will be placed back into the input tensor on all processes.\r\n\r\n    Args:\r\n        result: The value to sync and reduce (typically tensor or number)\r\n        group: The process group to gather results from. Defaults to all processes (world)\r\n        reduce_op: The reduction operation. Defaults to sum.\r\n            Can also be a string of 'avg', 'mean' to calculate the mean during reduction.\r\n\r\n    Return:\r\n        The reduced value.\r\n\r\n    \"\"\"\r\n    divide_by_world_size = False\r\n    group = torch.distributed.group.WORLD if group is None else group\r\n\r\n    op: Optional[ReduceOp]\r\n    if isinstance(reduce_op, str):\r\n        reduce_op = \"avg\" if reduce_op == \"mean\" else reduce_op\r\n        if reduce_op.lower() == \"avg\" and torch.distributed.get_backend(group) == \"gloo\":\r\n            op = ReduceOp.SUM  # type: ignore[assignment]\r\n            divide_by_world_size = True\r\n        else:\r\n            op = getattr(ReduceOp, reduce_op.upper())\r\n    else:\r\n        op = reduce_op\r\n\r\n    if (\r\n        package_available(\"habana_frameworks\")\r\n        and os.environ.get(\"HCCL_DISTRIBUTED_BACKEND\") == \"1\"\r\n        and result.type()\r\n        in (\r\n            \"torch.LongTensor\",\r\n            \"torch.hpu.LongTensor\",\r\n        )\r\n    ):\r\n        rank_zero_info(\"Long tensor unsupported on HPU, casting to float\")\r\n        result = result.float()\r\n\r\n    torch.distributed.barrier(group=group)\r\n    torch.distributed.all_reduce(result, op=op, group=group, async_op=False)\r\n    world_size = torch.distributed.get_world_size(group)\r\n\r\n    if not divide_by_world_size:\r\n        return result\r\n    if not torch.is_floating_point(result):\r\n        return result.copy_(result / world_size)\r\n    return result.div_(world_size)", "code_tokens": ["def", "_sync_ddp", "(", "result", ":", "Tensor", ",", "group", ":", "Optional", "[", "Any", "]", "=", "None", ",", "reduce_op", ":", "Optional", "[", "Union", "[", "ReduceOp", ",", "str", "]", "]", "=", "None", ")", "-", ">", "Tensor", ":", "STRING", "divide_by_world_size", "=", "False", "group", "=", "torch", ".", "distributed", ".", "group", ".", "WORLD", "if", "group", "is", "None", "else", "group", "op", ":", "Optional", "[", "ReduceOp", "]", "if", "isinstance", "(", "reduce_op", ",", "str", ")", ":", "reduce_op", "=", "STRING", "if", "reduce_op", "=", "=", "STRING", "else", "reduce_op", "if", "reduce_op", ".", "lower", "(", ")", "=", "=", "STRING", "and", "torch", ".", "distributed", ".", "get_backend", "(", "group", ")", "=", "=", "STRING", ":", "op", "=", "ReduceOp", ".", "SUM", "#", "type", ":", "ignore", "[", "assignment", "]", "divide_by_world_size", "=", "True", "else", ":", "op", "=", "getattr", "(", "ReduceOp", ",", "reduce_op", ".", "upper", "(", ")", ")", "else", ":", "op", "=", "reduce_op", "if", "(", "package_available", "(", "STRING", ")", "and", "os", ".", "environ", ".", "get", "(", "STRING", ")", "=", "=", "STRING", "and", "result", ".", "type", "(", ")", "in", "(", "STRING", ",", "STRING", ",", ")", ")", ":", "rank_zero_info", "(", "STRING", ")", "result", "=", "result", ".", "float", "(", ")", "torch", ".", "distributed", ".", "barrier", "(", "group", "=", "group", ")", "torch", ".", "distributed", ".", "all_reduce", "(", "result", ",", "op", "=", "op", ",", "group", "=", "group", ",", "async_op", "=", "False", ")", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "group", ")", "if", "not", "divide_by_world_size", ":", "return", "result", "if", "not", "torch", ".", "is_floating_point", "(", "result", ")", ":", "return", "result", ".", "copy_", "(", "result", "/", "world_size", ")", "return", "result", ".", "div_", "(", "world_size", ")"], "docstring": "The GLOO backend does not support the `ReduceOp.AVG` operation HPU doesn't support Long types, forcefully set it to float TODO: move this to the `lightning_habana` package Sync all processes before reduction `torch.distributed.all_reduce` is in-place, so we should do the division in-place to leave the modified tensors with the expected value", "docstring_tokens": ["the", "gloo", "backend", "does", "not", "support", "the", "reduceop", "avg", "operation", "hpu", "doesn", "t", "support", "long", "types", "forcefully", "set", "it", "to", "float", "todo", "move", "this", "to", "the", "lightning_habana", "package", "sync", "all", "processes", "before", "reduction", "torch", "distributed", "all_reduce", "is", "in", "place", "so", "we", "should", "do", "the", "division", "in", "place", "to", "leave", "the", "modified", "tensors", "with", "the", "expected", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\distributed.py", "start_line": 182, "end_line": 237, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\distributed.py", "func_name": "function_70", "original_string": "def _init_dist_connection(\r\n    cluster_environment: \"ClusterEnvironment\",\r\n    torch_distributed_backend: str,\r\n    global_rank: Optional[int] = None,\r\n    world_size: Optional[int] = None,\r\n    **kwargs: Any,\r\n) -> None:\r\n    \"\"\"Utility function to initialize distributed connection by setting env variables and initializing the distributed\r\n    process group.\r\n\r\n    Args:\r\n        cluster_environment: ``ClusterEnvironment`` instance\r\n        torch_distributed_backend: Backend to use (includes `nccl` and `gloo`)\r\n        global_rank: Rank of the current process\r\n        world_size: Number of processes in the group\r\n        kwargs: Kwargs for ``init_process_group``\r\n\r\n    Raises:\r\n        RuntimeError:\r\n            If ``torch.distributed`` is not available\r\n\r\n    \"\"\"\r\n    if not torch.distributed.is_available():\r\n        raise RuntimeError(\"torch.distributed is not available. Cannot initialize distributed process group\")\r\n    if torch.distributed.is_initialized():\r\n        log.debug(\"torch.distributed is already initialized. Exiting early\")\r\n        return\r\n    global_rank = global_rank if global_rank is not None else cluster_environment.global_rank()\r\n    world_size = world_size if world_size is not None else cluster_environment.world_size()\r\n    os.environ[\"MASTER_ADDR\"] = cluster_environment.main_address\r\n    os.environ[\"MASTER_PORT\"] = str(cluster_environment.main_port)\r\n    log.info(f\"Initializing distributed: GLOBAL_RANK: {global_rank}, MEMBER: {global_rank + 1}/{world_size}\")\r\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\r\n\r\n    if torch_distributed_backend == \"nccl\":\r\n        atexit.register(_destroy_dist_connection)\r\n\r\n    rank_zero_info(\r\n        f\"{'-' * 100}\\n\"\r\n        f\"distributed_backend={torch_distributed_backend}\\n\"\r\n        f\"All distributed processes registered. Starting with {world_size} processes\\n\"\r\n        f\"{'-' * 100}\\n\"\r\n    )", "language": "python", "code": "def _init_dist_connection(\r\n    cluster_environment: \"ClusterEnvironment\",\r\n    torch_distributed_backend: str,\r\n    global_rank: Optional[int] = None,\r\n    world_size: Optional[int] = None,\r\n    **kwargs: Any,\r\n) -> None:\r\n    \"\"\"Utility function to initialize distributed connection by setting env variables and initializing the distributed\r\n    process group.\r\n\r\n    Args:\r\n        cluster_environment: ``ClusterEnvironment`` instance\r\n        torch_distributed_backend: Backend to use (includes `nccl` and `gloo`)\r\n        global_rank: Rank of the current process\r\n        world_size: Number of processes in the group\r\n        kwargs: Kwargs for ``init_process_group``\r\n\r\n    Raises:\r\n        RuntimeError:\r\n            If ``torch.distributed`` is not available\r\n\r\n    \"\"\"\r\n    if not torch.distributed.is_available():\r\n        raise RuntimeError(\"torch.distributed is not available. Cannot initialize distributed process group\")\r\n    if torch.distributed.is_initialized():\r\n        log.debug(\"torch.distributed is already initialized. Exiting early\")\r\n        return\r\n    global_rank = global_rank if global_rank is not None else cluster_environment.global_rank()\r\n    world_size = world_size if world_size is not None else cluster_environment.world_size()\r\n    os.environ[\"MASTER_ADDR\"] = cluster_environment.main_address\r\n    os.environ[\"MASTER_PORT\"] = str(cluster_environment.main_port)\r\n    log.info(f\"Initializing distributed: GLOBAL_RANK: {global_rank}, MEMBER: {global_rank + 1}/{world_size}\")\r\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\r\n\r\n    if torch_distributed_backend == \"nccl\":\r\n        atexit.register(_destroy_dist_connection)\r\n\r\n    rank_zero_info(\r\n        f\"{'-' * 100}\\n\"\r\n        f\"distributed_backend={torch_distributed_backend}\\n\"\r\n        f\"All distributed processes registered. Starting with {world_size} processes\\n\"\r\n        f\"{'-' * 100}\\n\"\r\n    )", "code_tokens": ["def", "_init_dist_connection", "(", "cluster_environment", ":", "STRING", ",", "torch_distributed_backend", ":", "str", ",", "global_rank", ":", "Optional", "[", "int", "]", "=", "None", ",", "world_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "None", ":", "STRING", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "raise", "RuntimeError", "(", "STRING", ")", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "log", ".", "debug", "(", "STRING", ")", "return", "global_rank", "=", "global_rank", "if", "global_rank", "is", "not", "None", "else", "cluster_environment", ".", "global_rank", "(", ")", "world_size", "=", "world_size", "if", "world_size", "is", "not", "None", "else", "cluster_environment", ".", "world_size", "(", ")", "os", ".", "environ", "[", "STRING", "]", "=", "cluster_environment", ".", "main_address", "os", ".", "environ", "[", "STRING", "]", "=", "str", "(", "cluster_environment", ".", "main_port", ")", "log", ".", "info", "(", "fSTRING", ")", "torch", ".", "distributed", ".", "init_process_group", "(", "torch_distributed_backend", ",", "rank", "=", "global_rank", ",", "world_size", "=", "world_size", ",", "*", "*", "kwargs", ")", "if", "torch_distributed_backend", "=", "=", "STRING", ":", "atexit", ".", "register", "(", "_destroy_dist_connection", ")", "rank_zero_info", "(", "fSTRING", "fSTRING", "fSTRING", "fSTRING", ")"], "docstring": "PyTorch >= 2.4 warns about undestroyed NCCL process group, so we need to do it at program exit On rank=0 let everyone know training is starting", "docstring_tokens": ["pytorch", "2", "4", "warns", "about", "undestroyed", "nccl", "process", "group", "so", "we", "need", "to", "do", "it", "at", "program", "exit", "on", "rank", "0", "let", "everyone", "know", "training", "is", "starting"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\distributed.py", "start_line": 265, "end_line": 309, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\load.py", "func_name": "function_71", "original_string": "def _load_distributed_checkpoint(checkpoint_folder: Path) -> dict[str, Any]:\r\n    \"\"\"Loads a sharded checkpoint saved with the `torch.distributed.checkpoint` into a full state dict.\r\n\r\n    The current implementation assumes that the entire checkpoint fits in CPU memory.\r\n\r\n    \"\"\"\r\n    if not _TORCH_GREATER_EQUAL_2_3:\r\n        raise ImportError(\"Processing distributed checkpoints requires PyTorch >= 2.3.\")\r\n\r\n    from torch.distributed.checkpoint import FileSystemReader\r\n    from torch.distributed.checkpoint.format_utils import _EmptyStateDictLoadPlanner\r\n    from torch.distributed.checkpoint.state_dict_loader import _load_state_dict\r\n\r\n    checkpoint: dict[str, Any] = {}\r\n    _load_state_dict(\r\n        checkpoint,\r\n        storage_reader=FileSystemReader(checkpoint_folder),\r\n        planner=_EmptyStateDictLoadPlanner(),\r\n        no_dist=True,\r\n    )\r\n\r\n    extra_file = checkpoint_folder / _METADATA_FILENAME\r\n    extra = torch.load(extra_file, map_location=\"cpu\") if extra_file.is_file() else {}\r\n    checkpoint.update(extra)\r\n\r\n    return checkpoint", "language": "python", "code": "def _load_distributed_checkpoint(checkpoint_folder: Path) -> dict[str, Any]:\r\n    \"\"\"Loads a sharded checkpoint saved with the `torch.distributed.checkpoint` into a full state dict.\r\n\r\n    The current implementation assumes that the entire checkpoint fits in CPU memory.\r\n\r\n    \"\"\"\r\n    if not _TORCH_GREATER_EQUAL_2_3:\r\n        raise ImportError(\"Processing distributed checkpoints requires PyTorch >= 2.3.\")\r\n\r\n    from torch.distributed.checkpoint import FileSystemReader\r\n    from torch.distributed.checkpoint.format_utils import _EmptyStateDictLoadPlanner\r\n    from torch.distributed.checkpoint.state_dict_loader import _load_state_dict\r\n\r\n    checkpoint: dict[str, Any] = {}\r\n    _load_state_dict(\r\n        checkpoint,\r\n        storage_reader=FileSystemReader(checkpoint_folder),\r\n        planner=_EmptyStateDictLoadPlanner(),\r\n        no_dist=True,\r\n    )\r\n\r\n    extra_file = checkpoint_folder / _METADATA_FILENAME\r\n    extra = torch.load(extra_file, map_location=\"cpu\") if extra_file.is_file() else {}\r\n    checkpoint.update(extra)\r\n\r\n    return checkpoint", "code_tokens": ["def", "_load_distributed_checkpoint", "(", "checkpoint_folder", ":", "Path", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "_TORCH_GREATER_EQUAL_2_3", ":", "raise", "ImportError", "(", "STRING", ")", "from", "torch", ".", "distributed", ".", "checkpoint", "import", "FileSystemReader", "from", "torch", ".", "distributed", ".", "checkpoint", ".", "format_utils", "import", "_EmptyStateDictLoadPlanner", "from", "torch", ".", "distributed", ".", "checkpoint", ".", "state_dict_loader", "import", "_load_state_dict", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "_load_state_dict", "(", "checkpoint", ",", "storage_reader", "=", "FileSystemReader", "(", "checkpoint_folder", ")", ",", "planner", "=", "_EmptyStateDictLoadPlanner", "(", ")", ",", "no_dist", "=", "True", ",", ")", "extra_file", "=", "checkpoint_folder", "/", "_METADATA_FILENAME", "extra", "=", "torch", ".", "load", "(", "extra_file", ",", "map_location", "=", "STRING", ")", "if", "extra_file", ".", "is_file", "(", ")", "else", "{", "}", "checkpoint", ".", "update", "(", "extra", ")", "return", "checkpoint"], "docstring": "This is the extra file saved by Fabric, with user data separate from weights and optimizer states", "docstring_tokens": ["this", "is", "the", "extra", "file", "saved", "by", "fabric", "with", "user", "data", "separate", "from", "weights", "and", "optimizer", "states"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\load.py", "start_line": 239, "end_line": 265, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\logger.py", "func_name": "function_72", "original_string": "def _convert_params(params: Optional[Union[dict[str, Any], Namespace]]) -> dict[str, Any]:\r\n    \"\"\"Ensure parameters are a dict or convert to dict if necessary.\r\n\r\n    Args:\r\n        params: Target to be converted to a dictionary\r\n\r\n    Returns:\r\n        params as a dictionary\r\n\r\n    \"\"\"\r\n    if isinstance(params, Namespace):\r\n        params = vars(params)\r\n\r\n    if params is None:\r\n        params = {}\r\n\r\n    return params", "language": "python", "code": "def _convert_params(params: Optional[Union[dict[str, Any], Namespace]]) -> dict[str, Any]:\r\n    \"\"\"Ensure parameters are a dict or convert to dict if necessary.\r\n\r\n    Args:\r\n        params: Target to be converted to a dictionary\r\n\r\n    Returns:\r\n        params as a dictionary\r\n\r\n    \"\"\"\r\n    if isinstance(params, Namespace):\r\n        params = vars(params)\r\n\r\n    if params is None:\r\n        params = {}\r\n\r\n    return params", "code_tokens": ["def", "_convert_params", "(", "params", ":", "Optional", "[", "Union", "[", "dict", "[", "str", ",", "Any", "]", ",", "Namespace", "]", "]", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "isinstance", "(", "params", ",", "Namespace", ")", ":", "params", "=", "vars", "(", "params", ")", "if", "params", "is", "None", ":", "params", "=", "{", "}", "return", "params"], "docstring": "in case converting from namespace", "docstring_tokens": ["in", "case", "converting", "from", "namespace"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\logger.py", "start_line": 26, "end_line": 43, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\logger.py", "func_name": "function_73", "original_string": "def _sanitize_callable_params(params: dict[str, Any]) -> dict[str, Any]:\r\n    \"\"\"Sanitize callable params dict, e.g. ``{'a': <function_**** at 0x****>} -> {'a': 'function_****'}``.\r\n\r\n    Args:\r\n        params: Dictionary containing the hyperparameters\r\n\r\n    Returns:\r\n        dictionary with all callables sanitized\r\n\r\n    \"\"\"\r\n\r\n    def _sanitize_callable(val: Any) -> Any:\r\n        if inspect.isclass(val):\r\n            return val.__name__\r\n        if callable(val):\r\n            try:\r\n                _val = val()\r\n                if callable(_val):\r\n                    return val.__name__\r\n                return _val\r\n            except Exception:\r\n                return getattr(val, \"__name__\", None)\r\n        return val\r\n\r\n    return {key: _sanitize_callable(val) for key, val in params.items()}", "language": "python", "code": "def _sanitize_callable_params(params: dict[str, Any]) -> dict[str, Any]:\r\n    \"\"\"Sanitize callable params dict, e.g. ``{'a': <function_**** at 0x****>} -> {'a': 'function_****'}``.\r\n\r\n    Args:\r\n        params: Dictionary containing the hyperparameters\r\n\r\n    Returns:\r\n        dictionary with all callables sanitized\r\n\r\n    \"\"\"\r\n\r\n    def _sanitize_callable(val: Any) -> Any:\r\n        if inspect.isclass(val):\r\n            return val.__name__\r\n        if callable(val):\r\n            try:\r\n                _val = val()\r\n                if callable(_val):\r\n                    return val.__name__\r\n                return _val\r\n            except Exception:\r\n                return getattr(val, \"__name__\", None)\r\n        return val\r\n\r\n    return {key: _sanitize_callable(val) for key, val in params.items()}", "code_tokens": ["def", "_sanitize_callable_params", "(", "params", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "def", "_sanitize_callable", "(", "val", ":", "Any", ")", "-", ">", "Any", ":", "if", "inspect", ".", "isclass", "(", "val", ")", ":", "return", "val", ".", "__name__", "if", "callable", "(", "val", ")", ":", "try", ":", "_val", "=", "val", "(", ")", "if", "callable", "(", "_val", ")", ":", "return", "val", ".", "__name__", "return", "_val", "except", "Exception", ":", "return", "getattr", "(", "val", ",", "STRING", ",", "None", ")", "return", "val", "return", "{", "key", ":", "_sanitize_callable", "(", "val", ")", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", "}"], "docstring": "If it's a class, don't try to instantiate it, just return the name Callables get a chance to return a name todo: specify the possible exception", "docstring_tokens": ["if", "it", "s", "a", "class", "don", "t", "try", "to", "instantiate", "it", "just", "return", "the", "name", "callables", "get", "a", "chance", "to", "return", "a", "name", "todo", "specify", "the", "possible", "exception"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\logger.py", "start_line": 46, "end_line": 73, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\logger.py", "func_name": "function_74", "original_string": "def _flatten_dict(params: MutableMapping[Any, Any], delimiter: str = \"/\", parent_key: str = \"\") -> dict[str, Any]:\r\n    \"\"\"Flatten hierarchical dict, e.g. ``{'a': {'b': 'c'}} -> {'a/b': 'c'}``.\r\n\r\n    Args:\r\n        params: Dictionary containing the hyperparameters\r\n        delimiter: Delimiter to express the hierarchy. Defaults to ``'/'``.\r\n\r\n    Returns:\r\n        Flattened dict.\r\n\r\n    Examples:\r\n        >>> _flatten_dict({'a': {'b': 'c'}})\r\n        {'a/b': 'c'}\r\n        >>> _flatten_dict({'a': {'b': 123}})\r\n        {'a/b': 123}\r\n        >>> _flatten_dict({5: {'a': 123}})\r\n        {'5/a': 123}\r\n        >>> _flatten_dict({\"dl\": [{\"a\": 1, \"c\": 3}, {\"b\": 2, \"d\": 5}], \"l\": [1, 2, 3, 4]})\r\n        {'dl/0/a': 1, 'dl/0/c': 3, 'dl/1/b': 2, 'dl/1/d': 5, 'l': [1, 2, 3, 4]}\r\n\r\n    \"\"\"\r\n    result: dict[str, Any] = {}\r\n    for k, v in params.items():\r\n        new_key = parent_key + delimiter + str(k) if parent_key else str(k)\r\n        if is_dataclass(v) and not isinstance(v, type):\r\n            v = asdict(v)\r\n        elif isinstance(v, Namespace):\r\n            v = vars(v)\r\n\r\n        if isinstance(v, MutableMapping):\r\n            result = {**result, **_flatten_dict(v, parent_key=new_key, delimiter=delimiter)}\r\n        elif isinstance(v, list) and all(isinstance(item, MutableMapping) for item in v):\r\n            for i, item in enumerate(v):\r\n                result = {**result, **_flatten_dict(item, parent_key=f\"{new_key}/{i}\", delimiter=delimiter)}\r\n        else:\r\n            result[new_key] = v\r\n    return result", "language": "python", "code": "def _flatten_dict(params: MutableMapping[Any, Any], delimiter: str = \"/\", parent_key: str = \"\") -> dict[str, Any]:\r\n    \"\"\"Flatten hierarchical dict, e.g. ``{'a': {'b': 'c'}} -> {'a/b': 'c'}``.\r\n\r\n    Args:\r\n        params: Dictionary containing the hyperparameters\r\n        delimiter: Delimiter to express the hierarchy. Defaults to ``'/'``.\r\n\r\n    Returns:\r\n        Flattened dict.\r\n\r\n    Examples:\r\n        >>> _flatten_dict({'a': {'b': 'c'}})\r\n        {'a/b': 'c'}\r\n        >>> _flatten_dict({'a': {'b': 123}})\r\n        {'a/b': 123}\r\n        >>> _flatten_dict({5: {'a': 123}})\r\n        {'5/a': 123}\r\n        >>> _flatten_dict({\"dl\": [{\"a\": 1, \"c\": 3}, {\"b\": 2, \"d\": 5}], \"l\": [1, 2, 3, 4]})\r\n        {'dl/0/a': 1, 'dl/0/c': 3, 'dl/1/b': 2, 'dl/1/d': 5, 'l': [1, 2, 3, 4]}\r\n\r\n    \"\"\"\r\n    result: dict[str, Any] = {}\r\n    for k, v in params.items():\r\n        new_key = parent_key + delimiter + str(k) if parent_key else str(k)\r\n        if is_dataclass(v) and not isinstance(v, type):\r\n            v = asdict(v)\r\n        elif isinstance(v, Namespace):\r\n            v = vars(v)\r\n\r\n        if isinstance(v, MutableMapping):\r\n            result = {**result, **_flatten_dict(v, parent_key=new_key, delimiter=delimiter)}\r\n        elif isinstance(v, list) and all(isinstance(item, MutableMapping) for item in v):\r\n            for i, item in enumerate(v):\r\n                result = {**result, **_flatten_dict(item, parent_key=f\"{new_key}/{i}\", delimiter=delimiter)}\r\n        else:\r\n            result[new_key] = v\r\n    return result", "code_tokens": ["def", "_flatten_dict", "(", "params", ":", "MutableMapping", "[", "Any", ",", "Any", "]", ",", "delimiter", ":", "str", "=", "STRING", ",", "parent_key", ":", "str", "=", "STRING", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "result", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "new_key", "=", "parent_key", "+", "delimiter", "+", "str", "(", "k", ")", "if", "parent_key", "else", "str", "(", "k", ")", "if", "is_dataclass", "(", "v", ")", "and", "not", "isinstance", "(", "v", ",", "type", ")", ":", "v", "=", "asdict", "(", "v", ")", "elif", "isinstance", "(", "v", ",", "Namespace", ")", ":", "v", "=", "vars", "(", "v", ")", "if", "isinstance", "(", "v", ",", "MutableMapping", ")", ":", "result", "=", "{", "*", "*", "result", ",", "*", "*", "_flatten_dict", "(", "v", ",", "parent_key", "=", "new_key", ",", "delimiter", "=", "delimiter", ")", "}", "elif", "isinstance", "(", "v", ",", "list", ")", "and", "all", "(", "isinstance", "(", "item", ",", "MutableMapping", ")", "for", "item", "in", "v", ")", ":", "for", "i", ",", "item", "in", "enumerate", "(", "v", ")", ":", "result", "=", "{", "*", "*", "result", ",", "*", "*", "_flatten_dict", "(", "item", ",", "parent_key", "=", "fSTRING", ",", "delimiter", "=", "delimiter", ")", "}", "else", ":", "result", "[", "new_key", "]", "=", "v", "return", "result"], "docstring": "Also handle the case where v is a list of dictionaries", "docstring_tokens": ["also", "handle", "the", "case", "where", "v", "is", "a", "list", "of", "dictionaries"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\logger.py", "start_line": 76, "end_line": 113, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\logger.py", "func_name": "function_75", "original_string": "def _is_json_serializable(value: Any) -> bool:\r\n    \"\"\"Test whether a variable can be encoded as json.\"\"\"\r\n    if value is None or isinstance(value, (bool, int, float, str, list, dict)):  # fast path\r\n        return True\r\n    try:\r\n        json.dumps(value)\r\n        return True\r\n    except (TypeError, OverflowError):\r\n        return False", "language": "python", "code": "def _is_json_serializable(value: Any) -> bool:\r\n    \"\"\"Test whether a variable can be encoded as json.\"\"\"\r\n    if value is None or isinstance(value, (bool, int, float, str, list, dict)):  # fast path\r\n        return True\r\n    try:\r\n        json.dumps(value)\r\n        return True\r\n    except (TypeError, OverflowError):\r\n        return False", "code_tokens": ["def", "_is_json_serializable", "(", "value", ":", "Any", ")", "-", ">", "bool", ":", "STRING", "if", "value", "is", "None", "or", "isinstance", "(", "value", ",", "(", "bool", ",", "int", ",", "float", ",", "str", ",", "list", ",", "dict", ")", ")", ":", "#", "fast", "path", "return", "True", "try", ":", "json", ".", "dumps", "(", "value", ")", "return", "True", "except", "(", "TypeError", ",", "OverflowError", ")", ":", "return", "False"], "docstring": "OverflowError is raised if number is too large to encode", "docstring_tokens": ["overflowerror", "is", "raised", "if", "number", "is", "too", "large", "to", "encode"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\logger.py", "start_line": 154, "end_line": 163, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\optimizer.py", "func_name": "function_76", "original_string": "def _optimizer_to_device(optimizer: Optimizer, device: _DEVICE) -> None:\r\n    \"\"\"Moves the state of a single optimizer to the device.\"\"\"\r\n    for p, v in optimizer.state.items():\r\n        if not isinstance(v, MutableMapping):\r\n            optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device, allow_frozen=True)\r\n            continue\r\n        for key, val in v.items():\r\n            if key != \"step\":\r\n                v[key] = move_data_to_device(val, device)", "language": "python", "code": "def _optimizer_to_device(optimizer: Optimizer, device: _DEVICE) -> None:\r\n    \"\"\"Moves the state of a single optimizer to the device.\"\"\"\r\n    for p, v in optimizer.state.items():\r\n        if not isinstance(v, MutableMapping):\r\n            optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device, allow_frozen=True)\r\n            continue\r\n        for key, val in v.items():\r\n            if key != \"step\":\r\n                v[key] = move_data_to_device(val, device)", "code_tokens": ["def", "_optimizer_to_device", "(", "optimizer", ":", "Optimizer", ",", "device", ":", "_DEVICE", ")", "-", ">", "None", ":", "STRING", "for", "p", ",", "v", "in", "optimizer", ".", "state", ".", "items", "(", ")", ":", "if", "not", "isinstance", "(", "v", ",", "MutableMapping", ")", ":", "optimizer", ".", "state", "[", "p", "]", "=", "apply_to_collection", "(", "v", ",", "Tensor", ",", "move_data_to_device", ",", "device", ",", "allow_frozen", "=", "True", ")", "continue", "for", "key", ",", "val", "in", "v", ".", "items", "(", ")", ":", "if", "key", "!", "=", "STRING", ":", "v", "[", "key", "]", "=", "move_data_to_device", "(", "val", ",", "device", ")"], "docstring": "Support for custom optimizers The 'step' parameter needs to remain unmoved (possibly on the CPU) since that is where the optimizer needs it. See https://github.com/pytorch/pytorch/issues/74424", "docstring_tokens": ["support", "for", "custom", "optimizers", "the", "step", "parameter", "needs", "to", "remain", "unmoved", "possibly", "on", "the", "cpu", "since", "that", "is", "where", "the", "optimizer", "needs", "it", "see", "https", "github", "com", "pytorch", "pytorch", "issues", "74424"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\optimizer.py", "start_line": 29, "end_line": 40, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\seed.py", "func_name": "function_77", "original_string": "def pl_worker_init_function(worker_id: int, rank: Optional[int] = None) -> None:  # pragma: no cover\r\n    r\"\"\"The worker_init_fn that Lightning automatically adds to your dataloader if you previously set the seed with\r\n    ``seed_everything(seed, workers=True)``.\r\n\r\n    See also the PyTorch documentation on\r\n    `randomness in DataLoaders <https://pytorch.org/docs/stable/notes/randomness.html#dataloader>`_.\r\n\r\n    \"\"\"\r\n    global_rank = rank if rank is not None else rank_zero_only.rank\r\n    process_seed = torch.initial_seed()\r\n    base_seed = process_seed - worker_id\r\n    log.debug(\r\n        f\"Initializing random number generators of process {global_rank} worker {worker_id} with base seed {base_seed}\"\r\n    )\r\n    seed_sequence = _generate_seed_sequence(base_seed, worker_id, global_rank, count=4)\r\n    torch.manual_seed(seed_sequence[0])  # torch takes a 64-bit seed\r\n    random.seed((seed_sequence[1] << 32) | seed_sequence[2])  # combine two 64-bit seeds\r\n    if _NUMPY_AVAILABLE:\r\n        import numpy as np\r\n\r\n        ss = np.random.SeedSequence([base_seed, worker_id, global_rank])\r\n        np_rng_seed = ss.generate_state(4)\r\n\r\n        np.random.seed(np_rng_seed)", "language": "python", "code": "def pl_worker_init_function(worker_id: int, rank: Optional[int] = None) -> None:  # pragma: no cover\r\n    r\"\"\"The worker_init_fn that Lightning automatically adds to your dataloader if you previously set the seed with\r\n    ``seed_everything(seed, workers=True)``.\r\n\r\n    See also the PyTorch documentation on\r\n    `randomness in DataLoaders <https://pytorch.org/docs/stable/notes/randomness.html#dataloader>`_.\r\n\r\n    \"\"\"\r\n    global_rank = rank if rank is not None else rank_zero_only.rank\r\n    process_seed = torch.initial_seed()\r\n    base_seed = process_seed - worker_id\r\n    log.debug(\r\n        f\"Initializing random number generators of process {global_rank} worker {worker_id} with base seed {base_seed}\"\r\n    )\r\n    seed_sequence = _generate_seed_sequence(base_seed, worker_id, global_rank, count=4)\r\n    torch.manual_seed(seed_sequence[0])  # torch takes a 64-bit seed\r\n    random.seed((seed_sequence[1] << 32) | seed_sequence[2])  # combine two 64-bit seeds\r\n    if _NUMPY_AVAILABLE:\r\n        import numpy as np\r\n\r\n        ss = np.random.SeedSequence([base_seed, worker_id, global_rank])\r\n        np_rng_seed = ss.generate_state(4)\r\n\r\n        np.random.seed(np_rng_seed)", "code_tokens": ["def", "pl_worker_init_function", "(", "worker_id", ":", "int", ",", "rank", ":", "Optional", "[", "int", "]", "=", "None", ")", "-", ">", "None", ":", "#", "pragma", ":", "no", "cover", "rSTRING", "global_rank", "=", "rank", "if", "rank", "is", "not", "None", "else", "rank_zero_only", ".", "rank", "process_seed", "=", "torch", ".", "initial_seed", "(", ")", "base_seed", "=", "process_seed", "-", "worker_id", "log", ".", "debug", "(", "fSTRING", ")", "seed_sequence", "=", "_generate_seed_sequence", "(", "base_seed", ",", "worker_id", ",", "global_rank", ",", "count", "=", "4", ")", "torch", ".", "manual_seed", "(", "seed_sequence", "[", "0", "]", ")", "#", "torch", "takes", "a", "64", "-", "bit", "seed", "random", ".", "seed", "(", "(", "seed_sequence", "[", "1", "]", "<", "<", "32", ")", "|", "seed_sequence", "[", "2", "]", ")", "#", "combine", "two", "64", "-", "bit", "seeds", "if", "_NUMPY_AVAILABLE", ":", "import", "numpy", "as", "np", "ss", "=", "np", ".", "random", ".", "SeedSequence", "(", "[", "base_seed", ",", "worker_id", ",", "global_rank", "]", ")", "np_rng_seed", "=", "ss", ".", "generate_state", "(", "4", ")", "np", ".", "random", ".", "seed", "(", "np_rng_seed", ")"], "docstring": "implementation notes: https://github.com/pytorch/pytorch/issues/5059#issuecomment-817392562 back out the base seed so we can use all the bits", "docstring_tokens": ["implementation", "notes", "https", "github", "com", "pytorch", "pytorch", "issues", "5059", "issuecomment", "817392562", "back", "out", "the", "base", "seed", "so", "we", "can", "use", "all", "the", "bits"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\seed.py", "start_line": 84, "end_line": 109, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\seed.py", "func_name": "function_78", "original_string": "def _generate_seed_sequence(base_seed: int, worker_id: int, global_rank: int, count: int) -> list[int]:\r\n    \"\"\"Generates a sequence of seeds from a base seed, worker id and rank using the linear congruential generator (LCG)\r\n    algorithm.\"\"\"\r\n    combined_seed = (base_seed << 32) | (worker_id << 16) | global_rank\r\n    seeds = []\r\n    for _ in range(count):\r\n        combined_seed = (combined_seed * 6364136223846793005 + 1) & ((1 << 64) - 1)\r\n        seeds.append(combined_seed)\r\n    return seeds", "language": "python", "code": "def _generate_seed_sequence(base_seed: int, worker_id: int, global_rank: int, count: int) -> list[int]:\r\n    \"\"\"Generates a sequence of seeds from a base seed, worker id and rank using the linear congruential generator (LCG)\r\n    algorithm.\"\"\"\r\n    combined_seed = (base_seed << 32) | (worker_id << 16) | global_rank\r\n    seeds = []\r\n    for _ in range(count):\r\n        combined_seed = (combined_seed * 6364136223846793005 + 1) & ((1 << 64) - 1)\r\n        seeds.append(combined_seed)\r\n    return seeds", "code_tokens": ["def", "_generate_seed_sequence", "(", "base_seed", ":", "int", ",", "worker_id", ":", "int", ",", "global_rank", ":", "int", ",", "count", ":", "int", ")", "-", ">", "list", "[", "int", "]", ":", "STRING", "combined_seed", "=", "(", "base_seed", "<", "<", "32", ")", "|", "(", "worker_id", "<", "<", "16", ")", "|", "global_rank", "seeds", "=", "[", "]", "for", "_", "in", "range", "(", "count", ")", ":", "combined_seed", "=", "(", "combined_seed", "*", "6364136223846793005", "+", "1", ")", "&", "(", "(", "1", "<", "<", "64", ")", "-", "1", ")", "seeds", ".", "append", "(", "combined_seed", ")", "return", "seeds"], "docstring": "Combine base seed, worker id and rank into a unique 64-bit number x_(n+1) = (a * x_n + c) mod m. With c=1, m=2^64 and a is D. Knuth's constant", "docstring_tokens": ["combine", "base", "seed", "worker", "id", "and", "rank", "into", "a", "unique", "64", "bit", "number", "x_", "n", "1", "a", "x_n", "c", "mod", "m", "with", "c", "1", "m", "2", "64", "and", "a", "is", "d", "knuth", "s", "constant"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\seed.py", "start_line": 112, "end_line": 122, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\seed.py", "func_name": "function_79", "original_string": "def _set_rng_states(rng_state_dict: dict[str, Any]) -> None:\r\n    r\"\"\"Set the global random state of :mod:`torch`, :mod:`torch.cuda`, :mod:`numpy` and Python in the current\r\n    process.\"\"\"\r\n    torch.set_rng_state(rng_state_dict[\"torch\"])\r\n    if \"torch.cuda\" in rng_state_dict:\r\n        torch.cuda.set_rng_state_all(rng_state_dict[\"torch.cuda\"])\r\n    if _NUMPY_AVAILABLE and \"numpy\" in rng_state_dict:\r\n        import numpy as np\r\n\r\n        np.random.set_state(rng_state_dict[\"numpy\"])\r\n    version, state, gauss = rng_state_dict[\"python\"]\r\n    python_set_rng_state((version, tuple(state), gauss))", "language": "python", "code": "def _set_rng_states(rng_state_dict: dict[str, Any]) -> None:\r\n    r\"\"\"Set the global random state of :mod:`torch`, :mod:`torch.cuda`, :mod:`numpy` and Python in the current\r\n    process.\"\"\"\r\n    torch.set_rng_state(rng_state_dict[\"torch\"])\r\n    if \"torch.cuda\" in rng_state_dict:\r\n        torch.cuda.set_rng_state_all(rng_state_dict[\"torch.cuda\"])\r\n    if _NUMPY_AVAILABLE and \"numpy\" in rng_state_dict:\r\n        import numpy as np\r\n\r\n        np.random.set_state(rng_state_dict[\"numpy\"])\r\n    version, state, gauss = rng_state_dict[\"python\"]\r\n    python_set_rng_state((version, tuple(state), gauss))", "code_tokens": ["def", "_set_rng_states", "(", "rng_state_dict", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "rSTRING", "torch", ".", "set_rng_state", "(", "rng_state_dict", "[", "STRING", "]", ")", "if", "STRING", "in", "rng_state_dict", ":", "torch", ".", "cuda", ".", "set_rng_state_all", "(", "rng_state_dict", "[", "STRING", "]", ")", "if", "_NUMPY_AVAILABLE", "and", "STRING", "in", "rng_state_dict", ":", "import", "numpy", "as", "np", "np", ".", "random", ".", "set_state", "(", "rng_state_dict", "[", "STRING", "]", ")", "version", ",", "state", ",", "gauss", "=", "rng_state_dict", "[", "STRING", "]", "python_set_rng_state", "(", "(", "version", ",", "tuple", "(", "state", ")", ",", "gauss", ")", ")"], "docstring": "torch.cuda rng_state is only included since v1.8.", "docstring_tokens": ["torch", "cuda", "rng_state", "is", "only", "included", "since", "v1", "8"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\seed.py", "start_line": 140, "end_line": 152, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\spike.py", "func_name": "function_80", "original_string": "def on_train_batch_end(self, fabric: \"Fabric\", loss: torch.Tensor, batch: Any, batch_idx: int) -> None:\r\n        \"\"\"Checks if we currently have a loss-spike.\"\"\"\r\n        if batch_idx == 0:\r\n            self.running_mean.to(fabric.strategy.root_device)\r\n\r\n        if self.exclude_batches_path is None:\r\n            self.exclude_batches_path = os.getcwd()\r\n\r\n        if not str(self.exclude_batches_path).endswith(\".json\"):\r\n            self.exclude_batches_path = os.path.join(self.exclude_batches_path, \"skip_batches.json\")\r\n\r\n        is_spike = bool(batch_idx >= self.warmup and self._is_spike(loss))\r\n        fabric.strategy.barrier()\r\n\r\n        is_spike_global = fabric.strategy.reduce_boolean_decision(is_spike, all=False)\r\n\r\n        if is_spike_global:\r\n            self._handle_spike(fabric, batch_idx)\r\n        else:\r\n            is_finite_all = self.finite_only or fabric.strategy.reduce_boolean_decision(\r\n                bool(torch.isfinite(loss).all()), all=True\r\n            )\r\n            if is_finite_all:\r\n                self._update_stats(loss)", "language": "python", "code": "def on_train_batch_end(self, fabric: \"Fabric\", loss: torch.Tensor, batch: Any, batch_idx: int) -> None:\r\n        \"\"\"Checks if we currently have a loss-spike.\"\"\"\r\n        if batch_idx == 0:\r\n            self.running_mean.to(fabric.strategy.root_device)\r\n\r\n        if self.exclude_batches_path is None:\r\n            self.exclude_batches_path = os.getcwd()\r\n\r\n        if not str(self.exclude_batches_path).endswith(\".json\"):\r\n            self.exclude_batches_path = os.path.join(self.exclude_batches_path, \"skip_batches.json\")\r\n\r\n        is_spike = bool(batch_idx >= self.warmup and self._is_spike(loss))\r\n        fabric.strategy.barrier()\r\n\r\n        is_spike_global = fabric.strategy.reduce_boolean_decision(is_spike, all=False)\r\n\r\n        if is_spike_global:\r\n            self._handle_spike(fabric, batch_idx)\r\n        else:\r\n            is_finite_all = self.finite_only or fabric.strategy.reduce_boolean_decision(\r\n                bool(torch.isfinite(loss).all()), all=True\r\n            )\r\n            if is_finite_all:\r\n                self._update_stats(loss)", "code_tokens": ["def", "on_train_batch_end", "(", "self", ",", "fabric", ":", "STRING", ",", "loss", ":", "torch", ".", "Tensor", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ")", "-", ">", "None", ":", "STRING", "if", "batch_idx", "=", "=", "0", ":", "self", ".", "running_mean", ".", "to", "(", "fabric", ".", "strategy", ".", "root_device", ")", "if", "self", ".", "exclude_batches_path", "is", "None", ":", "self", ".", "exclude_batches_path", "=", "os", ".", "getcwd", "(", ")", "if", "not", "str", "(", "self", ".", "exclude_batches_path", ")", ".", "endswith", "(", "STRING", ")", ":", "self", ".", "exclude_batches_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "exclude_batches_path", ",", "STRING", ")", "is_spike", "=", "bool", "(", "batch_idx", ">", "=", "self", ".", "warmup", "and", "self", ".", "_is_spike", "(", "loss", ")", ")", "fabric", ".", "strategy", ".", "barrier", "(", ")", "is_spike_global", "=", "fabric", ".", "strategy", ".", "reduce_boolean_decision", "(", "is_spike", ",", "all", "=", "False", ")", "if", "is_spike_global", ":", "self", ".", "_handle_spike", "(", "fabric", ",", "batch_idx", ")", "else", ":", "is_finite_all", "=", "self", ".", "finite_only", "or", "fabric", ".", "strategy", ".", "reduce_boolean_decision", "(", "bool", "(", "torch", ".", "isfinite", "(", "loss", ")", ".", "all", "(", ")", ")", ",", "all", "=", "True", ")", "if", "is_finite_all", ":", "self", ".", "_update_stats", "(", "loss", ")"], "docstring": "While spike-detection happens on a per-rank level, we need to fail all ranks if any rank detected a spike", "docstring_tokens": ["while", "spike", "detection", "happens", "on", "a", "per", "rank", "level", "we", "need", "to", "fail", "all", "ranks", "if", "any", "rank", "detected", "a", "spike"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\spike.py", "start_line": 70, "end_line": 94, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\throughput.py", "func_name": "function_81", "original_string": "def update(\r\n        self,\r\n        *,\r\n        time: float,\r\n        batches: int,\r\n        samples: int,\r\n        lengths: Optional[int] = None,\r\n        flops: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Update throughput metrics.\r\n\r\n        Args:\r\n            time: Total elapsed time in seconds. It should monotonically increase by the iteration time with each\r\n                call.\r\n            batches: Total batches seen per device. It should monotonically increase with each call.\r\n            samples: Total samples seen per device. It should monotonically increase by the batch size with each call.\r\n            lengths: Total length of the samples seen. It should monotonically increase by the lengths of a batch with\r\n                each call.\r\n            flops: Flops elapased per device since last ``update()`` call. You can easily compute this by using\r\n                :func:`measure_flops` and multiplying it by the number of batches that have been processed.\r\n                The value might be different in each device if the batch size is not the same.\r\n\r\n        \"\"\"\r\n        self._time.append(time)\r\n        if samples < batches:\r\n            raise ValueError(f\"Expected samples ({samples}) to be greater or equal than batches ({batches})\")\r\n        self._batches.append(batches)\r\n        self._samples.append(samples)\r\n        if lengths is not None:\r\n            if lengths < samples:\r\n                raise ValueError(f\"Expected lengths ({lengths}) to be greater or equal than samples ({samples})\")\r\n            self._lengths.append(lengths)\r\n            if len(self._samples) != len(self._lengths):\r\n                raise RuntimeError(\r\n                    f\"If lengths are passed ({len(self._lengths)}), there needs to be the same number of samples\"\r\n                    f\" ({len(self._samples)})\"\r\n                )\r\n        if flops is not None:\r\n            self._flops.append(flops * self.world_size)", "language": "python", "code": "def update(\r\n        self,\r\n        *,\r\n        time: float,\r\n        batches: int,\r\n        samples: int,\r\n        lengths: Optional[int] = None,\r\n        flops: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Update throughput metrics.\r\n\r\n        Args:\r\n            time: Total elapsed time in seconds. It should monotonically increase by the iteration time with each\r\n                call.\r\n            batches: Total batches seen per device. It should monotonically increase with each call.\r\n            samples: Total samples seen per device. It should monotonically increase by the batch size with each call.\r\n            lengths: Total length of the samples seen. It should monotonically increase by the lengths of a batch with\r\n                each call.\r\n            flops: Flops elapased per device since last ``update()`` call. You can easily compute this by using\r\n                :func:`measure_flops` and multiplying it by the number of batches that have been processed.\r\n                The value might be different in each device if the batch size is not the same.\r\n\r\n        \"\"\"\r\n        self._time.append(time)\r\n        if samples < batches:\r\n            raise ValueError(f\"Expected samples ({samples}) to be greater or equal than batches ({batches})\")\r\n        self._batches.append(batches)\r\n        self._samples.append(samples)\r\n        if lengths is not None:\r\n            if lengths < samples:\r\n                raise ValueError(f\"Expected lengths ({lengths}) to be greater or equal than samples ({samples})\")\r\n            self._lengths.append(lengths)\r\n            if len(self._samples) != len(self._lengths):\r\n                raise RuntimeError(\r\n                    f\"If lengths are passed ({len(self._lengths)}), there needs to be the same number of samples\"\r\n                    f\" ({len(self._samples)})\"\r\n                )\r\n        if flops is not None:\r\n            self._flops.append(flops * self.world_size)", "code_tokens": ["def", "update", "(", "self", ",", "*", ",", "time", ":", "float", ",", "batches", ":", "int", ",", "samples", ":", "int", ",", "lengths", ":", "Optional", "[", "int", "]", "=", "None", ",", "flops", ":", "Optional", "[", "int", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "_time", ".", "append", "(", "time", ")", "if", "samples", "<", "batches", ":", "raise", "ValueError", "(", "fSTRING", ")", "self", ".", "_batches", ".", "append", "(", "batches", ")", "self", ".", "_samples", ".", "append", "(", "samples", ")", "if", "lengths", "is", "not", "None", ":", "if", "lengths", "<", "samples", ":", "raise", "ValueError", "(", "fSTRING", ")", "self", ".", "_lengths", ".", "append", "(", "lengths", ")", "if", "len", "(", "self", ".", "_samples", ")", "!", "=", "len", "(", "self", ".", "_lengths", ")", ":", "raise", "RuntimeError", "(", "fSTRING", "fSTRING", ")", "if", "flops", "is", "not", "None", ":", "self", ".", "_flops", ".", "append", "(", "flops", "*", "self", ".", "world_size", ")"], "docstring": "sum of flops across ranks", "docstring_tokens": ["sum", "of", "flops", "across", "ranks"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\throughput.py", "start_line": 112, "end_line": 151, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\throughput.py", "func_name": "function_82", "original_string": "def compute(self) -> _THROUGHPUT_METRICS:\r\n        \"\"\"Compute throughput metrics.\"\"\"\r\n        metrics = {\r\n            \"time\": self._time[-1],\r\n            \"batches\": self._batches[-1],\r\n            \"samples\": self._samples[-1],\r\n        }\r\n        if self._lengths:\r\n            metrics[\"lengths\"] = self._lengths[-1]\r\n\r\n        add_global_metrics = self.world_size > 1\r\n        if len(self._time) == self._time.maxlen:\r\n            elapsed_time = self._time[-1] - self._time[0]\r\n            elapsed_batches = self._batches[-1] - self._batches[0]\r\n            elapsed_samples = self._samples[-1] - self._samples[0]\r\n            dev_samples_per_sec = elapsed_samples / elapsed_time\r\n            dev_batches_per_sec = elapsed_batches / elapsed_time\r\n            metrics.update({\r\n                f\"device{self.separator}batches_per_sec\": elapsed_batches / elapsed_time,\r\n                f\"device{self.separator}samples_per_sec\": dev_samples_per_sec,\r\n            })\r\n            if add_global_metrics:\r\n                samples_per_sec = dev_batches_per_sec * self.world_size\r\n                metrics.update({\r\n                    \"batches_per_sec\": samples_per_sec,\r\n                    \"samples_per_sec\": dev_samples_per_sec * self.world_size,\r\n                })\r\n\r\n            if len(self._lengths) == self._lengths.maxlen:\r\n                elapsed_lengths = self._lengths[-1] - self._lengths[0]\r\n                dev_items_per_sec = elapsed_lengths / elapsed_time\r\n                metrics[f\"device{self.separator}items_per_sec\"] = dev_items_per_sec\r\n                if add_global_metrics:\r\n                    items_per_sec = dev_items_per_sec * self.world_size\r\n                    metrics[\"items_per_sec\"] = items_per_sec\r\n\r\n        if len(self._flops) == self._flops.maxlen:\r\n            elapsed_flops = sum(self._flops) - self._flops[0]\r\n            elapsed_time = self._time[-1] - self._time[0]\r\n            flops_per_sec = elapsed_flops / elapsed_time\r\n            dev_flops_per_sec = flops_per_sec / self.world_size\r\n            if add_global_metrics:\r\n                metrics[\"flops_per_sec\"] = flops_per_sec\r\n            metrics[f\"device{self.separator}flops_per_sec\"] = dev_flops_per_sec\r\n            if self.available_flops:\r\n                metrics[f\"device{self.separator}mfu\"] = dev_flops_per_sec / self.available_flops\r\n\r\n        return metrics", "language": "python", "code": "def compute(self) -> _THROUGHPUT_METRICS:\r\n        \"\"\"Compute throughput metrics.\"\"\"\r\n        metrics = {\r\n            \"time\": self._time[-1],\r\n            \"batches\": self._batches[-1],\r\n            \"samples\": self._samples[-1],\r\n        }\r\n        if self._lengths:\r\n            metrics[\"lengths\"] = self._lengths[-1]\r\n\r\n        add_global_metrics = self.world_size > 1\r\n        if len(self._time) == self._time.maxlen:\r\n            elapsed_time = self._time[-1] - self._time[0]\r\n            elapsed_batches = self._batches[-1] - self._batches[0]\r\n            elapsed_samples = self._samples[-1] - self._samples[0]\r\n            dev_samples_per_sec = elapsed_samples / elapsed_time\r\n            dev_batches_per_sec = elapsed_batches / elapsed_time\r\n            metrics.update({\r\n                f\"device{self.separator}batches_per_sec\": elapsed_batches / elapsed_time,\r\n                f\"device{self.separator}samples_per_sec\": dev_samples_per_sec,\r\n            })\r\n            if add_global_metrics:\r\n                samples_per_sec = dev_batches_per_sec * self.world_size\r\n                metrics.update({\r\n                    \"batches_per_sec\": samples_per_sec,\r\n                    \"samples_per_sec\": dev_samples_per_sec * self.world_size,\r\n                })\r\n\r\n            if len(self._lengths) == self._lengths.maxlen:\r\n                elapsed_lengths = self._lengths[-1] - self._lengths[0]\r\n                dev_items_per_sec = elapsed_lengths / elapsed_time\r\n                metrics[f\"device{self.separator}items_per_sec\"] = dev_items_per_sec\r\n                if add_global_metrics:\r\n                    items_per_sec = dev_items_per_sec * self.world_size\r\n                    metrics[\"items_per_sec\"] = items_per_sec\r\n\r\n        if len(self._flops) == self._flops.maxlen:\r\n            elapsed_flops = sum(self._flops) - self._flops[0]\r\n            elapsed_time = self._time[-1] - self._time[0]\r\n            flops_per_sec = elapsed_flops / elapsed_time\r\n            dev_flops_per_sec = flops_per_sec / self.world_size\r\n            if add_global_metrics:\r\n                metrics[\"flops_per_sec\"] = flops_per_sec\r\n            metrics[f\"device{self.separator}flops_per_sec\"] = dev_flops_per_sec\r\n            if self.available_flops:\r\n                metrics[f\"device{self.separator}mfu\"] = dev_flops_per_sec / self.available_flops\r\n\r\n        return metrics", "code_tokens": ["def", "compute", "(", "self", ")", "-", ">", "_THROUGHPUT_METRICS", ":", "STRING", "metrics", "=", "{", "STRING", ":", "self", ".", "_time", "[", "-", "1", "]", ",", "STRING", ":", "self", ".", "_batches", "[", "-", "1", "]", ",", "STRING", ":", "self", ".", "_samples", "[", "-", "1", "]", ",", "}", "if", "self", ".", "_lengths", ":", "metrics", "[", "STRING", "]", "=", "self", ".", "_lengths", "[", "-", "1", "]", "add_global_metrics", "=", "self", ".", "world_size", ">", "1", "if", "len", "(", "self", ".", "_time", ")", "=", "=", "self", ".", "_time", ".", "maxlen", ":", "elapsed_time", "=", "self", ".", "_time", "[", "-", "1", "]", "-", "self", ".", "_time", "[", "0", "]", "elapsed_batches", "=", "self", ".", "_batches", "[", "-", "1", "]", "-", "self", ".", "_batches", "[", "0", "]", "elapsed_samples", "=", "self", ".", "_samples", "[", "-", "1", "]", "-", "self", ".", "_samples", "[", "0", "]", "dev_samples_per_sec", "=", "elapsed_samples", "/", "elapsed_time", "dev_batches_per_sec", "=", "elapsed_batches", "/", "elapsed_time", "metrics", ".", "update", "(", "{", "fSTRING", ":", "elapsed_batches", "/", "elapsed_time", ",", "fSTRING", ":", "dev_samples_per_sec", ",", "}", ")", "if", "add_global_metrics", ":", "samples_per_sec", "=", "dev_batches_per_sec", "*", "self", ".", "world_size", "metrics", ".", "update", "(", "{", "STRING", ":", "samples_per_sec", ",", "STRING", ":", "dev_samples_per_sec", "*", "self", ".", "world_size", ",", "}", ")", "if", "len", "(", "self", ".", "_lengths", ")", "=", "=", "self", ".", "_lengths", ".", "maxlen", ":", "elapsed_lengths", "=", "self", ".", "_lengths", "[", "-", "1", "]", "-", "self", ".", "_lengths", "[", "0", "]", "dev_items_per_sec", "=", "elapsed_lengths", "/", "elapsed_time", "metrics", "[", "fSTRING", "]", "=", "dev_items_per_sec", "if", "add_global_metrics", ":", "items_per_sec", "=", "dev_items_per_sec", "*", "self", ".", "world_size", "metrics", "[", "STRING", "]", "=", "items_per_sec", "if", "len", "(", "self", ".", "_flops", ")", "=", "=", "self", ".", "_flops", ".", "maxlen", ":", "elapsed_flops", "=", "sum", "(", "self", ".", "_flops", ")", "-", "self", ".", "_flops", "[", "0", "]", "elapsed_time", "=", "self", ".", "_time", "[", "-", "1", "]", "-", "self", ".", "_time", "[", "0", "]", "flops_per_sec", "=", "elapsed_flops", "/", "elapsed_time", "dev_flops_per_sec", "=", "flops_per_sec", "/", "self", ".", "world_size", "if", "add_global_metrics", ":", "metrics", "[", "STRING", "]", "=", "flops_per_sec", "metrics", "[", "fSTRING", "]", "=", "dev_flops_per_sec", "if", "self", ".", "available_flops", ":", "metrics", "[", "fSTRING", "]", "=", "dev_flops_per_sec", "/", "self", ".", "available_flops", "return", "metrics"], "docstring": "a different but valid design choice would be to still compute all these metrics even if the window of values has not been filled we are safe from ZeroDivisionError thanks to `_MonotonicWindow`", "docstring_tokens": ["a", "different", "but", "valid", "design", "choice", "would", "be", "to", "still", "compute", "all", "these", "metrics", "even", "if", "the", "window", "of", "values", "has", "not", "been", "filled", "we", "are", "safe", "from", "zerodivisionerror", "thanks", "to", "_monotonicwindow"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\throughput.py", "start_line": 153, "end_line": 203, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\throughput.py", "func_name": "function_83", "original_string": "def get_available_flops(device: torch.device, dtype: Union[torch.dtype, str]) -> Optional[int]:\r\n    \"\"\"Returns the available theoretical FLOPs.\r\n\r\n    This is an optimistic upper limit that could only be achievable if only thick matmuls were run in a benchmark\r\n    environment.\r\n\r\n    \"\"\"\r\n    if device.type == \"cuda\":\r\n        device_name = torch.cuda.get_device_name(device)\r\n        chip = device_name.lower()\r\n        if \"h200\" in chip:\r\n            if \"sxm1\" in chip:\r\n                chip = \"h200 sxm1\"\r\n            elif \"nvl1\" in chip:\r\n                chip = \"h200 nvl1\"\r\n        elif \"h100\" in chip:\r\n            if \"hbm3\" in chip:\r\n                chip = \"h100 sxm\"\r\n            elif \"nvl\" in chip:\r\n                chip = \"h100 nvl\"\r\n            elif \"pcie\" in chip or \"hbm2e\" in chip:\r\n                chip = \"h100 pcie\"\r\n        elif \"l4\" in chip:\r\n            chip = \"l40\" if \"tesla\" in chip else \"l4\"\r\n        elif \"geforce rtx\" in chip:\r\n            number = chip.split(\" \")[3]\r\n            extra = \"\"\r\n            if \"super\" in chip:\r\n                extra = \" super\"\r\n            elif \"ti\" in chip:\r\n                extra = \" ti\"\r\n            chip = f\"rtx {number}{extra}\"\r\n        elif \"a6000\" in chip:\r\n            chip = \"a6000\"\r\n        elif \"a100\" in chip:\r\n            chip = \"a100\"\r\n        elif \"a40\" in chip:\r\n            chip = \"a40\"\r\n        elif \"a10g\" in chip:\r\n            chip = \"a10g\"\r\n        elif \"t4\" in chip:\r\n            chip = \"t4\"\r\n        elif \"quadro rtx 5000\" in chip:\r\n            chip = \"quadro rtx 5000\"\r\n        elif \"titan rtx\" in chip:\r\n            chip = \"titan rtx\"\r\n        elif \"v100-sxm\" in chip:\r\n            chip = \"v100 sxm\"\r\n        elif \"v100-pcie\" in chip:\r\n            chip = \"v100 pcie\"\r\n        elif \"v100s-pcie\" in chip:\r\n            chip = \"v100s pcie\"\r\n        else:\r\n            rank_zero_warn(f\"FLOPs not found for {device_name!r}\")\r\n            return None\r\n        if chip not in _CUDA_FLOPS:\r\n            rank_zero_warn(f\"FLOPs not found for {device_name!r}, chip is {chip!r}\")\r\n            return None\r\n        dtype_to_flops = _CUDA_FLOPS[chip]\r\n        if dtype is torch.float32:\r\n            from lightning.fabric.accelerators.cuda import _is_ampere_or_later\r\n\r\n            if _is_ampere_or_later() and torch.get_float32_matmul_precision() != \"highest\":\r\n                dtype = \"tfloat32\"\r\n        if dtype not in dtype_to_flops:\r\n            rank_zero_warn(f\"{device_name!r} does not support {dtype}\")\r\n            return None\r\n        return int(dtype_to_flops[dtype])\r\n\r\n    if device.type == \"xla\":\r\n        from lightning.fabric.accelerators.xla import _XLA_GREATER_EQUAL_2_1\r\n\r\n        if _XLA_GREATER_EQUAL_2_1:\r\n            from torch_xla._internal import tpu\r\n        else:\r\n            from torch_xla.experimental import tpu\r\n\r\n        tpu_env = tpu.get_tpu_env()\r\n        device_name = tpu_env.get(\"TYPE\") or tpu_env[\"ACCELERATOR_TYPE\"].split(\"-\")[0]\r\n        chip = device_name.lower()\r\n        assert isinstance(device_name, str)\r\n        if chip not in _TPU_FLOPS:\r\n            rank_zero_warn(f\"FLOPs not found for TPU {device_name!r} with {dtype}\")\r\n            return None\r\n        return int(_TPU_FLOPS[chip])", "language": "python", "code": "def get_available_flops(device: torch.device, dtype: Union[torch.dtype, str]) -> Optional[int]:\r\n    \"\"\"Returns the available theoretical FLOPs.\r\n\r\n    This is an optimistic upper limit that could only be achievable if only thick matmuls were run in a benchmark\r\n    environment.\r\n\r\n    \"\"\"\r\n    if device.type == \"cuda\":\r\n        device_name = torch.cuda.get_device_name(device)\r\n        chip = device_name.lower()\r\n        if \"h200\" in chip:\r\n            if \"sxm1\" in chip:\r\n                chip = \"h200 sxm1\"\r\n            elif \"nvl1\" in chip:\r\n                chip = \"h200 nvl1\"\r\n        elif \"h100\" in chip:\r\n            if \"hbm3\" in chip:\r\n                chip = \"h100 sxm\"\r\n            elif \"nvl\" in chip:\r\n                chip = \"h100 nvl\"\r\n            elif \"pcie\" in chip or \"hbm2e\" in chip:\r\n                chip = \"h100 pcie\"\r\n        elif \"l4\" in chip:\r\n            chip = \"l40\" if \"tesla\" in chip else \"l4\"\r\n        elif \"geforce rtx\" in chip:\r\n            number = chip.split(\" \")[3]\r\n            extra = \"\"\r\n            if \"super\" in chip:\r\n                extra = \" super\"\r\n            elif \"ti\" in chip:\r\n                extra = \" ti\"\r\n            chip = f\"rtx {number}{extra}\"\r\n        elif \"a6000\" in chip:\r\n            chip = \"a6000\"\r\n        elif \"a100\" in chip:\r\n            chip = \"a100\"\r\n        elif \"a40\" in chip:\r\n            chip = \"a40\"\r\n        elif \"a10g\" in chip:\r\n            chip = \"a10g\"\r\n        elif \"t4\" in chip:\r\n            chip = \"t4\"\r\n        elif \"quadro rtx 5000\" in chip:\r\n            chip = \"quadro rtx 5000\"\r\n        elif \"titan rtx\" in chip:\r\n            chip = \"titan rtx\"\r\n        elif \"v100-sxm\" in chip:\r\n            chip = \"v100 sxm\"\r\n        elif \"v100-pcie\" in chip:\r\n            chip = \"v100 pcie\"\r\n        elif \"v100s-pcie\" in chip:\r\n            chip = \"v100s pcie\"\r\n        else:\r\n            rank_zero_warn(f\"FLOPs not found for {device_name!r}\")\r\n            return None\r\n        if chip not in _CUDA_FLOPS:\r\n            rank_zero_warn(f\"FLOPs not found for {device_name!r}, chip is {chip!r}\")\r\n            return None\r\n        dtype_to_flops = _CUDA_FLOPS[chip]\r\n        if dtype is torch.float32:\r\n            from lightning.fabric.accelerators.cuda import _is_ampere_or_later\r\n\r\n            if _is_ampere_or_later() and torch.get_float32_matmul_precision() != \"highest\":\r\n                dtype = \"tfloat32\"\r\n        if dtype not in dtype_to_flops:\r\n            rank_zero_warn(f\"{device_name!r} does not support {dtype}\")\r\n            return None\r\n        return int(dtype_to_flops[dtype])\r\n\r\n    if device.type == \"xla\":\r\n        from lightning.fabric.accelerators.xla import _XLA_GREATER_EQUAL_2_1\r\n\r\n        if _XLA_GREATER_EQUAL_2_1:\r\n            from torch_xla._internal import tpu\r\n        else:\r\n            from torch_xla.experimental import tpu\r\n\r\n        tpu_env = tpu.get_tpu_env()\r\n        device_name = tpu_env.get(\"TYPE\") or tpu_env[\"ACCELERATOR_TYPE\"].split(\"-\")[0]\r\n        chip = device_name.lower()\r\n        assert isinstance(device_name, str)\r\n        if chip not in _TPU_FLOPS:\r\n            rank_zero_warn(f\"FLOPs not found for TPU {device_name!r} with {dtype}\")\r\n            return None\r\n        return int(_TPU_FLOPS[chip])", "code_tokens": ["def", "get_available_flops", "(", "device", ":", "torch", ".", "device", ",", "dtype", ":", "Union", "[", "torch", ".", "dtype", ",", "str", "]", ")", "-", ">", "Optional", "[", "int", "]", ":", "STRING", "if", "device", ".", "type", "=", "=", "STRING", ":", "device_name", "=", "torch", ".", "cuda", ".", "get_device_name", "(", "device", ")", "chip", "=", "device_name", ".", "lower", "(", ")", "if", "STRING", "in", "chip", ":", "if", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "if", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", "or", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "if", "STRING", "in", "chip", "else", "STRING", "elif", "STRING", "in", "chip", ":", "number", "=", "chip", ".", "split", "(", "STRING", ")", "[", "3", "]", "extra", "=", "STRING", "if", "STRING", "in", "chip", ":", "extra", "=", "STRING", "elif", "STRING", "in", "chip", ":", "extra", "=", "STRING", "chip", "=", "fSTRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "elif", "STRING", "in", "chip", ":", "chip", "=", "STRING", "else", ":", "rank_zero_warn", "(", "fSTRING", ")", "return", "None", "if", "chip", "not", "in", "_CUDA_FLOPS", ":", "rank_zero_warn", "(", "fSTRING", ")", "return", "None", "dtype_to_flops", "=", "_CUDA_FLOPS", "[", "chip", "]", "if", "dtype", "is", "torch", ".", "float32", ":", "from", "lightning", ".", "fabric", ".", "accelerators", ".", "cuda", "import", "_is_ampere_or_later", "if", "_is_ampere_or_later", "(", ")", "and", "torch", ".", "get_float32_matmul_precision", "(", ")", "!", "=", "STRING", ":", "dtype", "=", "STRING", "if", "dtype", "not", "in", "dtype_to_flops", ":", "rank_zero_warn", "(", "fSTRING", ")", "return", "None", "return", "int", "(", "dtype_to_flops", "[", "dtype", "]", ")", "if", "device", ".", "type", "=", "=", "STRING", ":", "from", "lightning", ".", "fabric", ".", "accelerators", ".", "xla", "import", "_XLA_GREATER_EQUAL_2_1", "if", "_XLA_GREATER_EQUAL_2_1", ":", "from", "torch_xla", ".", "_internal", "import", "tpu", "else", ":", "from", "torch_xla", ".", "experimental", "import", "tpu", "tpu_env", "=", "tpu", ".", "get_tpu_env", "(", ")", "device_name", "=", "tpu_env", ".", "get", "(", "STRING", ")", "or", "tpu_env", "[", "STRING", "]", ".", "split", "(", "STRING", ")", "[", "0", "]", "chip", "=", "device_name", ".", "lower", "(", ")", "assert", "isinstance", "(", "device_name", ",", "str", ")", "if", "chip", "not", "in", "_TPU_FLOPS", ":", "rank_zero_warn", "(", "fSTRING", ")", "return", "None", "return", "int", "(", "_TPU_FLOPS", "[", "chip", "]", ")"], "docstring": "the flops list is not exhaustive, return with a warning parsing is implemented but we don't have the stats for example, T4 doesn't support bfloat16. it might also be that we are missing this dtype from the list not all TPU generations define the \"TYPE\" envar. example: TYPE=\"V4\", ACCELERATOR_TYPE=\"v4-8\"", "docstring_tokens": ["the", "flops", "list", "is", "not", "exhaustive", "return", "with", "a", "warning", "parsing", "is", "implemented", "but", "we", "don", "t", "have", "the", "stats", "for", "example", "t4", "doesn", "t", "support", "bfloat16", "it", "might", "also", "be", "that", "we", "are", "missing", "this", "dtype", "from", "the", "list", "not", "all", "tpu", "generations", "define", "the", "type", "envar", "example", "type", "v4", "accelerator_type", "v4", "8"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\throughput.py", "start_line": 545, "end_line": 633, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\fabric\\utilities\\warnings.py", "func_name": "function_84", "original_string": "def _custom_format_warning(\r\n    message: Union[Warning, str], category: type[Warning], filename: str, lineno: int, line: Optional[str] = None\r\n) -> str:\r\n    \"\"\"Custom formatting that avoids an extra line in case warnings are emitted from the `rank_zero`-functions.\"\"\"\r\n    if _is_path_in_lightning(Path(filename)):\r\n        return f\"{filename}:{lineno}: {message}\\n\"\r\n    return _default_format_warning(message, category, filename, lineno, line)", "language": "python", "code": "def _custom_format_warning(\r\n    message: Union[Warning, str], category: type[Warning], filename: str, lineno: int, line: Optional[str] = None\r\n) -> str:\r\n    \"\"\"Custom formatting that avoids an extra line in case warnings are emitted from the `rank_zero`-functions.\"\"\"\r\n    if _is_path_in_lightning(Path(filename)):\r\n        return f\"{filename}:{lineno}: {message}\\n\"\r\n    return _default_format_warning(message, category, filename, lineno, line)", "code_tokens": ["def", "_custom_format_warning", "(", "message", ":", "Union", "[", "Warning", ",", "str", "]", ",", "category", ":", "type", "[", "Warning", "]", ",", "filename", ":", "str", ",", "lineno", ":", "int", ",", "line", ":", "Optional", "[", "str", "]", "=", "None", ")", "-", ">", "str", ":", "STRING", "if", "_is_path_in_lightning", "(", "Path", "(", "filename", ")", ")", ":", "return", "fSTRING", "return", "_default_format_warning", "(", "message", ",", "category", ",", "filename", ",", "lineno", ",", "line", ")"], "docstring": "The warning originates from the Lightning package", "docstring_tokens": ["the", "warning", "originates", "from", "the", "lightning", "package"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\fabric\\utilities\\warnings.py", "start_line": 39, "end_line": 46, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_85", "original_string": "def __init__(\r\n        self,\r\n        *args: Any,\r\n        description: str = \"Lightning Trainer command line tool\",\r\n        env_prefix: str = \"PL\",\r\n        default_env: bool = False,\r\n        **kwargs: Any,\r\n    ) -> None:\r\n        \"\"\"Initialize argument parser that supports configuration file input.\r\n\r\n        For full details of accepted arguments see `ArgumentParser.__init__\r\n        <https://jsonargparse.readthedocs.io/en/stable/#jsonargparse.ArgumentParser.__init__>`_.\r\n\r\n        Args:\r\n            description: Description of the tool shown when running ``--help``.\r\n            env_prefix: Prefix for environment variables. Set ``default_env=True`` to enable env parsing.\r\n            default_env: Whether to parse environment variables.\r\n\r\n        \"\"\"\r\n        if not _JSONARGPARSE_SIGNATURES_AVAILABLE:\r\n            raise ModuleNotFoundError(f\"{_JSONARGPARSE_SIGNATURES_AVAILABLE}\")\r\n        super().__init__(*args, description=description, env_prefix=env_prefix, default_env=default_env, **kwargs)\r\n        self.callback_keys: list[str] = []\r\n        self._optimizers: dict[str, tuple[Union[type, tuple[type, ...]], str]] = {}\r\n        self._lr_schedulers: dict[str, tuple[Union[type, tuple[type, ...]], str]] = {}", "language": "python", "code": "def __init__(\r\n        self,\r\n        *args: Any,\r\n        description: str = \"Lightning Trainer command line tool\",\r\n        env_prefix: str = \"PL\",\r\n        default_env: bool = False,\r\n        **kwargs: Any,\r\n    ) -> None:\r\n        \"\"\"Initialize argument parser that supports configuration file input.\r\n\r\n        For full details of accepted arguments see `ArgumentParser.__init__\r\n        <https://jsonargparse.readthedocs.io/en/stable/#jsonargparse.ArgumentParser.__init__>`_.\r\n\r\n        Args:\r\n            description: Description of the tool shown when running ``--help``.\r\n            env_prefix: Prefix for environment variables. Set ``default_env=True`` to enable env parsing.\r\n            default_env: Whether to parse environment variables.\r\n\r\n        \"\"\"\r\n        if not _JSONARGPARSE_SIGNATURES_AVAILABLE:\r\n            raise ModuleNotFoundError(f\"{_JSONARGPARSE_SIGNATURES_AVAILABLE}\")\r\n        super().__init__(*args, description=description, env_prefix=env_prefix, default_env=default_env, **kwargs)\r\n        self.callback_keys: list[str] = []\r\n        self._optimizers: dict[str, tuple[Union[type, tuple[type, ...]], str]] = {}\r\n        self._lr_schedulers: dict[str, tuple[Union[type, tuple[type, ...]], str]] = {}", "code_tokens": ["def", "__init__", "(", "self", ",", "*", "args", ":", "Any", ",", "description", ":", "str", "=", "STRING", ",", "env_prefix", ":", "str", "=", "STRING", ",", "default_env", ":", "bool", "=", "False", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "None", ":", "STRING", "if", "not", "_JSONARGPARSE_SIGNATURES_AVAILABLE", ":", "raise", "ModuleNotFoundError", "(", "fSTRING", ")", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "description", "=", "description", ",", "env_prefix", "=", "env_prefix", ",", "default_env", "=", "default_env", ",", "*", "*", "kwargs", ")", "self", ".", "callback_keys", ":", "list", "[", "str", "]", "=", "[", "]", "self", ".", "_optimizers", ":", "dict", "[", "str", ",", "tuple", "[", "Union", "[", "type", ",", "tuple", "[", "type", ",", ".", ".", ".", "]", "]", ",", "str", "]", "]", "=", "{", "}", "self", ".", "_lr_schedulers", ":", "dict", "[", "str", ",", "tuple", "[", "Union", "[", "type", ",", "tuple", "[", "type", ",", ".", ".", ".", "]", "]", ",", "str", "]", "]", "=", "{", "}"], "docstring": "separate optimizers and lr schedulers to know which were added", "docstring_tokens": ["separate", "optimizers", "and", "lr", "schedulers", "to", "know", "which", "were", "added"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 88, "end_line": 113, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_86", "original_string": "def __init__(\r\n        self,\r\n        model_class: Optional[Union[type[LightningModule], Callable[..., LightningModule]]] = None,\r\n        datamodule_class: Optional[Union[type[LightningDataModule], Callable[..., LightningDataModule]]] = None,\r\n        save_config_callback: Optional[type[SaveConfigCallback]] = SaveConfigCallback,\r\n        save_config_kwargs: Optional[dict[str, Any]] = None,\r\n        trainer_class: Union[type[Trainer], Callable[..., Trainer]] = Trainer,\r\n        trainer_defaults: Optional[dict[str, Any]] = None,\r\n        seed_everything_default: Union[bool, int] = True,\r\n        parser_kwargs: Optional[Union[dict[str, Any], dict[str, dict[str, Any]]]] = None,\r\n        parser_class: type[LightningArgumentParser] = LightningArgumentParser,\r\n        subclass_mode_model: bool = False,\r\n        subclass_mode_data: bool = False,\r\n        args: ArgsType = None,\r\n        run: bool = True,\r\n        auto_configure_optimizers: bool = True,\r\n        load_from_checkpoint_support: bool = True,\r\n    ) -> None:\r\n        \"\"\"Receives as input pytorch-lightning classes (or callables which return pytorch-lightning classes), which are\r\n        called / instantiated using a parsed configuration file and / or command line args.\r\n\r\n        Parsing of configuration from environment variables can be enabled by setting ``parser_kwargs={\"default_env\":\r\n        True}``. A full configuration yaml would be parsed from ``PL_CONFIG`` if set. Individual settings are so parsed\r\n        from variables named for example ``PL_TRAINER__MAX_EPOCHS``.\r\n\r\n        For more info, read :ref:`the CLI docs <lightning-cli>`.\r\n\r\n        Args:\r\n            model_class: An optional :class:`~lightning.pytorch.core.LightningModule` class to train on or a\r\n                callable which returns a :class:`~lightning.pytorch.core.LightningModule` instance when\r\n                called. If ``None``, you can pass a registered model with ``--model=MyModel``.\r\n            datamodule_class: An optional :class:`~lightning.pytorch.core.datamodule.LightningDataModule` class or a\r\n                callable which returns a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` instance when\r\n                called. If ``None``, you can pass a registered datamodule with ``--data=MyDataModule``.\r\n            save_config_callback: A callback class to save the config.\r\n            save_config_kwargs: Parameters that will be used to instantiate the save_config_callback.\r\n            trainer_class: An optional subclass of the :class:`~lightning.pytorch.trainer.trainer.Trainer` class or a\r\n                callable which returns a :class:`~lightning.pytorch.trainer.trainer.Trainer` instance when called.\r\n            trainer_defaults: Set to override Trainer defaults or add persistent callbacks. The callbacks added through\r\n                this argument will not be configurable from a configuration file and will always be present for\r\n                this particular CLI. Alternatively, configurable callbacks can be added as explained in\r\n                :ref:`the CLI docs <lightning-cli>`.\r\n            seed_everything_default: Number for the :func:`~lightning.fabric.utilities.seed.seed_everything`\r\n                seed value. Set to True to automatically choose a seed value.\r\n                Setting it to False will avoid calling ``seed_everything``.\r\n            parser_kwargs: Additional arguments to instantiate each ``LightningArgumentParser``.\r\n            subclass_mode_model: Whether model can be any `subclass\r\n                <https://jsonargparse.readthedocs.io/en/stable/#class-type-and-sub-classes>`_\r\n                of the given class.\r\n            subclass_mode_data: Whether datamodule can be any `subclass\r\n                <https://jsonargparse.readthedocs.io/en/stable/#class-type-and-sub-classes>`_\r\n                of the given class.\r\n            args: Arguments to parse. If ``None`` the arguments are taken from ``sys.argv``. Command line style\r\n                arguments can be given in a ``list``. Alternatively, structured config options can be given in a\r\n                ``dict`` or ``jsonargparse.Namespace``.\r\n            run: Whether subcommands should be added to run a :class:`~lightning.pytorch.trainer.trainer.Trainer`\r\n                method. If set to ``False``, the trainer and model classes will be instantiated only.\r\n            auto_configure_optimizers: Whether to automatically add default optimizer and lr_scheduler arguments.\r\n            load_from_checkpoint_support: Whether ``save_hyperparameters`` should save the original parsed\r\n                hyperparameters (instead of what ``__init__`` receives), such that it is possible for\r\n                ``load_from_checkpoint`` to correctly instantiate classes even when using complex nesting and\r\n                dependency injection.\r\n\r\n        \"\"\"\r\n        self.save_config_callback = save_config_callback\r\n        self.save_config_kwargs = save_config_kwargs or {}\r\n        self.trainer_class = trainer_class\r\n        self.trainer_defaults = trainer_defaults or {}\r\n        self.seed_everything_default = seed_everything_default\r\n        self.parser_kwargs = parser_kwargs or {}\r\n        self.parser_class = parser_class\r\n        self.auto_configure_optimizers = auto_configure_optimizers\r\n\r\n        self.model_class = model_class\r\n        self._model_class = model_class or LightningModule\r\n        self.subclass_mode_model = (model_class is None) or subclass_mode_model\r\n\r\n        self.datamodule_class = datamodule_class\r\n        self._datamodule_class = datamodule_class or LightningDataModule\r\n        self.subclass_mode_data = (datamodule_class is None) or subclass_mode_data\r\n\r\n        main_kwargs, subparser_kwargs = self._setup_parser_kwargs(self.parser_kwargs)\r\n        self.setup_parser(run, main_kwargs, subparser_kwargs)\r\n        self.parse_arguments(self.parser, args)\r\n        self._parse_ckpt_path()\r\n\r\n        self.subcommand = self.config[\"subcommand\"] if run else None\r\n\r\n        self._set_seed()\r\n\r\n        if load_from_checkpoint_support:\r\n            self._add_instantiators()\r\n        self.before_instantiate_classes()\r\n        self.instantiate_classes()\r\n        self.after_instantiate_classes()\r\n\r\n        if self.subcommand is not None:\r\n            self._run_subcommand(self.subcommand)", "language": "python", "code": "def __init__(\r\n        self,\r\n        model_class: Optional[Union[type[LightningModule], Callable[..., LightningModule]]] = None,\r\n        datamodule_class: Optional[Union[type[LightningDataModule], Callable[..., LightningDataModule]]] = None,\r\n        save_config_callback: Optional[type[SaveConfigCallback]] = SaveConfigCallback,\r\n        save_config_kwargs: Optional[dict[str, Any]] = None,\r\n        trainer_class: Union[type[Trainer], Callable[..., Trainer]] = Trainer,\r\n        trainer_defaults: Optional[dict[str, Any]] = None,\r\n        seed_everything_default: Union[bool, int] = True,\r\n        parser_kwargs: Optional[Union[dict[str, Any], dict[str, dict[str, Any]]]] = None,\r\n        parser_class: type[LightningArgumentParser] = LightningArgumentParser,\r\n        subclass_mode_model: bool = False,\r\n        subclass_mode_data: bool = False,\r\n        args: ArgsType = None,\r\n        run: bool = True,\r\n        auto_configure_optimizers: bool = True,\r\n        load_from_checkpoint_support: bool = True,\r\n    ) -> None:\r\n        \"\"\"Receives as input pytorch-lightning classes (or callables which return pytorch-lightning classes), which are\r\n        called / instantiated using a parsed configuration file and / or command line args.\r\n\r\n        Parsing of configuration from environment variables can be enabled by setting ``parser_kwargs={\"default_env\":\r\n        True}``. A full configuration yaml would be parsed from ``PL_CONFIG`` if set. Individual settings are so parsed\r\n        from variables named for example ``PL_TRAINER__MAX_EPOCHS``.\r\n\r\n        For more info, read :ref:`the CLI docs <lightning-cli>`.\r\n\r\n        Args:\r\n            model_class: An optional :class:`~lightning.pytorch.core.LightningModule` class to train on or a\r\n                callable which returns a :class:`~lightning.pytorch.core.LightningModule` instance when\r\n                called. If ``None``, you can pass a registered model with ``--model=MyModel``.\r\n            datamodule_class: An optional :class:`~lightning.pytorch.core.datamodule.LightningDataModule` class or a\r\n                callable which returns a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` instance when\r\n                called. If ``None``, you can pass a registered datamodule with ``--data=MyDataModule``.\r\n            save_config_callback: A callback class to save the config.\r\n            save_config_kwargs: Parameters that will be used to instantiate the save_config_callback.\r\n            trainer_class: An optional subclass of the :class:`~lightning.pytorch.trainer.trainer.Trainer` class or a\r\n                callable which returns a :class:`~lightning.pytorch.trainer.trainer.Trainer` instance when called.\r\n            trainer_defaults: Set to override Trainer defaults or add persistent callbacks. The callbacks added through\r\n                this argument will not be configurable from a configuration file and will always be present for\r\n                this particular CLI. Alternatively, configurable callbacks can be added as explained in\r\n                :ref:`the CLI docs <lightning-cli>`.\r\n            seed_everything_default: Number for the :func:`~lightning.fabric.utilities.seed.seed_everything`\r\n                seed value. Set to True to automatically choose a seed value.\r\n                Setting it to False will avoid calling ``seed_everything``.\r\n            parser_kwargs: Additional arguments to instantiate each ``LightningArgumentParser``.\r\n            subclass_mode_model: Whether model can be any `subclass\r\n                <https://jsonargparse.readthedocs.io/en/stable/#class-type-and-sub-classes>`_\r\n                of the given class.\r\n            subclass_mode_data: Whether datamodule can be any `subclass\r\n                <https://jsonargparse.readthedocs.io/en/stable/#class-type-and-sub-classes>`_\r\n                of the given class.\r\n            args: Arguments to parse. If ``None`` the arguments are taken from ``sys.argv``. Command line style\r\n                arguments can be given in a ``list``. Alternatively, structured config options can be given in a\r\n                ``dict`` or ``jsonargparse.Namespace``.\r\n            run: Whether subcommands should be added to run a :class:`~lightning.pytorch.trainer.trainer.Trainer`\r\n                method. If set to ``False``, the trainer and model classes will be instantiated only.\r\n            auto_configure_optimizers: Whether to automatically add default optimizer and lr_scheduler arguments.\r\n            load_from_checkpoint_support: Whether ``save_hyperparameters`` should save the original parsed\r\n                hyperparameters (instead of what ``__init__`` receives), such that it is possible for\r\n                ``load_from_checkpoint`` to correctly instantiate classes even when using complex nesting and\r\n                dependency injection.\r\n\r\n        \"\"\"\r\n        self.save_config_callback = save_config_callback\r\n        self.save_config_kwargs = save_config_kwargs or {}\r\n        self.trainer_class = trainer_class\r\n        self.trainer_defaults = trainer_defaults or {}\r\n        self.seed_everything_default = seed_everything_default\r\n        self.parser_kwargs = parser_kwargs or {}\r\n        self.parser_class = parser_class\r\n        self.auto_configure_optimizers = auto_configure_optimizers\r\n\r\n        self.model_class = model_class\r\n        self._model_class = model_class or LightningModule\r\n        self.subclass_mode_model = (model_class is None) or subclass_mode_model\r\n\r\n        self.datamodule_class = datamodule_class\r\n        self._datamodule_class = datamodule_class or LightningDataModule\r\n        self.subclass_mode_data = (datamodule_class is None) or subclass_mode_data\r\n\r\n        main_kwargs, subparser_kwargs = self._setup_parser_kwargs(self.parser_kwargs)\r\n        self.setup_parser(run, main_kwargs, subparser_kwargs)\r\n        self.parse_arguments(self.parser, args)\r\n        self._parse_ckpt_path()\r\n\r\n        self.subcommand = self.config[\"subcommand\"] if run else None\r\n\r\n        self._set_seed()\r\n\r\n        if load_from_checkpoint_support:\r\n            self._add_instantiators()\r\n        self.before_instantiate_classes()\r\n        self.instantiate_classes()\r\n        self.after_instantiate_classes()\r\n\r\n        if self.subcommand is not None:\r\n            self._run_subcommand(self.subcommand)", "code_tokens": ["def", "__init__", "(", "self", ",", "model_class", ":", "Optional", "[", "Union", "[", "type", "[", "LightningModule", "]", ",", "Callable", "[", ".", ".", ".", ",", "LightningModule", "]", "]", "]", "=", "None", ",", "datamodule_class", ":", "Optional", "[", "Union", "[", "type", "[", "LightningDataModule", "]", ",", "Callable", "[", ".", ".", ".", ",", "LightningDataModule", "]", "]", "]", "=", "None", ",", "save_config_callback", ":", "Optional", "[", "type", "[", "SaveConfigCallback", "]", "]", "=", "SaveConfigCallback", ",", "save_config_kwargs", ":", "Optional", "[", "dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "trainer_class", ":", "Union", "[", "type", "[", "Trainer", "]", ",", "Callable", "[", ".", ".", ".", ",", "Trainer", "]", "]", "=", "Trainer", ",", "trainer_defaults", ":", "Optional", "[", "dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "seed_everything_default", ":", "Union", "[", "bool", ",", "int", "]", "=", "True", ",", "parser_kwargs", ":", "Optional", "[", "Union", "[", "dict", "[", "str", ",", "Any", "]", ",", "dict", "[", "str", ",", "dict", "[", "str", ",", "Any", "]", "]", "]", "]", "=", "None", ",", "parser_class", ":", "type", "[", "LightningArgumentParser", "]", "=", "LightningArgumentParser", ",", "subclass_mode_model", ":", "bool", "=", "False", ",", "subclass_mode_data", ":", "bool", "=", "False", ",", "args", ":", "ArgsType", "=", "None", ",", "run", ":", "bool", "=", "True", ",", "auto_configure_optimizers", ":", "bool", "=", "True", ",", "load_from_checkpoint_support", ":", "bool", "=", "True", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "save_config_callback", "=", "save_config_callback", "self", ".", "save_config_kwargs", "=", "save_config_kwargs", "or", "{", "}", "self", ".", "trainer_class", "=", "trainer_class", "self", ".", "trainer_defaults", "=", "trainer_defaults", "or", "{", "}", "self", ".", "seed_everything_default", "=", "seed_everything_default", "self", ".", "parser_kwargs", "=", "parser_kwargs", "or", "{", "}", "self", ".", "parser_class", "=", "parser_class", "self", ".", "auto_configure_optimizers", "=", "auto_configure_optimizers", "self", ".", "model_class", "=", "model_class", "self", ".", "_model_class", "=", "model_class", "or", "LightningModule", "self", ".", "subclass_mode_model", "=", "(", "model_class", "is", "None", ")", "or", "subclass_mode_model", "self", ".", "datamodule_class", "=", "datamodule_class", "self", ".", "_datamodule_class", "=", "datamodule_class", "or", "LightningDataModule", "self", ".", "subclass_mode_data", "=", "(", "datamodule_class", "is", "None", ")", "or", "subclass_mode_data", "main_kwargs", ",", "subparser_kwargs", "=", "self", ".", "_setup_parser_kwargs", "(", "self", ".", "parser_kwargs", ")", "self", ".", "setup_parser", "(", "run", ",", "main_kwargs", ",", "subparser_kwargs", ")", "self", ".", "parse_arguments", "(", "self", ".", "parser", ",", "args", ")", "self", ".", "_parse_ckpt_path", "(", ")", "self", ".", "subcommand", "=", "self", ".", "config", "[", "STRING", "]", "if", "run", "else", "None", "self", ".", "_set_seed", "(", ")", "if", "load_from_checkpoint_support", ":", "self", ".", "_add_instantiators", "(", ")", "self", ".", "before_instantiate_classes", "(", ")", "self", ".", "instantiate_classes", "(", ")", "self", ".", "after_instantiate_classes", "(", ")", "if", "self", ".", "subcommand", "is", "not", "None", ":", "self", ".", "_run_subcommand", "(", "self", ".", "subcommand", ")"], "docstring": "used to differentiate between the original value and the processed value used to differentiate between the original value and the processed value", "docstring_tokens": ["used", "to", "differentiate", "between", "the", "original", "value", "and", "the", "processed", "value", "used", "to", "differentiate", "between", "the", "original", "value", "and", "the", "processed", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 314, "end_line": 413, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_87", "original_string": "def add_core_arguments_to_parser(self, parser: LightningArgumentParser) -> None:\r\n        \"\"\"Adds arguments from the core classes to the parser.\"\"\"\r\n        parser.add_lightning_class_args(self.trainer_class, \"trainer\")\r\n        trainer_defaults = {\"trainer.\" + k: v for k, v in self.trainer_defaults.items() if k != \"callbacks\"}\r\n        parser.set_defaults(trainer_defaults)\r\n\r\n        parser.add_lightning_class_args(self._model_class, \"model\", subclass_mode=self.subclass_mode_model)\r\n\r\n        if self.datamodule_class is not None:\r\n            parser.add_lightning_class_args(self._datamodule_class, \"data\", subclass_mode=self.subclass_mode_data)\r\n        else:\r\n            parser.add_lightning_class_args(\r\n                self._datamodule_class, \"data\", subclass_mode=self.subclass_mode_data, required=False\r\n            )", "language": "python", "code": "def add_core_arguments_to_parser(self, parser: LightningArgumentParser) -> None:\r\n        \"\"\"Adds arguments from the core classes to the parser.\"\"\"\r\n        parser.add_lightning_class_args(self.trainer_class, \"trainer\")\r\n        trainer_defaults = {\"trainer.\" + k: v for k, v in self.trainer_defaults.items() if k != \"callbacks\"}\r\n        parser.set_defaults(trainer_defaults)\r\n\r\n        parser.add_lightning_class_args(self._model_class, \"model\", subclass_mode=self.subclass_mode_model)\r\n\r\n        if self.datamodule_class is not None:\r\n            parser.add_lightning_class_args(self._datamodule_class, \"data\", subclass_mode=self.subclass_mode_data)\r\n        else:\r\n            parser.add_lightning_class_args(\r\n                self._datamodule_class, \"data\", subclass_mode=self.subclass_mode_data, required=False\r\n            )", "code_tokens": ["def", "add_core_arguments_to_parser", "(", "self", ",", "parser", ":", "LightningArgumentParser", ")", "-", ">", "None", ":", "STRING", "parser", ".", "add_lightning_class_args", "(", "self", ".", "trainer_class", ",", "STRING", ")", "trainer_defaults", "=", "{", "STRING", "+", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "trainer_defaults", ".", "items", "(", ")", "if", "k", "!", "=", "STRING", "}", "parser", ".", "set_defaults", "(", "trainer_defaults", ")", "parser", ".", "add_lightning_class_args", "(", "self", ".", "_model_class", ",", "STRING", ",", "subclass_mode", "=", "self", ".", "subclass_mode_model", ")", "if", "self", ".", "datamodule_class", "is", "not", "None", ":", "parser", ".", "add_lightning_class_args", "(", "self", ".", "_datamodule_class", ",", "STRING", ",", "subclass_mode", "=", "self", ".", "subclass_mode_data", ")", "else", ":", "parser", ".", "add_lightning_class_args", "(", "self", ".", "_datamodule_class", ",", "STRING", ",", "subclass_mode", "=", "self", ".", "subclass_mode_data", ",", "required", "=", "False", ")"], "docstring": "this should not be required because the user might want to use the `LightningModule` dataloaders", "docstring_tokens": ["this", "should", "not", "be", "required", "because", "the", "user", "might", "want", "to", "use", "the", "lightningmodule", "dataloaders"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 453, "end_line": 467, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_88", "original_string": "def _add_subcommands(self, parser: LightningArgumentParser, **kwargs: Any) -> None:\r\n        \"\"\"Adds subcommands to the input parser.\"\"\"\r\n        self._subcommand_parsers: dict[str, LightningArgumentParser] = {}\r\n        parser_subcommands = parser.add_subcommands()\r\n        trainer_class = (\r\n            self.trainer_class if isinstance(self.trainer_class, type) else class_from_function(self.trainer_class)\r\n        )\r\n        for subcommand in self.subcommands():\r\n            fn = getattr(trainer_class, subcommand)\r\n            description = _get_short_description(fn)\r\n            subparser_kwargs = kwargs.get(subcommand, {})\r\n            subparser_kwargs.setdefault(\"description\", description)\r\n            subcommand_parser = self._prepare_subcommand_parser(trainer_class, subcommand, **subparser_kwargs)\r\n            self._subcommand_parsers[subcommand] = subcommand_parser\r\n            parser_subcommands.add_subcommand(subcommand, subcommand_parser, help=description)", "language": "python", "code": "def _add_subcommands(self, parser: LightningArgumentParser, **kwargs: Any) -> None:\r\n        \"\"\"Adds subcommands to the input parser.\"\"\"\r\n        self._subcommand_parsers: dict[str, LightningArgumentParser] = {}\r\n        parser_subcommands = parser.add_subcommands()\r\n        trainer_class = (\r\n            self.trainer_class if isinstance(self.trainer_class, type) else class_from_function(self.trainer_class)\r\n        )\r\n        for subcommand in self.subcommands():\r\n            fn = getattr(trainer_class, subcommand)\r\n            description = _get_short_description(fn)\r\n            subparser_kwargs = kwargs.get(subcommand, {})\r\n            subparser_kwargs.setdefault(\"description\", description)\r\n            subcommand_parser = self._prepare_subcommand_parser(trainer_class, subcommand, **subparser_kwargs)\r\n            self._subcommand_parsers[subcommand] = subcommand_parser\r\n            parser_subcommands.add_subcommand(subcommand, subcommand_parser, help=description)", "code_tokens": ["def", "_add_subcommands", "(", "self", ",", "parser", ":", "LightningArgumentParser", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "self", ".", "_subcommand_parsers", ":", "dict", "[", "str", ",", "LightningArgumentParser", "]", "=", "{", "}", "parser_subcommands", "=", "parser", ".", "add_subcommands", "(", ")", "trainer_class", "=", "(", "self", ".", "trainer_class", "if", "isinstance", "(", "self", ".", "trainer_class", ",", "type", ")", "else", "class_from_function", "(", "self", ".", "trainer_class", ")", ")", "for", "subcommand", "in", "self", ".", "subcommands", "(", ")", ":", "fn", "=", "getattr", "(", "trainer_class", ",", "subcommand", ")", "description", "=", "_get_short_description", "(", "fn", ")", "subparser_kwargs", "=", "kwargs", ".", "get", "(", "subcommand", ",", "{", "}", ")", "subparser_kwargs", ".", "setdefault", "(", "STRING", ",", "description", ")", "subcommand_parser", "=", "self", ".", "_prepare_subcommand_parser", "(", "trainer_class", ",", "subcommand", ",", "*", "*", "subparser_kwargs", ")", "self", ".", "_subcommand_parsers", "[", "subcommand", "]", "=", "subcommand_parser", "parser_subcommands", ".", "add_subcommand", "(", "subcommand", ",", "subcommand_parser", ",", "help", "=", "description", ")"], "docstring": "the user might have passed a builder function register all subcommands in separate subcommand parsers under the main parser extract the first line description in the docstring for the subcommand help message", "docstring_tokens": ["the", "user", "might", "have", "passed", "a", "builder", "function", "register", "all", "subcommands", "in", "separate", "subcommand", "parsers", "under", "the", "main", "parser", "extract", "the", "first", "line", "description", "in", "the", "docstring", "for", "the", "subcommand", "help", "message"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 500, "end_line": 517, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_89", "original_string": "def _add_configure_optimizers_method_to_model(self, subcommand: Optional[str]) -> None:\r\n        \"\"\"Overrides the model's :meth:`~lightning.pytorch.core.LightningModule.configure_optimizers` method if a\r\n        single optimizer and optionally a scheduler argument groups are added to the parser as 'AUTOMATIC'.\"\"\"\r\n        if not self.auto_configure_optimizers:\r\n            return\r\n\r\n        parser = self._parser(subcommand)\r\n\r\n        def get_automatic(\r\n            class_type: Union[type, tuple[type, ...]], register: dict[str, tuple[Union[type, tuple[type, ...]], str]]\r\n        ) -> list[str]:\r\n            automatic = []\r\n            for key, (base_class, link_to) in register.items():\r\n                if not isinstance(base_class, tuple):\r\n                    base_class = (base_class,)\r\n                if link_to == \"AUTOMATIC\" and any(issubclass(c, class_type) for c in base_class):\r\n                    automatic.append(key)\r\n            return automatic\r\n\r\n        optimizers = get_automatic(Optimizer, parser._optimizers)\r\n        lr_schedulers = get_automatic(LRSchedulerTypeTuple, parser._lr_schedulers)\r\n\r\n        if len(optimizers) == 0:\r\n            return\r\n\r\n        if len(optimizers) > 1 or len(lr_schedulers) > 1:\r\n            raise MisconfigurationException(\r\n                f\"`{self.__class__.__name__}.add_configure_optimizers_method_to_model` expects at most one optimizer \"\r\n                f\"and one lr_scheduler to be 'AUTOMATIC', but found {optimizers + lr_schedulers}. In this case the \"\r\n                \"user is expected to link the argument groups and implement `configure_optimizers`, see \"\r\n                \"https://lightning.ai/docs/pytorch/stable/common/lightning_cli.html\"\r\n                \"#optimizers-and-learning-rate-schedulers\"\r\n            )\r\n\r\n        optimizer_class = parser._optimizers[optimizers[0]][0]\r\n        optimizer_init = self._get(self.config_init, optimizers[0])\r\n        if not isinstance(optimizer_class, tuple):\r\n            optimizer_init = _global_add_class_path(optimizer_class, optimizer_init)\r\n        if not optimizer_init:\r\n            return\r\n\r\n        lr_scheduler_init = None\r\n        if lr_schedulers:\r\n            lr_scheduler_class = parser._lr_schedulers[lr_schedulers[0]][0]\r\n            lr_scheduler_init = self._get(self.config_init, lr_schedulers[0])\r\n            if not isinstance(lr_scheduler_class, tuple):\r\n                lr_scheduler_init = _global_add_class_path(lr_scheduler_class, lr_scheduler_init)\r\n\r\n        if is_overridden(\"configure_optimizers\", self.model):\r\n            _warn(\r\n                f\"`{self.model.__class__.__name__}.configure_optimizers` will be overridden by \"\r\n                f\"`{self.__class__.__name__}.configure_optimizers`.\"\r\n            )\r\n\r\n        optimizer = instantiate_class(self.model.parameters(), optimizer_init)\r\n        lr_scheduler = instantiate_class(optimizer, lr_scheduler_init) if lr_scheduler_init else None\r\n        fn = partial(self.configure_optimizers, optimizer=optimizer, lr_scheduler=lr_scheduler)\r\n        update_wrapper(fn, self.configure_optimizers)  # necessary for `is_overridden`\r\n        self.model.configure_optimizers = MethodType(fn, self.model)", "language": "python", "code": "def _add_configure_optimizers_method_to_model(self, subcommand: Optional[str]) -> None:\r\n        \"\"\"Overrides the model's :meth:`~lightning.pytorch.core.LightningModule.configure_optimizers` method if a\r\n        single optimizer and optionally a scheduler argument groups are added to the parser as 'AUTOMATIC'.\"\"\"\r\n        if not self.auto_configure_optimizers:\r\n            return\r\n\r\n        parser = self._parser(subcommand)\r\n\r\n        def get_automatic(\r\n            class_type: Union[type, tuple[type, ...]], register: dict[str, tuple[Union[type, tuple[type, ...]], str]]\r\n        ) -> list[str]:\r\n            automatic = []\r\n            for key, (base_class, link_to) in register.items():\r\n                if not isinstance(base_class, tuple):\r\n                    base_class = (base_class,)\r\n                if link_to == \"AUTOMATIC\" and any(issubclass(c, class_type) for c in base_class):\r\n                    automatic.append(key)\r\n            return automatic\r\n\r\n        optimizers = get_automatic(Optimizer, parser._optimizers)\r\n        lr_schedulers = get_automatic(LRSchedulerTypeTuple, parser._lr_schedulers)\r\n\r\n        if len(optimizers) == 0:\r\n            return\r\n\r\n        if len(optimizers) > 1 or len(lr_schedulers) > 1:\r\n            raise MisconfigurationException(\r\n                f\"`{self.__class__.__name__}.add_configure_optimizers_method_to_model` expects at most one optimizer \"\r\n                f\"and one lr_scheduler to be 'AUTOMATIC', but found {optimizers + lr_schedulers}. In this case the \"\r\n                \"user is expected to link the argument groups and implement `configure_optimizers`, see \"\r\n                \"https://lightning.ai/docs/pytorch/stable/common/lightning_cli.html\"\r\n                \"#optimizers-and-learning-rate-schedulers\"\r\n            )\r\n\r\n        optimizer_class = parser._optimizers[optimizers[0]][0]\r\n        optimizer_init = self._get(self.config_init, optimizers[0])\r\n        if not isinstance(optimizer_class, tuple):\r\n            optimizer_init = _global_add_class_path(optimizer_class, optimizer_init)\r\n        if not optimizer_init:\r\n            return\r\n\r\n        lr_scheduler_init = None\r\n        if lr_schedulers:\r\n            lr_scheduler_class = parser._lr_schedulers[lr_schedulers[0]][0]\r\n            lr_scheduler_init = self._get(self.config_init, lr_schedulers[0])\r\n            if not isinstance(lr_scheduler_class, tuple):\r\n                lr_scheduler_init = _global_add_class_path(lr_scheduler_class, lr_scheduler_init)\r\n\r\n        if is_overridden(\"configure_optimizers\", self.model):\r\n            _warn(\r\n                f\"`{self.model.__class__.__name__}.configure_optimizers` will be overridden by \"\r\n                f\"`{self.__class__.__name__}.configure_optimizers`.\"\r\n            )\r\n\r\n        optimizer = instantiate_class(self.model.parameters(), optimizer_init)\r\n        lr_scheduler = instantiate_class(optimizer, lr_scheduler_init) if lr_scheduler_init else None\r\n        fn = partial(self.configure_optimizers, optimizer=optimizer, lr_scheduler=lr_scheduler)\r\n        update_wrapper(fn, self.configure_optimizers)  # necessary for `is_overridden`\r\n        self.model.configure_optimizers = MethodType(fn, self.model)", "code_tokens": ["def", "_add_configure_optimizers_method_to_model", "(", "self", ",", "subcommand", ":", "Optional", "[", "str", "]", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "auto_configure_optimizers", ":", "return", "parser", "=", "self", ".", "_parser", "(", "subcommand", ")", "def", "get_automatic", "(", "class_type", ":", "Union", "[", "type", ",", "tuple", "[", "type", ",", ".", ".", ".", "]", "]", ",", "register", ":", "dict", "[", "str", ",", "tuple", "[", "Union", "[", "type", ",", "tuple", "[", "type", ",", ".", ".", ".", "]", "]", ",", "str", "]", "]", ")", "-", ">", "list", "[", "str", "]", ":", "automatic", "=", "[", "]", "for", "key", ",", "(", "base_class", ",", "link_to", ")", "in", "register", ".", "items", "(", ")", ":", "if", "not", "isinstance", "(", "base_class", ",", "tuple", ")", ":", "base_class", "=", "(", "base_class", ",", ")", "if", "link_to", "=", "=", "STRING", "and", "any", "(", "issubclass", "(", "c", ",", "class_type", ")", "for", "c", "in", "base_class", ")", ":", "automatic", ".", "append", "(", "key", ")", "return", "automatic", "optimizers", "=", "get_automatic", "(", "Optimizer", ",", "parser", ".", "_optimizers", ")", "lr_schedulers", "=", "get_automatic", "(", "LRSchedulerTypeTuple", ",", "parser", ".", "_lr_schedulers", ")", "if", "len", "(", "optimizers", ")", "=", "=", "0", ":", "return", "if", "len", "(", "optimizers", ")", ">", "1", "or", "len", "(", "lr_schedulers", ")", ">", "1", ":", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", "STRING", "STRING", "STRING", ")", "optimizer_class", "=", "parser", ".", "_optimizers", "[", "optimizers", "[", "0", "]", "]", "[", "0", "]", "optimizer_init", "=", "self", ".", "_get", "(", "self", ".", "config_init", ",", "optimizers", "[", "0", "]", ")", "if", "not", "isinstance", "(", "optimizer_class", ",", "tuple", ")", ":", "optimizer_init", "=", "_global_add_class_path", "(", "optimizer_class", ",", "optimizer_init", ")", "if", "not", "optimizer_init", ":", "return", "lr_scheduler_init", "=", "None", "if", "lr_schedulers", ":", "lr_scheduler_class", "=", "parser", ".", "_lr_schedulers", "[", "lr_schedulers", "[", "0", "]", "]", "[", "0", "]", "lr_scheduler_init", "=", "self", ".", "_get", "(", "self", ".", "config_init", ",", "lr_schedulers", "[", "0", "]", ")", "if", "not", "isinstance", "(", "lr_scheduler_class", ",", "tuple", ")", ":", "lr_scheduler_init", "=", "_global_add_class_path", "(", "lr_scheduler_class", ",", "lr_scheduler_init", ")", "if", "is_overridden", "(", "STRING", ",", "self", ".", "model", ")", ":", "_warn", "(", "fSTRING", "fSTRING", ")", "optimizer", "=", "instantiate_class", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "optimizer_init", ")", "lr_scheduler", "=", "instantiate_class", "(", "optimizer", ",", "lr_scheduler_init", ")", "if", "lr_scheduler_init", "else", "None", "fn", "=", "partial", "(", "self", ".", "configure_optimizers", ",", "optimizer", "=", "optimizer", ",", "lr_scheduler", "=", "lr_scheduler", ")", "update_wrapper", "(", "fn", ",", "self", ".", "configure_optimizers", ")", "#", "necessary", "for", "`", "is_overridden", "`", "self", ".", "model", ".", "configure_optimizers", "=", "MethodType", "(", "fn", ",", "self", ".", "model", ")"], "docstring": "optimizers were registered automatically but not passed by the user override the existing method", "docstring_tokens": ["optimizers", "were", "registered", "automatically", "but", "not", "passed", "by", "the", "user", "override", "the", "existing", "method"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 676, "end_line": 736, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\cli.py", "func_name": "function_90", "original_string": "def _set_seed(self) -> None:\r\n        \"\"\"Sets the seed.\"\"\"\r\n        config_seed = self._get(self.config, \"seed_everything\")\r\n        if config_seed is False:\r\n            return\r\n        if config_seed is True:\r\n            config_seed = seed_everything(workers=True)\r\n        else:\r\n            config_seed = seed_everything(config_seed, workers=True)\r\n        if self.subcommand:\r\n            self.config[self.subcommand][\"seed_everything\"] = config_seed\r\n        else:\r\n            self.config[\"seed_everything\"] = config_seed", "language": "python", "code": "def _set_seed(self) -> None:\r\n        \"\"\"Sets the seed.\"\"\"\r\n        config_seed = self._get(self.config, \"seed_everything\")\r\n        if config_seed is False:\r\n            return\r\n        if config_seed is True:\r\n            config_seed = seed_everything(workers=True)\r\n        else:\r\n            config_seed = seed_everything(config_seed, workers=True)\r\n        if self.subcommand:\r\n            self.config[self.subcommand][\"seed_everything\"] = config_seed\r\n        else:\r\n            self.config[\"seed_everything\"] = config_seed", "code_tokens": ["def", "_set_seed", "(", "self", ")", "-", ">", "None", ":", "STRING", "config_seed", "=", "self", ".", "_get", "(", "self", ".", "config", ",", "STRING", ")", "if", "config_seed", "is", "False", ":", "return", "if", "config_seed", "is", "True", ":", "config_seed", "=", "seed_everything", "(", "workers", "=", "True", ")", "else", ":", "config_seed", "=", "seed_everything", "(", "config_seed", ",", "workers", "=", "True", ")", "if", "self", ".", "subcommand", ":", "self", ".", "config", "[", "self", ".", "subcommand", "]", "[", "STRING", "]", "=", "config_seed", "else", ":", "self", ".", "config", "[", "STRING", "]", "=", "config_seed"], "docstring": "user requested seeding, choose randomly", "docstring_tokens": ["user", "requested", "seeding", "choose", "randomly"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\cli.py", "start_line": 767, "end_line": 780, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\accelerators\\cuda.py", "func_name": "function_91", "original_string": "def _get_gpu_id(device_id: int) -> str:\r\n    \"\"\"Get the unmasked real GPU IDs.\"\"\"\r\n    default = \",\".join(str(i) for i in range(num_cuda_devices()))\r\n    cuda_visible_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\", default=default).split(\",\")\r\n    return cuda_visible_devices[device_id].strip()", "language": "python", "code": "def _get_gpu_id(device_id: int) -> str:\r\n    \"\"\"Get the unmasked real GPU IDs.\"\"\"\r\n    default = \",\".join(str(i) for i in range(num_cuda_devices()))\r\n    cuda_visible_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\", default=default).split(\",\")\r\n    return cuda_visible_devices[device_id].strip()", "code_tokens": ["def", "_get_gpu_id", "(", "device_id", ":", "int", ")", "-", ">", "str", ":", "STRING", "default", "=", "STRING", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "range", "(", "num_cuda_devices", "(", ")", ")", ")", "cuda_visible_devices", "=", "os", ".", "getenv", "(", "STRING", ",", "default", "=", "default", ")", ".", "split", "(", "STRING", ")", "return", "cuda_visible_devices", "[", "device_id", "]", ".", "strip", "(", ")"], "docstring": "All devices if `CUDA_VISIBLE_DEVICES` unset", "docstring_tokens": ["all", "devices", "if", "cuda_visible_devices", "unset"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\accelerators\\cuda.py", "start_line": 166, "end_line": 171, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\callback.py", "func_name": "function_92", "original_string": "def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Called when the train epoch ends.\r\n\r\n        To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the\r\n        :class:`lightning.pytorch.core.LightningModule` and access them in this hook:\r\n\r\n        .. code-block:: python\r\n\r\n            class MyLightningModule(L.LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.training_step_outputs = []\r\n\r\n                def training_step(self):\r\n                    loss = ...\r\n                    self.training_step_outputs.append(loss)\r\n                    return loss\r\n\r\n\r\n            class MyCallback(L.Callback):\r\n                def on_train_epoch_end(self, trainer, pl_module):\r\n                    epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\r\n                    pl_module.log(\"training_epoch_mean\", epoch_mean)\r\n                    pl_module.training_step_outputs.clear()\r\n\r\n        \"\"\"", "language": "python", "code": "def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Called when the train epoch ends.\r\n\r\n        To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the\r\n        :class:`lightning.pytorch.core.LightningModule` and access them in this hook:\r\n\r\n        .. code-block:: python\r\n\r\n            class MyLightningModule(L.LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.training_step_outputs = []\r\n\r\n                def training_step(self):\r\n                    loss = ...\r\n                    self.training_step_outputs.append(loss)\r\n                    return loss\r\n\r\n\r\n            class MyCallback(L.Callback):\r\n                def on_train_epoch_end(self, trainer, pl_module):\r\n                    epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\r\n                    pl_module.log(\"training_epoch_mean\", epoch_mean)\r\n                    pl_module.training_step_outputs.clear()\r\n\r\n        \"\"\"", "code_tokens": ["def", "on_train_epoch_end", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ")", "-", ">", "None", ":", "STRING"], "docstring": "do something with all training_step outputs, for example: free up the memory", "docstring_tokens": ["do", "something", "with", "all", "training_step", "outputs", "for", "example", "free", "up", "the", "memory"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\callback.py", "start_line": 94, "end_line": 121, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\early_stopping.py", "func_name": "function_93", "original_string": "def _run_early_stopping_check(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Checks whether the early stopping condition is met and if so tells the trainer to stop the training.\"\"\"\r\n        logs = trainer.callback_metrics\r\n\r\n        if trainer.fast_dev_run or not self._validate_condition_metric(  # disable early_stopping with fast_dev_run\r\n            logs\r\n        ):  # short circuit if metric not present\r\n            return\r\n\r\n        current = logs[self.monitor].squeeze()\r\n        should_stop, reason = self._evaluate_stopping_criteria(current)\r\n\r\n        should_stop = trainer.strategy.reduce_boolean_decision(should_stop, all=False)\r\n        trainer.should_stop = trainer.should_stop or should_stop\r\n        if should_stop:\r\n            self.stopped_epoch = trainer.current_epoch\r\n            self.stopping_reason_message = reason\r\n        if reason and self.verbose:\r\n            self._log_info(trainer, reason, self.log_rank_zero_only)", "language": "python", "code": "def _run_early_stopping_check(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Checks whether the early stopping condition is met and if so tells the trainer to stop the training.\"\"\"\r\n        logs = trainer.callback_metrics\r\n\r\n        if trainer.fast_dev_run or not self._validate_condition_metric(  # disable early_stopping with fast_dev_run\r\n            logs\r\n        ):  # short circuit if metric not present\r\n            return\r\n\r\n        current = logs[self.monitor].squeeze()\r\n        should_stop, reason = self._evaluate_stopping_criteria(current)\r\n\r\n        should_stop = trainer.strategy.reduce_boolean_decision(should_stop, all=False)\r\n        trainer.should_stop = trainer.should_stop or should_stop\r\n        if should_stop:\r\n            self.stopped_epoch = trainer.current_epoch\r\n            self.stopping_reason_message = reason\r\n        if reason and self.verbose:\r\n            self._log_info(trainer, reason, self.log_rank_zero_only)", "code_tokens": ["def", "_run_early_stopping_check", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "logs", "=", "trainer", ".", "callback_metrics", "if", "trainer", ".", "fast_dev_run", "or", "not", "self", ".", "_validate_condition_metric", "(", "#", "disable", "early_stopping", "with", "fast_dev_run", "logs", ")", ":", "#", "short", "circuit", "if", "metric", "not", "present", "return", "current", "=", "logs", "[", "self", ".", "monitor", "]", ".", "squeeze", "(", ")", "should_stop", ",", "reason", "=", "self", ".", "_evaluate_stopping_criteria", "(", "current", ")", "should_stop", "=", "trainer", ".", "strategy", ".", "reduce_boolean_decision", "(", "should_stop", ",", "all", "=", "False", ")", "trainer", ".", "should_stop", "=", "trainer", ".", "should_stop", "or", "should_stop", "if", "should_stop", ":", "self", ".", "stopped_epoch", "=", "trainer", ".", "current_epoch", "self", ".", "stopping_reason_message", "=", "reason", "if", "reason", "and", "self", ".", "verbose", ":", "self", ".", "_log_info", "(", "trainer", ",", "reason", ",", "self", ".", "log_rank_zero_only", ")"], "docstring": "stop every ddp process if any world process decides to stop", "docstring_tokens": ["stop", "every", "ddp", "process", "if", "any", "world", "process", "decides", "to", "stop"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\early_stopping.py", "start_line": 224, "end_line": 243, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "func_name": "function_94", "original_string": "def flatten_modules(modules: Union[Module, Iterable[Union[Module, Iterable]]]) -> list[Module]:\r\n        \"\"\"This function is used to flatten a module or an iterable of modules into a list of its leaf modules (modules\r\n        with no children) and parent modules that have parameters directly themselves.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n\r\n        Returns:\r\n            List of modules\r\n\r\n        \"\"\"\r\n        if isinstance(modules, ModuleDict):\r\n            modules = modules.values()\r\n\r\n        if isinstance(modules, Iterable):\r\n            _flatten_modules = []\r\n            for m in modules:\r\n                _flatten_modules.extend(BaseFinetuning.flatten_modules(m))\r\n\r\n            _modules = iter(_flatten_modules)\r\n        else:\r\n            _modules = modules.modules()\r\n\r\n        return [m for m in _modules if not list(m.children()) or m._parameters]", "language": "python", "code": "def flatten_modules(modules: Union[Module, Iterable[Union[Module, Iterable]]]) -> list[Module]:\r\n        \"\"\"This function is used to flatten a module or an iterable of modules into a list of its leaf modules (modules\r\n        with no children) and parent modules that have parameters directly themselves.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n\r\n        Returns:\r\n            List of modules\r\n\r\n        \"\"\"\r\n        if isinstance(modules, ModuleDict):\r\n            modules = modules.values()\r\n\r\n        if isinstance(modules, Iterable):\r\n            _flatten_modules = []\r\n            for m in modules:\r\n                _flatten_modules.extend(BaseFinetuning.flatten_modules(m))\r\n\r\n            _modules = iter(_flatten_modules)\r\n        else:\r\n            _modules = modules.modules()\r\n\r\n        return [m for m in _modules if not list(m.children()) or m._parameters]", "code_tokens": ["def", "flatten_modules", "(", "modules", ":", "Union", "[", "Module", ",", "Iterable", "[", "Union", "[", "Module", ",", "Iterable", "]", "]", "]", ")", "-", ">", "list", "[", "Module", "]", ":", "STRING", "if", "isinstance", "(", "modules", ",", "ModuleDict", ")", ":", "modules", "=", "modules", ".", "values", "(", ")", "if", "isinstance", "(", "modules", ",", "Iterable", ")", ":", "_flatten_modules", "=", "[", "]", "for", "m", "in", "modules", ":", "_flatten_modules", ".", "extend", "(", "BaseFinetuning", ".", "flatten_modules", "(", "m", ")", ")", "_modules", "=", "iter", "(", "_flatten_modules", ")", "else", ":", "_modules", "=", "modules", ".", "modules", "(", ")", "return", "[", "m", "for", "m", "in", "_modules", "if", "not", "list", "(", "m", ".", "children", "(", ")", ")", "or", "m", ".", "_parameters", "]"], "docstring": "Capture all leaf modules as well as parent modules that have parameters directly themselves", "docstring_tokens": ["capture", "all", "leaf", "modules", "as", "well", "as", "parent", "modules", "that", "have", "parameters", "directly", "themselves"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "start_line": 119, "end_line": 143, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "func_name": "function_95", "original_string": "def filter_params(\r\n        modules: Union[Module, Iterable[Union[Module, Iterable]]], train_bn: bool = True, requires_grad: bool = True\r\n    ) -> Generator:\r\n        \"\"\"Yields the `requires_grad` parameters of a given module or list of modules.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n            train_bn: Whether not to train the BatchNorm module\r\n            requires_grad: Whether to create a generator for trainable or non-trainable parameters.\r\n        Returns:\r\n            Generator\r\n\r\n        \"\"\"\r\n        modules = BaseFinetuning.flatten_modules(modules)\r\n        for mod in modules:\r\n            if isinstance(mod, _BatchNorm) and not train_bn:\r\n                continue\r\n            for param in mod.parameters(recurse=False):\r\n                if param.requires_grad == requires_grad:\r\n                    yield param", "language": "python", "code": "def filter_params(\r\n        modules: Union[Module, Iterable[Union[Module, Iterable]]], train_bn: bool = True, requires_grad: bool = True\r\n    ) -> Generator:\r\n        \"\"\"Yields the `requires_grad` parameters of a given module or list of modules.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n            train_bn: Whether not to train the BatchNorm module\r\n            requires_grad: Whether to create a generator for trainable or non-trainable parameters.\r\n        Returns:\r\n            Generator\r\n\r\n        \"\"\"\r\n        modules = BaseFinetuning.flatten_modules(modules)\r\n        for mod in modules:\r\n            if isinstance(mod, _BatchNorm) and not train_bn:\r\n                continue\r\n            for param in mod.parameters(recurse=False):\r\n                if param.requires_grad == requires_grad:\r\n                    yield param", "code_tokens": ["def", "filter_params", "(", "modules", ":", "Union", "[", "Module", ",", "Iterable", "[", "Union", "[", "Module", ",", "Iterable", "]", "]", "]", ",", "train_bn", ":", "bool", "=", "True", ",", "requires_grad", ":", "bool", "=", "True", ")", "-", ">", "Generator", ":", "STRING", "modules", "=", "BaseFinetuning", ".", "flatten_modules", "(", "modules", ")", "for", "mod", "in", "modules", ":", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", "and", "not", "train_bn", ":", "continue", "for", "param", "in", "mod", ".", "parameters", "(", "recurse", "=", "False", ")", ":", "if", "param", ".", "requires_grad", "=", "=", "requires_grad", ":", "yield", "param"], "docstring": "recursion could yield duplicate parameters for parent modules w/ parameters so disabling it", "docstring_tokens": ["recursion", "could", "yield", "duplicate", "parameters", "for", "parent", "modules", "w", "parameters", "so", "disabling", "it"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "start_line": 146, "end_line": 166, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "func_name": "function_96", "original_string": "def make_trainable(modules: Union[Module, Iterable[Union[Module, Iterable]]]) -> None:\r\n        \"\"\"Unfreezes the parameters of the provided modules.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n\r\n        \"\"\"\r\n        modules = BaseFinetuning.flatten_modules(modules)\r\n        for module in modules:\r\n            if isinstance(module, _BatchNorm):\r\n                module.track_running_stats = True\r\n            for param in module.parameters(recurse=False):\r\n                param.requires_grad = True", "language": "python", "code": "def make_trainable(modules: Union[Module, Iterable[Union[Module, Iterable]]]) -> None:\r\n        \"\"\"Unfreezes the parameters of the provided modules.\r\n\r\n        Args:\r\n            modules: A given module or an iterable of modules\r\n\r\n        \"\"\"\r\n        modules = BaseFinetuning.flatten_modules(modules)\r\n        for module in modules:\r\n            if isinstance(module, _BatchNorm):\r\n                module.track_running_stats = True\r\n            for param in module.parameters(recurse=False):\r\n                param.requires_grad = True", "code_tokens": ["def", "make_trainable", "(", "modules", ":", "Union", "[", "Module", ",", "Iterable", "[", "Union", "[", "Module", ",", "Iterable", "]", "]", "]", ")", "-", ">", "None", ":", "STRING", "modules", "=", "BaseFinetuning", ".", "flatten_modules", "(", "modules", ")", "for", "module", "in", "modules", ":", "if", "isinstance", "(", "module", ",", "_BatchNorm", ")", ":", "module", ".", "track_running_stats", "=", "True", "for", "param", "in", "module", ".", "parameters", "(", "recurse", "=", "False", ")", ":", "param", ".", "requires_grad", "=", "True"], "docstring": "recursion could yield duplicate parameters for parent modules w/ parameters so disabling it", "docstring_tokens": ["recursion", "could", "yield", "duplicate", "parameters", "for", "parent", "modules", "w", "parameters", "so", "disabling", "it"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "start_line": 169, "end_line": 182, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "func_name": "function_97", "original_string": "def freeze_module(module: Module) -> None:\r\n        \"\"\"Freezes the parameters of the provided module.\r\n\r\n        Args:\r\n            module: A given module\r\n\r\n        \"\"\"\r\n        if isinstance(module, _BatchNorm):\r\n            module.track_running_stats = False\r\n        for param in module.parameters(recurse=False):\r\n            param.requires_grad = False", "language": "python", "code": "def freeze_module(module: Module) -> None:\r\n        \"\"\"Freezes the parameters of the provided module.\r\n\r\n        Args:\r\n            module: A given module\r\n\r\n        \"\"\"\r\n        if isinstance(module, _BatchNorm):\r\n            module.track_running_stats = False\r\n        for param in module.parameters(recurse=False):\r\n            param.requires_grad = False", "code_tokens": ["def", "freeze_module", "(", "module", ":", "Module", ")", "-", ">", "None", ":", "STRING", "if", "isinstance", "(", "module", ",", "_BatchNorm", ")", ":", "module", ".", "track_running_stats", "=", "False", "for", "param", "in", "module", ".", "parameters", "(", "recurse", "=", "False", ")", ":", "param", ".", "requires_grad", "=", "False"], "docstring": "recursion could yield duplicate parameters for parent modules w/ parameters so disabling it", "docstring_tokens": ["recursion", "could", "yield", "duplicate", "parameters", "for", "parent", "modules", "w", "parameters", "so", "disabling", "it"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\finetuning.py", "start_line": 185, "end_line": 196, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\gradient_accumulation_scheduler.py", "func_name": "function_98", "original_string": "def on_train_start(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Performns a configuration validation before training starts and raises errors for incompatible settings.\"\"\"\r\n\r\n        if not pl_module.automatic_optimization:\r\n            raise RuntimeError(\r\n                \"\"\"Automatic gradient accumulation and the `GradientAccumulationScheduler` is not supported for\r\n                manual optimization. Please remove the callback or switch to automatic optimization.\"\"\"\r\n            )\r\n\r\n        overridden_optimizer_step = is_overridden(\"optimizer_step\", pl_module)\r\n        overridden_optimizer_zero_grad = is_overridden(\"optimizer_zero_grad\", pl_module)\r\n        going_to_accumulate_grad_batches = self.going_to_accumulate_grad_batches()\r\n        has_overridden_optimization_functions = overridden_optimizer_step or overridden_optimizer_zero_grad\r\n        if has_overridden_optimization_functions and going_to_accumulate_grad_batches:\r\n            rank_zero_warn(\r\n                \"When using `Trainer(accumulate_grad_batches != 1)` and overriding\"\r\n                \" `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch\"\r\n                \" (rather, they are called on every optimization step).\"\r\n            )\r\n\r\n        from lightning.pytorch.strategies import DeepSpeedStrategy\r\n\r\n        if isinstance(trainer.strategy, DeepSpeedStrategy):\r\n            raise RuntimeError(\r\n                f\"The `{type(trainer.strategy).__name__}` does not support `accumulate_grad_batches` changing\"\r\n                \" between epochs.\"\r\n            )\r\n        if trainer.accumulate_grad_batches != 1:\r\n            raise ValueError(\r\n                \"You have set `accumulate_grad_batches` and are using the `GradientAccumulationScheduler`\"\r\n                \" callback. Either remove `accumulate_grad_batches` from the Trainer or remove the callback.\"\r\n            )", "language": "python", "code": "def on_train_start(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Performns a configuration validation before training starts and raises errors for incompatible settings.\"\"\"\r\n\r\n        if not pl_module.automatic_optimization:\r\n            raise RuntimeError(\r\n                \"\"\"Automatic gradient accumulation and the `GradientAccumulationScheduler` is not supported for\r\n                manual optimization. Please remove the callback or switch to automatic optimization.\"\"\"\r\n            )\r\n\r\n        overridden_optimizer_step = is_overridden(\"optimizer_step\", pl_module)\r\n        overridden_optimizer_zero_grad = is_overridden(\"optimizer_zero_grad\", pl_module)\r\n        going_to_accumulate_grad_batches = self.going_to_accumulate_grad_batches()\r\n        has_overridden_optimization_functions = overridden_optimizer_step or overridden_optimizer_zero_grad\r\n        if has_overridden_optimization_functions and going_to_accumulate_grad_batches:\r\n            rank_zero_warn(\r\n                \"When using `Trainer(accumulate_grad_batches != 1)` and overriding\"\r\n                \" `LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch\"\r\n                \" (rather, they are called on every optimization step).\"\r\n            )\r\n\r\n        from lightning.pytorch.strategies import DeepSpeedStrategy\r\n\r\n        if isinstance(trainer.strategy, DeepSpeedStrategy):\r\n            raise RuntimeError(\r\n                f\"The `{type(trainer.strategy).__name__}` does not support `accumulate_grad_batches` changing\"\r\n                \" between epochs.\"\r\n            )\r\n        if trainer.accumulate_grad_batches != 1:\r\n            raise ValueError(\r\n                \"You have set `accumulate_grad_batches` and are using the `GradientAccumulationScheduler`\"\r\n                \" callback. Either remove `accumulate_grad_batches` from the Trainer or remove the callback.\"\r\n            )", "code_tokens": ["def", "on_train_start", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "if", "not", "pl_module", ".", "automatic_optimization", ":", "raise", "RuntimeError", "(", "STRING", ")", "overridden_optimizer_step", "=", "is_overridden", "(", "STRING", ",", "pl_module", ")", "overridden_optimizer_zero_grad", "=", "is_overridden", "(", "STRING", ",", "pl_module", ")", "going_to_accumulate_grad_batches", "=", "self", ".", "going_to_accumulate_grad_batches", "(", ")", "has_overridden_optimization_functions", "=", "overridden_optimizer_step", "or", "overridden_optimizer_zero_grad", "if", "has_overridden_optimization_functions", "and", "going_to_accumulate_grad_batches", ":", "rank_zero_warn", "(", "STRING", "STRING", "STRING", ")", "from", "lightning", ".", "pytorch", ".", "strategies", "import", "DeepSpeedStrategy", "if", "isinstance", "(", "trainer", ".", "strategy", ",", "DeepSpeedStrategy", ")", ":", "raise", "RuntimeError", "(", "fSTRING", "STRING", ")", "if", "trainer", ".", "accumulate_grad_batches", "!", "=", "1", ":", "raise", "ValueError", "(", "STRING", "STRING", ")"], "docstring": "local import to avoid circular import", "docstring_tokens": ["local", "import", "to", "avoid", "circular", "import"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\gradient_accumulation_scheduler.py", "start_line": 103, "end_line": 135, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\lr_monitor.py", "func_name": "function_99", "original_string": "def on_train_start(self, trainer: \"pl.Trainer\", *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Called before training, determines unique names for all lr schedulers in the case of multiple of the same\r\n        type or in the case of multiple parameter groups.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If ``Trainer`` has no ``logger``.\r\n\r\n        \"\"\"\r\n        if not trainer.loggers:\r\n            raise MisconfigurationException(\r\n                \"Cannot use `LearningRateMonitor` callback with `Trainer` that has no logger.\"\r\n            )\r\n\r\n        if self.log_momentum:\r\n\r\n            def _check_no_key(key: str) -> bool:\r\n                if trainer.lr_scheduler_configs:\r\n                    return any(\r\n                        key not in config.scheduler.optimizer.defaults for config in trainer.lr_scheduler_configs\r\n                    )\r\n\r\n                return any(key not in optimizer.defaults for optimizer in trainer.optimizers)\r\n\r\n            if _check_no_key(\"momentum\") and _check_no_key(\"betas\"):\r\n                rank_zero_warn(\r\n                    \"You have set log_momentum=True, but some optimizers do not\"\r\n                    \" have momentum. This will log a value 0 for the momentum.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n\r\n        names: list[list[str]] = []\r\n        (\r\n            sched_hparam_keys,\r\n            optimizers_with_scheduler,\r\n            optimizers_with_scheduler_types,\r\n        ) = self._find_names_from_schedulers(trainer.lr_scheduler_configs)\r\n        names.extend(sched_hparam_keys)\r\n\r\n        optimizer_hparam_keys, _ = self._find_names_from_optimizers(\r\n            trainer.optimizers,\r\n            seen_optimizers=optimizers_with_scheduler,\r\n            seen_optimizer_types=optimizers_with_scheduler_types,\r\n        )\r\n        names.extend(optimizer_hparam_keys)\r\n\r\n        names_flatten = list(itertools.chain.from_iterable(names))\r\n        self.lrs = {name: [] for name in names_flatten}\r\n        self.last_momentum_values = {name + \"-momentum\": None for name in names_flatten}\r\n        self.last_weight_decay_values = {name + \"-weight_decay\": None for name in names_flatten}", "language": "python", "code": "def on_train_start(self, trainer: \"pl.Trainer\", *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Called before training, determines unique names for all lr schedulers in the case of multiple of the same\r\n        type or in the case of multiple parameter groups.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If ``Trainer`` has no ``logger``.\r\n\r\n        \"\"\"\r\n        if not trainer.loggers:\r\n            raise MisconfigurationException(\r\n                \"Cannot use `LearningRateMonitor` callback with `Trainer` that has no logger.\"\r\n            )\r\n\r\n        if self.log_momentum:\r\n\r\n            def _check_no_key(key: str) -> bool:\r\n                if trainer.lr_scheduler_configs:\r\n                    return any(\r\n                        key not in config.scheduler.optimizer.defaults for config in trainer.lr_scheduler_configs\r\n                    )\r\n\r\n                return any(key not in optimizer.defaults for optimizer in trainer.optimizers)\r\n\r\n            if _check_no_key(\"momentum\") and _check_no_key(\"betas\"):\r\n                rank_zero_warn(\r\n                    \"You have set log_momentum=True, but some optimizers do not\"\r\n                    \" have momentum. This will log a value 0 for the momentum.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n\r\n        names: list[list[str]] = []\r\n        (\r\n            sched_hparam_keys,\r\n            optimizers_with_scheduler,\r\n            optimizers_with_scheduler_types,\r\n        ) = self._find_names_from_schedulers(trainer.lr_scheduler_configs)\r\n        names.extend(sched_hparam_keys)\r\n\r\n        optimizer_hparam_keys, _ = self._find_names_from_optimizers(\r\n            trainer.optimizers,\r\n            seen_optimizers=optimizers_with_scheduler,\r\n            seen_optimizer_types=optimizers_with_scheduler_types,\r\n        )\r\n        names.extend(optimizer_hparam_keys)\r\n\r\n        names_flatten = list(itertools.chain.from_iterable(names))\r\n        self.lrs = {name: [] for name in names_flatten}\r\n        self.last_momentum_values = {name + \"-momentum\": None for name in names_flatten}\r\n        self.last_weight_decay_values = {name + \"-weight_decay\": None for name in names_flatten}", "code_tokens": ["def", "on_train_start", "(", "self", ",", "trainer", ":", "STRING", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "if", "not", "trainer", ".", "loggers", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "if", "self", ".", "log_momentum", ":", "def", "_check_no_key", "(", "key", ":", "str", ")", "-", ">", "bool", ":", "if", "trainer", ".", "lr_scheduler_configs", ":", "return", "any", "(", "key", "not", "in", "config", ".", "scheduler", ".", "optimizer", ".", "defaults", "for", "config", "in", "trainer", ".", "lr_scheduler_configs", ")", "return", "any", "(", "key", "not", "in", "optimizer", ".", "defaults", "for", "optimizer", "in", "trainer", ".", "optimizers", ")", "if", "_check_no_key", "(", "STRING", ")", "and", "_check_no_key", "(", "STRING", ")", ":", "rank_zero_warn", "(", "STRING", "STRING", ",", "category", "=", "RuntimeWarning", ",", ")", "names", ":", "list", "[", "list", "[", "str", "]", "]", "=", "[", "]", "(", "sched_hparam_keys", ",", "optimizers_with_scheduler", ",", "optimizers_with_scheduler_types", ",", ")", "=", "self", ".", "_find_names_from_schedulers", "(", "trainer", ".", "lr_scheduler_configs", ")", "names", ".", "extend", "(", "sched_hparam_keys", ")", "optimizer_hparam_keys", ",", "_", "=", "self", ".", "_find_names_from_optimizers", "(", "trainer", ".", "optimizers", ",", "seen_optimizers", "=", "optimizers_with_scheduler", ",", "seen_optimizer_types", "=", "optimizers_with_scheduler_types", ",", ")", "names", ".", "extend", "(", "optimizer_hparam_keys", ")", "names_flatten", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "names", ")", ")", "self", ".", "lrs", "=", "{", "name", ":", "[", "]", "for", "name", "in", "names_flatten", "}", "self", ".", "last_momentum_values", "=", "{", "name", "+", "STRING", ":", "None", "for", "name", "in", "names_flatten", "}", "self", ".", "last_weight_decay_values", "=", "{", "name", "+", "STRING", ":", "None", "for", "name", "in", "names_flatten", "}"], "docstring": "Find names for schedulers Find names for leftover optimizers Initialize for storing values", "docstring_tokens": ["find", "names", "for", "schedulers", "find", "names", "for", "leftover", "optimizers", "initialize", "for", "storing", "values"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\lr_monitor.py", "start_line": 111, "end_line": 163, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "func_name": "function_100", "original_string": "def on_train_batch_end(\r\n        self,\r\n        trainer: \"pl.Trainer\",\r\n        pl_module: \"pl.LightningModule\",\r\n        outputs: STEP_OUTPUT,\r\n        batch: Any,\r\n        batch_idx: int,\r\n    ) -> None:\r\n        \"\"\"Save checkpoint on train batch end if we meet the criteria for `every_n_train_steps`\"\"\"\r\n        skip_due_to_state = self._should_skip_saving_checkpoint(trainer)\r\n        skip_batch = self._every_n_train_steps < 1 or (trainer.global_step % self._every_n_train_steps != 0)\r\n\r\n        train_time_interval = self._train_time_interval\r\n        skip_time = True\r\n        now = time.monotonic()\r\n        if train_time_interval is not None:\r\n            prev_time_check = self._last_time_checked\r\n            skip_time = prev_time_check is None or (now - prev_time_check) < train_time_interval.total_seconds()\r\n            skip_time = trainer.strategy.broadcast(skip_time)\r\n\r\n        if skip_batch and skip_time:\r\n            return\r\n        if not skip_time:\r\n            self._last_time_checked = now\r\n\r\n        monitor_candidates = self._monitor_candidates(trainer)\r\n        if self.monitor is not None and self.monitor not in monitor_candidates:\r\n            self._defer_save_until_validation = True\r\n            return\r\n\r\n        if (\r\n            self.monitor is not None\r\n            and not self._should_save_on_train_epoch_end(trainer)\r\n            and getattr(trainer.fit_loop.epoch_loop.batch_progress, \"is_last_batch\", False)\r\n        ):\r\n            will_run_val = False\r\n            if getattr(trainer, \"enable_validation\", False):\r\n                num_val_batches = (\r\n                    sum(trainer.num_val_batches)\r\n                    if isinstance(trainer.num_val_batches, list)\r\n                    else trainer.num_val_batches\r\n                )\r\n                if num_val_batches and num_val_batches > 0:\r\n                    cve = trainer.check_val_every_n_epoch\r\n                    if cve is None or ((trainer.current_epoch + 1) % cve == 0):\r\n                        will_run_val = True\r\n\r\n            if will_run_val:\r\n                self._defer_save_until_validation = True\r\n                return\r\n\r\n        if skip_due_to_state:\r\n            return\r\n\r\n        self._save_topk_checkpoint(trainer, monitor_candidates)\r\n        self._save_last_checkpoint(trainer, monitor_candidates)", "language": "python", "code": "def on_train_batch_end(\r\n        self,\r\n        trainer: \"pl.Trainer\",\r\n        pl_module: \"pl.LightningModule\",\r\n        outputs: STEP_OUTPUT,\r\n        batch: Any,\r\n        batch_idx: int,\r\n    ) -> None:\r\n        \"\"\"Save checkpoint on train batch end if we meet the criteria for `every_n_train_steps`\"\"\"\r\n        skip_due_to_state = self._should_skip_saving_checkpoint(trainer)\r\n        skip_batch = self._every_n_train_steps < 1 or (trainer.global_step % self._every_n_train_steps != 0)\r\n\r\n        train_time_interval = self._train_time_interval\r\n        skip_time = True\r\n        now = time.monotonic()\r\n        if train_time_interval is not None:\r\n            prev_time_check = self._last_time_checked\r\n            skip_time = prev_time_check is None or (now - prev_time_check) < train_time_interval.total_seconds()\r\n            skip_time = trainer.strategy.broadcast(skip_time)\r\n\r\n        if skip_batch and skip_time:\r\n            return\r\n        if not skip_time:\r\n            self._last_time_checked = now\r\n\r\n        monitor_candidates = self._monitor_candidates(trainer)\r\n        if self.monitor is not None and self.monitor not in monitor_candidates:\r\n            self._defer_save_until_validation = True\r\n            return\r\n\r\n        if (\r\n            self.monitor is not None\r\n            and not self._should_save_on_train_epoch_end(trainer)\r\n            and getattr(trainer.fit_loop.epoch_loop.batch_progress, \"is_last_batch\", False)\r\n        ):\r\n            will_run_val = False\r\n            if getattr(trainer, \"enable_validation\", False):\r\n                num_val_batches = (\r\n                    sum(trainer.num_val_batches)\r\n                    if isinstance(trainer.num_val_batches, list)\r\n                    else trainer.num_val_batches\r\n                )\r\n                if num_val_batches and num_val_batches > 0:\r\n                    cve = trainer.check_val_every_n_epoch\r\n                    if cve is None or ((trainer.current_epoch + 1) % cve == 0):\r\n                        will_run_val = True\r\n\r\n            if will_run_val:\r\n                self._defer_save_until_validation = True\r\n                return\r\n\r\n        if skip_due_to_state:\r\n            return\r\n\r\n        self._save_topk_checkpoint(trainer, monitor_candidates)\r\n        self._save_last_checkpoint(trainer, monitor_candidates)", "code_tokens": ["def", "on_train_batch_end", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "outputs", ":", "STEP_OUTPUT", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ",", ")", "-", ">", "None", ":", "STRING", "skip_due_to_state", "=", "self", ".", "_should_skip_saving_checkpoint", "(", "trainer", ")", "skip_batch", "=", "self", ".", "_every_n_train_steps", "<", "1", "or", "(", "trainer", ".", "global_step", "%", "self", ".", "_every_n_train_steps", "!", "=", "0", ")", "train_time_interval", "=", "self", ".", "_train_time_interval", "skip_time", "=", "True", "now", "=", "time", ".", "monotonic", "(", ")", "if", "train_time_interval", "is", "not", "None", ":", "prev_time_check", "=", "self", ".", "_last_time_checked", "skip_time", "=", "prev_time_check", "is", "None", "or", "(", "now", "-", "prev_time_check", ")", "<", "train_time_interval", ".", "total_seconds", "(", ")", "skip_time", "=", "trainer", ".", "strategy", ".", "broadcast", "(", "skip_time", ")", "if", "skip_batch", "and", "skip_time", ":", "return", "if", "not", "skip_time", ":", "self", ".", "_last_time_checked", "=", "now", "monitor_candidates", "=", "self", ".", "_monitor_candidates", "(", "trainer", ")", "if", "self", ".", "monitor", "is", "not", "None", "and", "self", ".", "monitor", "not", "in", "monitor_candidates", ":", "self", ".", "_defer_save_until_validation", "=", "True", "return", "if", "(", "self", ".", "monitor", "is", "not", "None", "and", "not", "self", ".", "_should_save_on_train_epoch_end", "(", "trainer", ")", "and", "getattr", "(", "trainer", ".", "fit_loop", ".", "epoch_loop", ".", "batch_progress", ",", "STRING", ",", "False", ")", ")", ":", "will_run_val", "=", "False", "if", "getattr", "(", "trainer", ",", "STRING", ",", "False", ")", ":", "num_val_batches", "=", "(", "sum", "(", "trainer", ".", "num_val_batches", ")", "if", "isinstance", "(", "trainer", ".", "num_val_batches", ",", "list", ")", "else", "trainer", ".", "num_val_batches", ")", "if", "num_val_batches", "and", "num_val_batches", ">", "0", ":", "cve", "=", "trainer", ".", "check_val_every_n_epoch", "if", "cve", "is", "None", "or", "(", "(", "trainer", ".", "current_epoch", "+", "1", ")", "%", "cve", "=", "=", "0", ")", ":", "will_run_val", "=", "True", "if", "will_run_val", ":", "self", ".", "_defer_save_until_validation", "=", "True", "return", "if", "skip_due_to_state", ":", "return", "self", ".", "_save_topk_checkpoint", "(", "trainer", ",", "monitor_candidates", ")", "self", ".", "_save_last_checkpoint", "(", "trainer", ",", "monitor_candidates", ")"], "docstring": "Do not return early here because we may need to set deferral flags even if a save already happened at this global step. We'll enforce the skip just before actually saving below. Important: allow zero timedelta as a valid interval in case we have time differences across ranks broadcast the decision on whether to checkpoint from rank 0 to avoid possible hangs If monitoring a metric that is not yet available (e.g., validation-only), defer saving until validation end so the metric is present. Defer both top-k and last to avoid blocking with `_last_global_step_saved` Even if the monitored key exists, it could be stale from a previous validation. If validation is scheduled to run right after this batch (e.g., last batch of epoch) and we are not saving at train epoch end, defer to `on_validation_end` to use fresh metrics. Only defer if a validation loop is expected to run after this batch. Only proceed to save if not skipping due to trainer/callback state", "docstring_tokens": ["do", "not", "return", "early", "here", "because", "we", "may", "need", "to", "set", "deferral", "flags", "even", "if", "a", "save", "already", "happened", "at", "this", "global", "step", "we", "ll", "enforce", "the", "skip", "just", "before", "actually", "saving", "below", "important", "allow", "zero", "timedelta", "as", "a", "valid", "interval", "in", "case", "we", "have", "time", "differences", "across", "ranks", "broadcast", "the", "decision", "on", "whether", "to", "checkpoint", "from", "rank", "0", "to", "avoid", "possible", "hangs", "if", "monitoring", "a", "metric", "that", "is", "not", "yet", "available", "e", "g", "validation", "only", "defer", "saving", "until", "validation", "end", "so", "the", "metric", "is", "present", "defer", "both", "top", "k", "and", "last", "to", "avoid", "blocking", "with", "_last_global_step_saved", "even", "if", "the", "monitored", "key", "exists", "it", "could", "be", "stale", "from", "a", "previous", "validation", "if", "validation", "is", "scheduled", "to", "run", "right", "after", "this", "batch", "e", "g", "last", "batch", "of", "epoch", "and", "we", "are", "not", "saving", "at", "train", "epoch", "end", "defer", "to", "on_validation_end", "to", "use", "fresh", "metrics", "only", "defer", "if", "a", "validation", "loop", "is", "expected", "to", "run", "after", "this", "batch", "only", "proceed", "to", "save", "if", "not", "skipping", "due", "to", "trainer", "callback", "state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "start_line": 304, "end_line": 373, "has_examples": false, "num_comments": 8, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "func_name": "function_101", "original_string": "def on_validation_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Save a checkpoint at the end of the validation stage.\"\"\"\r\n        if not self._should_skip_saving_checkpoint(trainer) and not self._should_save_on_train_epoch_end(trainer):\r\n            monitor_candidates = self._monitor_candidates(trainer)\r\n            if self._defer_save_until_validation:\r\n                self._save_topk_checkpoint(trainer, monitor_candidates)\r\n                self._save_last_checkpoint(trainer, monitor_candidates)\r\n                self._defer_save_until_validation = False\r\n                return\r\n\r\n            if self._every_n_epochs >= 1 and (trainer.current_epoch + 1) % self._every_n_epochs == 0:\r\n                self._save_topk_checkpoint(trainer, monitor_candidates)\r\n            self._save_last_checkpoint(trainer, monitor_candidates)", "language": "python", "code": "def on_validation_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\r\n        \"\"\"Save a checkpoint at the end of the validation stage.\"\"\"\r\n        if not self._should_skip_saving_checkpoint(trainer) and not self._should_save_on_train_epoch_end(trainer):\r\n            monitor_candidates = self._monitor_candidates(trainer)\r\n            if self._defer_save_until_validation:\r\n                self._save_topk_checkpoint(trainer, monitor_candidates)\r\n                self._save_last_checkpoint(trainer, monitor_candidates)\r\n                self._defer_save_until_validation = False\r\n                return\r\n\r\n            if self._every_n_epochs >= 1 and (trainer.current_epoch + 1) % self._every_n_epochs == 0:\r\n                self._save_topk_checkpoint(trainer, monitor_candidates)\r\n            self._save_last_checkpoint(trainer, monitor_candidates)", "code_tokens": ["def", "on_validation_end", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_should_skip_saving_checkpoint", "(", "trainer", ")", "and", "not", "self", ".", "_should_save_on_train_epoch_end", "(", "trainer", ")", ":", "monitor_candidates", "=", "self", ".", "_monitor_candidates", "(", "trainer", ")", "if", "self", ".", "_defer_save_until_validation", ":", "self", ".", "_save_topk_checkpoint", "(", "trainer", ",", "monitor_candidates", ")", "self", ".", "_save_last_checkpoint", "(", "trainer", ",", "monitor_candidates", ")", "self", ".", "_defer_save_until_validation", "=", "False", "return", "if", "self", ".", "_every_n_epochs", ">", "=", "1", "and", "(", "trainer", ".", "current_epoch", "+", "1", ")", "%", "self", ".", "_every_n_epochs", "=", "=", "0", ":", "self", ".", "_save_topk_checkpoint", "(", "trainer", ",", "monitor_candidates", ")", "self", ".", "_save_last_checkpoint", "(", "trainer", ",", "monitor_candidates", ")"], "docstring": "If a step/time-triggered save was deferred due to a missing monitored metric, perform the save now that validation metrics are available.", "docstring_tokens": ["if", "a", "step", "time", "triggered", "save", "was", "deferred", "due", "to", "a", "missing", "monitored", "metric", "perform", "the", "save", "now", "that", "validation", "metrics", "are", "available"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "start_line": 385, "end_line": 399, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "func_name": "function_102", "original_string": "def __resolve_ckpt_dir(self, trainer: \"pl.Trainer\") -> _PATH:\r\n        \"\"\"Determines model checkpoint save directory at runtime. Reference attributes from the trainer's logger to\r\n        determine where to save checkpoints. The path for saving weights is set in this priority:\r\n\r\n        1.  The ``ModelCheckpoint``'s ``dirpath`` if passed in\r\n        2.  The ``Logger``'s ``log_dir`` if the trainer has loggers\r\n        3.  The ``Trainer``'s ``default_root_dir`` if the trainer has no loggers\r\n\r\n        The path gets extended with subdirectory \"checkpoints\".\r\n\r\n        \"\"\"\r\n        if self.dirpath is not None:\r\n            return self.dirpath\r\n\r\n        if len(trainer.loggers) > 0:\r\n            if trainer.loggers[0].save_dir is not None:\r\n                save_dir = trainer.loggers[0].save_dir\r\n            else:\r\n                save_dir = trainer.default_root_dir\r\n            name = trainer.loggers[0].name\r\n            version = trainer.loggers[0].version\r\n            version = version if isinstance(version, str) else f\"version_{version}\"\r\n            ckpt_path = os.path.join(save_dir, str(name), version, \"checkpoints\")\r\n        else:\r\n            ckpt_path = os.path.join(trainer.default_root_dir, \"checkpoints\")\r\n\r\n        return ckpt_path", "language": "python", "code": "def __resolve_ckpt_dir(self, trainer: \"pl.Trainer\") -> _PATH:\r\n        \"\"\"Determines model checkpoint save directory at runtime. Reference attributes from the trainer's logger to\r\n        determine where to save checkpoints. The path for saving weights is set in this priority:\r\n\r\n        1.  The ``ModelCheckpoint``'s ``dirpath`` if passed in\r\n        2.  The ``Logger``'s ``log_dir`` if the trainer has loggers\r\n        3.  The ``Trainer``'s ``default_root_dir`` if the trainer has no loggers\r\n\r\n        The path gets extended with subdirectory \"checkpoints\".\r\n\r\n        \"\"\"\r\n        if self.dirpath is not None:\r\n            return self.dirpath\r\n\r\n        if len(trainer.loggers) > 0:\r\n            if trainer.loggers[0].save_dir is not None:\r\n                save_dir = trainer.loggers[0].save_dir\r\n            else:\r\n                save_dir = trainer.default_root_dir\r\n            name = trainer.loggers[0].name\r\n            version = trainer.loggers[0].version\r\n            version = version if isinstance(version, str) else f\"version_{version}\"\r\n            ckpt_path = os.path.join(save_dir, str(name), version, \"checkpoints\")\r\n        else:\r\n            ckpt_path = os.path.join(trainer.default_root_dir, \"checkpoints\")\r\n\r\n        return ckpt_path", "code_tokens": ["def", "__resolve_ckpt_dir", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "_PATH", ":", "STRING", "if", "self", ".", "dirpath", "is", "not", "None", ":", "return", "self", ".", "dirpath", "if", "len", "(", "trainer", ".", "loggers", ")", ">", "0", ":", "if", "trainer", ".", "loggers", "[", "0", "]", ".", "save_dir", "is", "not", "None", ":", "save_dir", "=", "trainer", ".", "loggers", "[", "0", "]", ".", "save_dir", "else", ":", "save_dir", "=", "trainer", ".", "default_root_dir", "name", "=", "trainer", ".", "loggers", "[", "0", "]", ".", "name", "version", "=", "trainer", ".", "loggers", "[", "0", "]", ".", "version", "version", "=", "version", "if", "isinstance", "(", "version", ",", "str", ")", "else", "fSTRING", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "str", "(", "name", ")", ",", "version", ",", "STRING", ")", "else", ":", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "trainer", ".", "default_root_dir", ",", "STRING", ")", "return", "ckpt_path"], "docstring": "short circuit if dirpath was passed to ModelCheckpoint if no loggers, use default_root_dir", "docstring_tokens": ["short", "circuit", "if", "dirpath", "was", "passed", "to", "modelcheckpoint", "if", "no", "loggers", "use", "default_root_dir"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\model_checkpoint.py", "start_line": 712, "end_line": 740, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\pruning.py", "func_name": "function_103", "original_string": "def __init__(\r\n        self,\r\n        pruning_fn: Union[Callable, str],\r\n        parameters_to_prune: _PARAM_LIST = (),\r\n        parameter_names: Optional[list[str]] = None,\r\n        use_global_unstructured: bool = True,\r\n        amount: Union[int, float, Callable[[int], Union[int, float]]] = 0.5,\r\n        apply_pruning: Union[bool, Callable[[int], bool]] = True,\r\n        make_pruning_permanent: bool = True,\r\n        use_lottery_ticket_hypothesis: Union[bool, Callable[[int], bool]] = True,\r\n        resample_parameters: bool = False,\r\n        pruning_dim: Optional[int] = None,\r\n        pruning_norm: Optional[int] = None,\r\n        verbose: int = 0,\r\n        prune_on_train_epoch_end: bool = True,\r\n    ) -> None:\r\n        \"\"\"Model pruning Callback, using PyTorch's prune utilities. This callback is responsible of pruning networks\r\n        parameters during training.\r\n\r\n        To learn more about pruning with PyTorch, please take a look at\r\n        `this tutorial <https://pytorch.org/tutorials/intermediate/pruning_tutorial.html>`_.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        .. code-block:: python\r\n\r\n            parameters_to_prune = [(model.mlp_1, \"weight\"), (model.mlp_2, \"weight\")]\r\n\r\n            trainer = Trainer(\r\n                callbacks=[\r\n                    ModelPruning(\r\n                        pruning_fn=\"l1_unstructured\",\r\n                        parameters_to_prune=parameters_to_prune,\r\n                        amount=0.01,\r\n                        use_global_unstructured=True,\r\n                    )\r\n                ]\r\n            )\r\n\r\n        When ``parameters_to_prune`` is ``None``, ``parameters_to_prune`` will contain all parameters from the model.\r\n        The user can override ``filter_parameters_to_prune`` to filter any ``nn.Module`` to be pruned.\r\n\r\n        Args:\r\n\r\n            pruning_fn: Function from torch.nn.utils.prune module or your own PyTorch ``BasePruningMethod`` subclass.\r\n                Can also be string e.g. `\"l1_unstructured\"`. See pytorch docs for more details.\r\n\r\n            parameters_to_prune: List of tuples ``(nn.Module, \"parameter_name_string\")``.\r\n\r\n            parameter_names: List of parameter names to be pruned from the nn.Module.\r\n                Can either be ``\"weight\"`` or ``\"bias\"``.\r\n\r\n            use_global_unstructured: Whether to apply pruning globally on the model.\r\n                If ``parameters_to_prune`` is provided, global unstructured will be restricted on them.\r\n\r\n            amount: Quantity of parameters to prune:\r\n\r\n                - ``float``. Between 0.0 and 1.0. Represents the fraction of parameters to prune.\r\n                - ``int``. Represents the absolute number of parameters to prune.\r\n                - ``Callable``. For dynamic values. Will be called every epoch. Should return a value.\r\n\r\n            apply_pruning: Whether to apply pruning.\r\n\r\n                - ``bool``. Always apply it or not.\r\n                - ``Callable[[epoch], bool]``. For dynamic values. Will be called every epoch.\r\n\r\n            make_pruning_permanent: Whether to remove all reparameterization pre-hooks and apply masks\r\n                when training ends or the model is saved.\r\n\r\n            use_lottery_ticket_hypothesis: See `The lottery ticket hypothesis <https://arxiv.org/abs/1803.03635>`_:\r\n\r\n                - ``bool``. Whether to apply it or not.\r\n                - ``Callable[[epoch], bool]``. For dynamic values. Will be called every epoch.\r\n\r\n            resample_parameters: Used with ``use_lottery_ticket_hypothesis``. If True, the model parameters will\r\n                be resampled, otherwise, the exact original parameters will be used.\r\n\r\n            pruning_dim: If you are using a structured pruning method you need to specify the dimension.\r\n\r\n            pruning_norm: If you are using ``ln_structured`` you need to specify the norm.\r\n\r\n            verbose: Verbosity level. 0 to disable, 1 to log overall sparsity, 2 to log per-layer sparsity\r\n\r\n            prune_on_train_epoch_end: whether to apply pruning at the end of the training epoch.\r\n                If this is ``False``, then the check runs at the end of the validation epoch.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If ``parameter_names`` is neither ``\"weight\"`` nor ``\"bias\"``,\r\n                if the provided ``pruning_fn`` is not supported,\r\n                if ``pruning_dim`` is not provided when ``\"unstructured\"``,\r\n                if ``pruning_norm`` is not provided when ``\"ln_structured\"``,\r\n                if ``pruning_fn`` is neither ``str`` nor :class:`torch.nn.utils.prune.BasePruningMethod`, or\r\n                if ``amount`` is none of ``int``, ``float`` and ``Callable``.\r\n\r\n        \"\"\"\r\n\r\n        self._use_global_unstructured = use_global_unstructured\r\n        self._parameters_to_prune = parameters_to_prune\r\n        self._use_lottery_ticket_hypothesis = use_lottery_ticket_hypothesis\r\n        self._resample_parameters = resample_parameters\r\n        self._prune_on_train_epoch_end = prune_on_train_epoch_end\r\n        self._parameter_names = parameter_names or self.PARAMETER_NAMES\r\n        self._global_kwargs: dict[str, Any] = {}\r\n        self._original_layers: Optional[dict[int, _LayerRef]] = None\r\n        self._pruning_method_name: Optional[str] = None\r\n\r\n        for name in self._parameter_names:\r\n            if name not in self.PARAMETER_NAMES:\r\n                raise MisconfigurationException(\r\n                    f\"The provided `parameter_names` name: {name} isn't in {self.PARAMETER_NAMES}\"\r\n                )\r\n\r\n        if isinstance(pruning_fn, str):\r\n            pruning_kwargs = {}\r\n            pruning_fn = pruning_fn.lower()\r\n            if pruning_fn not in _PYTORCH_PRUNING_FUNCTIONS:\r\n                raise MisconfigurationException(\r\n                    f\"The provided `pruning_fn` {pruning_fn} isn't available in PyTorch's\"\r\n                    f\" built-in functions: {list(_PYTORCH_PRUNING_FUNCTIONS.keys())} \"\r\n                )\r\n            if pruning_fn.endswith(\"_structured\"):\r\n                if pruning_dim is None:\r\n                    raise MisconfigurationException(\r\n                        \"When requesting `structured` pruning, the `pruning_dim` should be provided.\"\r\n                    )\r\n                if pruning_fn == \"ln_structured\":\r\n                    if pruning_norm is None:\r\n                        raise MisconfigurationException(\r\n                            \"When requesting `ln_structured` pruning, the `pruning_norm` should be provided.\"\r\n                        )\r\n                    pruning_kwargs[\"n\"] = pruning_norm\r\n                pruning_kwargs[\"dim\"] = pruning_dim\r\n            pruning_fn = self._create_pruning_fn(pruning_fn, **pruning_kwargs)\r\n        elif self._is_pruning_method(pruning_fn):\r\n            if not use_global_unstructured:\r\n                raise MisconfigurationException(\r\n                    \"PyTorch `BasePruningMethod` is currently only supported with `use_global_unstructured=True`.\"\r\n                )\r\n        else:\r\n            raise MisconfigurationException(\r\n                f\"`pruning_fn` is expected to be a str in {list(_PYTORCH_PRUNING_FUNCTIONS.keys())}\"\r\n                f\" or a PyTorch `BasePruningMethod`. Found: {pruning_fn}.\"\r\n                \" HINT: if passing a `BasePruningMethod`, pass the class, not an instance\"\r\n            )\r\n\r\n        if use_global_unstructured and pruning_fn.PRUNING_TYPE != \"unstructured\":  # type: ignore\r\n            raise MisconfigurationException(\r\n                'Only the \"unstructured\" PRUNING_TYPE is supported with `use_global_unstructured=True`.'\r\n                f\" Found method {pruning_fn} of type {pruning_fn.PRUNING_TYPE}. \"  # type: ignore[union-attr]\r\n            )\r\n\r\n        self.pruning_fn = pruning_fn\r\n        self._apply_pruning = apply_pruning\r\n        self._make_pruning_permanent = make_pruning_permanent\r\n\r\n        if not (isinstance(amount, (int, float)) or callable(amount)):\r\n            raise MisconfigurationException(\r\n                \"`amount` should be provided and be either an int, a float or Callable function.\"\r\n            )\r\n\r\n        self.amount = amount\r\n\r\n        if verbose not in (0, 1, 2):\r\n            raise MisconfigurationException(\"`verbose` must be any of (0, 1, 2)\")\r\n\r\n        self._verbose = verbose", "language": "python", "code": "def __init__(\r\n        self,\r\n        pruning_fn: Union[Callable, str],\r\n        parameters_to_prune: _PARAM_LIST = (),\r\n        parameter_names: Optional[list[str]] = None,\r\n        use_global_unstructured: bool = True,\r\n        amount: Union[int, float, Callable[[int], Union[int, float]]] = 0.5,\r\n        apply_pruning: Union[bool, Callable[[int], bool]] = True,\r\n        make_pruning_permanent: bool = True,\r\n        use_lottery_ticket_hypothesis: Union[bool, Callable[[int], bool]] = True,\r\n        resample_parameters: bool = False,\r\n        pruning_dim: Optional[int] = None,\r\n        pruning_norm: Optional[int] = None,\r\n        verbose: int = 0,\r\n        prune_on_train_epoch_end: bool = True,\r\n    ) -> None:\r\n        \"\"\"Model pruning Callback, using PyTorch's prune utilities. This callback is responsible of pruning networks\r\n        parameters during training.\r\n\r\n        To learn more about pruning with PyTorch, please take a look at\r\n        `this tutorial <https://pytorch.org/tutorials/intermediate/pruning_tutorial.html>`_.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        .. code-block:: python\r\n\r\n            parameters_to_prune = [(model.mlp_1, \"weight\"), (model.mlp_2, \"weight\")]\r\n\r\n            trainer = Trainer(\r\n                callbacks=[\r\n                    ModelPruning(\r\n                        pruning_fn=\"l1_unstructured\",\r\n                        parameters_to_prune=parameters_to_prune,\r\n                        amount=0.01,\r\n                        use_global_unstructured=True,\r\n                    )\r\n                ]\r\n            )\r\n\r\n        When ``parameters_to_prune`` is ``None``, ``parameters_to_prune`` will contain all parameters from the model.\r\n        The user can override ``filter_parameters_to_prune`` to filter any ``nn.Module`` to be pruned.\r\n\r\n        Args:\r\n\r\n            pruning_fn: Function from torch.nn.utils.prune module or your own PyTorch ``BasePruningMethod`` subclass.\r\n                Can also be string e.g. `\"l1_unstructured\"`. See pytorch docs for more details.\r\n\r\n            parameters_to_prune: List of tuples ``(nn.Module, \"parameter_name_string\")``.\r\n\r\n            parameter_names: List of parameter names to be pruned from the nn.Module.\r\n                Can either be ``\"weight\"`` or ``\"bias\"``.\r\n\r\n            use_global_unstructured: Whether to apply pruning globally on the model.\r\n                If ``parameters_to_prune`` is provided, global unstructured will be restricted on them.\r\n\r\n            amount: Quantity of parameters to prune:\r\n\r\n                - ``float``. Between 0.0 and 1.0. Represents the fraction of parameters to prune.\r\n                - ``int``. Represents the absolute number of parameters to prune.\r\n                - ``Callable``. For dynamic values. Will be called every epoch. Should return a value.\r\n\r\n            apply_pruning: Whether to apply pruning.\r\n\r\n                - ``bool``. Always apply it or not.\r\n                - ``Callable[[epoch], bool]``. For dynamic values. Will be called every epoch.\r\n\r\n            make_pruning_permanent: Whether to remove all reparameterization pre-hooks and apply masks\r\n                when training ends or the model is saved.\r\n\r\n            use_lottery_ticket_hypothesis: See `The lottery ticket hypothesis <https://arxiv.org/abs/1803.03635>`_:\r\n\r\n                - ``bool``. Whether to apply it or not.\r\n                - ``Callable[[epoch], bool]``. For dynamic values. Will be called every epoch.\r\n\r\n            resample_parameters: Used with ``use_lottery_ticket_hypothesis``. If True, the model parameters will\r\n                be resampled, otherwise, the exact original parameters will be used.\r\n\r\n            pruning_dim: If you are using a structured pruning method you need to specify the dimension.\r\n\r\n            pruning_norm: If you are using ``ln_structured`` you need to specify the norm.\r\n\r\n            verbose: Verbosity level. 0 to disable, 1 to log overall sparsity, 2 to log per-layer sparsity\r\n\r\n            prune_on_train_epoch_end: whether to apply pruning at the end of the training epoch.\r\n                If this is ``False``, then the check runs at the end of the validation epoch.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If ``parameter_names`` is neither ``\"weight\"`` nor ``\"bias\"``,\r\n                if the provided ``pruning_fn`` is not supported,\r\n                if ``pruning_dim`` is not provided when ``\"unstructured\"``,\r\n                if ``pruning_norm`` is not provided when ``\"ln_structured\"``,\r\n                if ``pruning_fn`` is neither ``str`` nor :class:`torch.nn.utils.prune.BasePruningMethod`, or\r\n                if ``amount`` is none of ``int``, ``float`` and ``Callable``.\r\n\r\n        \"\"\"\r\n\r\n        self._use_global_unstructured = use_global_unstructured\r\n        self._parameters_to_prune = parameters_to_prune\r\n        self._use_lottery_ticket_hypothesis = use_lottery_ticket_hypothesis\r\n        self._resample_parameters = resample_parameters\r\n        self._prune_on_train_epoch_end = prune_on_train_epoch_end\r\n        self._parameter_names = parameter_names or self.PARAMETER_NAMES\r\n        self._global_kwargs: dict[str, Any] = {}\r\n        self._original_layers: Optional[dict[int, _LayerRef]] = None\r\n        self._pruning_method_name: Optional[str] = None\r\n\r\n        for name in self._parameter_names:\r\n            if name not in self.PARAMETER_NAMES:\r\n                raise MisconfigurationException(\r\n                    f\"The provided `parameter_names` name: {name} isn't in {self.PARAMETER_NAMES}\"\r\n                )\r\n\r\n        if isinstance(pruning_fn, str):\r\n            pruning_kwargs = {}\r\n            pruning_fn = pruning_fn.lower()\r\n            if pruning_fn not in _PYTORCH_PRUNING_FUNCTIONS:\r\n                raise MisconfigurationException(\r\n                    f\"The provided `pruning_fn` {pruning_fn} isn't available in PyTorch's\"\r\n                    f\" built-in functions: {list(_PYTORCH_PRUNING_FUNCTIONS.keys())} \"\r\n                )\r\n            if pruning_fn.endswith(\"_structured\"):\r\n                if pruning_dim is None:\r\n                    raise MisconfigurationException(\r\n                        \"When requesting `structured` pruning, the `pruning_dim` should be provided.\"\r\n                    )\r\n                if pruning_fn == \"ln_structured\":\r\n                    if pruning_norm is None:\r\n                        raise MisconfigurationException(\r\n                            \"When requesting `ln_structured` pruning, the `pruning_norm` should be provided.\"\r\n                        )\r\n                    pruning_kwargs[\"n\"] = pruning_norm\r\n                pruning_kwargs[\"dim\"] = pruning_dim\r\n            pruning_fn = self._create_pruning_fn(pruning_fn, **pruning_kwargs)\r\n        elif self._is_pruning_method(pruning_fn):\r\n            if not use_global_unstructured:\r\n                raise MisconfigurationException(\r\n                    \"PyTorch `BasePruningMethod` is currently only supported with `use_global_unstructured=True`.\"\r\n                )\r\n        else:\r\n            raise MisconfigurationException(\r\n                f\"`pruning_fn` is expected to be a str in {list(_PYTORCH_PRUNING_FUNCTIONS.keys())}\"\r\n                f\" or a PyTorch `BasePruningMethod`. Found: {pruning_fn}.\"\r\n                \" HINT: if passing a `BasePruningMethod`, pass the class, not an instance\"\r\n            )\r\n\r\n        if use_global_unstructured and pruning_fn.PRUNING_TYPE != \"unstructured\":  # type: ignore\r\n            raise MisconfigurationException(\r\n                'Only the \"unstructured\" PRUNING_TYPE is supported with `use_global_unstructured=True`.'\r\n                f\" Found method {pruning_fn} of type {pruning_fn.PRUNING_TYPE}. \"  # type: ignore[union-attr]\r\n            )\r\n\r\n        self.pruning_fn = pruning_fn\r\n        self._apply_pruning = apply_pruning\r\n        self._make_pruning_permanent = make_pruning_permanent\r\n\r\n        if not (isinstance(amount, (int, float)) or callable(amount)):\r\n            raise MisconfigurationException(\r\n                \"`amount` should be provided and be either an int, a float or Callable function.\"\r\n            )\r\n\r\n        self.amount = amount\r\n\r\n        if verbose not in (0, 1, 2):\r\n            raise MisconfigurationException(\"`verbose` must be any of (0, 1, 2)\")\r\n\r\n        self._verbose = verbose", "code_tokens": ["def", "__init__", "(", "self", ",", "pruning_fn", ":", "Union", "[", "Callable", ",", "str", "]", ",", "parameters_to_prune", ":", "_PARAM_LIST", "=", "(", ")", ",", "parameter_names", ":", "Optional", "[", "list", "[", "str", "]", "]", "=", "None", ",", "use_global_unstructured", ":", "bool", "=", "True", ",", "amount", ":", "Union", "[", "int", ",", "float", ",", "Callable", "[", "[", "int", "]", ",", "Union", "[", "int", ",", "float", "]", "]", "]", "=", "0", ".", "5", ",", "apply_pruning", ":", "Union", "[", "bool", ",", "Callable", "[", "[", "int", "]", ",", "bool", "]", "]", "=", "True", ",", "make_pruning_permanent", ":", "bool", "=", "True", ",", "use_lottery_ticket_hypothesis", ":", "Union", "[", "bool", ",", "Callable", "[", "[", "int", "]", ",", "bool", "]", "]", "=", "True", ",", "resample_parameters", ":", "bool", "=", "False", ",", "pruning_dim", ":", "Optional", "[", "int", "]", "=", "None", ",", "pruning_norm", ":", "Optional", "[", "int", "]", "=", "None", ",", "verbose", ":", "int", "=", "0", ",", "prune_on_train_epoch_end", ":", "bool", "=", "True", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "_use_global_unstructured", "=", "use_global_unstructured", "self", ".", "_parameters_to_prune", "=", "parameters_to_prune", "self", ".", "_use_lottery_ticket_hypothesis", "=", "use_lottery_ticket_hypothesis", "self", ".", "_resample_parameters", "=", "resample_parameters", "self", ".", "_prune_on_train_epoch_end", "=", "prune_on_train_epoch_end", "self", ".", "_parameter_names", "=", "parameter_names", "or", "self", ".", "PARAMETER_NAMES", "self", ".", "_global_kwargs", ":", "dict", "[", "str", ",", "Any", "]", "=", "{", "}", "self", ".", "_original_layers", ":", "Optional", "[", "dict", "[", "int", ",", "_LayerRef", "]", "]", "=", "None", "self", ".", "_pruning_method_name", ":", "Optional", "[", "str", "]", "=", "None", "for", "name", "in", "self", ".", "_parameter_names", ":", "if", "name", "not", "in", "self", ".", "PARAMETER_NAMES", ":", "raise", "MisconfigurationException", "(", "fSTRING", ")", "if", "isinstance", "(", "pruning_fn", ",", "str", ")", ":", "pruning_kwargs", "=", "{", "}", "pruning_fn", "=", "pruning_fn", ".", "lower", "(", ")", "if", "pruning_fn", "not", "in", "_PYTORCH_PRUNING_FUNCTIONS", ":", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", ")", "if", "pruning_fn", ".", "endswith", "(", "STRING", ")", ":", "if", "pruning_dim", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "if", "pruning_fn", "=", "=", "STRING", ":", "if", "pruning_norm", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "pruning_kwargs", "[", "STRING", "]", "=", "pruning_norm", "pruning_kwargs", "[", "STRING", "]", "=", "pruning_dim", "pruning_fn", "=", "self", ".", "_create_pruning_fn", "(", "pruning_fn", ",", "*", "*", "pruning_kwargs", ")", "elif", "self", ".", "_is_pruning_method", "(", "pruning_fn", ")", ":", "if", "not", "use_global_unstructured", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "else", ":", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", "STRING", ")", "if", "use_global_unstructured", "and", "pruning_fn", ".", "PRUNING_TYPE", "!", "=", "STRING", ":", "#", "type", ":", "ignore", "raise", "MisconfigurationException", "(", "STRING", "fSTRING", "#", "type", ":", "ignore", "[", "union", "-", "attr", "]", ")", "self", ".", "pruning_fn", "=", "pruning_fn", "self", ".", "_apply_pruning", "=", "apply_pruning", "self", ".", "_make_pruning_permanent", "=", "make_pruning_permanent", "if", "not", "(", "isinstance", "(", "amount", ",", "(", "int", ",", "float", ")", ")", "or", "callable", "(", "amount", ")", ")", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "self", ".", "amount", "=", "amount", "if", "verbose", "not", "in", "(", "0", ",", "1", ",", "2", ")", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "self", ".", "_verbose", "=", "verbose"], "docstring": "need to ignore typing here since pytorch base class does not define the PRUNING_TYPE attribute", "docstring_tokens": ["need", "to", "ignore", "typing", "here", "since", "pytorch", "base", "class", "does", "not", "define", "the", "pruning_type", "attribute"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\pruning.py", "start_line": 65, "end_line": 232, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\pruning.py", "func_name": "function_104", "original_string": "def _create_pruning_fn(self, pruning_fn: str, **kwargs: Any) -> Union[Callable, pytorch_prune.BasePruningMethod]:\r\n        \"\"\"This function takes `pruning_fn`, a function name.\r\n\r\n        IF use_global_unstructured, pruning_fn will be resolved into its associated ``PyTorch BasePruningMethod`` ELSE,\r\n        pruning_fn will be resolved into its function counterpart from `torch.nn.utils.prune`.\r\n\r\n        \"\"\"\r\n        pruning_meth = (\r\n            _PYTORCH_PRUNING_METHOD[pruning_fn]\r\n            if self._use_global_unstructured\r\n            else _PYTORCH_PRUNING_FUNCTIONS[pruning_fn]\r\n        )\r\n        assert callable(pruning_meth), \"Selected pruning method is not callable\"\r\n        if self._use_global_unstructured:\r\n            self._global_kwargs = kwargs\r\n        self._pruning_method_name = pruning_meth.__name__\r\n        if self._use_global_unstructured:\r\n            return pruning_meth\r\n        return ModelPruning._wrap_pruning_fn(pruning_meth, **kwargs)", "language": "python", "code": "def _create_pruning_fn(self, pruning_fn: str, **kwargs: Any) -> Union[Callable, pytorch_prune.BasePruningMethod]:\r\n        \"\"\"This function takes `pruning_fn`, a function name.\r\n\r\n        IF use_global_unstructured, pruning_fn will be resolved into its associated ``PyTorch BasePruningMethod`` ELSE,\r\n        pruning_fn will be resolved into its function counterpart from `torch.nn.utils.prune`.\r\n\r\n        \"\"\"\r\n        pruning_meth = (\r\n            _PYTORCH_PRUNING_METHOD[pruning_fn]\r\n            if self._use_global_unstructured\r\n            else _PYTORCH_PRUNING_FUNCTIONS[pruning_fn]\r\n        )\r\n        assert callable(pruning_meth), \"Selected pruning method is not callable\"\r\n        if self._use_global_unstructured:\r\n            self._global_kwargs = kwargs\r\n        self._pruning_method_name = pruning_meth.__name__\r\n        if self._use_global_unstructured:\r\n            return pruning_meth\r\n        return ModelPruning._wrap_pruning_fn(pruning_meth, **kwargs)", "code_tokens": ["def", "_create_pruning_fn", "(", "self", ",", "pruning_fn", ":", "str", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Union", "[", "Callable", ",", "pytorch_prune", ".", "BasePruningMethod", "]", ":", "STRING", "pruning_meth", "=", "(", "_PYTORCH_PRUNING_METHOD", "[", "pruning_fn", "]", "if", "self", ".", "_use_global_unstructured", "else", "_PYTORCH_PRUNING_FUNCTIONS", "[", "pruning_fn", "]", ")", "assert", "callable", "(", "pruning_meth", ")", ",", "STRING", "if", "self", ".", "_use_global_unstructured", ":", "self", ".", "_global_kwargs", "=", "kwargs", "self", ".", "_pruning_method_name", "=", "pruning_meth", ".", "__name__", "if", "self", ".", "_use_global_unstructured", ":", "return", "pruning_meth", "return", "ModelPruning", ".", "_wrap_pruning_fn", "(", "pruning_meth", ",", "*", "*", "kwargs", ")"], "docstring": "save the function __name__ now because partial does not include it and there are issues setting the attribute manually in ddp.", "docstring_tokens": ["save", "the", "function", "__name__", "now", "because", "partial", "does", "not", "include", "it", "and", "there", "are", "issues", "setting", "the", "attribute", "manually", "in", "ddp"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\pruning.py", "start_line": 238, "end_line": 258, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "func_name": "function_105", "original_string": "def setup(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", stage: str) -> None:\r\n        \"\"\"Called when fit, validate, test, predict, or tune begins.\r\n\r\n        Creates an :class:`AveragedModel` when fit begins.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            stage: The :class:`~lightning.pytorch.trainer.trainer.Trainer` state.\r\n\r\n        \"\"\"\r\n        if stage == \"fit\":\r\n            device = self._device or pl_module.device\r\n\r\n            if is_overridden(\"configure_model\", pl_module):\r\n                rank_zero_warn(\r\n                    \"You're using the WeightAveraging callback with a model that overrides the configure_model \"\r\n                    \"callback. WeightAveraging doesn't support sharding model layers, so you may run out of memory.\"\r\n                )\r\n                pl_module.configure_model()\r\n\r\n            self._average_model = AveragedModel(\r\n                model=pl_module, device=device, use_buffers=self._use_buffers, **self._kwargs\r\n            )", "language": "python", "code": "def setup(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", stage: str) -> None:\r\n        \"\"\"Called when fit, validate, test, predict, or tune begins.\r\n\r\n        Creates an :class:`AveragedModel` when fit begins.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            stage: The :class:`~lightning.pytorch.trainer.trainer.Trainer` state.\r\n\r\n        \"\"\"\r\n        if stage == \"fit\":\r\n            device = self._device or pl_module.device\r\n\r\n            if is_overridden(\"configure_model\", pl_module):\r\n                rank_zero_warn(\r\n                    \"You're using the WeightAveraging callback with a model that overrides the configure_model \"\r\n                    \"callback. WeightAveraging doesn't support sharding model layers, so you may run out of memory.\"\r\n                )\r\n                pl_module.configure_model()\r\n\r\n            self._average_model = AveragedModel(\r\n                model=pl_module, device=device, use_buffers=self._use_buffers, **self._kwargs\r\n            )", "code_tokens": ["def", "setup", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "stage", ":", "str", ")", "-", ">", "None", ":", "STRING", "if", "stage", "=", "=", "STRING", ":", "device", "=", "self", ".", "_device", "or", "pl_module", ".", "device", "if", "is_overridden", "(", "STRING", ",", "pl_module", ")", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "pl_module", ".", "configure_model", "(", ")", "self", ".", "_average_model", "=", "AveragedModel", "(", "model", "=", "pl_module", ",", "device", "=", "device", ",", "use_buffers", "=", "self", ".", "_use_buffers", ",", "*", "*", "self", ".", "_kwargs", ")"], "docstring": "If the configure_model hook is overridden, call it to create the layers before constructing the AveragedModel. However, sharding will not be done and a warning will be issued.", "docstring_tokens": ["if", "the", "configure_model", "hook", "is", "overridden", "call", "it", "to", "create", "the", "layers", "before", "constructing", "the", "averagedmodel", "however", "sharding", "will", "not", "be", "done", "and", "a", "warning", "will", "be", "issued"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "start_line": 133, "end_line": 158, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "func_name": "function_106", "original_string": "def on_train_batch_end(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", outputs: STEP_OUTPUT, batch: Any, batch_idx: int\r\n    ) -> None:\r\n        \"\"\"Called when a training batch ends.\r\n\r\n        Updates the :class:`AveragedModel` parameters, if requested by ``self.should_update()``.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            outputs: Outputs from the training batch.\r\n            batch: The training batch.\r\n            batch_idx: Index of the training batch.\r\n\r\n        \"\"\"\r\n        step_idx = trainer.global_step - 1\r\n        if (trainer.global_step > self._latest_update_step) and self.should_update(step_idx=step_idx):\r\n            assert self._average_model is not None\r\n            self._average_model.update_parameters(pl_module)\r\n            self._latest_update_step = trainer.global_step", "language": "python", "code": "def on_train_batch_end(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", outputs: STEP_OUTPUT, batch: Any, batch_idx: int\r\n    ) -> None:\r\n        \"\"\"Called when a training batch ends.\r\n\r\n        Updates the :class:`AveragedModel` parameters, if requested by ``self.should_update()``.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            outputs: Outputs from the training batch.\r\n            batch: The training batch.\r\n            batch_idx: Index of the training batch.\r\n\r\n        \"\"\"\r\n        step_idx = trainer.global_step - 1\r\n        if (trainer.global_step > self._latest_update_step) and self.should_update(step_idx=step_idx):\r\n            assert self._average_model is not None\r\n            self._average_model.update_parameters(pl_module)\r\n            self._latest_update_step = trainer.global_step", "code_tokens": ["def", "on_train_batch_end", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "outputs", ":", "STEP_OUTPUT", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ")", "-", ">", "None", ":", "STRING", "step_idx", "=", "trainer", ".", "global_step", "-", "1", "if", "(", "trainer", ".", "global_step", ">", "self", ".", "_latest_update_step", ")", "and", "self", ".", "should_update", "(", "step_idx", "=", "step_idx", ")", ":", "assert", "self", ".", "_average_model", "is", "not", "None", "self", ".", "_average_model", ".", "update_parameters", "(", "pl_module", ")", "self", ".", "_latest_update_step", "=", "trainer", ".", "global_step"], "docstring": "trainer.global_step is the number of optimizer steps taken so far, i.e. 1 after the first optimizer step. To make step_idx consistent with epoch_idx, we'll pass a zero-based index.", "docstring_tokens": ["trainer", "global_step", "is", "the", "number", "of", "optimizer", "steps", "taken", "so", "far", "i", "e", "1", "after", "the", "first", "optimizer", "step", "to", "make", "step_idx", "consistent", "with", "epoch_idx", "we", "ll", "pass", "a", "zero", "based", "index"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "start_line": 161, "end_line": 182, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "func_name": "function_107", "original_string": "def on_save_checkpoint(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", checkpoint: dict[str, Any]\r\n    ) -> None:\r\n        r\"\"\"Called when saving a checkpoint.\r\n\r\n        Moves the current model state to the key ``current_model_state``, and places the average model state in\r\n        ``state_dict`` instead. Any other state variables of the ``AveragedModel`` will be saved in\r\n        ``averaging_state``.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            checkpoint: The checkpoint dictionary that will be saved.\r\n\r\n        \"\"\"\r\n        if self._average_model is None:\r\n            rank_zero_info(\r\n                \"You're using the WeightAveraging callback, but saving a checkpoint outside the 'fit' stage. The state \"\r\n                \"of the WeightAveraging callback won't be saved in the checkpoint. If training has finished, the \"\r\n                \"average model parameters will be saved to the state_dict in the checkpoint.\"\r\n            )\r\n        else:\r\n            average_model_state = self._average_model.state_dict()\r\n            checkpoint[\"current_model_state\"] = checkpoint[\"state_dict\"]\r\n            checkpoint[\"state_dict\"] = {\r\n                name[7:]: value for name, value in average_model_state.items() if name.startswith(\"module.\")\r\n            }\r\n            checkpoint[\"averaging_state\"] = {\r\n                name: value for name, value in average_model_state.items() if not name.startswith(\"module.\")\r\n            }", "language": "python", "code": "def on_save_checkpoint(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", checkpoint: dict[str, Any]\r\n    ) -> None:\r\n        r\"\"\"Called when saving a checkpoint.\r\n\r\n        Moves the current model state to the key ``current_model_state``, and places the average model state in\r\n        ``state_dict`` instead. Any other state variables of the ``AveragedModel`` will be saved in\r\n        ``averaging_state``.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            checkpoint: The checkpoint dictionary that will be saved.\r\n\r\n        \"\"\"\r\n        if self._average_model is None:\r\n            rank_zero_info(\r\n                \"You're using the WeightAveraging callback, but saving a checkpoint outside the 'fit' stage. The state \"\r\n                \"of the WeightAveraging callback won't be saved in the checkpoint. If training has finished, the \"\r\n                \"average model parameters will be saved to the state_dict in the checkpoint.\"\r\n            )\r\n        else:\r\n            average_model_state = self._average_model.state_dict()\r\n            checkpoint[\"current_model_state\"] = checkpoint[\"state_dict\"]\r\n            checkpoint[\"state_dict\"] = {\r\n                name[7:]: value for name, value in average_model_state.items() if name.startswith(\"module.\")\r\n            }\r\n            checkpoint[\"averaging_state\"] = {\r\n                name: value for name, value in average_model_state.items() if not name.startswith(\"module.\")\r\n            }", "code_tokens": ["def", "on_save_checkpoint", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "rSTRING", "if", "self", ".", "_average_model", "is", "None", ":", "rank_zero_info", "(", "STRING", "STRING", "STRING", ")", "else", ":", "average_model_state", "=", "self", ".", "_average_model", ".", "state_dict", "(", ")", "checkpoint", "[", "STRING", "]", "=", "checkpoint", "[", "STRING", "]", "checkpoint", "[", "STRING", "]", "=", "{", "name", "[", "7", ":", "]", ":", "value", "for", "name", ",", "value", "in", "average_model_state", ".", "items", "(", ")", "if", "name", ".", "startswith", "(", "STRING", ")", "}", "checkpoint", "[", "STRING", "]", "=", "{", "name", ":", "value", "for", "name", ",", "value", "in", "average_model_state", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "STRING", ")", "}"], "docstring": "Truncate the \"module.\" prefix (the first 7 characters) from the names of the variables in the AveragedModel state.", "docstring_tokens": ["truncate", "the", "module", "prefix", "the", "first", "7", "characters", "from", "the", "names", "of", "the", "variables", "in", "the", "averagedmodel", "state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "start_line": 267, "end_line": 298, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "func_name": "function_108", "original_string": "def on_load_checkpoint(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", checkpoint: dict[str, Any]\r\n    ) -> None:\r\n        r\"\"\"Called when loading a model checkpoint.\r\n\r\n        Loads the current model and the :class:`AveragedModel` parameters from the checkpoint.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            checkpoint: The full checkpoint dictionary that got loaded by the Trainer.\r\n\r\n        \"\"\"\r\n        if self._average_model is None:\r\n            rank_zero_warn(\r\n                \"You're using the WeightAveraging callback, but loading a checkpoint outside the 'fit' stage. The \"\r\n                \"WeightAveraging state cannot be restored. If you're using the checkpoint for prediction or testing, \"\r\n                \"you can ignore this warning. To disable the warning, remove the WeightAveraging callback.\"\r\n            )\r\n        elif (\"current_model_state\" in checkpoint) and (\"averaging_state\" in checkpoint):\r\n            rank_zero_info(\"Found current_model_state in the checkpoint. This will be used to initialize the model.\")\r\n            average_model_state = {\"module.\" + name: value for name, value in checkpoint[\"state_dict\"].items()}\r\n            average_model_state |= checkpoint[\"averaging_state\"]\r\n            self._average_model.load_state_dict(average_model_state)\r\n            pl_module.load_state_dict(checkpoint[\"current_model_state\"])\r\n        else:\r\n            rank_zero_warn(\r\n                \"The checkpoint was not created with WeightAveraging. Both the current and the average model will be \"\r\n                \"initialized with state_dict.\"\r\n            )\r\n            self._average_model.module.load_state_dict(deepcopy(checkpoint[\"state_dict\"]), strict=False)", "language": "python", "code": "def on_load_checkpoint(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", checkpoint: dict[str, Any]\r\n    ) -> None:\r\n        r\"\"\"Called when loading a model checkpoint.\r\n\r\n        Loads the current model and the :class:`AveragedModel` parameters from the checkpoint.\r\n\r\n        Args:\r\n            trainer: The current :class:`~lightning.pytorch.trainer.trainer.Trainer` instance.\r\n            pl_module: The current :class:`~lightning.pytorch.core.LightningModule` instance.\r\n            checkpoint: The full checkpoint dictionary that got loaded by the Trainer.\r\n\r\n        \"\"\"\r\n        if self._average_model is None:\r\n            rank_zero_warn(\r\n                \"You're using the WeightAveraging callback, but loading a checkpoint outside the 'fit' stage. The \"\r\n                \"WeightAveraging state cannot be restored. If you're using the checkpoint for prediction or testing, \"\r\n                \"you can ignore this warning. To disable the warning, remove the WeightAveraging callback.\"\r\n            )\r\n        elif (\"current_model_state\" in checkpoint) and (\"averaging_state\" in checkpoint):\r\n            rank_zero_info(\"Found current_model_state in the checkpoint. This will be used to initialize the model.\")\r\n            average_model_state = {\"module.\" + name: value for name, value in checkpoint[\"state_dict\"].items()}\r\n            average_model_state |= checkpoint[\"averaging_state\"]\r\n            self._average_model.load_state_dict(average_model_state)\r\n            pl_module.load_state_dict(checkpoint[\"current_model_state\"])\r\n        else:\r\n            rank_zero_warn(\r\n                \"The checkpoint was not created with WeightAveraging. Both the current and the average model will be \"\r\n                \"initialized with state_dict.\"\r\n            )\r\n            self._average_model.module.load_state_dict(deepcopy(checkpoint[\"state_dict\"]), strict=False)", "code_tokens": ["def", "on_load_checkpoint", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "rSTRING", "if", "self", ".", "_average_model", "is", "None", ":", "rank_zero_warn", "(", "STRING", "STRING", "STRING", ")", "elif", "(", "STRING", "in", "checkpoint", ")", "and", "(", "STRING", "in", "checkpoint", ")", ":", "rank_zero_info", "(", "STRING", ")", "average_model_state", "=", "{", "STRING", "+", "name", ":", "value", "for", "name", ",", "value", "in", "checkpoint", "[", "STRING", "]", ".", "items", "(", ")", "}", "average_model_state", "|", "=", "checkpoint", "[", "STRING", "]", "self", ".", "_average_model", ".", "load_state_dict", "(", "average_model_state", ")", "pl_module", ".", "load_state_dict", "(", "checkpoint", "[", "STRING", "]", ")", "else", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "self", ".", "_average_model", ".", "module", ".", "load_state_dict", "(", "deepcopy", "(", "checkpoint", "[", "STRING", "]", ")", ",", "strict", "=", "False", ")"], "docstring": "The current model state has already been loaded from \"state_dict\" (which contains the average model weights) at this point, so overwriting \"state_dict\" in the checkpoint dictionary makes no difference. We have to reload the model state from \"current_model_state\".", "docstring_tokens": ["the", "current", "model", "state", "has", "already", "been", "loaded", "from", "state_dict", "which", "contains", "the", "average", "model", "weights", "at", "this", "point", "so", "overwriting", "state_dict", "in", "the", "checkpoint", "dictionary", "makes", "no", "difference", "we", "have", "to", "reload", "the", "model", "state", "from", "current_model_state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\weight_averaging.py", "start_line": 301, "end_line": 334, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\progress\\progress_bar.py", "func_name": "function_109", "original_string": "def get_metrics(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\"\r\n    ) -> dict[str, Union[int, str, float, dict[str, float]]]:\r\n        r\"\"\"Combines progress bar metrics collected from the trainer with standard metrics from get_standard_metrics.\r\n        Implement this to override the items displayed in the progress bar.\r\n\r\n        Here is an example of how to override the defaults:\r\n\r\n        .. code-block:: python\r\n\r\n            def get_metrics(self, trainer, model):\r\n                items = super().get_metrics(trainer, model)\r\n                items.pop(\"v_num\", None)\r\n                return items\r\n\r\n        Return:\r\n            Dictionary with the items to be displayed in the progress bar.\r\n\r\n        \"\"\"\r\n        standard_metrics = get_standard_metrics(trainer)\r\n        pbar_metrics = trainer.progress_bar_metrics\r\n        duplicates = list(standard_metrics.keys() & pbar_metrics.keys())\r\n        if duplicates:\r\n            rank_zero_warn(\r\n                f\"The progress bar already tracks a metric with the name(s) '{', '.join(duplicates)}' and\"\r\n                f\" `self.log('{duplicates[0]}', ..., prog_bar=True)` will overwrite this value. \"\r\n                \" If this is undesired, change the name or override `get_metrics()` in the progress bar callback.\",\r\n            )\r\n\r\n        return {**standard_metrics, **pbar_metrics}", "language": "python", "code": "def get_metrics(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\"\r\n    ) -> dict[str, Union[int, str, float, dict[str, float]]]:\r\n        r\"\"\"Combines progress bar metrics collected from the trainer with standard metrics from get_standard_metrics.\r\n        Implement this to override the items displayed in the progress bar.\r\n\r\n        Here is an example of how to override the defaults:\r\n\r\n        .. code-block:: python\r\n\r\n            def get_metrics(self, trainer, model):\r\n                items = super().get_metrics(trainer, model)\r\n                items.pop(\"v_num\", None)\r\n                return items\r\n\r\n        Return:\r\n            Dictionary with the items to be displayed in the progress bar.\r\n\r\n        \"\"\"\r\n        standard_metrics = get_standard_metrics(trainer)\r\n        pbar_metrics = trainer.progress_bar_metrics\r\n        duplicates = list(standard_metrics.keys() & pbar_metrics.keys())\r\n        if duplicates:\r\n            rank_zero_warn(\r\n                f\"The progress bar already tracks a metric with the name(s) '{', '.join(duplicates)}' and\"\r\n                f\" `self.log('{duplicates[0]}', ..., prog_bar=True)` will overwrite this value. \"\r\n                \" If this is undesired, change the name or override `get_metrics()` in the progress bar callback.\",\r\n            )\r\n\r\n        return {**standard_metrics, **pbar_metrics}", "code_tokens": ["def", "get_metrics", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ")", "-", ">", "dict", "[", "str", ",", "Union", "[", "int", ",", "str", ",", "float", ",", "dict", "[", "str", ",", "float", "]", "]", "]", ":", "rSTRING", "standard_metrics", "=", "get_standard_metrics", "(", "trainer", ")", "pbar_metrics", "=", "trainer", ".", "progress_bar_metrics", "duplicates", "=", "list", "(", "standard_metrics", ".", "keys", "(", ")", "&", "pbar_metrics", ".", "keys", "(", ")", ")", "if", "duplicates", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", "STRING", ",", ")", "return", "{", "*", "*", "standard_metrics", ",", "*", "*", "pbar_metrics", "}"], "docstring": "don't show the version number", "docstring_tokens": ["don", "t", "show", "the", "version", "number"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\progress\\progress_bar.py", "start_line": 179, "end_line": 209, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\progress\\progress_bar.py", "func_name": "function_110", "original_string": "def get_standard_metrics(trainer: \"pl.Trainer\") -> dict[str, Union[int, str]]:\r\n    r\"\"\"Returns the standard metrics displayed in the progress bar. Currently, it only includes the version of the\r\n    experiment when using a logger.\r\n\r\n    .. code-block::\r\n\r\n        Epoch 1:   4%|\u258e         | 40/1095 [00:03<01:37, 10.84it/s, v_num=10]\r\n\r\n    Return:\r\n        Dictionary with the standard metrics to be displayed in the progress bar.\r\n\r\n    \"\"\"\r\n    items_dict: dict[str, Union[int, str]] = {}\r\n    if trainer.loggers:\r\n        from lightning.pytorch.loggers.utilities import _version\r\n\r\n        if (version := _version(trainer.loggers)) not in (\"\", None):\r\n            if isinstance(version, str):\r\n                version = version[-4:]\r\n            items_dict[\"v_num\"] = version\r\n\r\n    return items_dict", "language": "python", "code": "def get_standard_metrics(trainer: \"pl.Trainer\") -> dict[str, Union[int, str]]:\r\n    r\"\"\"Returns the standard metrics displayed in the progress bar. Currently, it only includes the version of the\r\n    experiment when using a logger.\r\n\r\n    .. code-block::\r\n\r\n        Epoch 1:   4%|\u258e         | 40/1095 [00:03<01:37, 10.84it/s, v_num=10]\r\n\r\n    Return:\r\n        Dictionary with the standard metrics to be displayed in the progress bar.\r\n\r\n    \"\"\"\r\n    items_dict: dict[str, Union[int, str]] = {}\r\n    if trainer.loggers:\r\n        from lightning.pytorch.loggers.utilities import _version\r\n\r\n        if (version := _version(trainer.loggers)) not in (\"\", None):\r\n            if isinstance(version, str):\r\n                version = version[-4:]\r\n            items_dict[\"v_num\"] = version\r\n\r\n    return items_dict", "code_tokens": ["def", "get_standard_metrics", "(", "trainer", ":", "STRING", ")", "-", ">", "dict", "[", "str", ",", "Union", "[", "int", ",", "str", "]", "]", ":", "rSTRING", "items_dict", ":", "dict", "[", "str", ",", "Union", "[", "int", ",", "str", "]", "]", "=", "{", "}", "if", "trainer", ".", "loggers", ":", "from", "lightning", ".", "pytorch", ".", "loggers", ".", "utilities", "import", "_version", "if", "(", "version", ":", "=", "_version", "(", "trainer", ".", "loggers", ")", ")", "not", "in", "(", "STRING", ",", "None", ")", ":", "if", "isinstance", "(", "version", ",", "str", ")", ":", "version", "=", "version", "[", "-", "4", ":", "]", "items_dict", "[", "STRING", "]", "=", "version", "return", "items_dict"], "docstring": "show last 4 places of long version strings", "docstring_tokens": ["show", "last", "4", "places", "of", "long", "version", "strings"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\progress\\progress_bar.py", "start_line": 212, "end_line": 234, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\progress\\tqdm_progress.py", "func_name": "function_111", "original_string": "def __init__(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Custom tqdm progressbar where we append 0 to floating points/strings to prevent the progress bar from\r\n        flickering.\"\"\"\r\n        super().__init__(*args, **kwargs)", "language": "python", "code": "def __init__(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Custom tqdm progressbar where we append 0 to floating points/strings to prevent the progress bar from\r\n        flickering.\"\"\"\r\n        super().__init__(*args, **kwargs)", "code_tokens": ["def", "__init__", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "*", "*", "kwargs", ")"], "docstring": "this just to make the make docs happy, otherwise it pulls docs which has some issues...", "docstring_tokens": ["this", "just", "to", "make", "the", "make", "docs", "happy", "otherwise", "it", "pulls", "docs", "which", "has", "some", "issues"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\progress\\tqdm_progress.py", "start_line": 39, "end_line": 43, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\callbacks\\progress\\tqdm_progress.py", "func_name": "function_112", "original_string": "def init_validation_tqdm(self) -> Tqdm:\r\n        \"\"\"Override this to customize the tqdm bar for validation.\"\"\"\r\n        has_main_bar = self.trainer.state.fn != \"validate\"\r\n        return Tqdm(\r\n            desc=self.validation_description,\r\n            position=(2 * self.process_position + has_main_bar),\r\n            disable=self.is_disabled,\r\n            leave=not has_main_bar,\r\n            dynamic_ncols=True,\r\n            file=sys.stdout,\r\n            bar_format=self.BAR_FORMAT,\r\n        )", "language": "python", "code": "def init_validation_tqdm(self) -> Tqdm:\r\n        \"\"\"Override this to customize the tqdm bar for validation.\"\"\"\r\n        has_main_bar = self.trainer.state.fn != \"validate\"\r\n        return Tqdm(\r\n            desc=self.validation_description,\r\n            position=(2 * self.process_position + has_main_bar),\r\n            disable=self.is_disabled,\r\n            leave=not has_main_bar,\r\n            dynamic_ncols=True,\r\n            file=sys.stdout,\r\n            bar_format=self.BAR_FORMAT,\r\n        )", "code_tokens": ["def", "init_validation_tqdm", "(", "self", ")", "-", ">", "Tqdm", ":", "STRING", "has_main_bar", "=", "self", ".", "trainer", ".", "state", ".", "fn", "!", "=", "STRING", "return", "Tqdm", "(", "desc", "=", "self", ".", "validation_description", ",", "position", "=", "(", "2", "*", "self", ".", "process_position", "+", "has_main_bar", ")", ",", "disable", "=", "self", ".", "is_disabled", ",", "leave", "=", "not", "has_main_bar", ",", "dynamic_ncols", "=", "True", ",", "file", "=", "sys", ".", "stdout", ",", "bar_format", "=", "self", ".", "BAR_FORMAT", ",", ")"], "docstring": "The train progress bar doesn't exist in `trainer.validate()`", "docstring_tokens": ["the", "train", "progress", "bar", "doesn", "t", "exist", "in", "trainer", "validate"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\callbacks\\progress\\tqdm_progress.py", "start_line": 223, "end_line": 235, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\datamodule.py", "func_name": "function_113", "original_string": "def load_from_checkpoint(\r\n        cls,\r\n        checkpoint_path: Union[_PATH, IO],\r\n        map_location: _MAP_LOCATION_TYPE = None,\r\n        hparams_file: Optional[_PATH] = None,\r\n        **kwargs: Any,\r\n    ) -> Self:\r\n        r\"\"\"Primary way of loading a datamodule from a checkpoint. When Lightning saves a checkpoint it stores the\r\n        arguments passed to ``__init__``  in the checkpoint under ``\"datamodule_hyper_parameters\"``.\r\n\r\n        Any arguments specified through \\*\\*kwargs will override args stored in ``\"datamodule_hyper_parameters\"``.\r\n\r\n        Args:\r\n            checkpoint_path: Path to checkpoint. This can also be a URL, or file-like object\r\n            map_location:\r\n                If your checkpoint saved a GPU model and you now load on CPUs\r\n                or a different number of GPUs, use this to map to the new setup.\r\n                The behaviour is the same as in :func:`torch.load`.\r\n            hparams_file: Optional path to a ``.yaml`` or ``.csv`` file with hierarchical structure\r\n                as in this example::\r\n\r\n                    dataloader:\r\n                        batch_size: 32\r\n\r\n                You most likely won't need this since Lightning will always save the hyperparameters\r\n                to the checkpoint.\r\n                However, if your checkpoint weights don't have the hyperparameters saved,\r\n                use this method to pass in a ``.yaml`` file with the hparams you'd like to use.\r\n                These will be converted into a :class:`~dict` and passed into your\r\n                :class:`LightningDataModule` for use.\r\n\r\n                If your datamodule's ``hparams`` argument is :class:`~argparse.Namespace`\r\n                and ``.yaml`` file has hierarchical structure, you need to refactor your datamodule to treat\r\n                ``hparams`` as :class:`~dict`.\r\n            \\**kwargs: Any extra keyword args needed to init the datamodule. Can also be used to override saved\r\n                hyperparameter values.\r\n\r\n        Return:\r\n            :class:`LightningDataModule` instance with loaded weights and hyperparameters (if available).\r\n\r\n        Note:\r\n            ``load_from_checkpoint`` is a **class** method. You must use your :class:`LightningDataModule`\r\n            **class** to call it instead of the :class:`LightningDataModule` instance, or a\r\n            ``TypeError`` will be raised.\r\n\r\n        Example::\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint('path/to/checkpoint.ckpt')\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                hparams_file='/path/to/hparams_file.yaml'\r\n            )\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint(\r\n                PATH,\r\n                batch_size=32,\r\n                num_workers=10,\r\n            )\r\n\r\n        \"\"\"\r\n        loaded = _load_from_checkpoint(\r\n            cls,\r\n            checkpoint_path,\r\n            map_location=map_location,\r\n            hparams_file=hparams_file,\r\n            strict=None,\r\n            **kwargs,\r\n        )\r\n        return cast(Self, loaded)", "language": "python", "code": "def load_from_checkpoint(\r\n        cls,\r\n        checkpoint_path: Union[_PATH, IO],\r\n        map_location: _MAP_LOCATION_TYPE = None,\r\n        hparams_file: Optional[_PATH] = None,\r\n        **kwargs: Any,\r\n    ) -> Self:\r\n        r\"\"\"Primary way of loading a datamodule from a checkpoint. When Lightning saves a checkpoint it stores the\r\n        arguments passed to ``__init__``  in the checkpoint under ``\"datamodule_hyper_parameters\"``.\r\n\r\n        Any arguments specified through \\*\\*kwargs will override args stored in ``\"datamodule_hyper_parameters\"``.\r\n\r\n        Args:\r\n            checkpoint_path: Path to checkpoint. This can also be a URL, or file-like object\r\n            map_location:\r\n                If your checkpoint saved a GPU model and you now load on CPUs\r\n                or a different number of GPUs, use this to map to the new setup.\r\n                The behaviour is the same as in :func:`torch.load`.\r\n            hparams_file: Optional path to a ``.yaml`` or ``.csv`` file with hierarchical structure\r\n                as in this example::\r\n\r\n                    dataloader:\r\n                        batch_size: 32\r\n\r\n                You most likely won't need this since Lightning will always save the hyperparameters\r\n                to the checkpoint.\r\n                However, if your checkpoint weights don't have the hyperparameters saved,\r\n                use this method to pass in a ``.yaml`` file with the hparams you'd like to use.\r\n                These will be converted into a :class:`~dict` and passed into your\r\n                :class:`LightningDataModule` for use.\r\n\r\n                If your datamodule's ``hparams`` argument is :class:`~argparse.Namespace`\r\n                and ``.yaml`` file has hierarchical structure, you need to refactor your datamodule to treat\r\n                ``hparams`` as :class:`~dict`.\r\n            \\**kwargs: Any extra keyword args needed to init the datamodule. Can also be used to override saved\r\n                hyperparameter values.\r\n\r\n        Return:\r\n            :class:`LightningDataModule` instance with loaded weights and hyperparameters (if available).\r\n\r\n        Note:\r\n            ``load_from_checkpoint`` is a **class** method. You must use your :class:`LightningDataModule`\r\n            **class** to call it instead of the :class:`LightningDataModule` instance, or a\r\n            ``TypeError`` will be raised.\r\n\r\n        Example::\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint('path/to/checkpoint.ckpt')\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                hparams_file='/path/to/hparams_file.yaml'\r\n            )\r\n\r\n            datamodule = MyLightningDataModule.load_from_checkpoint(\r\n                PATH,\r\n                batch_size=32,\r\n                num_workers=10,\r\n            )\r\n\r\n        \"\"\"\r\n        loaded = _load_from_checkpoint(\r\n            cls,\r\n            checkpoint_path,\r\n            map_location=map_location,\r\n            hparams_file=hparams_file,\r\n            strict=None,\r\n            **kwargs,\r\n        )\r\n        return cast(Self, loaded)", "code_tokens": ["def", "load_from_checkpoint", "(", "cls", ",", "checkpoint_path", ":", "Union", "[", "_PATH", ",", "IO", "]", ",", "map_location", ":", "_MAP_LOCATION_TYPE", "=", "None", ",", "hparams_file", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "Self", ":", "rSTRING", "loaded", "=", "_load_from_checkpoint", "(", "cls", ",", "checkpoint_path", ",", "map_location", "=", "map_location", ",", "hparams_file", "=", "hparams_file", ",", "strict", "=", "None", ",", "*", "*", "kwargs", ",", ")", "return", "cast", "(", "Self", ",", "loaded", ")"], "docstring": "load weights without mapping ... or load weights and hyperparameters from separate files. override some of the params with new values", "docstring_tokens": ["load", "weights", "without", "mapping", "or", "load", "weights", "and", "hyperparameters", "from", "separate", "files", "override", "some", "of", "the", "params", "with", "new", "values"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\datamodule.py", "start_line": 174, "end_line": 246, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\datamodule.py", "func_name": "function_114", "original_string": "def __str__(self) -> str:\r\n        \"\"\"Return a string representation of the datasets that are set up.\r\n\r\n        Returns:\r\n            A string representation of the datasets that are setup.\r\n\r\n        \"\"\"\r\n\r\n        class dataset_info:\r\n            def __init__(self, available: bool, length: str) -> None:\r\n                self.available = available\r\n                self.length = length\r\n\r\n        def retrieve_dataset_info(loader: DataLoader) -> dataset_info:\r\n            \"\"\"Helper function to compute dataset information.\"\"\"\r\n            dataset = loader.dataset\r\n            size: str = str(len(dataset)) if isinstance(dataset, Sized) else \"NA\"\r\n\r\n            return dataset_info(True, size)\r\n\r\n        def loader_info(\r\n            loader: Union[DataLoader, Iterable[DataLoader]],\r\n        ) -> Union[dataset_info, Iterable[dataset_info]]:\r\n            \"\"\"Helper function to compute dataset information.\"\"\"\r\n            return apply_to_collection(loader, DataLoader, retrieve_dataset_info)\r\n\r\n        def extract_loader_info(methods: list[tuple[str, str]]) -> dict:\r\n            \"\"\"Helper function to extract information for each dataloader method.\"\"\"\r\n            info: dict[str, Union[dataset_info, Iterable[dataset_info]]] = {}\r\n            for loader_name, func_name in methods:\r\n                loader_method = getattr(self, func_name, None)\r\n\r\n                try:\r\n                    loader = loader_method()  # type: ignore\r\n                    info[loader_name] = loader_info(loader)\r\n                except Exception:\r\n                    info[loader_name] = dataset_info(False, \"\")\r\n\r\n            return info\r\n\r\n        def format_loader_info(info: dict[str, Union[dataset_info, Iterable[dataset_info]]]) -> str:\r\n            \"\"\"Helper function to format loader information.\"\"\"\r\n            output = []\r\n            for loader_name, loader_info in info.items():\r\n                if isinstance(loader_info, dataset_info):\r\n                    loader_info_formatted = \"None\" if not loader_info.available else f\"size={loader_info.length}\"\r\n                else:\r\n                    loader_info_formatted = \" ; \".join(\r\n                        \"None\" if not loader_info_i.available else f\"{i}. size={loader_info_i.length}\"\r\n                        for i, loader_info_i in enumerate(loader_info, start=1)\r\n                    )\r\n\r\n                output.append(f\"{{{loader_name}: {loader_info_formatted}}}\")\r\n\r\n            return os.linesep.join(output)\r\n\r\n        datamodule_loader_methods: list[tuple[str, str]] = [\r\n            (\"Train dataloader\", \"train_dataloader\"),\r\n            (\"Validation dataloader\", \"val_dataloader\"),\r\n            (\"Test dataloader\", \"test_dataloader\"),\r\n            (\"Predict dataloader\", \"predict_dataloader\"),\r\n        ]\r\n\r\n        dataloader_info = extract_loader_info(datamodule_loader_methods)\r\n        dataloader_str = format_loader_info(dataloader_info)\r\n        return dataloader_str", "language": "python", "code": "def __str__(self) -> str:\r\n        \"\"\"Return a string representation of the datasets that are set up.\r\n\r\n        Returns:\r\n            A string representation of the datasets that are setup.\r\n\r\n        \"\"\"\r\n\r\n        class dataset_info:\r\n            def __init__(self, available: bool, length: str) -> None:\r\n                self.available = available\r\n                self.length = length\r\n\r\n        def retrieve_dataset_info(loader: DataLoader) -> dataset_info:\r\n            \"\"\"Helper function to compute dataset information.\"\"\"\r\n            dataset = loader.dataset\r\n            size: str = str(len(dataset)) if isinstance(dataset, Sized) else \"NA\"\r\n\r\n            return dataset_info(True, size)\r\n\r\n        def loader_info(\r\n            loader: Union[DataLoader, Iterable[DataLoader]],\r\n        ) -> Union[dataset_info, Iterable[dataset_info]]:\r\n            \"\"\"Helper function to compute dataset information.\"\"\"\r\n            return apply_to_collection(loader, DataLoader, retrieve_dataset_info)\r\n\r\n        def extract_loader_info(methods: list[tuple[str, str]]) -> dict:\r\n            \"\"\"Helper function to extract information for each dataloader method.\"\"\"\r\n            info: dict[str, Union[dataset_info, Iterable[dataset_info]]] = {}\r\n            for loader_name, func_name in methods:\r\n                loader_method = getattr(self, func_name, None)\r\n\r\n                try:\r\n                    loader = loader_method()  # type: ignore\r\n                    info[loader_name] = loader_info(loader)\r\n                except Exception:\r\n                    info[loader_name] = dataset_info(False, \"\")\r\n\r\n            return info\r\n\r\n        def format_loader_info(info: dict[str, Union[dataset_info, Iterable[dataset_info]]]) -> str:\r\n            \"\"\"Helper function to format loader information.\"\"\"\r\n            output = []\r\n            for loader_name, loader_info in info.items():\r\n                if isinstance(loader_info, dataset_info):\r\n                    loader_info_formatted = \"None\" if not loader_info.available else f\"size={loader_info.length}\"\r\n                else:\r\n                    loader_info_formatted = \" ; \".join(\r\n                        \"None\" if not loader_info_i.available else f\"{i}. size={loader_info_i.length}\"\r\n                        for i, loader_info_i in enumerate(loader_info, start=1)\r\n                    )\r\n\r\n                output.append(f\"{{{loader_name}: {loader_info_formatted}}}\")\r\n\r\n            return os.linesep.join(output)\r\n\r\n        datamodule_loader_methods: list[tuple[str, str]] = [\r\n            (\"Train dataloader\", \"train_dataloader\"),\r\n            (\"Validation dataloader\", \"val_dataloader\"),\r\n            (\"Test dataloader\", \"test_dataloader\"),\r\n            (\"Predict dataloader\", \"predict_dataloader\"),\r\n        ]\r\n\r\n        dataloader_info = extract_loader_info(datamodule_loader_methods)\r\n        dataloader_str = format_loader_info(dataloader_info)\r\n        return dataloader_str", "code_tokens": ["def", "__str__", "(", "self", ")", "-", ">", "str", ":", "STRING", "class", "dataset_info", ":", "def", "__init__", "(", "self", ",", "available", ":", "bool", ",", "length", ":", "str", ")", "-", ">", "None", ":", "self", ".", "available", "=", "available", "self", ".", "length", "=", "length", "def", "retrieve_dataset_info", "(", "loader", ":", "DataLoader", ")", "-", ">", "dataset_info", ":", "STRING", "dataset", "=", "loader", ".", "dataset", "size", ":", "str", "=", "str", "(", "len", "(", "dataset", ")", ")", "if", "isinstance", "(", "dataset", ",", "Sized", ")", "else", "STRING", "return", "dataset_info", "(", "True", ",", "size", ")", "def", "loader_info", "(", "loader", ":", "Union", "[", "DataLoader", ",", "Iterable", "[", "DataLoader", "]", "]", ",", ")", "-", ">", "Union", "[", "dataset_info", ",", "Iterable", "[", "dataset_info", "]", "]", ":", "STRING", "return", "apply_to_collection", "(", "loader", ",", "DataLoader", ",", "retrieve_dataset_info", ")", "def", "extract_loader_info", "(", "methods", ":", "list", "[", "tuple", "[", "str", ",", "str", "]", "]", ")", "-", ">", "dict", ":", "STRING", "info", ":", "dict", "[", "str", ",", "Union", "[", "dataset_info", ",", "Iterable", "[", "dataset_info", "]", "]", "]", "=", "{", "}", "for", "loader_name", ",", "func_name", "in", "methods", ":", "loader_method", "=", "getattr", "(", "self", ",", "func_name", ",", "None", ")", "try", ":", "loader", "=", "loader_method", "(", ")", "#", "type", ":", "ignore", "info", "[", "loader_name", "]", "=", "loader_info", "(", "loader", ")", "except", "Exception", ":", "info", "[", "loader_name", "]", "=", "dataset_info", "(", "False", ",", "STRING", ")", "return", "info", "def", "format_loader_info", "(", "info", ":", "dict", "[", "str", ",", "Union", "[", "dataset_info", ",", "Iterable", "[", "dataset_info", "]", "]", "]", ")", "-", ">", "str", ":", "STRING", "output", "=", "[", "]", "for", "loader_name", ",", "loader_info", "in", "info", ".", "items", "(", ")", ":", "if", "isinstance", "(", "loader_info", ",", "dataset_info", ")", ":", "loader_info_formatted", "=", "STRING", "if", "not", "loader_info", ".", "available", "else", "fSTRING", "else", ":", "loader_info_formatted", "=", "STRING", ".", "join", "(", "STRING", "if", "not", "loader_info_i", ".", "available", "else", "fSTRING", "for", "i", ",", "loader_info_i", "in", "enumerate", "(", "loader_info", ",", "start", "=", "1", ")", ")", "output", ".", "append", "(", "fSTRING", ")", "return", "os", ".", "linesep", ".", "join", "(", "output", ")", "datamodule_loader_methods", ":", "list", "[", "tuple", "[", "str", ",", "str", "]", "]", "=", "[", "(", "STRING", ",", "STRING", ")", ",", "(", "STRING", ",", "STRING", ")", ",", "(", "STRING", ",", "STRING", ")", ",", "(", "STRING", ",", "STRING", ")", ",", "]", "dataloader_info", "=", "extract_loader_info", "(", "datamodule_loader_methods", ")", "dataloader_str", "=", "format_loader_info", "(", "dataloader_info", ")", "return", "dataloader_str"], "docstring": "Single dataset Iterable of datasets Available dataloader methods Retrieve information for each dataloader method Format the information", "docstring_tokens": ["single", "dataset", "iterable", "of", "datasets", "available", "dataloader", "methods", "retrieve", "information", "for", "each", "dataloader", "method", "format", "the", "information"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\datamodule.py", "start_line": 248, "end_line": 318, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\datamodule.py", "func_name": "function_115", "original_string": "def format_loader_info(info: dict[str, Union[dataset_info, Iterable[dataset_info]]]) -> str:\r\n            \"\"\"Helper function to format loader information.\"\"\"\r\n            output = []\r\n            for loader_name, loader_info in info.items():\r\n                if isinstance(loader_info, dataset_info):\r\n                    loader_info_formatted = \"None\" if not loader_info.available else f\"size={loader_info.length}\"\r\n                else:\r\n                    loader_info_formatted = \" ; \".join(\r\n                        \"None\" if not loader_info_i.available else f\"{i}. size={loader_info_i.length}\"\r\n                        for i, loader_info_i in enumerate(loader_info, start=1)\r\n                    )\r\n\r\n                output.append(f\"{{{loader_name}: {loader_info_formatted}}}\")\r\n\r\n            return os.linesep.join(output)", "language": "python", "code": "def format_loader_info(info: dict[str, Union[dataset_info, Iterable[dataset_info]]]) -> str:\r\n            \"\"\"Helper function to format loader information.\"\"\"\r\n            output = []\r\n            for loader_name, loader_info in info.items():\r\n                if isinstance(loader_info, dataset_info):\r\n                    loader_info_formatted = \"None\" if not loader_info.available else f\"size={loader_info.length}\"\r\n                else:\r\n                    loader_info_formatted = \" ; \".join(\r\n                        \"None\" if not loader_info_i.available else f\"{i}. size={loader_info_i.length}\"\r\n                        for i, loader_info_i in enumerate(loader_info, start=1)\r\n                    )\r\n\r\n                output.append(f\"{{{loader_name}: {loader_info_formatted}}}\")\r\n\r\n            return os.linesep.join(output)", "code_tokens": ["def", "format_loader_info", "(", "info", ":", "dict", "[", "str", ",", "Union", "[", "dataset_info", ",", "Iterable", "[", "dataset_info", "]", "]", "]", ")", "-", ">", "str", ":", "STRING", "output", "=", "[", "]", "for", "loader_name", ",", "loader_info", "in", "info", ".", "items", "(", ")", ":", "if", "isinstance", "(", "loader_info", ",", "dataset_info", ")", ":", "loader_info_formatted", "=", "STRING", "if", "not", "loader_info", ".", "available", "else", "fSTRING", "else", ":", "loader_info_formatted", "=", "STRING", ".", "join", "(", "STRING", "if", "not", "loader_info_i", ".", "available", "else", "fSTRING", "for", "i", ",", "loader_info_i", "in", "enumerate", "(", "loader_info", ",", "start", "=", "1", ")", ")", "output", ".", "append", "(", "fSTRING", ")", "return", "os", ".", "linesep", ".", "join", "(", "output", ")"], "docstring": "Single dataset Iterable of datasets", "docstring_tokens": ["single", "dataset", "iterable", "of", "datasets"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\datamodule.py", "start_line": 288, "end_line": 304, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_116", "original_string": "def on_validation_model_train(self) -> None:\r\n        \"\"\"Called when the validation loop ends.\r\n\r\n        The validation loop by default restores the `training` mode of the LightningModule to what it was before\r\n        starting validation. Override this hook to change the behavior. See also\r\n        :meth:`~lightning.pytorch.core.hooks.ModelHooks.on_validation_model_eval`.\r\n\r\n        \"\"\"\r\n        self.trainer.model.train()", "language": "python", "code": "def on_validation_model_train(self) -> None:\r\n        \"\"\"Called when the validation loop ends.\r\n\r\n        The validation loop by default restores the `training` mode of the LightningModule to what it was before\r\n        starting validation. Override this hook to change the behavior. See also\r\n        :meth:`~lightning.pytorch.core.hooks.ModelHooks.on_validation_model_eval`.\r\n\r\n        \"\"\"\r\n        self.trainer.model.train()", "code_tokens": ["def", "on_validation_model_train", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "trainer", ".", "model", ".", "train", "(", ")"], "docstring": "The loop won't call this hook unless it is overridden. The line below is here in case the user calls super().", "docstring_tokens": ["the", "loop", "won", "t", "call", "this", "hook", "unless", "it", "is", "overridden", "the", "line", "below", "is", "here", "in", "case", "the", "user", "calls", "super"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 170, "end_line": 179, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_117", "original_string": "def on_test_model_train(self) -> None:\r\n        \"\"\"Called when the test loop ends.\r\n\r\n        The test loop by default restores the `training` mode of the LightningModule to what it was before\r\n        starting testing. Override this hook to change the behavior. See also\r\n        :meth:`~lightning.pytorch.core.hooks.ModelHooks.on_test_model_eval`.\r\n\r\n        \"\"\"\r\n        self.trainer.model.train()", "language": "python", "code": "def on_test_model_train(self) -> None:\r\n        \"\"\"Called when the test loop ends.\r\n\r\n        The test loop by default restores the `training` mode of the LightningModule to what it was before\r\n        starting testing. Override this hook to change the behavior. See also\r\n        :meth:`~lightning.pytorch.core.hooks.ModelHooks.on_test_model_eval`.\r\n\r\n        \"\"\"\r\n        self.trainer.model.train()", "code_tokens": ["def", "on_test_model_train", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "trainer", ".", "model", ".", "train", "(", ")"], "docstring": "The loop won't call this hook unless it is overridden. The line below is here in case the user calls super().", "docstring_tokens": ["the", "loop", "won", "t", "call", "this", "hook", "unless", "it", "is", "overridden", "the", "line", "below", "is", "here", "in", "case", "the", "user", "calls", "super"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 190, "end_line": 199, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_118", "original_string": "def on_train_epoch_end(self) -> None:\r\n        \"\"\"Called in the training loop at the very end of the epoch.\r\n\r\n        To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the\r\n        :class:`~lightning.pytorch.LightningModule` and access them in this hook:\r\n\r\n        .. code-block:: python\r\n\r\n            class MyLightningModule(L.LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.training_step_outputs = []\r\n\r\n                def training_step(self):\r\n                    loss = ...\r\n                    self.training_step_outputs.append(loss)\r\n                    return loss\r\n\r\n                def on_train_epoch_end(self):\r\n                    epoch_mean = torch.stack(self.training_step_outputs).mean()\r\n                    self.log(\"training_epoch_mean\", epoch_mean)\r\n                    self.training_step_outputs.clear()\r\n\r\n        \"\"\"", "language": "python", "code": "def on_train_epoch_end(self) -> None:\r\n        \"\"\"Called in the training loop at the very end of the epoch.\r\n\r\n        To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the\r\n        :class:`~lightning.pytorch.LightningModule` and access them in this hook:\r\n\r\n        .. code-block:: python\r\n\r\n            class MyLightningModule(L.LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.training_step_outputs = []\r\n\r\n                def training_step(self):\r\n                    loss = ...\r\n                    self.training_step_outputs.append(loss)\r\n                    return loss\r\n\r\n                def on_train_epoch_end(self):\r\n                    epoch_mean = torch.stack(self.training_step_outputs).mean()\r\n                    self.log(\"training_epoch_mean\", epoch_mean)\r\n                    self.training_step_outputs.clear()\r\n\r\n        \"\"\"", "code_tokens": ["def", "on_train_epoch_end", "(", "self", ")", "-", ">", "None", ":", "STRING"], "docstring": "do something with all training_step outputs, for example: free up the memory", "docstring_tokens": ["do", "something", "with", "all", "training_step", "outputs", "for", "example", "free", "up", "the", "memory"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 213, "end_line": 238, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_119", "original_string": "def on_before_optimizer_step(self, optimizer: Optimizer) -> None:\r\n        \"\"\"Called before ``optimizer.step()``.\r\n\r\n        If using gradient accumulation, the hook is called once the gradients have been accumulated.\r\n        See: :paramref:`~lightning.pytorch.trainer.trainer.Trainer.accumulate_grad_batches`.\r\n\r\n        If using AMP, the loss will be unscaled before calling this hook.\r\n        See these `docs <https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients>`__\r\n        for more information on the scaling of gradients.\r\n\r\n        If clipping gradients, the gradients will not have been clipped yet.\r\n\r\n        Args:\r\n            optimizer: Current optimizer being used.\r\n\r\n        Example::\r\n\r\n            def on_before_optimizer_step(self, optimizer):\r\n                if self.trainer.global_step % 25 == 0:  # don't make the tf file huge\r\n                    for k, v in self.named_parameters():\r\n                        self.logger.experiment.add_histogram(\r\n                            tag=k, values=v.grad, global_step=self.trainer.global_step\r\n                        )\r\n\r\n        \"\"\"", "language": "python", "code": "def on_before_optimizer_step(self, optimizer: Optimizer) -> None:\r\n        \"\"\"Called before ``optimizer.step()``.\r\n\r\n        If using gradient accumulation, the hook is called once the gradients have been accumulated.\r\n        See: :paramref:`~lightning.pytorch.trainer.trainer.Trainer.accumulate_grad_batches`.\r\n\r\n        If using AMP, the loss will be unscaled before calling this hook.\r\n        See these `docs <https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients>`__\r\n        for more information on the scaling of gradients.\r\n\r\n        If clipping gradients, the gradients will not have been clipped yet.\r\n\r\n        Args:\r\n            optimizer: Current optimizer being used.\r\n\r\n        Example::\r\n\r\n            def on_before_optimizer_step(self, optimizer):\r\n                if self.trainer.global_step % 25 == 0:  # don't make the tf file huge\r\n                    for k, v in self.named_parameters():\r\n                        self.logger.experiment.add_histogram(\r\n                            tag=k, values=v.grad, global_step=self.trainer.global_step\r\n                        )\r\n\r\n        \"\"\"", "code_tokens": ["def", "on_before_optimizer_step", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "None", ":", "STRING"], "docstring": "example to inspect gradient information in tensorboard", "docstring_tokens": ["example", "to", "inspect", "gradient", "information", "in", "tensorboard"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 297, "end_line": 322, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_120", "original_string": "def prepare_data(self) -> None:\r\n        \"\"\"Use this to download and prepare data. Downloading and saving data with multiple processes (distributed\r\n        settings) will result in corrupted data. Lightning ensures this method is called only within a single process,\r\n        so you can safely add your downloading logic within.\r\n\r\n        .. warning:: DO NOT set state to the model (use ``setup`` instead)\r\n            since this is NOT called on every device\r\n\r\n        Example::\r\n\r\n            def prepare_data(self):\r\n                download_data()\r\n                tokenize()\r\n                etc()\r\n\r\n                self.split = data_split\r\n                self.some_state = some_other_state()\r\n\r\n        In a distributed environment, ``prepare_data`` can be called in two ways\r\n        (using :ref:`prepare_data_per_node<common/lightning_module:prepare_data_per_node>`)\r\n\r\n        1. Once per node. This is the default and is only called on LOCAL_RANK=0.\r\n        2. Once in total. Only called on GLOBAL_RANK=0.\r\n\r\n        Example::\r\n\r\n            class LitDataModule(LightningDataModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.prepare_data_per_node = True\r\n\r\n\r\n            class LitDataModule(LightningDataModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.prepare_data_per_node = False\r\n\r\n        This is called before requesting the dataloaders:\r\n\r\n        .. code-block:: python\r\n\r\n            model.prepare_data()\r\n            initialize_distributed()\r\n            model.setup(stage)\r\n            model.train_dataloader()\r\n            model.val_dataloader()\r\n            model.test_dataloader()\r\n            model.predict_dataloader()\r\n\r\n        \"\"\"", "language": "python", "code": "def prepare_data(self) -> None:\r\n        \"\"\"Use this to download and prepare data. Downloading and saving data with multiple processes (distributed\r\n        settings) will result in corrupted data. Lightning ensures this method is called only within a single process,\r\n        so you can safely add your downloading logic within.\r\n\r\n        .. warning:: DO NOT set state to the model (use ``setup`` instead)\r\n            since this is NOT called on every device\r\n\r\n        Example::\r\n\r\n            def prepare_data(self):\r\n                download_data()\r\n                tokenize()\r\n                etc()\r\n\r\n                self.split = data_split\r\n                self.some_state = some_other_state()\r\n\r\n        In a distributed environment, ``prepare_data`` can be called in two ways\r\n        (using :ref:`prepare_data_per_node<common/lightning_module:prepare_data_per_node>`)\r\n\r\n        1. Once per node. This is the default and is only called on LOCAL_RANK=0.\r\n        2. Once in total. Only called on GLOBAL_RANK=0.\r\n\r\n        Example::\r\n\r\n            class LitDataModule(LightningDataModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.prepare_data_per_node = True\r\n\r\n\r\n            class LitDataModule(LightningDataModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.prepare_data_per_node = False\r\n\r\n        This is called before requesting the dataloaders:\r\n\r\n        .. code-block:: python\r\n\r\n            model.prepare_data()\r\n            initialize_distributed()\r\n            model.setup(stage)\r\n            model.train_dataloader()\r\n            model.val_dataloader()\r\n            model.test_dataloader()\r\n            model.predict_dataloader()\r\n\r\n        \"\"\"", "code_tokens": ["def", "prepare_data", "(", "self", ")", "-", ">", "None", ":", "STRING"], "docstring": "good bad DEFAULT called once per node on LOCAL_RANK=0 of that node call on GLOBAL_RANK=0 (great for shared file systems)", "docstring_tokens": ["good", "bad", "default", "called", "once", "per", "node", "on", "local_rank", "0", "of", "that", "node", "call", "on", "global_rank", "0", "great", "for", "shared", "file", "systems"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 363, "end_line": 417, "has_examples": true, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_121", "original_string": "def setup(self, stage: str) -> None:\r\n        \"\"\"Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you\r\n        need to build models dynamically or adjust something about them. This hook is called on every process when\r\n        using DDP.\r\n\r\n        Args:\r\n            stage: either ``'fit'``, ``'validate'``, ``'test'``, or ``'predict'``\r\n\r\n        Example::\r\n\r\n            class LitModel(...):\r\n                def __init__(self):\r\n                    self.l1 = None\r\n\r\n                def prepare_data(self):\r\n                    download_data()\r\n                    tokenize()\r\n\r\n                    self.something = else\r\n\r\n                def setup(self, stage):\r\n                    data = load_data(...)\r\n                    self.l1 = nn.Linear(28, data.num_classes)\r\n\r\n        \"\"\"", "language": "python", "code": "def setup(self, stage: str) -> None:\r\n        \"\"\"Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you\r\n        need to build models dynamically or adjust something about them. This hook is called on every process when\r\n        using DDP.\r\n\r\n        Args:\r\n            stage: either ``'fit'``, ``'validate'``, ``'test'``, or ``'predict'``\r\n\r\n        Example::\r\n\r\n            class LitModel(...):\r\n                def __init__(self):\r\n                    self.l1 = None\r\n\r\n                def prepare_data(self):\r\n                    download_data()\r\n                    tokenize()\r\n\r\n                    self.something = else\r\n\r\n                def setup(self, stage):\r\n                    data = load_data(...)\r\n                    self.l1 = nn.Linear(28, data.num_classes)\r\n\r\n        \"\"\"", "code_tokens": ["def", "setup", "(", "self", ",", "stage", ":", "str", ")", "-", ">", "None", ":", "STRING"], "docstring": "don't do this", "docstring_tokens": ["don", "t", "do", "this"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 419, "end_line": 444, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_122", "original_string": "def transfer_batch_to_device(self, batch: Any, device: torch.device, dataloader_idx: int) -> Any:\r\n        \"\"\"Override this hook if your :class:`~torch.utils.data.DataLoader` returns tensors wrapped in a custom data\r\n        structure.\r\n\r\n        The data types listed below (and any arbitrary nesting of them) are supported out of the box:\r\n\r\n        - :class:`torch.Tensor` or anything that implements `.to(...)`\r\n        - :class:`list`\r\n        - :class:`dict`\r\n        - :class:`tuple`\r\n\r\n        For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).\r\n\r\n        Note:\r\n            This hook should only transfer the data and not modify it, nor should it move the data to\r\n            any other device than the one passed in as argument (unless you know what you are doing).\r\n            To check the current state of execution of this hook you can use\r\n            ``self.trainer.training/testing/validating/predicting`` so that you can\r\n            add different logic as per your requirement.\r\n\r\n        Args:\r\n            batch: A batch of data that needs to be transferred to a new device.\r\n            device: The target device as defined in PyTorch.\r\n            dataloader_idx: The index of the dataloader to which the batch belongs.\r\n\r\n        Returns:\r\n            A reference to the data on the new device.\r\n\r\n        Example::\r\n\r\n            def transfer_batch_to_device(self, batch, device, dataloader_idx):\r\n                if isinstance(batch, CustomBatch):\r\n                    batch.samples = batch.samples.to(device)\r\n                    batch.targets = batch.targets.to(device)\r\n                elif dataloader_idx == 0:\r\n                    pass\r\n                else:\r\n                    batch = super().transfer_batch_to_device(batch, device, dataloader_idx)\r\n                return batch\r\n\r\n        See Also:\r\n            - :meth:`move_data_to_device`\r\n            - :meth:`apply_to_collection`\r\n\r\n        \"\"\"\r\n        return move_data_to_device(batch, device)", "language": "python", "code": "def transfer_batch_to_device(self, batch: Any, device: torch.device, dataloader_idx: int) -> Any:\r\n        \"\"\"Override this hook if your :class:`~torch.utils.data.DataLoader` returns tensors wrapped in a custom data\r\n        structure.\r\n\r\n        The data types listed below (and any arbitrary nesting of them) are supported out of the box:\r\n\r\n        - :class:`torch.Tensor` or anything that implements `.to(...)`\r\n        - :class:`list`\r\n        - :class:`dict`\r\n        - :class:`tuple`\r\n\r\n        For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).\r\n\r\n        Note:\r\n            This hook should only transfer the data and not modify it, nor should it move the data to\r\n            any other device than the one passed in as argument (unless you know what you are doing).\r\n            To check the current state of execution of this hook you can use\r\n            ``self.trainer.training/testing/validating/predicting`` so that you can\r\n            add different logic as per your requirement.\r\n\r\n        Args:\r\n            batch: A batch of data that needs to be transferred to a new device.\r\n            device: The target device as defined in PyTorch.\r\n            dataloader_idx: The index of the dataloader to which the batch belongs.\r\n\r\n        Returns:\r\n            A reference to the data on the new device.\r\n\r\n        Example::\r\n\r\n            def transfer_batch_to_device(self, batch, device, dataloader_idx):\r\n                if isinstance(batch, CustomBatch):\r\n                    batch.samples = batch.samples.to(device)\r\n                    batch.targets = batch.targets.to(device)\r\n                elif dataloader_idx == 0:\r\n                    pass\r\n                else:\r\n                    batch = super().transfer_batch_to_device(batch, device, dataloader_idx)\r\n                return batch\r\n\r\n        See Also:\r\n            - :meth:`move_data_to_device`\r\n            - :meth:`apply_to_collection`\r\n\r\n        \"\"\"\r\n        return move_data_to_device(batch, device)", "code_tokens": ["def", "transfer_batch_to_device", "(", "self", ",", "batch", ":", "Any", ",", "device", ":", "torch", ".", "device", ",", "dataloader_idx", ":", "int", ")", "-", ">", "Any", ":", "STRING", "return", "move_data_to_device", "(", "batch", ",", "device", ")"], "docstring": "move all tensors in your custom data structure to the device skip device transfer for the first dataloader or anything you wish", "docstring_tokens": ["move", "all", "tensors", "in", "your", "custom", "data", "structure", "to", "the", "device", "skip", "device", "transfer", "for", "the", "first", "dataloader", "or", "anything", "you", "wish"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 563, "end_line": 610, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_123", "original_string": "def on_load_checkpoint(self, checkpoint: dict[str, Any]) -> None:\r\n        r\"\"\"Called by Lightning to restore your model. If you saved something with :meth:`on_save_checkpoint` this is\r\n        your chance to restore this.\r\n\r\n        Args:\r\n            checkpoint: Loaded checkpoint\r\n\r\n        Example::\r\n\r\n            def on_load_checkpoint(self, checkpoint):\r\n                self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']\r\n\r\n        Note:\r\n            Lightning auto-restores global step, epoch, and train state including amp scaling.\r\n            There is no need for you to restore anything regarding training.\r\n\r\n        \"\"\"", "language": "python", "code": "def on_load_checkpoint(self, checkpoint: dict[str, Any]) -> None:\r\n        r\"\"\"Called by Lightning to restore your model. If you saved something with :meth:`on_save_checkpoint` this is\r\n        your chance to restore this.\r\n\r\n        Args:\r\n            checkpoint: Loaded checkpoint\r\n\r\n        Example::\r\n\r\n            def on_load_checkpoint(self, checkpoint):\r\n                self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']\r\n\r\n        Note:\r\n            Lightning auto-restores global step, epoch, and train state including amp scaling.\r\n            There is no need for you to restore anything regarding training.\r\n\r\n        \"\"\"", "code_tokens": ["def", "on_load_checkpoint", "(", "self", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "rSTRING"], "docstring": "99% of the time you don't need to implement this method", "docstring_tokens": ["99", "of", "the", "time", "you", "don", "t", "need", "to", "implement", "this", "method"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 672, "end_line": 689, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\hooks.py", "func_name": "function_124", "original_string": "def on_save_checkpoint(self, checkpoint: dict[str, Any]) -> None:\r\n        r\"\"\"Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to\r\n        save.\r\n\r\n        Args:\r\n            checkpoint: The full checkpoint dictionary before it gets dumped to a file.\r\n                Implementations of this hook can insert additional data into this dictionary.\r\n\r\n        Example::\r\n\r\n            def on_save_checkpoint(self, checkpoint):\r\n                checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object\r\n\r\n        Note:\r\n            Lightning saves all aspects of training (epoch, global step, etc...)\r\n            including amp scaling.\r\n            There is no need for you to store anything about training.\r\n\r\n        \"\"\"", "language": "python", "code": "def on_save_checkpoint(self, checkpoint: dict[str, Any]) -> None:\r\n        r\"\"\"Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to\r\n        save.\r\n\r\n        Args:\r\n            checkpoint: The full checkpoint dictionary before it gets dumped to a file.\r\n                Implementations of this hook can insert additional data into this dictionary.\r\n\r\n        Example::\r\n\r\n            def on_save_checkpoint(self, checkpoint):\r\n                checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object\r\n\r\n        Note:\r\n            Lightning saves all aspects of training (epoch, global step, etc...)\r\n            including amp scaling.\r\n            There is no need for you to store anything about training.\r\n\r\n        \"\"\"", "code_tokens": ["def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "rSTRING"], "docstring": "99% of use cases you don't need to implement this method", "docstring_tokens": ["99", "of", "use", "cases", "you", "don", "t", "need", "to", "implement", "this", "method"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\hooks.py", "start_line": 691, "end_line": 710, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_125", "original_string": "def optimizers(self, use_pl_optimizer: bool = True) -> MODULE_OPTIMIZERS:\r\n        \"\"\"Returns the optimizer(s) that are being used during training. Useful for manual optimization.\r\n\r\n        Args:\r\n            use_pl_optimizer: If ``True``, will wrap the optimizer(s) in a\r\n                :class:`~lightning.pytorch.core.optimizer.LightningOptimizer` for automatic handling of precision,\r\n                profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the\r\n                ``step`` method and custom optimizers that don't have this method are not supported.\r\n\r\n        Returns:\r\n            A single optimizer, or a list of optimizers in case multiple ones are present.\r\n\r\n        \"\"\"\r\n        if self._fabric:\r\n            opts: MODULE_OPTIMIZERS = self._fabric_optimizers\r\n        elif use_pl_optimizer:\r\n            opts = self.trainer.strategy._lightning_optimizers\r\n        else:\r\n            opts = self.trainer.optimizers\r\n\r\n        if (\r\n            isinstance(opts, list)\r\n            and len(opts) == 1\r\n            and isinstance(opts[0], (Optimizer, LightningOptimizer, _FabricOptimizer))\r\n        ):\r\n            return opts[0]\r\n        return opts", "language": "python", "code": "def optimizers(self, use_pl_optimizer: bool = True) -> MODULE_OPTIMIZERS:\r\n        \"\"\"Returns the optimizer(s) that are being used during training. Useful for manual optimization.\r\n\r\n        Args:\r\n            use_pl_optimizer: If ``True``, will wrap the optimizer(s) in a\r\n                :class:`~lightning.pytorch.core.optimizer.LightningOptimizer` for automatic handling of precision,\r\n                profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the\r\n                ``step`` method and custom optimizers that don't have this method are not supported.\r\n\r\n        Returns:\r\n            A single optimizer, or a list of optimizers in case multiple ones are present.\r\n\r\n        \"\"\"\r\n        if self._fabric:\r\n            opts: MODULE_OPTIMIZERS = self._fabric_optimizers\r\n        elif use_pl_optimizer:\r\n            opts = self.trainer.strategy._lightning_optimizers\r\n        else:\r\n            opts = self.trainer.optimizers\r\n\r\n        if (\r\n            isinstance(opts, list)\r\n            and len(opts) == 1\r\n            and isinstance(opts[0], (Optimizer, LightningOptimizer, _FabricOptimizer))\r\n        ):\r\n            return opts[0]\r\n        return opts", "code_tokens": ["def", "optimizers", "(", "self", ",", "use_pl_optimizer", ":", "bool", "=", "True", ")", "-", ">", "MODULE_OPTIMIZERS", ":", "STRING", "if", "self", ".", "_fabric", ":", "opts", ":", "MODULE_OPTIMIZERS", "=", "self", ".", "_fabric_optimizers", "elif", "use_pl_optimizer", ":", "opts", "=", "self", ".", "trainer", ".", "strategy", ".", "_lightning_optimizers", "else", ":", "opts", "=", "self", ".", "trainer", ".", "optimizers", "if", "(", "isinstance", "(", "opts", ",", "list", ")", "and", "len", "(", "opts", ")", "=", "=", "1", "and", "isinstance", "(", "opts", "[", "0", "]", ",", "(", "Optimizer", ",", "LightningOptimizer", ",", "_FabricOptimizer", ")", ")", ")", ":", "return", "opts", "[", "0", "]", "return", "opts"], "docstring": "single optimizer multiple opts", "docstring_tokens": ["single", "optimizer", "multiple", "opts"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 167, "end_line": 195, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_126", "original_string": "def lr_schedulers(self) -> Union[None, list[LRSchedulerPLType], LRSchedulerPLType]:\r\n        \"\"\"Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.\r\n\r\n        Returns:\r\n            A single scheduler, or a list of schedulers in case multiple ones are present, or ``None`` if no\r\n            schedulers were returned in :meth:`~lightning.pytorch.core.LightningModule.configure_optimizers`.\r\n\r\n        \"\"\"\r\n        if not self.trainer.lr_scheduler_configs:\r\n            return None\r\n\r\n        lr_schedulers: list[LRSchedulerPLType] = [config.scheduler for config in self.trainer.lr_scheduler_configs]\r\n\r\n        if len(lr_schedulers) == 1:\r\n            return lr_schedulers[0]\r\n\r\n        return lr_schedulers", "language": "python", "code": "def lr_schedulers(self) -> Union[None, list[LRSchedulerPLType], LRSchedulerPLType]:\r\n        \"\"\"Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.\r\n\r\n        Returns:\r\n            A single scheduler, or a list of schedulers in case multiple ones are present, or ``None`` if no\r\n            schedulers were returned in :meth:`~lightning.pytorch.core.LightningModule.configure_optimizers`.\r\n\r\n        \"\"\"\r\n        if not self.trainer.lr_scheduler_configs:\r\n            return None\r\n\r\n        lr_schedulers: list[LRSchedulerPLType] = [config.scheduler for config in self.trainer.lr_scheduler_configs]\r\n\r\n        if len(lr_schedulers) == 1:\r\n            return lr_schedulers[0]\r\n\r\n        return lr_schedulers", "code_tokens": ["def", "lr_schedulers", "(", "self", ")", "-", ">", "Union", "[", "None", ",", "list", "[", "LRSchedulerPLType", "]", ",", "LRSchedulerPLType", "]", ":", "STRING", "if", "not", "self", ".", "trainer", ".", "lr_scheduler_configs", ":", "return", "None", "lr_schedulers", ":", "list", "[", "LRSchedulerPLType", "]", "=", "[", "config", ".", "scheduler", "for", "config", "in", "self", ".", "trainer", ".", "lr_scheduler_configs", "]", "if", "len", "(", "lr_schedulers", ")", "=", "=", "1", ":", "return", "lr_schedulers", "[", "0", "]", "return", "lr_schedulers"], "docstring": "ignore other keys \"interval\", \"frequency\", etc. single scheduler multiple schedulers", "docstring_tokens": ["ignore", "other", "keys", "interval", "frequency", "etc", "single", "scheduler", "multiple", "schedulers"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 197, "end_line": 216, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_127", "original_string": "def strict_loading(self) -> bool:\r\n        \"\"\"Determines how Lightning loads this model using `.load_state_dict(..., strict=model.strict_loading)`.\"\"\"\r\n        return self._strict_loading in (None, True)", "language": "python", "code": "def strict_loading(self) -> bool:\r\n        \"\"\"Determines how Lightning loads this model using `.load_state_dict(..., strict=model.strict_loading)`.\"\"\"\r\n        return self._strict_loading in (None, True)", "code_tokens": ["def", "strict_loading", "(", "self", ")", "-", ">", "bool", ":", "STRING", "return", "self", ".", "_strict_loading", "in", "(", "None", ",", "True", ")"], "docstring": "We use None as the default internally to determine whether the user has set a value", "docstring_tokens": ["we", "use", "none", "as", "the", "default", "internally", "to", "determine", "whether", "the", "user", "has", "set", "a", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 308, "end_line": 311, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_128", "original_string": "def log(\r\n        self,\r\n        name: str,\r\n        value: _METRIC,\r\n        prog_bar: bool = False,\r\n        logger: Optional[bool] = None,\r\n        on_step: Optional[bool] = None,\r\n        on_epoch: Optional[bool] = None,\r\n        reduce_fx: Union[str, Callable[[Any], Any]] = \"mean\",\r\n        enable_graph: bool = False,\r\n        sync_dist: bool = False,\r\n        sync_dist_group: Optional[Any] = None,\r\n        add_dataloader_idx: bool = True,\r\n        batch_size: Optional[int] = None,\r\n        metric_attribute: Optional[str] = None,\r\n        rank_zero_only: bool = False,\r\n    ) -> None:\r\n        \"\"\"Log a key, value pair.\r\n\r\n        Example::\r\n\r\n            self.log('train_loss', loss)\r\n\r\n        The default behavior per hook is documented here: :ref:`extensions/logging:Automatic Logging`.\r\n\r\n        Args:\r\n            name: key to log. Must be identical across all processes if using DDP or any other distributed strategy.\r\n            value: value to log. Can be a ``float``, ``Tensor``, or a ``Metric``.\r\n            prog_bar: if ``True`` logs to the progress bar.\r\n            logger: if ``True`` logs to the logger.\r\n            on_step: if ``True`` logs at this step. The default value is determined by the hook.\r\n                See :ref:`extensions/logging:Automatic Logging` for details.\r\n            on_epoch: if ``True`` logs epoch accumulated metrics. The default value is determined by the hook.\r\n                See :ref:`extensions/logging:Automatic Logging` for details.\r\n            reduce_fx: reduction function over step values for end of epoch. :meth:`torch.mean` by default.\r\n            enable_graph: if ``True``, will not auto detach the graph.\r\n            sync_dist: if ``True``, reduces the metric across devices. Use with care as this may lead to a significant\r\n                communication overhead.\r\n            sync_dist_group: the DDP group to sync across.\r\n            add_dataloader_idx: if ``True``, appends the index of the current dataloader to\r\n                the name (when using multiple dataloaders). If False, user needs to give unique names for\r\n                each dataloader to not mix the values.\r\n            batch_size: Current batch_size. This will be directly inferred from the loaded batch,\r\n                but for some data structures you might need to explicitly provide it.\r\n            metric_attribute: To restore the metric state, Lightning requires the reference of the\r\n                :class:`torchmetrics.Metric` in your model. This is found automatically if it is a model attribute.\r\n            rank_zero_only: Tells Lightning if you are calling ``self.log`` from every process (default) or only from\r\n                rank 0. If ``True``, you won't be able to use this metric as a monitor in callbacks\r\n                (e.g., early stopping). Warning: Improper use can lead to deadlocks! See\r\n                :ref:`Advanced Logging <visualize/logging_advanced:rank_zero_only>` for more details.\r\n\r\n        \"\"\"\r\n        if self._fabric is not None:\r\n            self._log_dict_through_fabric(dictionary={name: value}, logger=logger)\r\n            return\r\n\r\n        apply_to_collection(value, dict, self.__check_not_nested, name)\r\n        apply_to_collection(\r\n            value, object, self.__check_allowed, name, value, wrong_dtype=(numbers.Number, Metric, Tensor)\r\n        )\r\n\r\n        trainer = self._trainer\r\n        if trainer is None:\r\n            rank_zero_warn(\r\n                \"You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet.\"\r\n                \" This is most likely because the model hasn't been passed to the `Trainer`\"\r\n            )\r\n            return\r\n        if trainer.barebones:\r\n            rank_zero_warn(\r\n                \"You are trying to `self.log()` but `Trainer(barebones=True)` is configured.\"\r\n                \" Logging can impact raw speed so it is disabled under this setting.\"\r\n            )\r\n            return\r\n        results = trainer._results\r\n        if results is None:\r\n            raise MisconfigurationException(\r\n                \"You are trying to `self.log()` but the loop's result collection is not registered\"\r\n                \" yet. This is most likely because you are trying to log in a `predict` hook,\"\r\n                \" but it doesn't support logging\"\r\n            )\r\n        if self._current_fx_name is None:\r\n            raise MisconfigurationException(\r\n                \"You are trying to `self.log()` but it is not managed by the `Trainer` control flow\"\r\n            )\r\n\r\n        on_step, on_epoch = _FxValidator.check_logging_and_get_default_levels(\r\n            self._current_fx_name, on_step=on_step, on_epoch=on_epoch\r\n        )\r\n\r\n        if add_dataloader_idx and \"/dataloader_idx_\" in name:\r\n            raise MisconfigurationException(\r\n                f\"You called `self.log` with the key `{name}`\"\r\n                \" but it should not contain information about `dataloader_idx` when `add_dataloader_idx=True`\"\r\n            )\r\n\r\n        value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)\r\n\r\n        if trainer._logger_connector.should_reset_tensors(self._current_fx_name):\r\n            results.reset(metrics=False, fx=self._current_fx_name)\r\n\r\n        if metric_attribute is None and isinstance(value, Metric):\r\n            if self._metric_attributes is None:\r\n                self._metric_attributes = {\r\n                    id(module): name for name, module in self.named_modules() if isinstance(module, Metric)\r\n                }\r\n                if not self._metric_attributes:\r\n                    raise MisconfigurationException(\r\n                        \"Could not find the `LightningModule` attribute for the `torchmetrics.Metric` logged.\"\r\n                        \" You can fix this by setting an attribute for the metric in your `LightningModule`.\"\r\n                    )\r\n            metric_attribute = self._metric_attributes.get(id(value), None)\r\n            if metric_attribute is None:\r\n                raise MisconfigurationException(\r\n                    \"Could not find the `LightningModule` attribute for the `torchmetrics.Metric` logged.\"\r\n                    f\" You can fix this by calling `self.log({name}, ..., metric_attribute=name)` where `name` is one\"\r\n                    f\" of {list(self._metric_attributes.values())}\"\r\n                )\r\n\r\n        if (\r\n            trainer.training\r\n            and is_param_in_hook_signature(self.training_step, \"dataloader_iter\", explicit=True)\r\n            and batch_size is None\r\n        ):\r\n            raise MisconfigurationException(\r\n                \"With `def training_step(self, dataloader_iter)`, `self.log(..., batch_size=...)` should be provided.\"\r\n            )\r\n\r\n        if logger and trainer.logger is None:\r\n            rank_zero_warn(\r\n                f\"You called `self.log({name!r}, ..., logger=True)` but have no logger configured. You can enable one\"\r\n                \" by doing `Trainer(logger=ALogger(...))`\"\r\n            )\r\n        if logger is None:\r\n            logger = True\r\n\r\n        results.log(\r\n            self._current_fx_name,\r\n            name,\r\n            value,\r\n            prog_bar=prog_bar,\r\n            logger=logger,\r\n            on_step=on_step,\r\n            on_epoch=on_epoch,\r\n            reduce_fx=reduce_fx,\r\n            enable_graph=enable_graph,\r\n            add_dataloader_idx=add_dataloader_idx,\r\n            batch_size=batch_size,\r\n            sync_dist=sync_dist and trainer._accelerator_connector.is_distributed,\r\n            sync_dist_fn=trainer.strategy.reduce,\r\n            sync_dist_group=sync_dist_group,\r\n            metric_attribute=metric_attribute,\r\n            rank_zero_only=rank_zero_only,\r\n        )\r\n\r\n        trainer._logger_connector._current_fx = self._current_fx_name", "language": "python", "code": "def log(\r\n        self,\r\n        name: str,\r\n        value: _METRIC,\r\n        prog_bar: bool = False,\r\n        logger: Optional[bool] = None,\r\n        on_step: Optional[bool] = None,\r\n        on_epoch: Optional[bool] = None,\r\n        reduce_fx: Union[str, Callable[[Any], Any]] = \"mean\",\r\n        enable_graph: bool = False,\r\n        sync_dist: bool = False,\r\n        sync_dist_group: Optional[Any] = None,\r\n        add_dataloader_idx: bool = True,\r\n        batch_size: Optional[int] = None,\r\n        metric_attribute: Optional[str] = None,\r\n        rank_zero_only: bool = False,\r\n    ) -> None:\r\n        \"\"\"Log a key, value pair.\r\n\r\n        Example::\r\n\r\n            self.log('train_loss', loss)\r\n\r\n        The default behavior per hook is documented here: :ref:`extensions/logging:Automatic Logging`.\r\n\r\n        Args:\r\n            name: key to log. Must be identical across all processes if using DDP or any other distributed strategy.\r\n            value: value to log. Can be a ``float``, ``Tensor``, or a ``Metric``.\r\n            prog_bar: if ``True`` logs to the progress bar.\r\n            logger: if ``True`` logs to the logger.\r\n            on_step: if ``True`` logs at this step. The default value is determined by the hook.\r\n                See :ref:`extensions/logging:Automatic Logging` for details.\r\n            on_epoch: if ``True`` logs epoch accumulated metrics. The default value is determined by the hook.\r\n                See :ref:`extensions/logging:Automatic Logging` for details.\r\n            reduce_fx: reduction function over step values for end of epoch. :meth:`torch.mean` by default.\r\n            enable_graph: if ``True``, will not auto detach the graph.\r\n            sync_dist: if ``True``, reduces the metric across devices. Use with care as this may lead to a significant\r\n                communication overhead.\r\n            sync_dist_group: the DDP group to sync across.\r\n            add_dataloader_idx: if ``True``, appends the index of the current dataloader to\r\n                the name (when using multiple dataloaders). If False, user needs to give unique names for\r\n                each dataloader to not mix the values.\r\n            batch_size: Current batch_size. This will be directly inferred from the loaded batch,\r\n                but for some data structures you might need to explicitly provide it.\r\n            metric_attribute: To restore the metric state, Lightning requires the reference of the\r\n                :class:`torchmetrics.Metric` in your model. This is found automatically if it is a model attribute.\r\n            rank_zero_only: Tells Lightning if you are calling ``self.log`` from every process (default) or only from\r\n                rank 0. If ``True``, you won't be able to use this metric as a monitor in callbacks\r\n                (e.g., early stopping). Warning: Improper use can lead to deadlocks! See\r\n                :ref:`Advanced Logging <visualize/logging_advanced:rank_zero_only>` for more details.\r\n\r\n        \"\"\"\r\n        if self._fabric is not None:\r\n            self._log_dict_through_fabric(dictionary={name: value}, logger=logger)\r\n            return\r\n\r\n        apply_to_collection(value, dict, self.__check_not_nested, name)\r\n        apply_to_collection(\r\n            value, object, self.__check_allowed, name, value, wrong_dtype=(numbers.Number, Metric, Tensor)\r\n        )\r\n\r\n        trainer = self._trainer\r\n        if trainer is None:\r\n            rank_zero_warn(\r\n                \"You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet.\"\r\n                \" This is most likely because the model hasn't been passed to the `Trainer`\"\r\n            )\r\n            return\r\n        if trainer.barebones:\r\n            rank_zero_warn(\r\n                \"You are trying to `self.log()` but `Trainer(barebones=True)` is configured.\"\r\n                \" Logging can impact raw speed so it is disabled under this setting.\"\r\n            )\r\n            return\r\n        results = trainer._results\r\n        if results is None:\r\n            raise MisconfigurationException(\r\n                \"You are trying to `self.log()` but the loop's result collection is not registered\"\r\n                \" yet. This is most likely because you are trying to log in a `predict` hook,\"\r\n                \" but it doesn't support logging\"\r\n            )\r\n        if self._current_fx_name is None:\r\n            raise MisconfigurationException(\r\n                \"You are trying to `self.log()` but it is not managed by the `Trainer` control flow\"\r\n            )\r\n\r\n        on_step, on_epoch = _FxValidator.check_logging_and_get_default_levels(\r\n            self._current_fx_name, on_step=on_step, on_epoch=on_epoch\r\n        )\r\n\r\n        if add_dataloader_idx and \"/dataloader_idx_\" in name:\r\n            raise MisconfigurationException(\r\n                f\"You called `self.log` with the key `{name}`\"\r\n                \" but it should not contain information about `dataloader_idx` when `add_dataloader_idx=True`\"\r\n            )\r\n\r\n        value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)\r\n\r\n        if trainer._logger_connector.should_reset_tensors(self._current_fx_name):\r\n            results.reset(metrics=False, fx=self._current_fx_name)\r\n\r\n        if metric_attribute is None and isinstance(value, Metric):\r\n            if self._metric_attributes is None:\r\n                self._metric_attributes = {\r\n                    id(module): name for name, module in self.named_modules() if isinstance(module, Metric)\r\n                }\r\n                if not self._metric_attributes:\r\n                    raise MisconfigurationException(\r\n                        \"Could not find the `LightningModule` attribute for the `torchmetrics.Metric` logged.\"\r\n                        \" You can fix this by setting an attribute for the metric in your `LightningModule`.\"\r\n                    )\r\n            metric_attribute = self._metric_attributes.get(id(value), None)\r\n            if metric_attribute is None:\r\n                raise MisconfigurationException(\r\n                    \"Could not find the `LightningModule` attribute for the `torchmetrics.Metric` logged.\"\r\n                    f\" You can fix this by calling `self.log({name}, ..., metric_attribute=name)` where `name` is one\"\r\n                    f\" of {list(self._metric_attributes.values())}\"\r\n                )\r\n\r\n        if (\r\n            trainer.training\r\n            and is_param_in_hook_signature(self.training_step, \"dataloader_iter\", explicit=True)\r\n            and batch_size is None\r\n        ):\r\n            raise MisconfigurationException(\r\n                \"With `def training_step(self, dataloader_iter)`, `self.log(..., batch_size=...)` should be provided.\"\r\n            )\r\n\r\n        if logger and trainer.logger is None:\r\n            rank_zero_warn(\r\n                f\"You called `self.log({name!r}, ..., logger=True)` but have no logger configured. You can enable one\"\r\n                \" by doing `Trainer(logger=ALogger(...))`\"\r\n            )\r\n        if logger is None:\r\n            logger = True\r\n\r\n        results.log(\r\n            self._current_fx_name,\r\n            name,\r\n            value,\r\n            prog_bar=prog_bar,\r\n            logger=logger,\r\n            on_step=on_step,\r\n            on_epoch=on_epoch,\r\n            reduce_fx=reduce_fx,\r\n            enable_graph=enable_graph,\r\n            add_dataloader_idx=add_dataloader_idx,\r\n            batch_size=batch_size,\r\n            sync_dist=sync_dist and trainer._accelerator_connector.is_distributed,\r\n            sync_dist_fn=trainer.strategy.reduce,\r\n            sync_dist_group=sync_dist_group,\r\n            metric_attribute=metric_attribute,\r\n            rank_zero_only=rank_zero_only,\r\n        )\r\n\r\n        trainer._logger_connector._current_fx = self._current_fx_name", "code_tokens": ["def", "log", "(", "self", ",", "name", ":", "str", ",", "value", ":", "_METRIC", ",", "prog_bar", ":", "bool", "=", "False", ",", "logger", ":", "Optional", "[", "bool", "]", "=", "None", ",", "on_step", ":", "Optional", "[", "bool", "]", "=", "None", ",", "on_epoch", ":", "Optional", "[", "bool", "]", "=", "None", ",", "reduce_fx", ":", "Union", "[", "str", ",", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "]", "=", "STRING", ",", "enable_graph", ":", "bool", "=", "False", ",", "sync_dist", ":", "bool", "=", "False", ",", "sync_dist_group", ":", "Optional", "[", "Any", "]", "=", "None", ",", "add_dataloader_idx", ":", "bool", "=", "True", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "metric_attribute", ":", "Optional", "[", "str", "]", "=", "None", ",", "rank_zero_only", ":", "bool", "=", "False", ",", ")", "-", ">", "None", ":", "STRING", "if", "self", ".", "_fabric", "is", "not", "None", ":", "self", ".", "_log_dict_through_fabric", "(", "dictionary", "=", "{", "name", ":", "value", "}", ",", "logger", "=", "logger", ")", "return", "apply_to_collection", "(", "value", ",", "dict", ",", "self", ".", "__check_not_nested", ",", "name", ")", "apply_to_collection", "(", "value", ",", "object", ",", "self", ".", "__check_allowed", ",", "name", ",", "value", ",", "wrong_dtype", "=", "(", "numbers", ".", "Number", ",", "Metric", ",", "Tensor", ")", ")", "trainer", "=", "self", ".", "_trainer", "if", "trainer", "is", "None", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "return", "if", "trainer", ".", "barebones", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "return", "results", "=", "trainer", ".", "_results", "if", "results", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", "STRING", ")", "if", "self", ".", "_current_fx_name", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "on_step", ",", "on_epoch", "=", "_FxValidator", ".", "check_logging_and_get_default_levels", "(", "self", ".", "_current_fx_name", ",", "on_step", "=", "on_step", ",", "on_epoch", "=", "on_epoch", ")", "if", "add_dataloader_idx", "and", "STRING", "in", "name", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", ")", "value", "=", "apply_to_collection", "(", "value", ",", "(", "Tensor", ",", "numbers", ".", "Number", ")", ",", "self", ".", "__to_tensor", ",", "name", ")", "if", "trainer", ".", "_logger_connector", ".", "should_reset_tensors", "(", "self", ".", "_current_fx_name", ")", ":", "results", ".", "reset", "(", "metrics", "=", "False", ",", "fx", "=", "self", ".", "_current_fx_name", ")", "if", "metric_attribute", "is", "None", "and", "isinstance", "(", "value", ",", "Metric", ")", ":", "if", "self", ".", "_metric_attributes", "is", "None", ":", "self", ".", "_metric_attributes", "=", "{", "id", "(", "module", ")", ":", "name", "for", "name", ",", "module", "in", "self", ".", "named_modules", "(", ")", "if", "isinstance", "(", "module", ",", "Metric", ")", "}", "if", "not", "self", ".", "_metric_attributes", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", ")", "metric_attribute", "=", "self", ".", "_metric_attributes", ".", "get", "(", "id", "(", "value", ")", ",", "None", ")", "if", "metric_attribute", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", "fSTRING", "fSTRING", ")", "if", "(", "trainer", ".", "training", "and", "is_param_in_hook_signature", "(", "self", ".", "training_step", ",", "STRING", ",", "explicit", "=", "True", ")", "and", "batch_size", "is", "None", ")", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "if", "logger", "and", "trainer", ".", "logger", "is", "None", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ")", "if", "logger", "is", "None", ":", "logger", "=", "True", "results", ".", "log", "(", "self", ".", "_current_fx_name", ",", "name", ",", "value", ",", "prog_bar", "=", "prog_bar", ",", "logger", "=", "logger", ",", "on_step", "=", "on_step", ",", "on_epoch", "=", "on_epoch", ",", "reduce_fx", "=", "reduce_fx", ",", "enable_graph", "=", "enable_graph", ",", "add_dataloader_idx", "=", "add_dataloader_idx", ",", "batch_size", "=", "batch_size", ",", "sync_dist", "=", "sync_dist", "and", "trainer", ".", "_accelerator_connector", ".", "is_distributed", ",", "sync_dist_fn"], "docstring": "check for invalid values not an error to support testing the `*_step` methods without a `Trainer` reference make sure user doesn't introduce logic for multi-dataloaders if we started a new epoch (running its first batch) the hook name has changed reset any tensors for the new hook name compute once try to find the passed metric in the LightningModule we could set false here if there's no configured logger, however, we still need to compute the \"logged\" metrics anyway because that's what the evaluation loops use as return value", "docstring_tokens": ["check", "for", "invalid", "values", "not", "an", "error", "to", "support", "testing", "the", "_step", "methods", "without", "a", "trainer", "reference", "make", "sure", "user", "doesn", "t", "introduce", "logic", "for", "multi", "dataloaders", "if", "we", "started", "a", "new", "epoch", "running", "its", "first", "batch", "the", "hook", "name", "has", "changed", "reset", "any", "tensors", "for", "the", "new", "hook", "name", "compute", "once", "try", "to", "find", "the", "passed", "metric", "in", "the", "lightningmodule", "we", "could", "set", "false", "here", "if", "there", "s", "no", "configured", "logger", "however", "we", "still", "need", "to", "compute", "the", "logged", "metrics", "anyway", "because", "that", "s", "what", "the", "evaluation", "loops", "use", "as", "return", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 385, "end_line": 549, "has_examples": true, "num_comments": 7, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_129", "original_string": "def training_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or\r\n        logger.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary which can include any keys, but must include the key ``'loss'`` in the case of\r\n              automatic optimization.\r\n            - ``None`` - In automatic optimization, this will skip to the next batch (but is not supported for\r\n              multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning\r\n              the loss is not required.\r\n\r\n        In this step you'd normally do the forward pass and calculate the loss for a batch.\r\n        You can also do fancier things like multiple forward passes or something model specific.\r\n\r\n        Example::\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                x, y, z = batch\r\n                out = self.encoder(x)\r\n                loss = self.loss(out, x)\r\n                return loss\r\n\r\n        To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:\r\n\r\n        .. code-block:: python\r\n\r\n            def __init__(self):\r\n                super().__init__()\r\n                self.automatic_optimization = False\r\n\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt1, opt2 = self.optimizers()\r\n\r\n                ...\r\n                opt1.step()\r\n                ...\r\n                opt2.step()\r\n\r\n        Note:\r\n            When ``accumulate_grad_batches`` > 1, the loss returned here will be automatically\r\n            normalized by ``accumulate_grad_batches`` internally.\r\n\r\n        \"\"\"\r\n        rank_zero_warn(\"`training_step` must be implemented to be used with the Lightning Trainer\")", "language": "python", "code": "def training_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or\r\n        logger.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary which can include any keys, but must include the key ``'loss'`` in the case of\r\n              automatic optimization.\r\n            - ``None`` - In automatic optimization, this will skip to the next batch (but is not supported for\r\n              multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning\r\n              the loss is not required.\r\n\r\n        In this step you'd normally do the forward pass and calculate the loss for a batch.\r\n        You can also do fancier things like multiple forward passes or something model specific.\r\n\r\n        Example::\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                x, y, z = batch\r\n                out = self.encoder(x)\r\n                loss = self.loss(out, x)\r\n                return loss\r\n\r\n        To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:\r\n\r\n        .. code-block:: python\r\n\r\n            def __init__(self):\r\n                super().__init__()\r\n                self.automatic_optimization = False\r\n\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt1, opt2 = self.optimizers()\r\n\r\n                ...\r\n                opt1.step()\r\n                ...\r\n                opt2.step()\r\n\r\n        Note:\r\n            When ``accumulate_grad_batches`` > 1, the loss returned here will be automatically\r\n            normalized by ``accumulate_grad_batches`` internally.\r\n\r\n        \"\"\"\r\n        rank_zero_warn(\"`training_step` must be implemented to be used with the Lightning Trainer\")", "code_tokens": ["def", "training_step", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "STEP_OUTPUT", ":", "rSTRING", "rank_zero_warn", "(", "STRING", ")"], "docstring": "Multiple optimizers (e.g.: GANs) do training_step with encoder do training_step with decoder", "docstring_tokens": ["multiple", "optimizers", "e", "g", "gans", "do", "training_step", "with", "encoder", "do", "training_step", "with", "decoder"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 709, "end_line": 763, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_130", "original_string": "def validation_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Operates on a single batch of data from the validation set. In this step you'd might generate examples or\r\n        calculate anything of interest like accuracy.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``.\r\n            - ``None`` - Skip to the next batch.\r\n\r\n        .. code-block:: python\r\n\r\n            def validation_step(self, batch, batch_idx): ...\r\n\r\n\r\n            def validation_step(self, batch, batch_idx, dataloader_idx=0): ...\r\n\r\n        Examples::\r\n\r\n            def validation_step(self, batch, batch_idx):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n                loss = self.loss(out, y)\r\n\r\n                sample_imgs = x[:6]\r\n                grid = torchvision.utils.make_grid(sample_imgs)\r\n                self.logger.experiment.add_image('example_images', grid, 0)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({'val_loss': loss, 'val_acc': val_acc})\r\n\r\n        If you pass in multiple val dataloaders, :meth:`validation_step` will have an additional argument. We recommend\r\n        setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\r\n\r\n        .. code-block:: python\r\n\r\n            def validation_step(self, batch, batch_idx, dataloader_idx=0):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n\r\n                if dataloader_idx == 0:\r\n                    loss = self.loss0(out, y)\r\n                else:\r\n                    loss = self.loss1(out, y)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({f\"val_loss_{dataloader_idx}\": loss, f\"val_acc_{dataloader_idx}\": acc})\r\n\r\n        Note:\r\n            If you don't need to validate you don't need to implement this method.\r\n\r\n        Note:\r\n            When the :meth:`validation_step` is called, the model has been put in eval mode\r\n            and PyTorch gradients have been disabled. At the end of validation,\r\n            the model goes back to training mode and gradients are enabled.\r\n\r\n        \"\"\"", "language": "python", "code": "def validation_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Operates on a single batch of data from the validation set. In this step you'd might generate examples or\r\n        calculate anything of interest like accuracy.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``.\r\n            - ``None`` - Skip to the next batch.\r\n\r\n        .. code-block:: python\r\n\r\n            def validation_step(self, batch, batch_idx): ...\r\n\r\n\r\n            def validation_step(self, batch, batch_idx, dataloader_idx=0): ...\r\n\r\n        Examples::\r\n\r\n            def validation_step(self, batch, batch_idx):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n                loss = self.loss(out, y)\r\n\r\n                sample_imgs = x[:6]\r\n                grid = torchvision.utils.make_grid(sample_imgs)\r\n                self.logger.experiment.add_image('example_images', grid, 0)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({'val_loss': loss, 'val_acc': val_acc})\r\n\r\n        If you pass in multiple val dataloaders, :meth:`validation_step` will have an additional argument. We recommend\r\n        setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\r\n\r\n        .. code-block:: python\r\n\r\n            def validation_step(self, batch, batch_idx, dataloader_idx=0):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n\r\n                if dataloader_idx == 0:\r\n                    loss = self.loss0(out, y)\r\n                else:\r\n                    loss = self.loss1(out, y)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({f\"val_loss_{dataloader_idx}\": loss, f\"val_acc_{dataloader_idx}\": acc})\r\n\r\n        Note:\r\n            If you don't need to validate you don't need to implement this method.\r\n\r\n        Note:\r\n            When the :meth:`validation_step` is called, the model has been put in eval mode\r\n            and PyTorch gradients have been disabled. At the end of validation,\r\n            the model goes back to training mode and gradients are enabled.\r\n\r\n        \"\"\"", "code_tokens": ["def", "validation_step", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "STEP_OUTPUT", ":", "rSTRING"], "docstring": "if you have one val dataloader: if you have multiple val dataloaders: CASE 1: A single validation dataset implement your own log 6 example images or generated text... or whatever calculate acc log the outputs! CASE 2: multiple validation dataloaders dataloader_idx tells you which dataset this is. implement your own calculate acc log the outputs separately for each dataloader", "docstring_tokens": ["if", "you", "have", "one", "val", "dataloader", "if", "you", "have", "multiple", "val", "dataloaders", "case", "1", "a", "single", "validation", "dataset", "implement", "your", "own", "log", "6", "example", "images", "or", "generated", "text", "or", "whatever", "calculate", "acc", "log", "the", "outputs", "case", "2", "multiple", "validation", "dataloaders", "dataloader_idx", "tells", "you", "which", "dataset", "this", "is", "implement", "your", "own", "calculate", "acc", "log", "the", "outputs", "separately", "for", "each", "dataloader"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 765, "end_line": 845, "has_examples": true, "num_comments": 12, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_131", "original_string": "def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Operates on a single batch of data from the test set. In this step you'd normally generate examples or\r\n        calculate anything of interest such as accuracy.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``.\r\n            - ``None`` - Skip to the next batch.\r\n\r\n        .. code-block:: python\r\n\r\n            def test_step(self, batch, batch_idx): ...\r\n\r\n\r\n            def test_step(self, batch, batch_idx, dataloader_idx=0): ...\r\n\r\n        Examples::\r\n\r\n            def test_step(self, batch, batch_idx):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n                loss = self.loss(out, y)\r\n\r\n                sample_imgs = x[:6]\r\n                grid = torchvision.utils.make_grid(sample_imgs)\r\n                self.logger.experiment.add_image('example_images', grid, 0)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({'test_loss': loss, 'test_acc': test_acc})\r\n\r\n        If you pass in multiple test dataloaders, :meth:`test_step` will have an additional argument. We recommend\r\n        setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\r\n\r\n        .. code-block:: python\r\n\r\n            def test_step(self, batch, batch_idx, dataloader_idx=0):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n\r\n                if dataloader_idx == 0:\r\n                    loss = self.loss0(out, y)\r\n                else:\r\n                    loss = self.loss1(out, y)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({f\"test_loss_{dataloader_idx}\": loss, f\"test_acc_{dataloader_idx}\": acc})\r\n\r\n        Note:\r\n            If you don't need to test you don't need to implement this method.\r\n\r\n        Note:\r\n            When the :meth:`test_step` is called, the model has been put in eval mode and\r\n            PyTorch gradients have been disabled. At the end of the test epoch, the model goes back\r\n            to training mode and gradients are enabled.\r\n\r\n        \"\"\"", "language": "python", "code": "def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:\r\n        r\"\"\"Operates on a single batch of data from the test set. In this step you'd normally generate examples or\r\n        calculate anything of interest such as accuracy.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            - :class:`~torch.Tensor` - The loss tensor\r\n            - ``dict`` - A dictionary. Can include any keys, but must include the key ``'loss'``.\r\n            - ``None`` - Skip to the next batch.\r\n\r\n        .. code-block:: python\r\n\r\n            def test_step(self, batch, batch_idx): ...\r\n\r\n\r\n            def test_step(self, batch, batch_idx, dataloader_idx=0): ...\r\n\r\n        Examples::\r\n\r\n            def test_step(self, batch, batch_idx):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n                loss = self.loss(out, y)\r\n\r\n                sample_imgs = x[:6]\r\n                grid = torchvision.utils.make_grid(sample_imgs)\r\n                self.logger.experiment.add_image('example_images', grid, 0)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({'test_loss': loss, 'test_acc': test_acc})\r\n\r\n        If you pass in multiple test dataloaders, :meth:`test_step` will have an additional argument. We recommend\r\n        setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.\r\n\r\n        .. code-block:: python\r\n\r\n            def test_step(self, batch, batch_idx, dataloader_idx=0):\r\n                x, y = batch\r\n\r\n                out = self(x)\r\n\r\n                if dataloader_idx == 0:\r\n                    loss = self.loss0(out, y)\r\n                else:\r\n                    loss = self.loss1(out, y)\r\n\r\n                labels_hat = torch.argmax(out, dim=1)\r\n                acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\r\n\r\n                self.log_dict({f\"test_loss_{dataloader_idx}\": loss, f\"test_acc_{dataloader_idx}\": acc})\r\n\r\n        Note:\r\n            If you don't need to test you don't need to implement this method.\r\n\r\n        Note:\r\n            When the :meth:`test_step` is called, the model has been put in eval mode and\r\n            PyTorch gradients have been disabled. At the end of the test epoch, the model goes back\r\n            to training mode and gradients are enabled.\r\n\r\n        \"\"\"", "code_tokens": ["def", "test_step", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "STEP_OUTPUT", ":", "rSTRING"], "docstring": "if you have one test dataloader: if you have multiple test dataloaders: CASE 1: A single test dataset implement your own log 6 example images or generated text... or whatever calculate acc log the outputs! CASE 2: multiple test dataloaders dataloader_idx tells you which dataset this is. implement your own calculate acc log the outputs separately for each dataloader", "docstring_tokens": ["if", "you", "have", "one", "test", "dataloader", "if", "you", "have", "multiple", "test", "dataloaders", "case", "1", "a", "single", "test", "dataset", "implement", "your", "own", "log", "6", "example", "images", "or", "generated", "text", "or", "whatever", "calculate", "acc", "log", "the", "outputs", "case", "2", "multiple", "test", "dataloaders", "dataloader_idx", "tells", "you", "which", "dataset", "this", "is", "implement", "your", "own", "calculate", "acc", "log", "the", "outputs", "separately", "for", "each", "dataloader"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 847, "end_line": 927, "has_examples": true, "num_comments": 12, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_132", "original_string": "def predict_step(self, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Step function called during :meth:`~lightning.pytorch.trainer.trainer.Trainer.predict`. By default, it calls\r\n        :meth:`~lightning.pytorch.core.LightningModule.forward`. Override to add any processing logic.\r\n\r\n        The :meth:`~lightning.pytorch.core.LightningModule.predict_step` is used\r\n        to scale inference on multi-devices.\r\n\r\n        To prevent an OOM error, it is possible to use :class:`~lightning.pytorch.callbacks.BasePredictionWriter`\r\n        callback to write the predictions to disk or database after each batch or on epoch end.\r\n\r\n        The :class:`~lightning.pytorch.callbacks.BasePredictionWriter` should be used while using a spawn\r\n        based accelerator. This happens for ``Trainer(strategy=\"ddp_spawn\")``\r\n        or training on 8 TPU cores with ``Trainer(accelerator=\"tpu\", devices=8)`` as predictions won't be returned.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            Predicted output (optional).\r\n\r\n        Example ::\r\n\r\n            class MyModel(LightningModule):\r\n\r\n                def predict_step(self, batch, batch_idx, dataloader_idx=0):\r\n                    return self(batch)\r\n\r\n            dm = ...\r\n            model = MyModel()\r\n            trainer = Trainer(accelerator=\"gpu\", devices=2)\r\n            predictions = trainer.predict(model, dm)\r\n\r\n        \"\"\"\r\n        batch = kwargs.get(\"batch\", args[0])\r\n        return self(batch)", "language": "python", "code": "def predict_step(self, *args: Any, **kwargs: Any) -> Any:\r\n        \"\"\"Step function called during :meth:`~lightning.pytorch.trainer.trainer.Trainer.predict`. By default, it calls\r\n        :meth:`~lightning.pytorch.core.LightningModule.forward`. Override to add any processing logic.\r\n\r\n        The :meth:`~lightning.pytorch.core.LightningModule.predict_step` is used\r\n        to scale inference on multi-devices.\r\n\r\n        To prevent an OOM error, it is possible to use :class:`~lightning.pytorch.callbacks.BasePredictionWriter`\r\n        callback to write the predictions to disk or database after each batch or on epoch end.\r\n\r\n        The :class:`~lightning.pytorch.callbacks.BasePredictionWriter` should be used while using a spawn\r\n        based accelerator. This happens for ``Trainer(strategy=\"ddp_spawn\")``\r\n        or training on 8 TPU cores with ``Trainer(accelerator=\"tpu\", devices=8)`` as predictions won't be returned.\r\n\r\n        Args:\r\n            batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.\r\n            batch_idx: The index of this batch.\r\n            dataloader_idx: The index of the dataloader that produced this batch.\r\n                (only if multiple dataloaders used)\r\n\r\n        Return:\r\n            Predicted output (optional).\r\n\r\n        Example ::\r\n\r\n            class MyModel(LightningModule):\r\n\r\n                def predict_step(self, batch, batch_idx, dataloader_idx=0):\r\n                    return self(batch)\r\n\r\n            dm = ...\r\n            model = MyModel()\r\n            trainer = Trainer(accelerator=\"gpu\", devices=2)\r\n            predictions = trainer.predict(model, dm)\r\n\r\n        \"\"\"\r\n        batch = kwargs.get(\"batch\", args[0])\r\n        return self(batch)", "code_tokens": ["def", "predict_step", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "batch", "=", "kwargs", ".", "get", "(", "STRING", ",", "args", "[", "0", "]", ")", "return", "self", "(", "batch", ")"], "docstring": "For backwards compatibility", "docstring_tokens": ["for", "backwards", "compatibility"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 929, "end_line": 967, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_133", "original_string": "def configure_optimizers(self) -> OptimizerLRScheduler:\r\n        r\"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.\r\n        But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in\r\n        the manual optimization mode.\r\n\r\n        Return:\r\n            Any of these 6 options.\r\n\r\n            - **Single optimizer**.\r\n            - **List or Tuple** of optimizers.\r\n            - **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\r\n              (or multiple ``lr_scheduler_config``).\r\n            - **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\r\n              key whose value is a single LR scheduler or ``lr_scheduler_config``.\r\n            - **None** - Fit will run without any optimizer.\r\n\r\n        The ``lr_scheduler_config`` is a dictionary which contains the scheduler and its associated configuration.\r\n        The default configuration is shown below.\r\n\r\n        .. code-block:: python\r\n\r\n            lr_scheduler_config = {\r\n                \"scheduler\": lr_scheduler,\r\n                \"interval\": \"epoch\",\r\n                \"frequency\": 1,\r\n                \"monitor\": \"val_loss\",\r\n                \"strict\": True,\r\n                \"name\": None,\r\n            }\r\n\r\n        When there are schedulers in which the ``.step()`` method is conditioned on a value, such as the\r\n        :class:`torch.optim.lr_scheduler.ReduceLROnPlateau` scheduler, Lightning requires that the\r\n        ``lr_scheduler_config`` contains the keyword ``\"monitor\"`` set to the metric name that the scheduler\r\n        should be conditioned on.\r\n\r\n        .. testcode::\r\n\r\n            def configure_optimizers(self):\r\n                optimizer = Adam(...)\r\n                return {\r\n                    \"optimizer\": optimizer,\r\n                    \"lr_scheduler\": {\r\n                        \"scheduler\": ReduceLROnPlateau(optimizer, ...),\r\n                        \"monitor\": \"metric_to_track\",\r\n                        \"frequency\": \"indicates how often the metric is updated\",\r\n                    },\r\n                }\r\n\r\n\r\n            def configure_optimizers(self):\r\n                optimizer1 = Adam(...)\r\n                optimizer2 = SGD(...)\r\n                scheduler1 = ReduceLROnPlateau(optimizer1, ...)\r\n                scheduler2 = LambdaLR(optimizer2, ...)\r\n                return (\r\n                    {\r\n                        \"optimizer\": optimizer1,\r\n                        \"lr_scheduler\": {\r\n                            \"scheduler\": scheduler1,\r\n                            \"monitor\": \"metric_to_track\",\r\n                        },\r\n                    },\r\n                    {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\r\n                )\r\n\r\n        Metrics can be made available to monitor by simply logging it using\r\n        ``self.log('metric_to_track', metric_val)`` in your :class:`~lightning.pytorch.core.LightningModule`.\r\n\r\n        Note:\r\n            Some things to know:\r\n\r\n            - Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\r\n            - If a learning rate scheduler is specified in ``configure_optimizers()`` with key\r\n              ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\r\n              the scheduler's ``.step()`` method automatically in case of automatic optimization.\r\n            - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\r\n            - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\r\n            - If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\r\n              yourself.\r\n            - If you need to control how often the optimizer steps, override the :meth:`optimizer_step` hook.\r\n\r\n        \"\"\"\r\n        rank_zero_warn(\"`configure_optimizers` must be implemented to be used with the Lightning Trainer\")", "language": "python", "code": "def configure_optimizers(self) -> OptimizerLRScheduler:\r\n        r\"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.\r\n        But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in\r\n        the manual optimization mode.\r\n\r\n        Return:\r\n            Any of these 6 options.\r\n\r\n            - **Single optimizer**.\r\n            - **List or Tuple** of optimizers.\r\n            - **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\r\n              (or multiple ``lr_scheduler_config``).\r\n            - **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\r\n              key whose value is a single LR scheduler or ``lr_scheduler_config``.\r\n            - **None** - Fit will run without any optimizer.\r\n\r\n        The ``lr_scheduler_config`` is a dictionary which contains the scheduler and its associated configuration.\r\n        The default configuration is shown below.\r\n\r\n        .. code-block:: python\r\n\r\n            lr_scheduler_config = {\r\n                \"scheduler\": lr_scheduler,\r\n                \"interval\": \"epoch\",\r\n                \"frequency\": 1,\r\n                \"monitor\": \"val_loss\",\r\n                \"strict\": True,\r\n                \"name\": None,\r\n            }\r\n\r\n        When there are schedulers in which the ``.step()`` method is conditioned on a value, such as the\r\n        :class:`torch.optim.lr_scheduler.ReduceLROnPlateau` scheduler, Lightning requires that the\r\n        ``lr_scheduler_config`` contains the keyword ``\"monitor\"`` set to the metric name that the scheduler\r\n        should be conditioned on.\r\n\r\n        .. testcode::\r\n\r\n            def configure_optimizers(self):\r\n                optimizer = Adam(...)\r\n                return {\r\n                    \"optimizer\": optimizer,\r\n                    \"lr_scheduler\": {\r\n                        \"scheduler\": ReduceLROnPlateau(optimizer, ...),\r\n                        \"monitor\": \"metric_to_track\",\r\n                        \"frequency\": \"indicates how often the metric is updated\",\r\n                    },\r\n                }\r\n\r\n\r\n            def configure_optimizers(self):\r\n                optimizer1 = Adam(...)\r\n                optimizer2 = SGD(...)\r\n                scheduler1 = ReduceLROnPlateau(optimizer1, ...)\r\n                scheduler2 = LambdaLR(optimizer2, ...)\r\n                return (\r\n                    {\r\n                        \"optimizer\": optimizer1,\r\n                        \"lr_scheduler\": {\r\n                            \"scheduler\": scheduler1,\r\n                            \"monitor\": \"metric_to_track\",\r\n                        },\r\n                    },\r\n                    {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\r\n                )\r\n\r\n        Metrics can be made available to monitor by simply logging it using\r\n        ``self.log('metric_to_track', metric_val)`` in your :class:`~lightning.pytorch.core.LightningModule`.\r\n\r\n        Note:\r\n            Some things to know:\r\n\r\n            - Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\r\n            - If a learning rate scheduler is specified in ``configure_optimizers()`` with key\r\n              ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\r\n              the scheduler's ``.step()`` method automatically in case of automatic optimization.\r\n            - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\r\n            - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\r\n            - If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\r\n              yourself.\r\n            - If you need to control how often the optimizer steps, override the :meth:`optimizer_step` hook.\r\n\r\n        \"\"\"\r\n        rank_zero_warn(\"`configure_optimizers` must be implemented to be used with the Lightning Trainer\")", "code_tokens": ["def", "configure_optimizers", "(", "self", ")", "-", ">", "OptimizerLRScheduler", ":", "rSTRING", "rank_zero_warn", "(", "STRING", ")"], "docstring": "REQUIRED: The scheduler instance The unit of the scheduler's step size, could also be 'step'. 'epoch' updates the scheduler on epoch end whereas 'step' updates it after a optimizer update. How many epochs/steps should pass between calls to `scheduler.step()`. 1 corresponds to updating the learning rate after every epoch/step. Metric to monitor for schedulers like `ReduceLROnPlateau` If set to `True`, will enforce that the value specified 'monitor' is available when the scheduler is updated, thus stopping training if not found. If set to `False`, it will only produce a warning If using the `LearningRateMonitor` callback to monitor the learning rate progress, this keyword can be used to specify a custom logged name The ReduceLROnPlateau scheduler requires a monitor If \"monitor\" references validation metrics, then \"frequency\" should be set to a multiple of \"trainer.check_val_every_n_epoch\". In the case of two optimizers, only one using the ReduceLROnPlateau scheduler", "docstring_tokens": ["required", "the", "scheduler", "instance", "the", "unit", "of", "the", "scheduler", "s", "step", "size", "could", "also", "be", "step", "epoch", "updates", "the", "scheduler", "on", "epoch", "end", "whereas", "step", "updates", "it", "after", "a", "optimizer", "update", "how", "many", "epochs", "steps", "should", "pass", "between", "calls", "to", "scheduler", "step", "1", "corresponds", "to", "updating", "the", "learning", "rate", "after", "every", "epoch", "step", "metric", "to", "monitor", "for", "schedulers", "like", "reducelronplateau", "if", "set", "to", "true", "will", "enforce", "that", "the", "value", "specified", "monitor", "is", "available", "when", "the", "scheduler", "is", "updated", "thus", "stopping", "training", "if", "not", "found", "if", "set", "to", "false", "it", "will", "only", "produce", "a", "warning", "if", "using", "the", "learningratemonitor", "callback", "to", "monitor", "the", "learning", "rate", "progress", "this", "keyword", "can", "be", "used", "to", "specify", "a", "custom", "logged", "name", "the", "reducelronplateau", "scheduler", "requires", "a", "monitor", "if", "monitor", "references", "validation", "metrics", "then", "frequency", "should", "be", "set", "to", "a", "multiple", "of", "trainer", "check_val_every_n_epoch", "in", "the", "case", "of", "two", "optimizers", "only", "one", "using", "the", "reducelronplateau", "scheduler"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 989, "end_line": 1089, "has_examples": false, "num_comments": 9, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_134", "original_string": "def manual_backward(self, loss: Tensor, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Call this directly from your :meth:`training_step` when doing optimizations manually. By using this,\r\n        Lightning can ensure that all the proper scaling gets applied when using mixed precision.\r\n\r\n        See :ref:`manual optimization<common/optimization:Manual optimization>` for more examples.\r\n\r\n        Example::\r\n\r\n            def training_step(...):\r\n                opt = self.optimizers()\r\n                loss = ...\r\n                opt.zero_grad()\r\n                self.manual_backward(loss)\r\n                opt.step()\r\n\r\n        Args:\r\n            loss: The tensor on which to compute gradients. Must have a graph attached.\r\n            *args: Additional positional arguments to be forwarded to :meth:`~torch.Tensor.backward`\r\n            **kwargs: Additional keyword arguments to be forwarded to :meth:`~torch.Tensor.backward`\r\n\r\n        \"\"\"\r\n        if self._fabric:\r\n            self._fabric.backward(loss, *args, **kwargs)\r\n        else:\r\n            self._verify_is_manual_optimization(\"manual_backward\")\r\n            self.trainer.strategy.backward(loss, None, *args, **kwargs)", "language": "python", "code": "def manual_backward(self, loss: Tensor, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Call this directly from your :meth:`training_step` when doing optimizations manually. By using this,\r\n        Lightning can ensure that all the proper scaling gets applied when using mixed precision.\r\n\r\n        See :ref:`manual optimization<common/optimization:Manual optimization>` for more examples.\r\n\r\n        Example::\r\n\r\n            def training_step(...):\r\n                opt = self.optimizers()\r\n                loss = ...\r\n                opt.zero_grad()\r\n                self.manual_backward(loss)\r\n                opt.step()\r\n\r\n        Args:\r\n            loss: The tensor on which to compute gradients. Must have a graph attached.\r\n            *args: Additional positional arguments to be forwarded to :meth:`~torch.Tensor.backward`\r\n            **kwargs: Additional keyword arguments to be forwarded to :meth:`~torch.Tensor.backward`\r\n\r\n        \"\"\"\r\n        if self._fabric:\r\n            self._fabric.backward(loss, *args, **kwargs)\r\n        else:\r\n            self._verify_is_manual_optimization(\"manual_backward\")\r\n            self.trainer.strategy.backward(loss, None, *args, **kwargs)", "code_tokens": ["def", "manual_backward", "(", "self", ",", "loss", ":", "Tensor", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "if", "self", ".", "_fabric", ":", "self", ".", "_fabric", ".", "backward", "(", "loss", ",", "*", "args", ",", "*", "*", "kwargs", ")", "else", ":", "self", ".", "_verify_is_manual_optimization", "(", "STRING", ")", "self", ".", "trainer", ".", "strategy", ".", "backward", "(", "loss", ",", "None", ",", "*", "args", ",", "*", "*", "kwargs", ")"], "docstring": "automatically applies scaling, etc...", "docstring_tokens": ["automatically", "applies", "scaling", "etc"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1091, "end_line": 1117, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_135", "original_string": "def toggle_optimizer(self, optimizer: Union[Optimizer, LightningOptimizer]) -> None:\r\n        \"\"\"Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to\r\n        prevent dangling gradients in multiple-optimizer setup.\r\n\r\n        It works with :meth:`untoggle_optimizer` to make sure ``param_requires_grad_state`` is properly reset.\r\n\r\n        Args:\r\n            optimizer: The optimizer to toggle.\r\n\r\n        \"\"\"\r\n        param_requires_grad_state = {}\r\n        for opt in self.trainer.optimizers:\r\n            for group in opt.param_groups:\r\n                for param in group[\"params\"]:\r\n                    if param in param_requires_grad_state:\r\n                        continue\r\n                    param_requires_grad_state[param] = param.requires_grad\r\n                    param.requires_grad = False\r\n\r\n        for group in optimizer.param_groups:\r\n            for param in group[\"params\"]:\r\n                param.requires_grad = param_requires_grad_state[param]\r\n        self._param_requires_grad_state = param_requires_grad_state", "language": "python", "code": "def toggle_optimizer(self, optimizer: Union[Optimizer, LightningOptimizer]) -> None:\r\n        \"\"\"Makes sure only the gradients of the current optimizer's parameters are calculated in the training step to\r\n        prevent dangling gradients in multiple-optimizer setup.\r\n\r\n        It works with :meth:`untoggle_optimizer` to make sure ``param_requires_grad_state`` is properly reset.\r\n\r\n        Args:\r\n            optimizer: The optimizer to toggle.\r\n\r\n        \"\"\"\r\n        param_requires_grad_state = {}\r\n        for opt in self.trainer.optimizers:\r\n            for group in opt.param_groups:\r\n                for param in group[\"params\"]:\r\n                    if param in param_requires_grad_state:\r\n                        continue\r\n                    param_requires_grad_state[param] = param.requires_grad\r\n                    param.requires_grad = False\r\n\r\n        for group in optimizer.param_groups:\r\n            for param in group[\"params\"]:\r\n                param.requires_grad = param_requires_grad_state[param]\r\n        self._param_requires_grad_state = param_requires_grad_state", "code_tokens": ["def", "toggle_optimizer", "(", "self", ",", "optimizer", ":", "Union", "[", "Optimizer", ",", "LightningOptimizer", "]", ")", "-", ">", "None", ":", "STRING", "param_requires_grad_state", "=", "{", "}", "for", "opt", "in", "self", ".", "trainer", ".", "optimizers", ":", "for", "group", "in", "opt", ".", "param_groups", ":", "for", "param", "in", "group", "[", "STRING", "]", ":", "if", "param", "in", "param_requires_grad_state", ":", "continue", "param_requires_grad_state", "[", "param", "]", "=", "param", ".", "requires_grad", "param", ".", "requires_grad", "=", "False", "for", "group", "in", "optimizer", ".", "param_groups", ":", "for", "param", "in", "group", "[", "STRING", "]", ":", "param", ".", "requires_grad", "=", "param_requires_grad_state", "[", "param", "]", "self", ".", "_param_requires_grad_state", "=", "param_requires_grad_state"], "docstring": "Iterate over all optimizer parameters to preserve their `requires_grad` information in case these are pre-defined during `configure_optimizers` If a param already appear in param_requires_grad_state, continue Then iterate over the current optimizer's parameters and set its `requires_grad` properties accordingly", "docstring_tokens": ["iterate", "over", "all", "optimizer", "parameters", "to", "preserve", "their", "requires_grad", "information", "in", "case", "these", "are", "pre", "defined", "during", "configure_optimizers", "if", "a", "param", "already", "appear", "in", "param_requires_grad_state", "continue", "then", "iterate", "over", "the", "current", "optimizer", "s", "parameters", "and", "set", "its", "requires_grad", "properties", "accordingly"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1138, "end_line": 1165, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_136", "original_string": "def untoggle_optimizer(self, optimizer: Union[Optimizer, LightningOptimizer]) -> None:\r\n        \"\"\"Resets the state of required gradients that were toggled with :meth:`toggle_optimizer`.\r\n\r\n        Args:\r\n            optimizer: The optimizer to untoggle.\r\n\r\n        \"\"\"\r\n        for opt in self.trainer.optimizers:\r\n            if not (opt is optimizer or (isinstance(optimizer, LightningOptimizer) and opt is optimizer.optimizer)):\r\n                for group in opt.param_groups:\r\n                    for param in group[\"params\"]:\r\n                        if param in self._param_requires_grad_state:\r\n                            param.requires_grad = self._param_requires_grad_state[param]\r\n        self._param_requires_grad_state = {}", "language": "python", "code": "def untoggle_optimizer(self, optimizer: Union[Optimizer, LightningOptimizer]) -> None:\r\n        \"\"\"Resets the state of required gradients that were toggled with :meth:`toggle_optimizer`.\r\n\r\n        Args:\r\n            optimizer: The optimizer to untoggle.\r\n\r\n        \"\"\"\r\n        for opt in self.trainer.optimizers:\r\n            if not (opt is optimizer or (isinstance(optimizer, LightningOptimizer) and opt is optimizer.optimizer)):\r\n                for group in opt.param_groups:\r\n                    for param in group[\"params\"]:\r\n                        if param in self._param_requires_grad_state:\r\n                            param.requires_grad = self._param_requires_grad_state[param]\r\n        self._param_requires_grad_state = {}", "code_tokens": ["def", "untoggle_optimizer", "(", "self", ",", "optimizer", ":", "Union", "[", "Optimizer", ",", "LightningOptimizer", "]", ")", "-", ">", "None", ":", "STRING", "for", "opt", "in", "self", ".", "trainer", ".", "optimizers", ":", "if", "not", "(", "opt", "is", "optimizer", "or", "(", "isinstance", "(", "optimizer", ",", "LightningOptimizer", ")", "and", "opt", "is", "optimizer", ".", "optimizer", ")", ")", ":", "for", "group", "in", "opt", ".", "param_groups", ":", "for", "param", "in", "group", "[", "STRING", "]", ":", "if", "param", "in", "self", ".", "_param_requires_grad_state", ":", "param", ".", "requires_grad", "=", "self", ".", "_param_requires_grad_state", "[", "param", "]", "self", ".", "_param_requires_grad_state", "=", "{", "}"], "docstring": "save memory", "docstring_tokens": ["save", "memory"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1167, "end_line": 1181, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_137", "original_string": "def configure_gradient_clipping(\r\n        self,\r\n        optimizer: Optimizer,\r\n        gradient_clip_val: Optional[Union[int, float]] = None,\r\n        gradient_clip_algorithm: Optional[str] = None,\r\n    ) -> None:\r\n        \"\"\"Perform gradient clipping for the optimizer parameters. Called before :meth:`optimizer_step`.\r\n\r\n        Args:\r\n            optimizer: Current optimizer being used.\r\n            gradient_clip_val: The value at which to clip gradients. By default, value passed in Trainer\r\n                will be available here.\r\n            gradient_clip_algorithm: The gradient clipping algorithm to use. By default, value\r\n                passed in Trainer will be available here.\r\n\r\n        Example::\r\n\r\n            def configure_gradient_clipping(self, optimizer, gradient_clip_val, gradient_clip_algorithm):\r\n                self.clip_gradients(\r\n                    optimizer,\r\n                    gradient_clip_val=gradient_clip_val,\r\n                    gradient_clip_algorithm=gradient_clip_algorithm\r\n                )\r\n\r\n        \"\"\"\r\n        self.clip_gradients(\r\n            optimizer, gradient_clip_val=gradient_clip_val, gradient_clip_algorithm=gradient_clip_algorithm\r\n        )", "language": "python", "code": "def configure_gradient_clipping(\r\n        self,\r\n        optimizer: Optimizer,\r\n        gradient_clip_val: Optional[Union[int, float]] = None,\r\n        gradient_clip_algorithm: Optional[str] = None,\r\n    ) -> None:\r\n        \"\"\"Perform gradient clipping for the optimizer parameters. Called before :meth:`optimizer_step`.\r\n\r\n        Args:\r\n            optimizer: Current optimizer being used.\r\n            gradient_clip_val: The value at which to clip gradients. By default, value passed in Trainer\r\n                will be available here.\r\n            gradient_clip_algorithm: The gradient clipping algorithm to use. By default, value\r\n                passed in Trainer will be available here.\r\n\r\n        Example::\r\n\r\n            def configure_gradient_clipping(self, optimizer, gradient_clip_val, gradient_clip_algorithm):\r\n                self.clip_gradients(\r\n                    optimizer,\r\n                    gradient_clip_val=gradient_clip_val,\r\n                    gradient_clip_algorithm=gradient_clip_algorithm\r\n                )\r\n\r\n        \"\"\"\r\n        self.clip_gradients(\r\n            optimizer, gradient_clip_val=gradient_clip_val, gradient_clip_algorithm=gradient_clip_algorithm\r\n        )", "code_tokens": ["def", "configure_gradient_clipping", "(", "self", ",", "optimizer", ":", "Optimizer", ",", "gradient_clip_val", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "gradient_clip_algorithm", ":", "Optional", "[", "str", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "clip_gradients", "(", "optimizer", ",", "gradient_clip_val", "=", "gradient_clip_val", ",", "gradient_clip_algorithm", "=", "gradient_clip_algorithm", ")"], "docstring": "Implement your own custom logic to clip gradients You can call `self.clip_gradients` with your settings:", "docstring_tokens": ["implement", "your", "own", "custom", "logic", "to", "clip", "gradients", "you", "can", "call", "self", "clip_gradients", "with", "your", "settings"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1277, "end_line": 1306, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_138", "original_string": "def lr_scheduler_step(self, scheduler: LRSchedulerTypeUnion, metric: Optional[Any]) -> None:\r\n        r\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\r\n        each scheduler. By default, Lightning calls ``step()`` and as shown in the example for each scheduler based on\r\n        its ``interval``.\r\n\r\n        Args:\r\n            scheduler: Learning rate scheduler.\r\n            metric: Value of the monitor used for schedulers like ``ReduceLROnPlateau``.\r\n\r\n        Examples::\r\n\r\n            def lr_scheduler_step(self, scheduler, metric):\r\n                if metric is None:\r\n                    scheduler.step()\r\n                else:\r\n                    scheduler.step(metric)\r\n\r\n            def lr_scheduler_step(self, scheduler, metric):\r\n                scheduler.step(epoch=self.current_epoch)\r\n\r\n        \"\"\"\r\n        if metric is None:\r\n            scheduler.step()  # type: ignore[call-arg]\r\n        else:\r\n            scheduler.step(metric)", "language": "python", "code": "def lr_scheduler_step(self, scheduler: LRSchedulerTypeUnion, metric: Optional[Any]) -> None:\r\n        r\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\r\n        each scheduler. By default, Lightning calls ``step()`` and as shown in the example for each scheduler based on\r\n        its ``interval``.\r\n\r\n        Args:\r\n            scheduler: Learning rate scheduler.\r\n            metric: Value of the monitor used for schedulers like ``ReduceLROnPlateau``.\r\n\r\n        Examples::\r\n\r\n            def lr_scheduler_step(self, scheduler, metric):\r\n                if metric is None:\r\n                    scheduler.step()\r\n                else:\r\n                    scheduler.step(metric)\r\n\r\n            def lr_scheduler_step(self, scheduler, metric):\r\n                scheduler.step(epoch=self.current_epoch)\r\n\r\n        \"\"\"\r\n        if metric is None:\r\n            scheduler.step()  # type: ignore[call-arg]\r\n        else:\r\n            scheduler.step(metric)", "code_tokens": ["def", "lr_scheduler_step", "(", "self", ",", "scheduler", ":", "LRSchedulerTypeUnion", ",", "metric", ":", "Optional", "[", "Any", "]", ")", "-", ">", "None", ":", "rSTRING", "if", "metric", "is", "None", ":", "scheduler", ".", "step", "(", ")", "#", "type", ":", "ignore", "[", "call", "-", "arg", "]", "else", ":", "scheduler", ".", "step", "(", "metric", ")"], "docstring": "DEFAULT Alternative way to update schedulers if it requires an epoch value", "docstring_tokens": ["default", "alternative", "way", "to", "update", "schedulers", "if", "it", "requires", "an", "epoch", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1308, "end_line": 1334, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_139", "original_string": "def optimizer_zero_grad(self, epoch: int, batch_idx: int, optimizer: Optimizer) -> None:\r\n        \"\"\"Override this method to change the default behaviour of ``optimizer.zero_grad()``.\r\n\r\n        Args:\r\n            epoch: Current epoch\r\n            batch_idx: Index of current batch\r\n            optimizer: A PyTorch optimizer\r\n\r\n        Examples::\r\n\r\n            def optimizer_zero_grad(self, epoch, batch_idx, optimizer):\r\n                optimizer.zero_grad()\r\n\r\n            def optimizer_zero_grad(self, epoch, batch_idx, optimizer):\r\n                optimizer.zero_grad(set_to_none=True)\r\n\r\n        See :meth:`torch.optim.Optimizer.zero_grad` for the explanation of the above example.\r\n\r\n        \"\"\"\r\n        optimizer.zero_grad()", "language": "python", "code": "def optimizer_zero_grad(self, epoch: int, batch_idx: int, optimizer: Optimizer) -> None:\r\n        \"\"\"Override this method to change the default behaviour of ``optimizer.zero_grad()``.\r\n\r\n        Args:\r\n            epoch: Current epoch\r\n            batch_idx: Index of current batch\r\n            optimizer: A PyTorch optimizer\r\n\r\n        Examples::\r\n\r\n            def optimizer_zero_grad(self, epoch, batch_idx, optimizer):\r\n                optimizer.zero_grad()\r\n\r\n            def optimizer_zero_grad(self, epoch, batch_idx, optimizer):\r\n                optimizer.zero_grad(set_to_none=True)\r\n\r\n        See :meth:`torch.optim.Optimizer.zero_grad` for the explanation of the above example.\r\n\r\n        \"\"\"\r\n        optimizer.zero_grad()", "code_tokens": ["def", "optimizer_zero_grad", "(", "self", ",", "epoch", ":", "int", ",", "batch_idx", ":", "int", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "None", ":", "STRING", "optimizer", ".", "zero_grad", "(", ")"], "docstring": "DEFAULT Set gradients to `None` instead of zero to improve performance (not required on `torch>=2.0.0`).", "docstring_tokens": ["default", "set", "gradients", "to", "none", "instead", "of", "zero", "to", "improve", "performance", "not", "required", "on", "torch", "2", "0", "0"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1369, "end_line": 1390, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_140", "original_string": "def to_onnx(\r\n        self,\r\n        file_path: Union[str, Path, BytesIO, None] = None,\r\n        input_sample: Optional[Any] = None,\r\n        **kwargs: Any,\r\n    ) -> Optional[\"ONNXProgram\"]:\r\n        \"\"\"Saves the model in ONNX format.\r\n\r\n        Args:\r\n            file_path: The path of the file the onnx model should be saved to. Default: None (no file saved).\r\n            input_sample: An input for tracing. Default: None (Use self.example_input_array)\r\n\r\n            **kwargs: Will be passed to torch.onnx.export function.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)\r\n\r\n            model = SimpleModel()\r\n            input_sample = torch.randn(1, 64)\r\n            model.to_onnx(\"export.onnx\", input_sample, export_params=True)\r\n\r\n        \"\"\"\r\n        if not _ONNX_AVAILABLE:\r\n            raise ModuleNotFoundError(f\"`{type(self).__name__}.to_onnx()` requires `onnx` to be installed.\")\r\n\r\n        if kwargs.get(\"dynamo\", False) and not (_ONNXSCRIPT_AVAILABLE and _TORCH_GREATER_EQUAL_2_5):\r\n            raise ModuleNotFoundError(\r\n                f\"`{type(self).__name__}.to_onnx(dynamo=True)` \"\r\n                \"requires `onnxscript` and `torch>=2.5.0` to be installed.\"\r\n            )\r\n\r\n        mode = self.training\r\n\r\n        if input_sample is None:\r\n            if self.example_input_array is None:\r\n                raise ValueError(\r\n                    \"Could not export to ONNX since neither `input_sample` nor\"\r\n                    \" `model.example_input_array` attribute is set.\"\r\n                )\r\n            input_sample = self.example_input_array\r\n\r\n        input_sample = self._on_before_batch_transfer(input_sample)\r\n        input_sample = self._apply_batch_transfer_handler(input_sample)\r\n\r\n        file_path = str(file_path) if isinstance(file_path, Path) else file_path\r\n        ret = torch.onnx.export(self, input_sample, file_path, **kwargs)  # type: ignore\r\n        self.train(mode)\r\n        return ret", "language": "python", "code": "def to_onnx(\r\n        self,\r\n        file_path: Union[str, Path, BytesIO, None] = None,\r\n        input_sample: Optional[Any] = None,\r\n        **kwargs: Any,\r\n    ) -> Optional[\"ONNXProgram\"]:\r\n        \"\"\"Saves the model in ONNX format.\r\n\r\n        Args:\r\n            file_path: The path of the file the onnx model should be saved to. Default: None (no file saved).\r\n            input_sample: An input for tracing. Default: None (Use self.example_input_array)\r\n\r\n            **kwargs: Will be passed to torch.onnx.export function.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)\r\n\r\n            model = SimpleModel()\r\n            input_sample = torch.randn(1, 64)\r\n            model.to_onnx(\"export.onnx\", input_sample, export_params=True)\r\n\r\n        \"\"\"\r\n        if not _ONNX_AVAILABLE:\r\n            raise ModuleNotFoundError(f\"`{type(self).__name__}.to_onnx()` requires `onnx` to be installed.\")\r\n\r\n        if kwargs.get(\"dynamo\", False) and not (_ONNXSCRIPT_AVAILABLE and _TORCH_GREATER_EQUAL_2_5):\r\n            raise ModuleNotFoundError(\r\n                f\"`{type(self).__name__}.to_onnx(dynamo=True)` \"\r\n                \"requires `onnxscript` and `torch>=2.5.0` to be installed.\"\r\n            )\r\n\r\n        mode = self.training\r\n\r\n        if input_sample is None:\r\n            if self.example_input_array is None:\r\n                raise ValueError(\r\n                    \"Could not export to ONNX since neither `input_sample` nor\"\r\n                    \" `model.example_input_array` attribute is set.\"\r\n                )\r\n            input_sample = self.example_input_array\r\n\r\n        input_sample = self._on_before_batch_transfer(input_sample)\r\n        input_sample = self._apply_batch_transfer_handler(input_sample)\r\n\r\n        file_path = str(file_path) if isinstance(file_path, Path) else file_path\r\n        ret = torch.onnx.export(self, input_sample, file_path, **kwargs)  # type: ignore\r\n        self.train(mode)\r\n        return ret", "code_tokens": ["def", "to_onnx", "(", "self", ",", "file_path", ":", "Union", "[", "str", ",", "Path", ",", "BytesIO", ",", "None", "]", "=", "None", ",", "input_sample", ":", "Optional", "[", "Any", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "Optional", "[", "STRING", "]", ":", "STRING", "if", "not", "_ONNX_AVAILABLE", ":", "raise", "ModuleNotFoundError", "(", "fSTRING", ")", "if", "kwargs", ".", "get", "(", "STRING", ",", "False", ")", "and", "not", "(", "_ONNXSCRIPT_AVAILABLE", "and", "_TORCH_GREATER_EQUAL_2_5", ")", ":", "raise", "ModuleNotFoundError", "(", "fSTRING", "STRING", ")", "mode", "=", "self", ".", "training", "if", "input_sample", "is", "None", ":", "if", "self", ".", "example_input_array", "is", "None", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "input_sample", "=", "self", ".", "example_input_array", "input_sample", "=", "self", ".", "_on_before_batch_transfer", "(", "input_sample", ")", "input_sample", "=", "self", ".", "_apply_batch_transfer_handler", "(", "input_sample", ")", "file_path", "=", "str", "(", "file_path", ")", "if", "isinstance", "(", "file_path", ",", "Path", ")", "else", "file_path", "ret", "=", "torch", ".", "onnx", ".", "export", "(", "self", ",", "input_sample", ",", "file_path", ",", "*", "*", "kwargs", ")", "#", "type", ":", "ignore", "self", ".", "train", "(", "mode", ")", "return", "ret"], "docstring": "PyTorch (2.5) declares file_path to be str | PathLike[Any] | None, but BytesIO does work, too.", "docstring_tokens": ["pytorch", "2", "5", "declares", "file_path", "to", "be", "str", "pathlike", "any", "none", "but", "bytesio", "does", "work", "too"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1428, "end_line": 1484, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_141", "original_string": "def to_torchscript(\r\n        self,\r\n        file_path: Optional[Union[str, Path]] = None,\r\n        method: Optional[str] = \"script\",\r\n        example_inputs: Optional[Any] = None,\r\n        **kwargs: Any,\r\n    ) -> Union[ScriptModule, dict[str, ScriptModule]]:\r\n        \"\"\"By default compiles the whole model to a :class:`~torch.jit.ScriptModule`. If you want to use tracing,\r\n        please provided the argument ``method='trace'`` and make sure that either the `example_inputs` argument is\r\n        provided, or the model has :attr:`example_input_array` set. If you would like to customize the modules that are\r\n        scripted you should override this method. In case you want to return multiple modules, we recommend using a\r\n        dictionary.\r\n\r\n        Args:\r\n            file_path: Path where to save the torchscript. Default: None (no file saved).\r\n            method: Whether to use TorchScript's script or trace method. Default: 'script'\r\n            example_inputs: An input to be used to do tracing when method is set to 'trace'.\r\n              Default: None (uses :attr:`example_input_array`)\r\n            **kwargs: Additional arguments that will be passed to the :func:`torch.jit.script` or\r\n              :func:`torch.jit.trace` function.\r\n\r\n        Note:\r\n            - Requires the implementation of the\r\n              :meth:`~lightning.pytorch.core.LightningModule.forward` method.\r\n            - The exported script will be set to evaluation mode.\r\n            - It is recommended that you install the latest supported version of PyTorch\r\n              to use this feature without limitations. See also the :mod:`torch.jit`\r\n              documentation for supported features.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n            model = SimpleModel()\r\n            model.to_torchscript(file_path=\"model.pt\")\r\n\r\n            torch.jit.save(model.to_torchscript(\r\n                file_path=\"model_trace.pt\", method='trace', example_inputs=torch.randn(1, 64))\r\n            )\r\n\r\n        Return:\r\n            This LightningModule as a torchscript, regardless of whether `file_path` is\r\n            defined or not.\r\n\r\n        \"\"\"\r\n        mode = self.training\r\n\r\n        if method == \"script\":\r\n            with _jit_is_scripting():\r\n                torchscript_module = torch.jit.script(self.eval(), **kwargs)\r\n        elif method == \"trace\":\r\n            if example_inputs is None:\r\n                if self.example_input_array is None:\r\n                    raise ValueError(\r\n                        \"Choosing method=`trace` requires either `example_inputs`\"\r\n                        \" or `model.example_input_array` to be defined.\"\r\n                    )\r\n                example_inputs = self.example_input_array\r\n\r\n            if kwargs.get(\"check_inputs\") is not None:\r\n                kwargs[\"check_inputs\"] = self._on_before_batch_transfer(kwargs[\"check_inputs\"])\r\n                kwargs[\"check_inputs\"] = self._apply_batch_transfer_handler(kwargs[\"check_inputs\"])\r\n\r\n            example_inputs = self._on_before_batch_transfer(example_inputs)\r\n            example_inputs = self._apply_batch_transfer_handler(example_inputs)\r\n            with _jit_is_scripting():\r\n                torchscript_module = torch.jit.trace(func=self.eval(), example_inputs=example_inputs, **kwargs)\r\n        else:\r\n            raise ValueError(f\"The 'method' parameter only supports 'script' or 'trace', but value given was: {method}\")\r\n\r\n        self.train(mode)\r\n\r\n        if file_path is not None:\r\n            fs = get_filesystem(file_path)\r\n            with fs.open(file_path, \"wb\") as f:\r\n                torch.jit.save(torchscript_module, f)\r\n\r\n        return torchscript_module", "language": "python", "code": "def to_torchscript(\r\n        self,\r\n        file_path: Optional[Union[str, Path]] = None,\r\n        method: Optional[str] = \"script\",\r\n        example_inputs: Optional[Any] = None,\r\n        **kwargs: Any,\r\n    ) -> Union[ScriptModule, dict[str, ScriptModule]]:\r\n        \"\"\"By default compiles the whole model to a :class:`~torch.jit.ScriptModule`. If you want to use tracing,\r\n        please provided the argument ``method='trace'`` and make sure that either the `example_inputs` argument is\r\n        provided, or the model has :attr:`example_input_array` set. If you would like to customize the modules that are\r\n        scripted you should override this method. In case you want to return multiple modules, we recommend using a\r\n        dictionary.\r\n\r\n        Args:\r\n            file_path: Path where to save the torchscript. Default: None (no file saved).\r\n            method: Whether to use TorchScript's script or trace method. Default: 'script'\r\n            example_inputs: An input to be used to do tracing when method is set to 'trace'.\r\n              Default: None (uses :attr:`example_input_array`)\r\n            **kwargs: Additional arguments that will be passed to the :func:`torch.jit.script` or\r\n              :func:`torch.jit.trace` function.\r\n\r\n        Note:\r\n            - Requires the implementation of the\r\n              :meth:`~lightning.pytorch.core.LightningModule.forward` method.\r\n            - The exported script will be set to evaluation mode.\r\n            - It is recommended that you install the latest supported version of PyTorch\r\n              to use this feature without limitations. See also the :mod:`torch.jit`\r\n              documentation for supported features.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)))\r\n\r\n            model = SimpleModel()\r\n            model.to_torchscript(file_path=\"model.pt\")\r\n\r\n            torch.jit.save(model.to_torchscript(\r\n                file_path=\"model_trace.pt\", method='trace', example_inputs=torch.randn(1, 64))\r\n            )\r\n\r\n        Return:\r\n            This LightningModule as a torchscript, regardless of whether `file_path` is\r\n            defined or not.\r\n\r\n        \"\"\"\r\n        mode = self.training\r\n\r\n        if method == \"script\":\r\n            with _jit_is_scripting():\r\n                torchscript_module = torch.jit.script(self.eval(), **kwargs)\r\n        elif method == \"trace\":\r\n            if example_inputs is None:\r\n                if self.example_input_array is None:\r\n                    raise ValueError(\r\n                        \"Choosing method=`trace` requires either `example_inputs`\"\r\n                        \" or `model.example_input_array` to be defined.\"\r\n                    )\r\n                example_inputs = self.example_input_array\r\n\r\n            if kwargs.get(\"check_inputs\") is not None:\r\n                kwargs[\"check_inputs\"] = self._on_before_batch_transfer(kwargs[\"check_inputs\"])\r\n                kwargs[\"check_inputs\"] = self._apply_batch_transfer_handler(kwargs[\"check_inputs\"])\r\n\r\n            example_inputs = self._on_before_batch_transfer(example_inputs)\r\n            example_inputs = self._apply_batch_transfer_handler(example_inputs)\r\n            with _jit_is_scripting():\r\n                torchscript_module = torch.jit.trace(func=self.eval(), example_inputs=example_inputs, **kwargs)\r\n        else:\r\n            raise ValueError(f\"The 'method' parameter only supports 'script' or 'trace', but value given was: {method}\")\r\n\r\n        self.train(mode)\r\n\r\n        if file_path is not None:\r\n            fs = get_filesystem(file_path)\r\n            with fs.open(file_path, \"wb\") as f:\r\n                torch.jit.save(torchscript_module, f)\r\n\r\n        return torchscript_module", "code_tokens": ["def", "to_torchscript", "(", "self", ",", "file_path", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "method", ":", "Optional", "[", "str", "]", "=", "STRING", ",", "example_inputs", ":", "Optional", "[", "Any", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "Union", "[", "ScriptModule", ",", "dict", "[", "str", ",", "ScriptModule", "]", "]", ":", "STRING", "mode", "=", "self", ".", "training", "if", "method", "=", "=", "STRING", ":", "with", "_jit_is_scripting", "(", ")", ":", "torchscript_module", "=", "torch", ".", "jit", ".", "script", "(", "self", ".", "eval", "(", ")", ",", "*", "*", "kwargs", ")", "elif", "method", "=", "=", "STRING", ":", "if", "example_inputs", "is", "None", ":", "if", "self", ".", "example_input_array", "is", "None", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "example_inputs", "=", "self", ".", "example_input_array", "if", "kwargs", ".", "get", "(", "STRING", ")", "is", "not", "None", ":", "kwargs", "[", "STRING", "]", "=", "self", ".", "_on_before_batch_transfer", "(", "kwargs", "[", "STRING", "]", ")", "kwargs", "[", "STRING", "]", "=", "self", ".", "_apply_batch_transfer_handler", "(", "kwargs", "[", "STRING", "]", ")", "example_inputs", "=", "self", ".", "_on_before_batch_transfer", "(", "example_inputs", ")", "example_inputs", "=", "self", ".", "_apply_batch_transfer_handler", "(", "example_inputs", ")", "with", "_jit_is_scripting", "(", ")", ":", "torchscript_module", "=", "torch", ".", "jit", ".", "trace", "(", "func", "=", "self", ".", "eval", "(", ")", ",", "example_inputs", "=", "example_inputs", ",", "*", "*", "kwargs", ")", "else", ":", "raise", "ValueError", "(", "fSTRING", ")", "self", ".", "train", "(", "mode", ")", "if", "file_path", "is", "not", "None", ":", "fs", "=", "get_filesystem", "(", "file_path", ")", "with", "fs", ".", "open", "(", "file_path", ",", "STRING", ")", "as", "f", ":", "torch", ".", "jit", ".", "save", "(", "torchscript_module", ",", "f", ")", "return", "torchscript_module"], "docstring": "if no example inputs are provided, try to see if model has example_input_array set automatically send example inputs to the right device and use trace", "docstring_tokens": ["if", "no", "example", "inputs", "are", "provided", "try", "to", "see", "if", "model", "has", "example_input_array", "set", "automatically", "send", "example", "inputs", "to", "the", "right", "device", "and", "use", "trace"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1487, "end_line": 1572, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_142", "original_string": "def to_tensorrt(\r\n        self,\r\n        file_path: Optional[Union[str, Path, BytesIO]] = None,\r\n        input_sample: Optional[Any] = None,\r\n        ir: Literal[\"default\", \"dynamo\", \"ts\"] = \"default\",\r\n        output_format: Literal[\"exported_program\", \"torchscript\"] = \"exported_program\",\r\n        retrace: bool = False,\r\n        default_device: Union[str, torch.device] = \"cuda\",\r\n        **compile_kwargs: Any,\r\n    ) -> Union[ScriptModule, torch.fx.GraphModule]:\r\n        \"\"\"Export the model to ScriptModule or GraphModule using TensorRT compile backend.\r\n\r\n        Args:\r\n            file_path: Path where to save the tensorrt model. Default: None (no file saved).\r\n            input_sample: inputs to be used during `torch_tensorrt.compile`.\r\n                Default: None (Use :attr:`example_input_array`).\r\n            ir: The IR mode to use for TensorRT compilation. Default: \"default\".\r\n            output_format: The format of the output model. Default: \"exported_program\".\r\n            retrace: Whether to retrace the model. Default: False.\r\n            default_device: The device to use for the model when the current model is not in CUDA. Default: \"cuda\".\r\n            **compile_kwargs: Additional arguments that will be passed to the TensorRT compile function.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)\r\n\r\n            model = SimpleModel()\r\n            input_sample = torch.randn(1, 64)\r\n            exported_program = model.to_tensorrt(\r\n                file_path=\"export.ep\",\r\n                inputs=input_sample,\r\n            )\r\n\r\n        \"\"\"\r\n        if not _TORCH_GREATER_EQUAL_2_2:\r\n            raise MisconfigurationException(\r\n                f\"TensorRT export requires PyTorch 2.2 or higher. Current version is {torch.__version__}.\"\r\n            )\r\n\r\n        if not _TORCH_TRT_AVAILABLE:\r\n            raise ModuleNotFoundError(\r\n                f\"`{type(self).__name__}.to_tensorrt` requires `torch_tensorrt` to be installed. \"\r\n            )\r\n\r\n        mode = self.training\r\n        device = self.device\r\n        if self.device.type != \"cuda\":\r\n            default_device = torch.device(default_device) if isinstance(default_device, str) else default_device\r\n\r\n            if not torch.cuda.is_available() or default_device.type != \"cuda\":\r\n                raise MisconfigurationException(\r\n                    f\"TensorRT only supports CUDA devices. The current device is {self.device}.\"\r\n                    f\" Please set the `default_device` argument to a CUDA device.\"\r\n                )\r\n\r\n            self.to(default_device)\r\n\r\n        if input_sample is None:\r\n            if self.example_input_array is None:\r\n                raise ValueError(\r\n                    \"Could not export to TensorRT since neither `input_sample` nor\"\r\n                    \" `model.example_input_array` attribute is set.\"\r\n                )\r\n            input_sample = self.example_input_array\r\n\r\n        import torch_tensorrt\r\n\r\n        input_sample = copy.deepcopy((input_sample,) if isinstance(input_sample, torch.Tensor) else input_sample)\r\n        input_sample = self._on_before_batch_transfer(input_sample)\r\n        input_sample = self._apply_batch_transfer_handler(input_sample)\r\n\r\n        with _jit_is_scripting() if ir == \"ts\" else nullcontext():\r\n            trt_obj = torch_tensorrt.compile(\r\n                module=self.eval(),\r\n                ir=ir,\r\n                inputs=input_sample,\r\n                **compile_kwargs,\r\n            )\r\n        self.train(mode)\r\n        self.to(device)\r\n\r\n        if file_path is not None:\r\n            if ir == \"ts\":\r\n                if output_format != \"torchscript\":\r\n                    raise ValueError(\r\n                        \"TensorRT with IR mode 'ts' only supports output format 'torchscript'.\"\r\n                        f\" The current output format is {output_format}.\"\r\n                    )\r\n                assert isinstance(trt_obj, (torch.jit.ScriptModule, torch.jit.ScriptFunction)), (\r\n                    f\"Expected TensorRT object to be a ScriptModule, but got {type(trt_obj)}.\"\r\n                )\r\n                torch.jit.save(trt_obj, file_path)\r\n            else:\r\n                torch_tensorrt.save(\r\n                    trt_obj,\r\n                    file_path,\r\n                    inputs=input_sample,\r\n                    output_format=output_format,\r\n                    retrace=retrace,\r\n                )\r\n        return trt_obj", "language": "python", "code": "def to_tensorrt(\r\n        self,\r\n        file_path: Optional[Union[str, Path, BytesIO]] = None,\r\n        input_sample: Optional[Any] = None,\r\n        ir: Literal[\"default\", \"dynamo\", \"ts\"] = \"default\",\r\n        output_format: Literal[\"exported_program\", \"torchscript\"] = \"exported_program\",\r\n        retrace: bool = False,\r\n        default_device: Union[str, torch.device] = \"cuda\",\r\n        **compile_kwargs: Any,\r\n    ) -> Union[ScriptModule, torch.fx.GraphModule]:\r\n        \"\"\"Export the model to ScriptModule or GraphModule using TensorRT compile backend.\r\n\r\n        Args:\r\n            file_path: Path where to save the tensorrt model. Default: None (no file saved).\r\n            input_sample: inputs to be used during `torch_tensorrt.compile`.\r\n                Default: None (Use :attr:`example_input_array`).\r\n            ir: The IR mode to use for TensorRT compilation. Default: \"default\".\r\n            output_format: The format of the output model. Default: \"exported_program\".\r\n            retrace: Whether to retrace the model. Default: False.\r\n            default_device: The device to use for the model when the current model is not in CUDA. Default: \"cuda\".\r\n            **compile_kwargs: Additional arguments that will be passed to the TensorRT compile function.\r\n\r\n        Example::\r\n\r\n            class SimpleModel(LightningModule):\r\n                def __init__(self):\r\n                    super().__init__()\r\n                    self.l1 = torch.nn.Linear(in_features=64, out_features=4)\r\n\r\n                def forward(self, x):\r\n                    return torch.relu(self.l1(x.view(x.size(0), -1)\r\n\r\n            model = SimpleModel()\r\n            input_sample = torch.randn(1, 64)\r\n            exported_program = model.to_tensorrt(\r\n                file_path=\"export.ep\",\r\n                inputs=input_sample,\r\n            )\r\n\r\n        \"\"\"\r\n        if not _TORCH_GREATER_EQUAL_2_2:\r\n            raise MisconfigurationException(\r\n                f\"TensorRT export requires PyTorch 2.2 or higher. Current version is {torch.__version__}.\"\r\n            )\r\n\r\n        if not _TORCH_TRT_AVAILABLE:\r\n            raise ModuleNotFoundError(\r\n                f\"`{type(self).__name__}.to_tensorrt` requires `torch_tensorrt` to be installed. \"\r\n            )\r\n\r\n        mode = self.training\r\n        device = self.device\r\n        if self.device.type != \"cuda\":\r\n            default_device = torch.device(default_device) if isinstance(default_device, str) else default_device\r\n\r\n            if not torch.cuda.is_available() or default_device.type != \"cuda\":\r\n                raise MisconfigurationException(\r\n                    f\"TensorRT only supports CUDA devices. The current device is {self.device}.\"\r\n                    f\" Please set the `default_device` argument to a CUDA device.\"\r\n                )\r\n\r\n            self.to(default_device)\r\n\r\n        if input_sample is None:\r\n            if self.example_input_array is None:\r\n                raise ValueError(\r\n                    \"Could not export to TensorRT since neither `input_sample` nor\"\r\n                    \" `model.example_input_array` attribute is set.\"\r\n                )\r\n            input_sample = self.example_input_array\r\n\r\n        import torch_tensorrt\r\n\r\n        input_sample = copy.deepcopy((input_sample,) if isinstance(input_sample, torch.Tensor) else input_sample)\r\n        input_sample = self._on_before_batch_transfer(input_sample)\r\n        input_sample = self._apply_batch_transfer_handler(input_sample)\r\n\r\n        with _jit_is_scripting() if ir == \"ts\" else nullcontext():\r\n            trt_obj = torch_tensorrt.compile(\r\n                module=self.eval(),\r\n                ir=ir,\r\n                inputs=input_sample,\r\n                **compile_kwargs,\r\n            )\r\n        self.train(mode)\r\n        self.to(device)\r\n\r\n        if file_path is not None:\r\n            if ir == \"ts\":\r\n                if output_format != \"torchscript\":\r\n                    raise ValueError(\r\n                        \"TensorRT with IR mode 'ts' only supports output format 'torchscript'.\"\r\n                        f\" The current output format is {output_format}.\"\r\n                    )\r\n                assert isinstance(trt_obj, (torch.jit.ScriptModule, torch.jit.ScriptFunction)), (\r\n                    f\"Expected TensorRT object to be a ScriptModule, but got {type(trt_obj)}.\"\r\n                )\r\n                torch.jit.save(trt_obj, file_path)\r\n            else:\r\n                torch_tensorrt.save(\r\n                    trt_obj,\r\n                    file_path,\r\n                    inputs=input_sample,\r\n                    output_format=output_format,\r\n                    retrace=retrace,\r\n                )\r\n        return trt_obj", "code_tokens": ["def", "to_tensorrt", "(", "self", ",", "file_path", ":", "Optional", "[", "Union", "[", "str", ",", "Path", ",", "BytesIO", "]", "]", "=", "None", ",", "input_sample", ":", "Optional", "[", "Any", "]", "=", "None", ",", "ir", ":", "Literal", "[", "STRING", ",", "STRING", ",", "STRING", "]", "=", "STRING", ",", "output_format", ":", "Literal", "[", "STRING", ",", "STRING", "]", "=", "STRING", ",", "retrace", ":", "bool", "=", "False", ",", "default_device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "STRING", ",", "*", "*", "compile_kwargs", ":", "Any", ",", ")", "-", ">", "Union", "[", "ScriptModule", ",", "torch", ".", "fx", ".", "GraphModule", "]", ":", "STRING", "if", "not", "_TORCH_GREATER_EQUAL_2_2", ":", "raise", "MisconfigurationException", "(", "fSTRING", ")", "if", "not", "_TORCH_TRT_AVAILABLE", ":", "raise", "ModuleNotFoundError", "(", "fSTRING", ")", "mode", "=", "self", ".", "training", "device", "=", "self", ".", "device", "if", "self", ".", "device", ".", "type", "!", "=", "STRING", ":", "default_device", "=", "torch", ".", "device", "(", "default_device", ")", "if", "isinstance", "(", "default_device", ",", "str", ")", "else", "default_device", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "or", "default_device", ".", "type", "!", "=", "STRING", ":", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", ")", "self", ".", "to", "(", "default_device", ")", "if", "input_sample", "is", "None", ":", "if", "self", ".", "example_input_array", "is", "None", ":", "raise", "ValueError", "(", "STRING", "STRING", ")", "input_sample", "=", "self", ".", "example_input_array", "import", "torch_tensorrt", "input_sample", "=", "copy", ".", "deepcopy", "(", "(", "input_sample", ",", ")", "if", "isinstance", "(", "input_sample", ",", "torch", ".", "Tensor", ")", "else", "input_sample", ")", "input_sample", "=", "self", ".", "_on_before_batch_transfer", "(", "input_sample", ")", "input_sample", "=", "self", ".", "_apply_batch_transfer_handler", "(", "input_sample", ")", "with", "_jit_is_scripting", "(", ")", "if", "ir", "=", "=", "STRING", "else", "nullcontext", "(", ")", ":", "trt_obj", "=", "torch_tensorrt", ".", "compile", "(", "module", "=", "self", ".", "eval", "(", ")", ",", "ir", "=", "ir", ",", "inputs", "=", "input_sample", ",", "*", "*", "compile_kwargs", ",", ")", "self", ".", "train", "(", "mode", ")", "self", ".", "to", "(", "device", ")", "if", "file_path", "is", "not", "None", ":", "if", "ir", "=", "=", "STRING", ":", "if", "output_format", "!", "=", "STRING", ":", "raise", "ValueError", "(", "STRING", "fSTRING", ")", "assert", "isinstance", "(", "trt_obj", ",", "(", "torch", ".", "jit", ".", "ScriptModule", ",", "torch", ".", "jit", ".", "ScriptFunction", ")", ")", ",", "(", "fSTRING", ")", "torch", ".", "jit", ".", "save", "(", "trt_obj", ",", "file_path", ")", "else", ":", "torch_tensorrt", ".", "save", "(", "trt_obj", ",", "file_path", ",", "inputs", "=", "input_sample", ",", "output_format", "=", "output_format", ",", "retrace", "=", "retrace", ",", ")", "return", "trt_obj"], "docstring": "Because of https://github.com/pytorch/TensorRT/issues/3775, we'll need to take special care for the ScriptModule", "docstring_tokens": ["because", "of", "https", "github", "com", "pytorch", "tensorrt", "issues", "3775", "we", "ll", "need", "to", "take", "special", "care", "for", "the", "scriptmodule"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1575, "end_line": 1683, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\module.py", "func_name": "function_143", "original_string": "def load_from_checkpoint(\r\n        cls,\r\n        checkpoint_path: Union[_PATH, IO],\r\n        map_location: _MAP_LOCATION_TYPE = None,\r\n        hparams_file: Optional[_PATH] = None,\r\n        strict: Optional[bool] = None,\r\n        **kwargs: Any,\r\n    ) -> Self:\r\n        r\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\r\n        passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\r\n\r\n        Any arguments specified through \\*\\*kwargs will override args stored in ``\"hyper_parameters\"``.\r\n\r\n        Args:\r\n            checkpoint_path: Path to checkpoint. This can also be a URL, or file-like object\r\n            map_location:\r\n                If your checkpoint saved a GPU model and you now load on CPUs\r\n                or a different number of GPUs, use this to map to the new setup.\r\n                The behaviour is the same as in :func:`torch.load`.\r\n            hparams_file: Optional path to a ``.yaml`` or ``.csv`` file with hierarchical structure\r\n                as in this example::\r\n\r\n                    drop_prob: 0.2\r\n                    dataloader:\r\n                        batch_size: 32\r\n\r\n                You most likely won't need this since Lightning will always save the hyperparameters\r\n                to the checkpoint.\r\n                However, if your checkpoint weights don't have the hyperparameters saved,\r\n                use this method to pass in a ``.yaml`` file with the hparams you'd like to use.\r\n                These will be converted into a :class:`~dict` and passed into your\r\n                :class:`LightningModule` for use.\r\n\r\n                If your model's ``hparams`` argument is :class:`~argparse.Namespace`\r\n                and ``.yaml`` file has hierarchical structure, you need to refactor your model to treat\r\n                ``hparams`` as :class:`~dict`.\r\n            strict: Whether to strictly enforce that the keys in :attr:`checkpoint_path` match the keys\r\n                returned by this module's state dict. Defaults to ``True`` unless ``LightningModule.strict_loading`` is\r\n                set, in which case it defaults to the value of ``LightningModule.strict_loading``.\r\n            \\**kwargs: Any extra keyword args needed to init the model. Can also be used to override saved\r\n                hyperparameter values.\r\n\r\n        Return:\r\n            :class:`LightningModule` instance with loaded weights and hyperparameters (if available).\r\n\r\n        Note:\r\n            ``load_from_checkpoint`` is a **class** method. You should use your :class:`LightningModule`\r\n            **class** to call it instead of the :class:`LightningModule` instance, or a\r\n            ``TypeError`` will be raised.\r\n\r\n        Note:\r\n            To ensure all layers can be loaded from the checkpoint, this function will call\r\n            :meth:`~lightning.pytorch.core.hooks.ModelHooks.configure_model` directly after instantiating the\r\n            model if this hook is overridden in your LightningModule. However, note that ``load_from_checkpoint`` does\r\n            not support loading sharded checkpoints, and you may run out of memory if the model is too large. In this\r\n            case, consider loading through the Trainer via ``.fit(ckpt_path=...)``.\r\n\r\n        Example::\r\n\r\n            model = MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')\r\n\r\n            map_location = {'cuda:1':'cuda:0'}\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                map_location=map_location\r\n            )\r\n\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                hparams_file='/path/to/hparams_file.yaml'\r\n            )\r\n\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                PATH,\r\n                num_layers=128,\r\n                pretrained_ckpt_path=NEW_PATH,\r\n            )\r\n\r\n            pretrained_model.eval()\r\n            pretrained_model.freeze()\r\n            y_hat = pretrained_model(x)\r\n\r\n        \"\"\"\r\n        loaded = _load_from_checkpoint(\r\n            cls,\r\n            checkpoint_path,\r\n            map_location,\r\n            hparams_file,\r\n            strict,\r\n            **kwargs,\r\n        )\r\n        return cast(Self, loaded)", "language": "python", "code": "def load_from_checkpoint(\r\n        cls,\r\n        checkpoint_path: Union[_PATH, IO],\r\n        map_location: _MAP_LOCATION_TYPE = None,\r\n        hparams_file: Optional[_PATH] = None,\r\n        strict: Optional[bool] = None,\r\n        **kwargs: Any,\r\n    ) -> Self:\r\n        r\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\r\n        passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\r\n\r\n        Any arguments specified through \\*\\*kwargs will override args stored in ``\"hyper_parameters\"``.\r\n\r\n        Args:\r\n            checkpoint_path: Path to checkpoint. This can also be a URL, or file-like object\r\n            map_location:\r\n                If your checkpoint saved a GPU model and you now load on CPUs\r\n                or a different number of GPUs, use this to map to the new setup.\r\n                The behaviour is the same as in :func:`torch.load`.\r\n            hparams_file: Optional path to a ``.yaml`` or ``.csv`` file with hierarchical structure\r\n                as in this example::\r\n\r\n                    drop_prob: 0.2\r\n                    dataloader:\r\n                        batch_size: 32\r\n\r\n                You most likely won't need this since Lightning will always save the hyperparameters\r\n                to the checkpoint.\r\n                However, if your checkpoint weights don't have the hyperparameters saved,\r\n                use this method to pass in a ``.yaml`` file with the hparams you'd like to use.\r\n                These will be converted into a :class:`~dict` and passed into your\r\n                :class:`LightningModule` for use.\r\n\r\n                If your model's ``hparams`` argument is :class:`~argparse.Namespace`\r\n                and ``.yaml`` file has hierarchical structure, you need to refactor your model to treat\r\n                ``hparams`` as :class:`~dict`.\r\n            strict: Whether to strictly enforce that the keys in :attr:`checkpoint_path` match the keys\r\n                returned by this module's state dict. Defaults to ``True`` unless ``LightningModule.strict_loading`` is\r\n                set, in which case it defaults to the value of ``LightningModule.strict_loading``.\r\n            \\**kwargs: Any extra keyword args needed to init the model. Can also be used to override saved\r\n                hyperparameter values.\r\n\r\n        Return:\r\n            :class:`LightningModule` instance with loaded weights and hyperparameters (if available).\r\n\r\n        Note:\r\n            ``load_from_checkpoint`` is a **class** method. You should use your :class:`LightningModule`\r\n            **class** to call it instead of the :class:`LightningModule` instance, or a\r\n            ``TypeError`` will be raised.\r\n\r\n        Note:\r\n            To ensure all layers can be loaded from the checkpoint, this function will call\r\n            :meth:`~lightning.pytorch.core.hooks.ModelHooks.configure_model` directly after instantiating the\r\n            model if this hook is overridden in your LightningModule. However, note that ``load_from_checkpoint`` does\r\n            not support loading sharded checkpoints, and you may run out of memory if the model is too large. In this\r\n            case, consider loading through the Trainer via ``.fit(ckpt_path=...)``.\r\n\r\n        Example::\r\n\r\n            model = MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')\r\n\r\n            map_location = {'cuda:1':'cuda:0'}\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                map_location=map_location\r\n            )\r\n\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                'path/to/checkpoint.ckpt',\r\n                hparams_file='/path/to/hparams_file.yaml'\r\n            )\r\n\r\n            model = MyLightningModule.load_from_checkpoint(\r\n                PATH,\r\n                num_layers=128,\r\n                pretrained_ckpt_path=NEW_PATH,\r\n            )\r\n\r\n            pretrained_model.eval()\r\n            pretrained_model.freeze()\r\n            y_hat = pretrained_model(x)\r\n\r\n        \"\"\"\r\n        loaded = _load_from_checkpoint(\r\n            cls,\r\n            checkpoint_path,\r\n            map_location,\r\n            hparams_file,\r\n            strict,\r\n            **kwargs,\r\n        )\r\n        return cast(Self, loaded)", "code_tokens": ["def", "load_from_checkpoint", "(", "cls", ",", "checkpoint_path", ":", "Union", "[", "_PATH", ",", "IO", "]", ",", "map_location", ":", "_MAP_LOCATION_TYPE", "=", "None", ",", "hparams_file", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "strict", ":", "Optional", "[", "bool", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "Self", ":", "rSTRING", "loaded", "=", "_load_from_checkpoint", "(", "cls", ",", "checkpoint_path", ",", "map_location", ",", "hparams_file", ",", "strict", ",", "*", "*", "kwargs", ",", ")", "return", "cast", "(", "Self", ",", "loaded", ")"], "docstring": "load weights without mapping ... or load weights mapping all weights from GPU 1 to GPU 0 ... or load weights and hyperparameters from separate files. override some of the params with new values predict", "docstring_tokens": ["load", "weights", "without", "mapping", "or", "load", "weights", "mapping", "all", "weights", "from", "gpu", "1", "to", "gpu", "0", "or", "load", "weights", "and", "hyperparameters", "from", "separate", "files", "override", "some", "of", "the", "params", "with", "new", "values", "predict"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\module.py", "start_line": 1686, "end_line": 1782, "has_examples": true, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\optimizer.py", "func_name": "function_144", "original_string": "def toggle_model(self, sync_grad: bool = True) -> Generator[None, None, None]:\r\n        \"\"\"This function is just a helper for advanced users.\r\n\r\n        Considering the current optimizer as A and all other optimizers as B.\r\n        Toggling means all parameters from B exclusive to A will have ``requires_grad`` set to False.\r\n\r\n        When performing gradient accumulation, there is no need to perform grad synchronization\r\n        during the accumulation phase.\r\n        Setting `sync_grad` to False will block this synchronization and improve performance.\r\n\r\n        \"\"\"\r\n        from lightning.pytorch.loops.utilities import _block_parallel_sync_behavior\r\n\r\n        assert self._strategy is not None\r\n        lightning_module = self._strategy.lightning_module\r\n        assert lightning_module is not None\r\n        with _block_parallel_sync_behavior(self._strategy, block=(not sync_grad)):\r\n            lightning_module.toggle_optimizer(self)\r\n            yield\r\n            lightning_module.untoggle_optimizer(self)", "language": "python", "code": "def toggle_model(self, sync_grad: bool = True) -> Generator[None, None, None]:\r\n        \"\"\"This function is just a helper for advanced users.\r\n\r\n        Considering the current optimizer as A and all other optimizers as B.\r\n        Toggling means all parameters from B exclusive to A will have ``requires_grad`` set to False.\r\n\r\n        When performing gradient accumulation, there is no need to perform grad synchronization\r\n        during the accumulation phase.\r\n        Setting `sync_grad` to False will block this synchronization and improve performance.\r\n\r\n        \"\"\"\r\n        from lightning.pytorch.loops.utilities import _block_parallel_sync_behavior\r\n\r\n        assert self._strategy is not None\r\n        lightning_module = self._strategy.lightning_module\r\n        assert lightning_module is not None\r\n        with _block_parallel_sync_behavior(self._strategy, block=(not sync_grad)):\r\n            lightning_module.toggle_optimizer(self)\r\n            yield\r\n            lightning_module.untoggle_optimizer(self)", "code_tokens": ["def", "toggle_model", "(", "self", ",", "sync_grad", ":", "bool", "=", "True", ")", "-", ">", "Generator", "[", "None", ",", "None", ",", "None", "]", ":", "STRING", "from", "lightning", ".", "pytorch", ".", "loops", ".", "utilities", "import", "_block_parallel_sync_behavior", "assert", "self", ".", "_strategy", "is", "not", "None", "lightning_module", "=", "self", ".", "_strategy", ".", "lightning_module", "assert", "lightning_module", "is", "not", "None", "with", "_block_parallel_sync_behavior", "(", "self", ".", "_strategy", ",", "block", "=", "(", "not", "sync_grad", ")", ")", ":", "lightning_module", ".", "toggle_optimizer", "(", "self", ")", "yield", "lightning_module", ".", "untoggle_optimizer", "(", "self", ")"], "docstring": "local import here to avoid circular import", "docstring_tokens": ["local", "import", "here", "to", "avoid", "circular", "import"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\optimizer.py", "start_line": 62, "end_line": 82, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\optimizer.py", "func_name": "function_145", "original_string": "def step(self, closure: Optional[Callable[[], Any]] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Performs a single optimization step (parameter update).\r\n\r\n        Args:\r\n            closure: An optional optimizer closure.\r\n            kwargs: Any additional arguments to the ``optimizer.step()`` call.\r\n\r\n        Returns:\r\n            The output from the step call, which is generally the output of the closure execution.\r\n\r\n        Example::\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt_gen, opt_dis = self.optimizers()\r\n\r\n                ...\r\n\r\n                loss_gen = self.compute_generator_loss(...)\r\n                opt_gen.zero_grad()\r\n                self.manual_backward(loss_gen)\r\n                opt_gen.step()\r\n\r\n                loss_dis = self.compute_discriminator_loss(...)\r\n\r\n                opt_dis.zero_grad()\r\n                self.manual_backward(loss_dis)\r\n                opt_dis.step()\r\n\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt_gen, opt_dis = self.optimizers()\r\n\r\n                ...\r\n                accumulated_grad_batches = batch_idx % 2 == 0\r\n\r\n                def closure_gen():\r\n                    loss_gen = self.compute_generator_loss(...)\r\n                    self.manual_backward(loss_gen)\r\n                    if accumulated_grad_batches:\r\n                        opt_gen.zero_grad()\r\n\r\n                with opt_gen.toggle_model(sync_grad=accumulated_grad_batches):\r\n                    opt_gen.step(closure=closure_gen)\r\n\r\n                def closure_dis():\r\n                    loss_dis = self.compute_discriminator_loss(...)\r\n                    self.manual_backward(loss_dis)\r\n                    if accumulated_grad_batches:\r\n                        opt_dis.zero_grad()\r\n\r\n                with opt_dis.toggle_model(sync_grad=accumulated_grad_batches):\r\n                    opt_dis.step(closure=closure_dis)\r\n\r\n        \"\"\"\r\n        self._on_before_step()\r\n\r\n        if closure is None:\r\n            closure = do_nothing_closure\r\n        elif not callable(closure):\r\n            raise MisconfigurationException(\"When `optimizer.step(closure)` is called, the closure should be callable\")\r\n\r\n        assert self._strategy is not None\r\n        step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\r\n\r\n        self._on_after_step()\r\n\r\n        return step_output", "language": "python", "code": "def step(self, closure: Optional[Callable[[], Any]] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Performs a single optimization step (parameter update).\r\n\r\n        Args:\r\n            closure: An optional optimizer closure.\r\n            kwargs: Any additional arguments to the ``optimizer.step()`` call.\r\n\r\n        Returns:\r\n            The output from the step call, which is generally the output of the closure execution.\r\n\r\n        Example::\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt_gen, opt_dis = self.optimizers()\r\n\r\n                ...\r\n\r\n                loss_gen = self.compute_generator_loss(...)\r\n                opt_gen.zero_grad()\r\n                self.manual_backward(loss_gen)\r\n                opt_gen.step()\r\n\r\n                loss_dis = self.compute_discriminator_loss(...)\r\n\r\n                opt_dis.zero_grad()\r\n                self.manual_backward(loss_dis)\r\n                opt_dis.step()\r\n\r\n\r\n            def training_step(self, batch, batch_idx):\r\n                opt_gen, opt_dis = self.optimizers()\r\n\r\n                ...\r\n                accumulated_grad_batches = batch_idx % 2 == 0\r\n\r\n                def closure_gen():\r\n                    loss_gen = self.compute_generator_loss(...)\r\n                    self.manual_backward(loss_gen)\r\n                    if accumulated_grad_batches:\r\n                        opt_gen.zero_grad()\r\n\r\n                with opt_gen.toggle_model(sync_grad=accumulated_grad_batches):\r\n                    opt_gen.step(closure=closure_gen)\r\n\r\n                def closure_dis():\r\n                    loss_dis = self.compute_discriminator_loss(...)\r\n                    self.manual_backward(loss_dis)\r\n                    if accumulated_grad_batches:\r\n                        opt_dis.zero_grad()\r\n\r\n                with opt_dis.toggle_model(sync_grad=accumulated_grad_batches):\r\n                    opt_dis.step(closure=closure_dis)\r\n\r\n        \"\"\"\r\n        self._on_before_step()\r\n\r\n        if closure is None:\r\n            closure = do_nothing_closure\r\n        elif not callable(closure):\r\n            raise MisconfigurationException(\"When `optimizer.step(closure)` is called, the closure should be callable\")\r\n\r\n        assert self._strategy is not None\r\n        step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\r\n\r\n        self._on_after_step()\r\n\r\n        return step_output", "code_tokens": ["def", "step", "(", "self", ",", "closure", ":", "Optional", "[", "Callable", "[", "[", "]", ",", "Any", "]", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "self", ".", "_on_before_step", "(", ")", "if", "closure", "is", "None", ":", "closure", "=", "do_nothing_closure", "elif", "not", "callable", "(", "closure", ")", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "assert", "self", ".", "_strategy", "is", "not", "None", "step_output", "=", "self", ".", "_strategy", ".", "optimizer_step", "(", "self", ".", "_optimizer", ",", "closure", ",", "*", "*", "kwargs", ")", "self", ".", "_on_after_step", "(", ")", "return", "step_output"], "docstring": "Scenario for a GAN using manual optimization compute generator loss zero_grad needs to be called before backward compute discriminator loss zero_grad needs to be called before backward A more advanced example compute generator loss", "docstring_tokens": ["scenario", "for", "a", "gan", "using", "manual", "optimization", "compute", "generator", "loss", "zero_grad", "needs", "to", "be", "called", "before", "backward", "compute", "discriminator", "loss", "zero_grad", "needs", "to", "be", "called", "before", "backward", "a", "more", "advanced", "example", "compute", "generator", "loss"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\optimizer.py", "start_line": 84, "end_line": 157, "has_examples": true, "num_comments": 7, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\optimizer.py", "func_name": "function_146", "original_string": "def _configure_schedulers_automatic_opt(schedulers: list, monitor: Optional[str]) -> list[LRSchedulerConfig]:\r\n    \"\"\"Convert each scheduler into `LRSchedulerConfig` with relevant information, when using automatic optimization.\"\"\"\r\n    lr_scheduler_configs = []\r\n    for scheduler in schedulers:\r\n        if isinstance(scheduler, dict):\r\n            supported_keys = {field.name for field in fields(LRSchedulerConfig)}\r\n            extra_keys = scheduler.keys() - supported_keys\r\n            if extra_keys:\r\n                rank_zero_warn(\r\n                    f\"Found unsupported keys in the lr scheduler dict: {extra_keys}.\"\r\n                    \" HINT: remove them from the output of `configure_optimizers`.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n                scheduler = {k: v for k, v in scheduler.items() if k in supported_keys}\r\n            if \"scheduler\" not in scheduler:\r\n                raise MisconfigurationException(\r\n                    'The lr scheduler dict must have the key \"scheduler\" with its item being an lr scheduler'\r\n                )\r\n            if \"interval\" in scheduler and scheduler[\"interval\"] not in (\"step\", \"epoch\"):\r\n                raise MisconfigurationException(\r\n                    'The \"interval\" key in lr scheduler dict must be \"step\" or \"epoch\"'\r\n                    f' but is \"{scheduler[\"interval\"]}\"'\r\n                )\r\n            scheduler[\"reduce_on_plateau\"] = scheduler.get(\r\n                \"reduce_on_plateau\", isinstance(scheduler[\"scheduler\"], optim.lr_scheduler.ReduceLROnPlateau)\r\n            )\r\n            if scheduler[\"reduce_on_plateau\"] and scheduler.get(\"monitor\") is None:\r\n                raise MisconfigurationException(\r\n                    \"The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used.\"\r\n                    ' For example: {\"optimizer\": optimizer, \"lr_scheduler\":'\r\n                    ' {\"scheduler\": scheduler, \"monitor\": \"your_loss\"}}'\r\n                )\r\n            is_one_cycle = isinstance(scheduler[\"scheduler\"], optim.lr_scheduler.OneCycleLR)\r\n            if is_one_cycle and scheduler.get(\"interval\", \"epoch\") == \"epoch\":\r\n                rank_zero_warn(\r\n                    \"A `OneCycleLR` scheduler is using 'interval': 'epoch'.\"\r\n                    \" Are you sure you didn't mean 'interval': 'step'?\",\r\n                    category=RuntimeWarning,\r\n                )\r\n            config = LRSchedulerConfig(**scheduler)\r\n        elif isinstance(scheduler, ReduceLROnPlateau):\r\n            if monitor is None:\r\n                raise MisconfigurationException(\r\n                    \"`configure_optimizers` must include a monitor when a `ReduceLROnPlateau`\"\r\n                    \" scheduler is used. For example:\"\r\n                    ' {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"metric_to_track\"}'\r\n                )\r\n            config = LRSchedulerConfig(scheduler, reduce_on_plateau=True, monitor=monitor)\r\n        else:\r\n            config = LRSchedulerConfig(scheduler)\r\n        lr_scheduler_configs.append(config)\r\n    return lr_scheduler_configs", "language": "python", "code": "def _configure_schedulers_automatic_opt(schedulers: list, monitor: Optional[str]) -> list[LRSchedulerConfig]:\r\n    \"\"\"Convert each scheduler into `LRSchedulerConfig` with relevant information, when using automatic optimization.\"\"\"\r\n    lr_scheduler_configs = []\r\n    for scheduler in schedulers:\r\n        if isinstance(scheduler, dict):\r\n            supported_keys = {field.name for field in fields(LRSchedulerConfig)}\r\n            extra_keys = scheduler.keys() - supported_keys\r\n            if extra_keys:\r\n                rank_zero_warn(\r\n                    f\"Found unsupported keys in the lr scheduler dict: {extra_keys}.\"\r\n                    \" HINT: remove them from the output of `configure_optimizers`.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n                scheduler = {k: v for k, v in scheduler.items() if k in supported_keys}\r\n            if \"scheduler\" not in scheduler:\r\n                raise MisconfigurationException(\r\n                    'The lr scheduler dict must have the key \"scheduler\" with its item being an lr scheduler'\r\n                )\r\n            if \"interval\" in scheduler and scheduler[\"interval\"] not in (\"step\", \"epoch\"):\r\n                raise MisconfigurationException(\r\n                    'The \"interval\" key in lr scheduler dict must be \"step\" or \"epoch\"'\r\n                    f' but is \"{scheduler[\"interval\"]}\"'\r\n                )\r\n            scheduler[\"reduce_on_plateau\"] = scheduler.get(\r\n                \"reduce_on_plateau\", isinstance(scheduler[\"scheduler\"], optim.lr_scheduler.ReduceLROnPlateau)\r\n            )\r\n            if scheduler[\"reduce_on_plateau\"] and scheduler.get(\"monitor\") is None:\r\n                raise MisconfigurationException(\r\n                    \"The lr scheduler dict must include a monitor when a `ReduceLROnPlateau` scheduler is used.\"\r\n                    ' For example: {\"optimizer\": optimizer, \"lr_scheduler\":'\r\n                    ' {\"scheduler\": scheduler, \"monitor\": \"your_loss\"}}'\r\n                )\r\n            is_one_cycle = isinstance(scheduler[\"scheduler\"], optim.lr_scheduler.OneCycleLR)\r\n            if is_one_cycle and scheduler.get(\"interval\", \"epoch\") == \"epoch\":\r\n                rank_zero_warn(\r\n                    \"A `OneCycleLR` scheduler is using 'interval': 'epoch'.\"\r\n                    \" Are you sure you didn't mean 'interval': 'step'?\",\r\n                    category=RuntimeWarning,\r\n                )\r\n            config = LRSchedulerConfig(**scheduler)\r\n        elif isinstance(scheduler, ReduceLROnPlateau):\r\n            if monitor is None:\r\n                raise MisconfigurationException(\r\n                    \"`configure_optimizers` must include a monitor when a `ReduceLROnPlateau`\"\r\n                    \" scheduler is used. For example:\"\r\n                    ' {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"metric_to_track\"}'\r\n                )\r\n            config = LRSchedulerConfig(scheduler, reduce_on_plateau=True, monitor=monitor)\r\n        else:\r\n            config = LRSchedulerConfig(scheduler)\r\n        lr_scheduler_configs.append(config)\r\n    return lr_scheduler_configs", "code_tokens": ["def", "_configure_schedulers_automatic_opt", "(", "schedulers", ":", "list", ",", "monitor", ":", "Optional", "[", "str", "]", ")", "-", ">", "list", "[", "LRSchedulerConfig", "]", ":", "STRING", "lr_scheduler_configs", "=", "[", "]", "for", "scheduler", "in", "schedulers", ":", "if", "isinstance", "(", "scheduler", ",", "dict", ")", ":", "supported_keys", "=", "{", "field", ".", "name", "for", "field", "in", "fields", "(", "LRSchedulerConfig", ")", "}", "extra_keys", "=", "scheduler", ".", "keys", "(", ")", "-", "supported_keys", "if", "extra_keys", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ",", "category", "=", "RuntimeWarning", ",", ")", "scheduler", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "scheduler", ".", "items", "(", ")", "if", "k", "in", "supported_keys", "}", "if", "STRING", "not", "in", "scheduler", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "if", "STRING", "in", "scheduler", "and", "scheduler", "[", "STRING", "]", "not", "in", "(", "STRING", ",", "STRING", ")", ":", "raise", "MisconfigurationException", "(", "STRING", "fSTRING", ")", "scheduler", "[", "STRING", "]", "=", "scheduler", ".", "get", "(", "STRING", ",", "isinstance", "(", "scheduler", "[", "STRING", "]", ",", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", ")", ")", "if", "scheduler", "[", "STRING", "]", "and", "scheduler", ".", "get", "(", "STRING", ")", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", "STRING", ")", "is_one_cycle", "=", "isinstance", "(", "scheduler", "[", "STRING", "]", ",", "optim", ".", "lr_scheduler", ".", "OneCycleLR", ")", "if", "is_one_cycle", "and", "scheduler", ".", "get", "(", "STRING", ",", "STRING", ")", "=", "=", "STRING", ":", "rank_zero_warn", "(", "STRING", "STRING", ",", "category", "=", "RuntimeWarning", ",", ")", "config", "=", "LRSchedulerConfig", "(", "*", "*", "scheduler", ")", "elif", "isinstance", "(", "scheduler", ",", "ReduceLROnPlateau", ")", ":", "if", "monitor", "is", "None", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", "STRING", ")", "config", "=", "LRSchedulerConfig", "(", "scheduler", ",", "reduce_on_plateau", "=", "True", ",", "monitor", "=", "monitor", ")", "else", ":", "config", "=", "LRSchedulerConfig", "(", "scheduler", ")", "lr_scheduler_configs", ".", "append", "(", "config", ")", "return", "lr_scheduler_configs"], "docstring": "check provided keys", "docstring_tokens": ["check", "provided", "keys"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\optimizer.py", "start_line": 249, "end_line": 301, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\optimizer.py", "func_name": "function_147", "original_string": "def _configure_schedulers_manual_opt(schedulers: list) -> list[LRSchedulerConfig]:\r\n    \"\"\"Convert each scheduler into `LRSchedulerConfig` structure with relevant information, when using manual\r\n    optimization.\"\"\"\r\n    lr_scheduler_configs = []\r\n    for scheduler in schedulers:\r\n        if isinstance(scheduler, dict):\r\n            invalid_keys = {\"reduce_on_plateau\", \"monitor\", \"strict\"}\r\n            keys_to_warn = [k for k in scheduler if k in invalid_keys]\r\n\r\n            if keys_to_warn:\r\n                rank_zero_warn(\r\n                    f\"The lr scheduler dict contains the key(s) {keys_to_warn}, but the keys will be ignored.\"\r\n                    \" You need to call `lr_scheduler.step()` manually in manual optimization.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n\r\n            config = LRSchedulerConfig(**{key: scheduler[key] for key in scheduler if key not in invalid_keys})\r\n        else:\r\n            config = LRSchedulerConfig(scheduler)\r\n        lr_scheduler_configs.append(config)\r\n    return lr_scheduler_configs", "language": "python", "code": "def _configure_schedulers_manual_opt(schedulers: list) -> list[LRSchedulerConfig]:\r\n    \"\"\"Convert each scheduler into `LRSchedulerConfig` structure with relevant information, when using manual\r\n    optimization.\"\"\"\r\n    lr_scheduler_configs = []\r\n    for scheduler in schedulers:\r\n        if isinstance(scheduler, dict):\r\n            invalid_keys = {\"reduce_on_plateau\", \"monitor\", \"strict\"}\r\n            keys_to_warn = [k for k in scheduler if k in invalid_keys]\r\n\r\n            if keys_to_warn:\r\n                rank_zero_warn(\r\n                    f\"The lr scheduler dict contains the key(s) {keys_to_warn}, but the keys will be ignored.\"\r\n                    \" You need to call `lr_scheduler.step()` manually in manual optimization.\",\r\n                    category=RuntimeWarning,\r\n                )\r\n\r\n            config = LRSchedulerConfig(**{key: scheduler[key] for key in scheduler if key not in invalid_keys})\r\n        else:\r\n            config = LRSchedulerConfig(scheduler)\r\n        lr_scheduler_configs.append(config)\r\n    return lr_scheduler_configs", "code_tokens": ["def", "_configure_schedulers_manual_opt", "(", "schedulers", ":", "list", ")", "-", ">", "list", "[", "LRSchedulerConfig", "]", ":", "STRING", "lr_scheduler_configs", "=", "[", "]", "for", "scheduler", "in", "schedulers", ":", "if", "isinstance", "(", "scheduler", ",", "dict", ")", ":", "invalid_keys", "=", "{", "STRING", ",", "STRING", ",", "STRING", "}", "keys_to_warn", "=", "[", "k", "for", "k", "in", "scheduler", "if", "k", "in", "invalid_keys", "]", "if", "keys_to_warn", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ",", "category", "=", "RuntimeWarning", ",", ")", "config", "=", "LRSchedulerConfig", "(", "*", "*", "{", "key", ":", "scheduler", "[", "key", "]", "for", "key", "in", "scheduler", "if", "key", "not", "in", "invalid_keys", "}", ")", "else", ":", "config", "=", "LRSchedulerConfig", "(", "scheduler", ")", "lr_scheduler_configs", ".", "append", "(", "config", ")", "return", "lr_scheduler_configs"], "docstring": "interval is not in this list even though the user needs to manually call the scheduler because the `LearningRateMonitor` callback needs to check its value to know when to log the learning rate", "docstring_tokens": ["interval", "is", "not", "in", "this", "list", "even", "though", "the", "user", "needs", "to", "manually", "call", "the", "scheduler", "because", "the", "learningratemonitor", "callback", "needs", "to", "check", "its", "value", "to", "know", "when", "to", "log", "the", "learning", "rate"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\optimizer.py", "start_line": 304, "end_line": 326, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\saving.py", "func_name": "function_148", "original_string": "def _convert_loaded_hparams(\r\n    model_args: dict[str, Any], hparams_type: Optional[Union[Callable, str]] = None\r\n) -> dict[str, Any]:\r\n    \"\"\"Convert hparams according given type in callable or string (past) format.\"\"\"\r\n    if not hparams_type:\r\n        return model_args\r\n    if isinstance(hparams_type, str):\r\n        hparams_type = AttributeDict\r\n    return hparams_type(model_args)", "language": "python", "code": "def _convert_loaded_hparams(\r\n    model_args: dict[str, Any], hparams_type: Optional[Union[Callable, str]] = None\r\n) -> dict[str, Any]:\r\n    \"\"\"Convert hparams according given type in callable or string (past) format.\"\"\"\r\n    if not hparams_type:\r\n        return model_args\r\n    if isinstance(hparams_type, str):\r\n        hparams_type = AttributeDict\r\n    return hparams_type(model_args)", "code_tokens": ["def", "_convert_loaded_hparams", "(", "model_args", ":", "dict", "[", "str", ",", "Any", "]", ",", "hparams_type", ":", "Optional", "[", "Union", "[", "Callable", ",", "str", "]", "]", "=", "None", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "hparams_type", ":", "return", "model_args", "if", "isinstance", "(", "hparams_type", ",", "str", ")", ":", "hparams_type", "=", "AttributeDict", "return", "hparams_type", "(", "model_args", ")"], "docstring": "if not hparams type define if past checkpoint loaded, convert str to callable convert hparams", "docstring_tokens": ["if", "not", "hparams", "type", "define", "if", "past", "checkpoint", "loaded", "convert", "str", "to", "callable", "convert", "hparams"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\saving.py", "start_line": 201, "end_line": 212, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\saving.py", "func_name": "function_149", "original_string": "def update_hparams(hparams: dict, updates: dict) -> None:\r\n    \"\"\"Overrides hparams with new values.\r\n\r\n    >>> hparams = {'c': 4}\r\n    >>> update_hparams(hparams, {'a': {'b': 2}, 'c': 1})\r\n    >>> hparams['a']['b'], hparams['c']\r\n    (2, 1)\r\n    >>> update_hparams(hparams, {'a': {'b': 4}, 'c': 7})\r\n    >>> hparams['a']['b'], hparams['c']\r\n    (4, 7)\r\n\r\n    Args:\r\n        hparams: the original params and also target object\r\n        updates: new params to be used as update\r\n\r\n    \"\"\"\r\n    for k, v in updates.items():\r\n        if k not in hparams:\r\n            hparams[k] = v\r\n            continue\r\n\r\n        if isinstance(v, dict):\r\n            update_hparams(hparams[k], updates[k])\r\n        else:\r\n            hparams.update({k: v})", "language": "python", "code": "def update_hparams(hparams: dict, updates: dict) -> None:\r\n    \"\"\"Overrides hparams with new values.\r\n\r\n    >>> hparams = {'c': 4}\r\n    >>> update_hparams(hparams, {'a': {'b': 2}, 'c': 1})\r\n    >>> hparams['a']['b'], hparams['c']\r\n    (2, 1)\r\n    >>> update_hparams(hparams, {'a': {'b': 4}, 'c': 7})\r\n    >>> hparams['a']['b'], hparams['c']\r\n    (4, 7)\r\n\r\n    Args:\r\n        hparams: the original params and also target object\r\n        updates: new params to be used as update\r\n\r\n    \"\"\"\r\n    for k, v in updates.items():\r\n        if k not in hparams:\r\n            hparams[k] = v\r\n            continue\r\n\r\n        if isinstance(v, dict):\r\n            update_hparams(hparams[k], updates[k])\r\n        else:\r\n            hparams.update({k: v})", "code_tokens": ["def", "update_hparams", "(", "hparams", ":", "dict", ",", "updates", ":", "dict", ")", "-", ">", "None", ":", "STRING", "for", "k", ",", "v", "in", "updates", ".", "items", "(", ")", ":", "if", "k", "not", "in", "hparams", ":", "hparams", "[", "k", "]", "=", "v", "continue", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "update_hparams", "(", "hparams", "[", "k", "]", ",", "updates", "[", "k", "]", ")", "else", ":", "hparams", ".", "update", "(", "{", "k", ":", "v", "}", ")"], "docstring": "if missing, add the key recurse if dictionary update the value", "docstring_tokens": ["if", "missing", "add", "the", "key", "recurse", "if", "dictionary", "update", "the", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\saving.py", "start_line": 215, "end_line": 242, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\saving.py", "func_name": "function_150", "original_string": "def save_hparams_to_yaml(config_yaml: _PATH, hparams: Union[dict, Namespace], use_omegaconf: bool = True) -> None:\r\n    \"\"\"\r\n    Args:\r\n        config_yaml: path to new YAML file\r\n        hparams: parameters to be saved\r\n        use_omegaconf: If omegaconf is available and ``use_omegaconf=True``,\r\n            the hparams will be converted to ``DictConfig`` if possible.\r\n\r\n    \"\"\"\r\n    fs = get_filesystem(config_yaml)\r\n    if not _is_dir(fs, os.path.dirname(config_yaml)):\r\n        raise RuntimeError(f\"Missing folder: {os.path.dirname(config_yaml)}.\")\r\n\r\n    if isinstance(hparams, Namespace):\r\n        hparams = vars(hparams)\r\n    elif isinstance(hparams, AttributeDict):\r\n        hparams = dict(hparams)\r\n\r\n    if _OMEGACONF_AVAILABLE and use_omegaconf:\r\n        from omegaconf import OmegaConf\r\n        from omegaconf.dictconfig import DictConfig\r\n        from omegaconf.errors import UnsupportedValueType, ValidationError\r\n\r\n        hparams = deepcopy(hparams)\r\n        hparams = apply_to_collection(hparams, DictConfig, OmegaConf.to_container, resolve=True)\r\n        with fs.open(config_yaml, \"w\", encoding=\"utf-8\") as fp:\r\n            try:\r\n                OmegaConf.save(hparams, fp)\r\n                return\r\n            except (UnsupportedValueType, ValidationError):\r\n                pass\r\n\r\n    if not isinstance(hparams, dict):\r\n        raise TypeError(\"hparams must be dictionary\")\r\n\r\n    hparams_allowed = {}\r\n    for k, v in hparams.items():\r\n        try:\r\n            v = v.name if isinstance(v, Enum) else v\r\n            yaml.dump(v)\r\n        except (TypeError, ValueError):\r\n            warn(f\"Skipping '{k}' parameter because it is not possible to safely dump to YAML.\")\r\n            hparams[k] = type(v).__name__\r\n        else:\r\n            hparams_allowed[k] = v\r\n\r\n    with fs.open(config_yaml, \"w\", newline=\"\") as fp:\r\n        yaml.dump(hparams_allowed, fp)", "language": "python", "code": "def save_hparams_to_yaml(config_yaml: _PATH, hparams: Union[dict, Namespace], use_omegaconf: bool = True) -> None:\r\n    \"\"\"\r\n    Args:\r\n        config_yaml: path to new YAML file\r\n        hparams: parameters to be saved\r\n        use_omegaconf: If omegaconf is available and ``use_omegaconf=True``,\r\n            the hparams will be converted to ``DictConfig`` if possible.\r\n\r\n    \"\"\"\r\n    fs = get_filesystem(config_yaml)\r\n    if not _is_dir(fs, os.path.dirname(config_yaml)):\r\n        raise RuntimeError(f\"Missing folder: {os.path.dirname(config_yaml)}.\")\r\n\r\n    if isinstance(hparams, Namespace):\r\n        hparams = vars(hparams)\r\n    elif isinstance(hparams, AttributeDict):\r\n        hparams = dict(hparams)\r\n\r\n    if _OMEGACONF_AVAILABLE and use_omegaconf:\r\n        from omegaconf import OmegaConf\r\n        from omegaconf.dictconfig import DictConfig\r\n        from omegaconf.errors import UnsupportedValueType, ValidationError\r\n\r\n        hparams = deepcopy(hparams)\r\n        hparams = apply_to_collection(hparams, DictConfig, OmegaConf.to_container, resolve=True)\r\n        with fs.open(config_yaml, \"w\", encoding=\"utf-8\") as fp:\r\n            try:\r\n                OmegaConf.save(hparams, fp)\r\n                return\r\n            except (UnsupportedValueType, ValidationError):\r\n                pass\r\n\r\n    if not isinstance(hparams, dict):\r\n        raise TypeError(\"hparams must be dictionary\")\r\n\r\n    hparams_allowed = {}\r\n    for k, v in hparams.items():\r\n        try:\r\n            v = v.name if isinstance(v, Enum) else v\r\n            yaml.dump(v)\r\n        except (TypeError, ValueError):\r\n            warn(f\"Skipping '{k}' parameter because it is not possible to safely dump to YAML.\")\r\n            hparams[k] = type(v).__name__\r\n        else:\r\n            hparams_allowed[k] = v\r\n\r\n    with fs.open(config_yaml, \"w\", newline=\"\") as fp:\r\n        yaml.dump(hparams_allowed, fp)", "code_tokens": ["def", "save_hparams_to_yaml", "(", "config_yaml", ":", "_PATH", ",", "hparams", ":", "Union", "[", "dict", ",", "Namespace", "]", ",", "use_omegaconf", ":", "bool", "=", "True", ")", "-", ">", "None", ":", "STRING", "fs", "=", "get_filesystem", "(", "config_yaml", ")", "if", "not", "_is_dir", "(", "fs", ",", "os", ".", "path", ".", "dirname", "(", "config_yaml", ")", ")", ":", "raise", "RuntimeError", "(", "fSTRING", ")", "if", "isinstance", "(", "hparams", ",", "Namespace", ")", ":", "hparams", "=", "vars", "(", "hparams", ")", "elif", "isinstance", "(", "hparams", ",", "AttributeDict", ")", ":", "hparams", "=", "dict", "(", "hparams", ")", "if", "_OMEGACONF_AVAILABLE", "and", "use_omegaconf", ":", "from", "omegaconf", "import", "OmegaConf", "from", "omegaconf", ".", "dictconfig", "import", "DictConfig", "from", "omegaconf", ".", "errors", "import", "UnsupportedValueType", ",", "ValidationError", "hparams", "=", "deepcopy", "(", "hparams", ")", "hparams", "=", "apply_to_collection", "(", "hparams", ",", "DictConfig", ",", "OmegaConf", ".", "to_container", ",", "resolve", "=", "True", ")", "with", "fs", ".", "open", "(", "config_yaml", ",", "STRING", ",", "encoding", "=", "STRING", ")", "as", "fp", ":", "try", ":", "OmegaConf", ".", "save", "(", "hparams", ",", "fp", ")", "return", "except", "(", "UnsupportedValueType", ",", "ValidationError", ")", ":", "pass", "if", "not", "isinstance", "(", "hparams", ",", "dict", ")", ":", "raise", "TypeError", "(", "STRING", ")", "hparams_allowed", "=", "{", "}", "for", "k", ",", "v", "in", "hparams", ".", "items", "(", ")", ":", "try", ":", "v", "=", "v", ".", "name", "if", "isinstance", "(", "v", ",", "Enum", ")", "else", "v", "yaml", ".", "dump", "(", "v", ")", "except", "(", "TypeError", ",", "ValueError", ")", ":", "warn", "(", "fSTRING", ")", "hparams", "[", "k", "]", "=", "type", "(", "v", ")", ".", "__name__", "else", ":", "hparams_allowed", "[", "k", "]", "=", "v", "with", "fs", ".", "open", "(", "config_yaml", ",", "STRING", ",", "newline", "=", "STRING", ")", "as", "fp", ":", "yaml", ".", "dump", "(", "hparams_allowed", ",", "fp", ")"], "docstring": "convert Namespace or AD to dict saving with OmegaConf objects deepcopy: hparams from user shouldn't be resolved drop parameters which contain some strange datatypes as fsspec saving the standard way", "docstring_tokens": ["convert", "namespace", "or", "ad", "to", "dict", "saving", "with", "omegaconf", "objects", "deepcopy", "hparams", "from", "user", "shouldn", "t", "be", "resolved", "drop", "parameters", "which", "contain", "some", "strange", "datatypes", "as", "fsspec", "saving", "the", "standard", "way"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\saving.py", "start_line": 317, "end_line": 369, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\mixins\\hparams_mixin.py", "func_name": "function_151", "original_string": "def save_hyperparameters(\r\n        self,\r\n        *args: Any,\r\n        ignore: Optional[Union[Sequence[str], str]] = None,\r\n        frame: Optional[types.FrameType] = None,\r\n        logger: bool = True,\r\n    ) -> None:\r\n        \"\"\"Save arguments to ``hparams`` attribute.\r\n\r\n        Args:\r\n            args: single object of `dict`, `NameSpace` or `OmegaConf`\r\n                or string names or arguments from class ``__init__``\r\n            ignore: an argument name or a list of argument names from\r\n                class ``__init__`` to be ignored\r\n            frame: a frame object. Default is None\r\n            logger: Whether to send the hyperparameters to the logger. Default: True\r\n\r\n        Example::\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class ManuallyArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # manually assign arguments\r\n            ...         self.save_hyperparameters('arg1', 'arg3')\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = ManuallyArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class AutomaticArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # equivalent automatic\r\n            ...         self.save_hyperparameters()\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = AutomaticArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg2\": abc\r\n            \"arg3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class SingleArgModel(HyperparametersMixin):\r\n            ...     def __init__(self, params):\r\n            ...         super().__init__()\r\n            ...         # manually assign single argument\r\n            ...         self.save_hyperparameters(params)\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = SingleArgModel(Namespace(p1=1, p2='abc', p3=3.14))\r\n            >>> model.hparams\r\n            \"p1\": 1\r\n            \"p2\": abc\r\n            \"p3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class ManuallyArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # pass argument(s) to ignore as a string or in a list\r\n            ...         self.save_hyperparameters(ignore='arg2')\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = ManuallyArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg3\": 3.14\r\n\r\n        \"\"\"\r\n        self._log_hyperparams = logger\r\n        given_hparams = _given_hyperparameters.get()\r\n        if given_hparams is None and not frame:\r\n            current_frame = inspect.currentframe()\r\n            if current_frame:\r\n                frame = current_frame.f_back\r\n        save_hyperparameters(self, *args, ignore=ignore, frame=frame, given_hparams=given_hparams)", "language": "python", "code": "def save_hyperparameters(\r\n        self,\r\n        *args: Any,\r\n        ignore: Optional[Union[Sequence[str], str]] = None,\r\n        frame: Optional[types.FrameType] = None,\r\n        logger: bool = True,\r\n    ) -> None:\r\n        \"\"\"Save arguments to ``hparams`` attribute.\r\n\r\n        Args:\r\n            args: single object of `dict`, `NameSpace` or `OmegaConf`\r\n                or string names or arguments from class ``__init__``\r\n            ignore: an argument name or a list of argument names from\r\n                class ``__init__`` to be ignored\r\n            frame: a frame object. Default is None\r\n            logger: Whether to send the hyperparameters to the logger. Default: True\r\n\r\n        Example::\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class ManuallyArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # manually assign arguments\r\n            ...         self.save_hyperparameters('arg1', 'arg3')\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = ManuallyArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class AutomaticArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # equivalent automatic\r\n            ...         self.save_hyperparameters()\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = AutomaticArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg2\": abc\r\n            \"arg3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class SingleArgModel(HyperparametersMixin):\r\n            ...     def __init__(self, params):\r\n            ...         super().__init__()\r\n            ...         # manually assign single argument\r\n            ...         self.save_hyperparameters(params)\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = SingleArgModel(Namespace(p1=1, p2='abc', p3=3.14))\r\n            >>> model.hparams\r\n            \"p1\": 1\r\n            \"p2\": abc\r\n            \"p3\": 3.14\r\n\r\n            >>> from lightning.pytorch.core.mixins import HyperparametersMixin\r\n            >>> class ManuallyArgsModel(HyperparametersMixin):\r\n            ...     def __init__(self, arg1, arg2, arg3):\r\n            ...         super().__init__()\r\n            ...         # pass argument(s) to ignore as a string or in a list\r\n            ...         self.save_hyperparameters(ignore='arg2')\r\n            ...     def forward(self, *args, **kwargs):\r\n            ...         ...\r\n            >>> model = ManuallyArgsModel(1, 'abc', 3.14)\r\n            >>> model.hparams\r\n            \"arg1\": 1\r\n            \"arg3\": 3.14\r\n\r\n        \"\"\"\r\n        self._log_hyperparams = logger\r\n        given_hparams = _given_hyperparameters.get()\r\n        if given_hparams is None and not frame:\r\n            current_frame = inspect.currentframe()\r\n            if current_frame:\r\n                frame = current_frame.f_back\r\n        save_hyperparameters(self, *args, ignore=ignore, frame=frame, given_hparams=given_hparams)", "code_tokens": ["def", "save_hyperparameters", "(", "self", ",", "*", "args", ":", "Any", ",", "ignore", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "str", "]", "]", "=", "None", ",", "frame", ":", "Optional", "[", "types", ".", "FrameType", "]", "=", "None", ",", "logger", ":", "bool", "=", "True", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "_log_hyperparams", "=", "logger", "given_hparams", "=", "_given_hyperparameters", ".", "get", "(", ")", "if", "given_hparams", "is", "None", "and", "not", "frame", ":", "current_frame", "=", "inspect", ".", "currentframe", "(", ")", "if", "current_frame", ":", "frame", "=", "current_frame", ".", "f_back", "save_hyperparameters", "(", "self", ",", "*", "args", ",", "ignore", "=", "ignore", ",", "frame", "=", "frame", ",", "given_hparams", "=", "given_hparams", ")"], "docstring": "the frame needs to be created in this file.", "docstring_tokens": ["the", "frame", "needs", "to", "be", "created", "in", "this", "file"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\mixins\\hparams_mixin.py", "start_line": 50, "end_line": 130, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\core\\mixins\\hparams_mixin.py", "func_name": "function_152", "original_string": "def hparams_initial(self) -> AttributeDict:\r\n        \"\"\"The collection of hyperparameters saved with :meth:`save_hyperparameters`. These contents are read-only.\r\n        Manual updates to the saved hyperparameters can instead be performed through :attr:`hparams`.\r\n\r\n        Returns:\r\n            AttributeDict: immutable initial hyperparameters\r\n\r\n        \"\"\"\r\n        if not hasattr(self, \"_hparams_initial\"):\r\n            return AttributeDict()\r\n        return copy.deepcopy(self._hparams_initial)", "language": "python", "code": "def hparams_initial(self) -> AttributeDict:\r\n        \"\"\"The collection of hyperparameters saved with :meth:`save_hyperparameters`. These contents are read-only.\r\n        Manual updates to the saved hyperparameters can instead be performed through :attr:`hparams`.\r\n\r\n        Returns:\r\n            AttributeDict: immutable initial hyperparameters\r\n\r\n        \"\"\"\r\n        if not hasattr(self, \"_hparams_initial\"):\r\n            return AttributeDict()\r\n        return copy.deepcopy(self._hparams_initial)", "code_tokens": ["def", "hparams_initial", "(", "self", ")", "-", ">", "AttributeDict", ":", "STRING", "if", "not", "hasattr", "(", "self", ",", "STRING", ")", ":", "return", "AttributeDict", "(", ")", "return", "copy", ".", "deepcopy", "(", "self", ".", "_hparams_initial", ")"], "docstring": "prevent any change", "docstring_tokens": ["prevent", "any", "change"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\core\\mixins\\hparams_mixin.py", "start_line": 166, "end_line": 177, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\demos\\mnist_datamodule.py", "func_name": "function_153", "original_string": "def _try_load(path_data: str, trials: int = 30, delta: float = 1.0) -> tuple[Tensor, Tensor]:\r\n        \"\"\"Resolving loading from the same time from multiple concurrent processes.\"\"\"\r\n        res, exception = None, None\r\n        assert trials, \"at least some trial has to be set\"\r\n        assert os.path.isfile(path_data), f\"missing file: {path_data}\"\r\n        for _ in range(trials):\r\n            try:\r\n                res = torch.load(path_data)\r\n            except Exception as ex:\r\n                exception = ex\r\n                time.sleep(delta * random.random())  # noqa: S311\r\n            else:\r\n                break\r\n        assert res is not None\r\n        if exception is not None:\r\n            raise exception\r\n        return res", "language": "python", "code": "def _try_load(path_data: str, trials: int = 30, delta: float = 1.0) -> tuple[Tensor, Tensor]:\r\n        \"\"\"Resolving loading from the same time from multiple concurrent processes.\"\"\"\r\n        res, exception = None, None\r\n        assert trials, \"at least some trial has to be set\"\r\n        assert os.path.isfile(path_data), f\"missing file: {path_data}\"\r\n        for _ in range(trials):\r\n            try:\r\n                res = torch.load(path_data)\r\n            except Exception as ex:\r\n                exception = ex\r\n                time.sleep(delta * random.random())  # noqa: S311\r\n            else:\r\n                break\r\n        assert res is not None\r\n        if exception is not None:\r\n            raise exception\r\n        return res", "code_tokens": ["def", "_try_load", "(", "path_data", ":", "str", ",", "trials", ":", "int", "=", "30", ",", "delta", ":", "float", "=", "1", ".", "0", ")", "-", ">", "tuple", "[", "Tensor", ",", "Tensor", "]", ":", "STRING", "res", ",", "exception", "=", "None", ",", "None", "assert", "trials", ",", "STRING", "assert", "os", ".", "path", ".", "isfile", "(", "path_data", ")", ",", "fSTRING", "for", "_", "in", "range", "(", "trials", ")", ":", "try", ":", "res", "=", "torch", ".", "load", "(", "path_data", ")", "except", "Exception", "as", "ex", ":", "exception", "=", "ex", "time", ".", "sleep", "(", "delta", "*", "random", ".", "random", "(", ")", ")", "#", "noqa", ":", "S311", "else", ":", "break", "assert", "res", "is", "not", "None", "if", "exception", "is", "not", "None", ":", "raise", "exception", "return", "res"], "docstring": "todo: specify the possible exception raise the caught exception", "docstring_tokens": ["todo", "specify", "the", "possible", "exception", "raise", "the", "caught", "exception"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\demos\\mnist_datamodule.py", "start_line": 102, "end_line": 120, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\demos\\mnist_datamodule.py", "func_name": "function_154", "original_string": "def __init__(\r\n        self,\r\n        data_dir: str = _DATASETS_PATH,\r\n        val_split: int = 5000,\r\n        num_workers: int = 16,\r\n        normalize: bool = False,\r\n        seed: int = 42,\r\n        batch_size: int = 32,\r\n    ) -> None:\r\n        \"\"\"\r\n        Args:\r\n            data_dir: where to save/load the data\r\n            val_split: how many of the training images to use for the validation split\r\n            num_workers: how many workers to use for loading data\r\n            normalize: If true applies image normalize\r\n            seed: starting seed for RNG.\r\n            batch_size: desired batch size.\r\n        \"\"\"\r\n        super().__init__()\r\n        if num_workers and _IS_WINDOWS:\r\n            warn(\r\n                f\"You have requested num_workers={num_workers} on Windows,\"\r\n                \" but currently recommended is 0, so we set it for you\"\r\n            )\r\n            num_workers = 0\r\n\r\n        self.data_dir = data_dir\r\n        self.val_split = val_split\r\n        self.num_workers = num_workers\r\n        self.normalize = normalize\r\n        self.seed = seed\r\n        self.batch_size = batch_size", "language": "python", "code": "def __init__(\r\n        self,\r\n        data_dir: str = _DATASETS_PATH,\r\n        val_split: int = 5000,\r\n        num_workers: int = 16,\r\n        normalize: bool = False,\r\n        seed: int = 42,\r\n        batch_size: int = 32,\r\n    ) -> None:\r\n        \"\"\"\r\n        Args:\r\n            data_dir: where to save/load the data\r\n            val_split: how many of the training images to use for the validation split\r\n            num_workers: how many workers to use for loading data\r\n            normalize: If true applies image normalize\r\n            seed: starting seed for RNG.\r\n            batch_size: desired batch size.\r\n        \"\"\"\r\n        super().__init__()\r\n        if num_workers and _IS_WINDOWS:\r\n            warn(\r\n                f\"You have requested num_workers={num_workers} on Windows,\"\r\n                \" but currently recommended is 0, so we set it for you\"\r\n            )\r\n            num_workers = 0\r\n\r\n        self.data_dir = data_dir\r\n        self.val_split = val_split\r\n        self.num_workers = num_workers\r\n        self.normalize = normalize\r\n        self.seed = seed\r\n        self.batch_size = batch_size", "code_tokens": ["def", "__init__", "(", "self", ",", "data_dir", ":", "str", "=", "_DATASETS_PATH", ",", "val_split", ":", "int", "=", "5000", ",", "num_workers", ":", "int", "=", "16", ",", "normalize", ":", "bool", "=", "False", ",", "seed", ":", "int", "=", "42", ",", "batch_size", ":", "int", "=", "32", ",", ")", "-", ">", "None", ":", "STRING", "super", "(", ")", ".", "__init__", "(", ")", "if", "num_workers", "and", "_IS_WINDOWS", ":", "warn", "(", "fSTRING", "STRING", ")", "num_workers", "=", "0", "self", ".", "data_dir", "=", "data_dir", "self", ".", "val_split", "=", "val_split", "self", ".", "num_workers", "=", "num_workers", "self", ".", "normalize", "=", "normalize", "self", ".", "seed", "=", "seed", "self", ".", "batch_size", "=", "batch_size"], "docstring": "see: https://stackoverflow.com/a/59680818", "docstring_tokens": ["see", "https", "stackoverflow", "com", "a", "59680818"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\demos\\mnist_datamodule.py", "start_line": 155, "end_line": 187, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\comet.py", "func_name": "function_155", "original_string": "def experiment(self) -> comet_experiment:\r\n        r\"\"\"Actual Comet object. To use Comet features in your :class:`~lightning.pytorch.core.LightningModule` do the\r\n        following.\r\n\r\n        Example::\r\n\r\n            self.logger.experiment.some_comet_function()\r\n\r\n        \"\"\"\r\n\r\n        if not self._experiment:\r\n            self._create_experiment()\r\n\r\n        return self._experiment", "language": "python", "code": "def experiment(self) -> comet_experiment:\r\n        r\"\"\"Actual Comet object. To use Comet features in your :class:`~lightning.pytorch.core.LightningModule` do the\r\n        following.\r\n\r\n        Example::\r\n\r\n            self.logger.experiment.some_comet_function()\r\n\r\n        \"\"\"\r\n\r\n        if not self._experiment:\r\n            self._create_experiment()\r\n\r\n        return self._experiment", "code_tokens": ["def", "experiment", "(", "self", ")", "-", ">", "comet_experiment", ":", "rSTRING", "if", "not", "self", ".", "_experiment", ":", "self", ".", "_create_experiment", "(", ")", "return", "self", ".", "_experiment"], "docstring": "if by some chance there is no experiment created yet (for example, when strategy=ddp_spawn) then we will create a new one", "docstring_tokens": ["if", "by", "some", "chance", "there", "is", "no", "experiment", "created", "yet", "for", "example", "when", "strategy", "ddp_spawn", "then", "we", "will", "create", "a", "new", "one"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\comet.py", "start_line": 305, "end_line": 320, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\comet.py", "func_name": "function_156", "original_string": "def finalize(self, status: str) -> None:\r\n        \"\"\"We will not end experiment (will not call self._experiment.end()) here to have an ability to continue using\r\n        it after training is complete but instead of ending we will upload/save all the data.\"\"\"\r\n        if self._experiment is None:\r\n            return\r\n\r\n        self.experiment.flush()", "language": "python", "code": "def finalize(self, status: str) -> None:\r\n        \"\"\"We will not end experiment (will not call self._experiment.end()) here to have an ability to continue using\r\n        it after training is complete but instead of ending we will upload/save all the data.\"\"\"\r\n        if self._experiment is None:\r\n            return\r\n\r\n        self.experiment.flush()", "code_tokens": ["def", "finalize", "(", "self", ",", "status", ":", "str", ")", "-", ">", "None", ":", "STRING", "if", "self", ".", "_experiment", "is", "None", ":", "return", "self", ".", "experiment", ".", "flush", "(", ")"], "docstring": "When using multiprocessing, finalize() should be a no-op on the main process, as no experiment has been initialized there just save the data", "docstring_tokens": ["when", "using", "multiprocessing", "finalize", "should", "be", "a", "no", "op", "on", "the", "main", "process", "as", "no", "experiment", "has", "been", "initialized", "there", "just", "save", "the", "data"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\comet.py", "start_line": 354, "end_line": 363, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\comet.py", "func_name": "function_157", "original_string": "def version(self) -> Optional[str]:\r\n        \"\"\"Gets the version.\r\n\r\n        Returns:\r\n            The experiment key if present\r\n\r\n        \"\"\"\r\n        if self._experiment is not None:\r\n            return self._experiment.get_key()", "language": "python", "code": "def version(self) -> Optional[str]:\r\n        \"\"\"Gets the version.\r\n\r\n        Returns:\r\n            The experiment key if present\r\n\r\n        \"\"\"\r\n        if self._experiment is not None:\r\n            return self._experiment.get_key()", "code_tokens": ["def", "version", "(", "self", ")", "-", ">", "Optional", "[", "str", "]", ":", "STRING", "if", "self", ".", "_experiment", "is", "not", "None", ":", "return", "self", ".", "_experiment", ".", "get_key", "(", ")"], "docstring": "Don't create an experiment if we don't have one", "docstring_tokens": ["don", "t", "create", "an", "experiment", "if", "we", "don", "t", "have", "one"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\comet.py", "start_line": 389, "end_line": 398, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\csv_logs.py", "func_name": "function_158", "original_string": "def log_dir(self) -> str:\r\n        \"\"\"The log directory for this run.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        return os.path.join(self.root_dir, version)", "language": "python", "code": "def log_dir(self) -> str:\r\n        \"\"\"The log directory for this run.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        return os.path.join(self.root_dir, version)", "code_tokens": ["def", "log_dir", "(", "self", ")", "-", ">", "str", ":", "STRING", "version", "=", "self", ".", "version", "if", "isinstance", "(", "self", ".", "version", ",", "str", ")", "else", "fSTRING", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "version", ")"], "docstring": "create a pseudo standard path", "docstring_tokens": ["create", "a", "pseudo", "standard", "path"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\csv_logs.py", "start_line": 117, "end_line": 126, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\neptune.py", "func_name": "function_159", "original_string": "def experiment(self) -> \"Run\":\r\n        r\"\"\"Actual Neptune run object. Allows you to use neptune logging features in your\r\n        :class:`~lightning.pytorch.core.LightningModule`.\r\n\r\n        Example::\r\n\r\n            class LitModel(LightningModule):\r\n                def training_step(self, batch, batch_idx):\r\n                    acc = ...\r\n                    self.logger.experiment[\"train/acc\"].append(acc)\r\n\r\n                    img = ...\r\n                    self.logger.experiment[\"train/misclassified_images\"].append(File.as_image(img))\r\n\r\n        Note that the syntax ``self.logger.experiment[\"your/metadata/structure\"].append(metadata)``\r\n        is specific to Neptune and extends the logger capabilities.\r\n        It lets you log various types of metadata, such as scores, files,\r\n        images, interactive visuals, and CSVs. Refer to the\r\n        `Neptune docs <https://docs.neptune.ai/logging/methods>`_\r\n        for more detailed explanations.\r\n        You can also use the regular logger methods ``log_metrics()``, and ``log_hyperparams()``\r\n        with NeptuneLogger.\r\n\r\n        \"\"\"\r\n        return self.run", "language": "python", "code": "def experiment(self) -> \"Run\":\r\n        r\"\"\"Actual Neptune run object. Allows you to use neptune logging features in your\r\n        :class:`~lightning.pytorch.core.LightningModule`.\r\n\r\n        Example::\r\n\r\n            class LitModel(LightningModule):\r\n                def training_step(self, batch, batch_idx):\r\n                    acc = ...\r\n                    self.logger.experiment[\"train/acc\"].append(acc)\r\n\r\n                    img = ...\r\n                    self.logger.experiment[\"train/misclassified_images\"].append(File.as_image(img))\r\n\r\n        Note that the syntax ``self.logger.experiment[\"your/metadata/structure\"].append(metadata)``\r\n        is specific to Neptune and extends the logger capabilities.\r\n        It lets you log various types of metadata, such as scores, files,\r\n        images, interactive visuals, and CSVs. Refer to the\r\n        `Neptune docs <https://docs.neptune.ai/logging/methods>`_\r\n        for more detailed explanations.\r\n        You can also use the regular logger methods ``log_metrics()``, and ``log_hyperparams()``\r\n        with NeptuneLogger.\r\n\r\n        \"\"\"\r\n        return self.run", "code_tokens": ["def", "experiment", "(", "self", ")", "-", ">", "STRING", ":", "rSTRING", "return", "self", ".", "run"], "docstring": "log metrics log images", "docstring_tokens": ["log", "metrics", "log", "images"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\neptune.py", "start_line": 354, "end_line": 380, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\neptune.py", "func_name": "function_160", "original_string": "def after_save_checkpoint(self, checkpoint_callback: Checkpoint) -> None:\r\n        \"\"\"Automatically log checkpointed model. Called after model checkpoint callback saves a new checkpoint.\r\n\r\n        Args:\r\n            checkpoint_callback: the model checkpoint callback instance\r\n\r\n        \"\"\"\r\n        if not self._log_model_checkpoints:\r\n            return\r\n\r\n        file_names = set()\r\n        checkpoints_namespace = self._construct_path_with_prefix(\"model/checkpoints\")\r\n\r\n        if hasattr(checkpoint_callback, \"last_model_path\") and checkpoint_callback.last_model_path:\r\n            model_last_name = self._get_full_model_name(checkpoint_callback.last_model_path, checkpoint_callback)\r\n            file_names.add(model_last_name)\r\n            self.run[f\"{checkpoints_namespace}/{model_last_name}\"].upload(checkpoint_callback.last_model_path)\r\n\r\n        if hasattr(checkpoint_callback, \"best_k_models\"):\r\n            for key in checkpoint_callback.best_k_models:\r\n                model_name = self._get_full_model_name(key, checkpoint_callback)\r\n                file_names.add(model_name)\r\n                self.run[f\"{checkpoints_namespace}/{model_name}\"].upload(key)\r\n\r\n        if hasattr(checkpoint_callback, \"best_model_path\") and checkpoint_callback.best_model_path:\r\n            self.run[self._construct_path_with_prefix(\"model/best_model_path\")] = checkpoint_callback.best_model_path\r\n\r\n            model_name = self._get_full_model_name(checkpoint_callback.best_model_path, checkpoint_callback)\r\n            file_names.add(model_name)\r\n            self.run[f\"{checkpoints_namespace}/{model_name}\"].upload(checkpoint_callback.best_model_path)\r\n\r\n        if self.run.exists(checkpoints_namespace):\r\n            exp_structure = self.run.get_structure()\r\n            uploaded_model_names = self._get_full_model_names_from_exp_structure(exp_structure, checkpoints_namespace)\r\n\r\n            for file_to_drop in list(uploaded_model_names - file_names):\r\n                del self.run[f\"{checkpoints_namespace}/{file_to_drop}\"]\r\n\r\n        if hasattr(checkpoint_callback, \"best_model_score\") and checkpoint_callback.best_model_score:\r\n            self.run[self._construct_path_with_prefix(\"model/best_model_score\")] = (\r\n                checkpoint_callback.best_model_score.cpu().detach().numpy()\r\n            )", "language": "python", "code": "def after_save_checkpoint(self, checkpoint_callback: Checkpoint) -> None:\r\n        \"\"\"Automatically log checkpointed model. Called after model checkpoint callback saves a new checkpoint.\r\n\r\n        Args:\r\n            checkpoint_callback: the model checkpoint callback instance\r\n\r\n        \"\"\"\r\n        if not self._log_model_checkpoints:\r\n            return\r\n\r\n        file_names = set()\r\n        checkpoints_namespace = self._construct_path_with_prefix(\"model/checkpoints\")\r\n\r\n        if hasattr(checkpoint_callback, \"last_model_path\") and checkpoint_callback.last_model_path:\r\n            model_last_name = self._get_full_model_name(checkpoint_callback.last_model_path, checkpoint_callback)\r\n            file_names.add(model_last_name)\r\n            self.run[f\"{checkpoints_namespace}/{model_last_name}\"].upload(checkpoint_callback.last_model_path)\r\n\r\n        if hasattr(checkpoint_callback, \"best_k_models\"):\r\n            for key in checkpoint_callback.best_k_models:\r\n                model_name = self._get_full_model_name(key, checkpoint_callback)\r\n                file_names.add(model_name)\r\n                self.run[f\"{checkpoints_namespace}/{model_name}\"].upload(key)\r\n\r\n        if hasattr(checkpoint_callback, \"best_model_path\") and checkpoint_callback.best_model_path:\r\n            self.run[self._construct_path_with_prefix(\"model/best_model_path\")] = checkpoint_callback.best_model_path\r\n\r\n            model_name = self._get_full_model_name(checkpoint_callback.best_model_path, checkpoint_callback)\r\n            file_names.add(model_name)\r\n            self.run[f\"{checkpoints_namespace}/{model_name}\"].upload(checkpoint_callback.best_model_path)\r\n\r\n        if self.run.exists(checkpoints_namespace):\r\n            exp_structure = self.run.get_structure()\r\n            uploaded_model_names = self._get_full_model_names_from_exp_structure(exp_structure, checkpoints_namespace)\r\n\r\n            for file_to_drop in list(uploaded_model_names - file_names):\r\n                del self.run[f\"{checkpoints_namespace}/{file_to_drop}\"]\r\n\r\n        if hasattr(checkpoint_callback, \"best_model_score\") and checkpoint_callback.best_model_score:\r\n            self.run[self._construct_path_with_prefix(\"model/best_model_score\")] = (\r\n                checkpoint_callback.best_model_score.cpu().detach().numpy()\r\n            )", "code_tokens": ["def", "after_save_checkpoint", "(", "self", ",", "checkpoint_callback", ":", "Checkpoint", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_log_model_checkpoints", ":", "return", "file_names", "=", "set", "(", ")", "checkpoints_namespace", "=", "self", ".", "_construct_path_with_prefix", "(", "STRING", ")", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", "and", "checkpoint_callback", ".", "last_model_path", ":", "model_last_name", "=", "self", ".", "_get_full_model_name", "(", "checkpoint_callback", ".", "last_model_path", ",", "checkpoint_callback", ")", "file_names", ".", "add", "(", "model_last_name", ")", "self", ".", "run", "[", "fSTRING", "]", ".", "upload", "(", "checkpoint_callback", ".", "last_model_path", ")", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", ":", "for", "key", "in", "checkpoint_callback", ".", "best_k_models", ":", "model_name", "=", "self", ".", "_get_full_model_name", "(", "key", ",", "checkpoint_callback", ")", "file_names", ".", "add", "(", "model_name", ")", "self", ".", "run", "[", "fSTRING", "]", ".", "upload", "(", "key", ")", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", "and", "checkpoint_callback", ".", "best_model_path", ":", "self", ".", "run", "[", "self", ".", "_construct_path_with_prefix", "(", "STRING", ")", "]", "=", "checkpoint_callback", ".", "best_model_path", "model_name", "=", "self", ".", "_get_full_model_name", "(", "checkpoint_callback", ".", "best_model_path", ",", "checkpoint_callback", ")", "file_names", ".", "add", "(", "model_name", ")", "self", ".", "run", "[", "fSTRING", "]", ".", "upload", "(", "checkpoint_callback", ".", "best_model_path", ")", "if", "self", ".", "run", ".", "exists", "(", "checkpoints_namespace", ")", ":", "exp_structure", "=", "self", ".", "run", ".", "get_structure", "(", ")", "uploaded_model_names", "=", "self", ".", "_get_full_model_names_from_exp_structure", "(", "exp_structure", ",", "checkpoints_namespace", ")", "for", "file_to_drop", "in", "list", "(", "uploaded_model_names", "-", "file_names", ")", ":", "del", "self", ".", "run", "[", "fSTRING", "]", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", "and", "checkpoint_callback", ".", "best_model_score", ":", "self", ".", "run", "[", "self", ".", "_construct_path_with_prefix", "(", "STRING", ")", "]", "=", "(", "checkpoint_callback", ".", "best_model_score", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")"], "docstring": "save last model save best k models log best model path and checkpoint remove old models logged to experiment if they are not part of best k models at this point log best model score", "docstring_tokens": ["save", "last", "model", "save", "best", "k", "models", "log", "best", "model", "path", "and", "checkpoint", "remove", "old", "models", "logged", "to", "experiment", "if", "they", "are", "not", "part", "of", "best", "k", "models", "at", "this", "point", "log", "best", "model", "score"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\neptune.py", "start_line": 500, "end_line": 546, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\neptune.py", "func_name": "function_161", "original_string": "def _get_full_model_name(model_path: str, checkpoint_callback: Checkpoint) -> str:\r\n        \"\"\"Returns model name which is string `model_path` appended to `checkpoint_callback.dirpath`.\"\"\"\r\n        if hasattr(checkpoint_callback, \"dirpath\"):\r\n            model_path = os.path.normpath(model_path)\r\n            expected_model_path = os.path.normpath(checkpoint_callback.dirpath)\r\n            if not model_path.startswith(expected_model_path):\r\n                raise ValueError(f\"{model_path} was expected to start with {expected_model_path}.\")\r\n            filepath, _ = os.path.splitext(model_path[len(expected_model_path) + 1 :])\r\n            return filepath.replace(os.sep, \"/\")\r\n        return model_path.replace(os.sep, \"/\")", "language": "python", "code": "def _get_full_model_name(model_path: str, checkpoint_callback: Checkpoint) -> str:\r\n        \"\"\"Returns model name which is string `model_path` appended to `checkpoint_callback.dirpath`.\"\"\"\r\n        if hasattr(checkpoint_callback, \"dirpath\"):\r\n            model_path = os.path.normpath(model_path)\r\n            expected_model_path = os.path.normpath(checkpoint_callback.dirpath)\r\n            if not model_path.startswith(expected_model_path):\r\n                raise ValueError(f\"{model_path} was expected to start with {expected_model_path}.\")\r\n            filepath, _ = os.path.splitext(model_path[len(expected_model_path) + 1 :])\r\n            return filepath.replace(os.sep, \"/\")\r\n        return model_path.replace(os.sep, \"/\")", "code_tokens": ["def", "_get_full_model_name", "(", "model_path", ":", "str", ",", "checkpoint_callback", ":", "Checkpoint", ")", "-", ">", "str", ":", "STRING", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", ":", "model_path", "=", "os", ".", "path", ".", "normpath", "(", "model_path", ")", "expected_model_path", "=", "os", ".", "path", ".", "normpath", "(", "checkpoint_callback", ".", "dirpath", ")", "if", "not", "model_path", ".", "startswith", "(", "expected_model_path", ")", ":", "raise", "ValueError", "(", "fSTRING", ")", "filepath", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "model_path", "[", "len", "(", "expected_model_path", ")", "+", "1", ":", "]", ")", "return", "filepath", ".", "replace", "(", "os", ".", "sep", ",", "STRING", ")", "return", "model_path", ".", "replace", "(", "os", ".", "sep", ",", "STRING", ")"], "docstring": "Remove extension from filepath", "docstring_tokens": ["remove", "extension", "from", "filepath"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\neptune.py", "start_line": 549, "end_line": 559, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\tensorboard.py", "func_name": "function_162", "original_string": "def log_dir(self) -> str:\r\n        \"\"\"The directory for this run's tensorboard checkpoint.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        log_dir = os.path.join(self.root_dir, version)\r\n        if isinstance(self.sub_dir, str):\r\n            log_dir = os.path.join(log_dir, self.sub_dir)\r\n        log_dir = os.path.expandvars(log_dir)\r\n        log_dir = os.path.expanduser(log_dir)\r\n        return log_dir", "language": "python", "code": "def log_dir(self) -> str:\r\n        \"\"\"The directory for this run's tensorboard checkpoint.\r\n\r\n        By default, it is named ``'version_${self.version}'`` but it can be overridden by passing a string value for the\r\n        constructor's version parameter instead of ``None`` or an int.\r\n\r\n        \"\"\"\r\n        version = self.version if isinstance(self.version, str) else f\"version_{self.version}\"\r\n        log_dir = os.path.join(self.root_dir, version)\r\n        if isinstance(self.sub_dir, str):\r\n            log_dir = os.path.join(log_dir, self.sub_dir)\r\n        log_dir = os.path.expandvars(log_dir)\r\n        log_dir = os.path.expanduser(log_dir)\r\n        return log_dir", "code_tokens": ["def", "log_dir", "(", "self", ")", "-", ">", "str", ":", "STRING", "version", "=", "self", ".", "version", "if", "isinstance", "(", "self", ".", "version", ",", "str", ")", "else", "fSTRING", "log_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "version", ")", "if", "isinstance", "(", "self", ".", "sub_dir", ",", "str", ")", ":", "log_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "self", ".", "sub_dir", ")", "log_dir", "=", "os", ".", "path", ".", "expandvars", "(", "log_dir", ")", "log_dir", "=", "os", ".", "path", ".", "expanduser", "(", "log_dir", ")", "return", "log_dir"], "docstring": "create a pseudo standard path ala test-tube", "docstring_tokens": ["create", "a", "pseudo", "standard", "path", "ala", "test", "tube"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\tensorboard.py", "start_line": 125, "end_line": 139, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\tensorboard.py", "func_name": "function_163", "original_string": "def log_hyperparams(\r\n        self,\r\n        params: Union[dict[str, Any], Namespace],\r\n        metrics: Optional[dict[str, Any]] = None,\r\n        step: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Record hyperparameters. TensorBoard logs with and without saved hyperparameters are incompatible, the\r\n        hyperparameters are then not displayed in the TensorBoard. Please delete or move the previously saved logs to\r\n        display the new ones with hyperparameters.\r\n\r\n        Args:\r\n            params: A dictionary-like container with the hyperparameters\r\n            metrics: Dictionary with metric names as keys and measured quantities as values\r\n            step: Optional global step number for the logged metrics\r\n\r\n        \"\"\"\r\n        if _OMEGACONF_AVAILABLE:\r\n            from omegaconf import Container, OmegaConf\r\n\r\n        params = _convert_params(params)\r\n\r\n        if _OMEGACONF_AVAILABLE and isinstance(params, Container):\r\n            self.hparams = OmegaConf.merge(self.hparams, params)\r\n        else:\r\n            self.hparams.update(params)\r\n\r\n        return super().log_hyperparams(params=params, metrics=metrics, step=step)", "language": "python", "code": "def log_hyperparams(\r\n        self,\r\n        params: Union[dict[str, Any], Namespace],\r\n        metrics: Optional[dict[str, Any]] = None,\r\n        step: Optional[int] = None,\r\n    ) -> None:\r\n        \"\"\"Record hyperparameters. TensorBoard logs with and without saved hyperparameters are incompatible, the\r\n        hyperparameters are then not displayed in the TensorBoard. Please delete or move the previously saved logs to\r\n        display the new ones with hyperparameters.\r\n\r\n        Args:\r\n            params: A dictionary-like container with the hyperparameters\r\n            metrics: Dictionary with metric names as keys and measured quantities as values\r\n            step: Optional global step number for the logged metrics\r\n\r\n        \"\"\"\r\n        if _OMEGACONF_AVAILABLE:\r\n            from omegaconf import Container, OmegaConf\r\n\r\n        params = _convert_params(params)\r\n\r\n        if _OMEGACONF_AVAILABLE and isinstance(params, Container):\r\n            self.hparams = OmegaConf.merge(self.hparams, params)\r\n        else:\r\n            self.hparams.update(params)\r\n\r\n        return super().log_hyperparams(params=params, metrics=metrics, step=step)", "code_tokens": ["def", "log_hyperparams", "(", "self", ",", "params", ":", "Union", "[", "dict", "[", "str", ",", "Any", "]", ",", "Namespace", "]", ",", "metrics", ":", "Optional", "[", "dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "step", ":", "Optional", "[", "int", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "_OMEGACONF_AVAILABLE", ":", "from", "omegaconf", "import", "Container", ",", "OmegaConf", "params", "=", "_convert_params", "(", "params", ")", "if", "_OMEGACONF_AVAILABLE", "and", "isinstance", "(", "params", ",", "Container", ")", ":", "self", ".", "hparams", "=", "OmegaConf", ".", "merge", "(", "self", ".", "hparams", ",", "params", ")", "else", ":", "self", ".", "hparams", ".", "update", "(", "params", ")", "return", "super", "(", ")", ".", "log_hyperparams", "(", "params", "=", "params", ",", "metrics", "=", "metrics", ",", "step", "=", "step", ")"], "docstring": "store params to output", "docstring_tokens": ["store", "params", "to", "output"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\tensorboard.py", "start_line": 154, "end_line": 181, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\utilities.py", "func_name": "function_164", "original_string": "def _scan_checkpoints(checkpoint_callback: Checkpoint, logged_model_time: dict) -> list[tuple[float, str, float, str]]:\r\n    \"\"\"Return the checkpoints to be logged.\r\n\r\n    Args:\r\n        checkpoint_callback: Checkpoint callback reference.\r\n        logged_model_time: dictionary containing the logged model times.\r\n\r\n    \"\"\"\r\n    checkpoints = {}\r\n    if hasattr(checkpoint_callback, \"last_model_path\") and hasattr(checkpoint_callback, \"current_score\"):\r\n        checkpoints[checkpoint_callback.last_model_path] = (checkpoint_callback.current_score, \"latest\")\r\n\r\n    if hasattr(checkpoint_callback, \"best_model_path\") and hasattr(checkpoint_callback, \"best_model_score\"):\r\n        checkpoints[checkpoint_callback.best_model_path] = (checkpoint_callback.best_model_score, \"best\")\r\n\r\n    if hasattr(checkpoint_callback, \"best_k_models\"):\r\n        for key, value in checkpoint_callback.best_k_models.items():\r\n            checkpoints[key] = (value, \"best_k\")\r\n\r\n    checkpoints = sorted(\r\n        (Path(p).stat().st_mtime, p, s, tag) for p, (s, tag) in checkpoints.items() if Path(p).is_file()\r\n    )\r\n    checkpoints = [c for c in checkpoints if c[1] not in logged_model_time or logged_model_time[c[1]] < c[0]]\r\n    return checkpoints", "language": "python", "code": "def _scan_checkpoints(checkpoint_callback: Checkpoint, logged_model_time: dict) -> list[tuple[float, str, float, str]]:\r\n    \"\"\"Return the checkpoints to be logged.\r\n\r\n    Args:\r\n        checkpoint_callback: Checkpoint callback reference.\r\n        logged_model_time: dictionary containing the logged model times.\r\n\r\n    \"\"\"\r\n    checkpoints = {}\r\n    if hasattr(checkpoint_callback, \"last_model_path\") and hasattr(checkpoint_callback, \"current_score\"):\r\n        checkpoints[checkpoint_callback.last_model_path] = (checkpoint_callback.current_score, \"latest\")\r\n\r\n    if hasattr(checkpoint_callback, \"best_model_path\") and hasattr(checkpoint_callback, \"best_model_score\"):\r\n        checkpoints[checkpoint_callback.best_model_path] = (checkpoint_callback.best_model_score, \"best\")\r\n\r\n    if hasattr(checkpoint_callback, \"best_k_models\"):\r\n        for key, value in checkpoint_callback.best_k_models.items():\r\n            checkpoints[key] = (value, \"best_k\")\r\n\r\n    checkpoints = sorted(\r\n        (Path(p).stat().st_mtime, p, s, tag) for p, (s, tag) in checkpoints.items() if Path(p).is_file()\r\n    )\r\n    checkpoints = [c for c in checkpoints if c[1] not in logged_model_time or logged_model_time[c[1]] < c[0]]\r\n    return checkpoints", "code_tokens": ["def", "_scan_checkpoints", "(", "checkpoint_callback", ":", "Checkpoint", ",", "logged_model_time", ":", "dict", ")", "-", ">", "list", "[", "tuple", "[", "float", ",", "str", ",", "float", ",", "str", "]", "]", ":", "STRING", "checkpoints", "=", "{", "}", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", "and", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", ":", "checkpoints", "[", "checkpoint_callback", ".", "last_model_path", "]", "=", "(", "checkpoint_callback", ".", "current_score", ",", "STRING", ")", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", "and", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", ":", "checkpoints", "[", "checkpoint_callback", ".", "best_model_path", "]", "=", "(", "checkpoint_callback", ".", "best_model_score", ",", "STRING", ")", "if", "hasattr", "(", "checkpoint_callback", ",", "STRING", ")", ":", "for", "key", ",", "value", "in", "checkpoint_callback", ".", "best_k_models", ".", "items", "(", ")", ":", "checkpoints", "[", "key", "]", "=", "(", "value", ",", "STRING", ")", "checkpoints", "=", "sorted", "(", "(", "Path", "(", "p", ")", ".", "stat", "(", ")", ".", "st_mtime", ",", "p", ",", "s", ",", "tag", ")", "for", "p", ",", "(", "s", ",", "tag", ")", "in", "checkpoints", ".", "items", "(", ")", "if", "Path", "(", "p", ")", ".", "is_file", "(", ")", ")", "checkpoints", "=", "[", "c", "for", "c", "in", "checkpoints", "if", "c", "[", "1", "]", "not", "in", "logged_model_time", "or", "logged_model_time", "[", "c", "[", "1", "]", "]", "<", "c", "[", "0", "]", "]", "return", "checkpoints"], "docstring": "get checkpoints to be saved with associated score", "docstring_tokens": ["get", "checkpoints", "to", "be", "saved", "with", "associated", "score"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\utilities.py", "start_line": 31, "end_line": 55, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\wandb.py", "func_name": "function_165", "original_string": "def experiment(self) -> Union[\"Run\", \"RunDisabled\"]:\r\n        r\"\"\"Actual wandb object. To use wandb features in your :class:`~lightning.pytorch.core.LightningModule` do the\r\n        following.\r\n\r\n        Example::\r\n\r\n        .. code-block:: python\r\n\r\n            self.logger.experiment.some_wandb_function()\r\n\r\n        \"\"\"\r\n        import wandb\r\n        from wandb.sdk.lib import RunDisabled\r\n        from wandb.wandb_run import Run\r\n\r\n        if self._experiment is None:\r\n            if self._offline:\r\n                os.environ[\"WANDB_MODE\"] = \"dryrun\"\r\n\r\n            attach_id = getattr(self, \"_attach_id\", None)\r\n            if wandb.run is not None:\r\n                rank_zero_warn(\r\n                    \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\r\n                    \" this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\"\r\n                )\r\n                self._experiment = wandb.run\r\n            elif attach_id is not None and hasattr(wandb, \"_attach\"):\r\n                self._experiment = wandb._attach(attach_id)\r\n            else:\r\n                self._experiment = wandb.init(**self._wandb_init)\r\n\r\n                if isinstance(self._experiment, (Run, RunDisabled)) and getattr(\r\n                    self._experiment, \"define_metric\", None\r\n                ):\r\n                    if self._wandb_init.get(\"sync_tensorboard\"):\r\n                        self._experiment.define_metric(\"*\", step_metric=\"global_step\")\r\n                    else:\r\n                        self._experiment.define_metric(\"trainer/global_step\")\r\n                        self._experiment.define_metric(\"*\", step_metric=\"trainer/global_step\", step_sync=True)\r\n\r\n        return self._experiment", "language": "python", "code": "def experiment(self) -> Union[\"Run\", \"RunDisabled\"]:\r\n        r\"\"\"Actual wandb object. To use wandb features in your :class:`~lightning.pytorch.core.LightningModule` do the\r\n        following.\r\n\r\n        Example::\r\n\r\n        .. code-block:: python\r\n\r\n            self.logger.experiment.some_wandb_function()\r\n\r\n        \"\"\"\r\n        import wandb\r\n        from wandb.sdk.lib import RunDisabled\r\n        from wandb.wandb_run import Run\r\n\r\n        if self._experiment is None:\r\n            if self._offline:\r\n                os.environ[\"WANDB_MODE\"] = \"dryrun\"\r\n\r\n            attach_id = getattr(self, \"_attach_id\", None)\r\n            if wandb.run is not None:\r\n                rank_zero_warn(\r\n                    \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\r\n                    \" this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\"\r\n                )\r\n                self._experiment = wandb.run\r\n            elif attach_id is not None and hasattr(wandb, \"_attach\"):\r\n                self._experiment = wandb._attach(attach_id)\r\n            else:\r\n                self._experiment = wandb.init(**self._wandb_init)\r\n\r\n                if isinstance(self._experiment, (Run, RunDisabled)) and getattr(\r\n                    self._experiment, \"define_metric\", None\r\n                ):\r\n                    if self._wandb_init.get(\"sync_tensorboard\"):\r\n                        self._experiment.define_metric(\"*\", step_metric=\"global_step\")\r\n                    else:\r\n                        self._experiment.define_metric(\"trainer/global_step\")\r\n                        self._experiment.define_metric(\"*\", step_metric=\"trainer/global_step\", step_sync=True)\r\n\r\n        return self._experiment", "code_tokens": ["def", "experiment", "(", "self", ")", "-", ">", "Union", "[", "STRING", ",", "STRING", "]", ":", "rSTRING", "import", "wandb", "from", "wandb", ".", "sdk", ".", "lib", "import", "RunDisabled", "from", "wandb", ".", "wandb_run", "import", "Run", "if", "self", ".", "_experiment", "is", "None", ":", "if", "self", ".", "_offline", ":", "os", ".", "environ", "[", "STRING", "]", "=", "STRING", "attach_id", "=", "getattr", "(", "self", ",", "STRING", ",", "None", ")", "if", "wandb", ".", "run", "is", "not", "None", ":", "rank_zero_warn", "(", "STRING", "STRING", ")", "self", ".", "_experiment", "=", "wandb", ".", "run", "elif", "attach_id", "is", "not", "None", "and", "hasattr", "(", "wandb", ",", "STRING", ")", ":", "self", ".", "_experiment", "=", "wandb", ".", "_attach", "(", "attach_id", ")", "else", ":", "self", ".", "_experiment", "=", "wandb", ".", "init", "(", "*", "*", "self", ".", "_wandb_init", ")", "if", "isinstance", "(", "self", ".", "_experiment", ",", "(", "Run", ",", "RunDisabled", ")", ")", "and", "getattr", "(", "self", ".", "_experiment", ",", "STRING", ",", "None", ")", ":", "if", "self", ".", "_wandb_init", ".", "get", "(", "STRING", ")", ":", "self", ".", "_experiment", ".", "define_metric", "(", "STRING", ",", "step_metric", "=", "STRING", ")", "else", ":", "self", ".", "_experiment", ".", "define_metric", "(", "STRING", ")", "self", ".", "_experiment", ".", "define_metric", "(", "STRING", ",", "step_metric", "=", "STRING", ",", "step_sync", "=", "True", ")", "return", "self", ".", "_experiment"], "docstring": "wandb process already created in this instance attach to wandb process referenced create new wandb process define default x-axis", "docstring_tokens": ["wandb", "process", "already", "created", "in", "this", "instance", "attach", "to", "wandb", "process", "referenced", "create", "new", "wandb", "process", "define", "default", "x", "axis"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\wandb.py", "start_line": 377, "end_line": 421, "has_examples": true, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loggers\\wandb.py", "func_name": "function_166", "original_string": "def version(self) -> Optional[str]:\r\n        \"\"\"Gets the id of the experiment.\r\n\r\n        Returns:\r\n            The id of the experiment if the experiment exists else the id given to the constructor.\r\n\r\n        \"\"\"\r\n        return self._experiment.id if self._experiment else self._id", "language": "python", "code": "def version(self) -> Optional[str]:\r\n        \"\"\"Gets the id of the experiment.\r\n\r\n        Returns:\r\n            The id of the experiment if the experiment exists else the id given to the constructor.\r\n\r\n        \"\"\"\r\n        return self._experiment.id if self._experiment else self._id", "code_tokens": ["def", "version", "(", "self", ")", "-", ">", "Optional", "[", "str", "]", ":", "STRING", "return", "self", ".", "_experiment", ".", "id", "if", "self", ".", "_experiment", "else", "self", ".", "_id"], "docstring": "don't create an experiment if we don't have one", "docstring_tokens": ["don", "t", "create", "an", "experiment", "if", "we", "don", "t", "have", "one"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loggers\\wandb.py", "start_line": 580, "end_line": 588, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "func_name": "function_167", "original_string": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop.\"\"\"\r\n        trainer = self.trainer\r\n\r\n        self._has_run = False\r\n        self._logged_outputs = []\r\n\r\n        if not self.restarting:\r\n            self.batch_progress.reset_on_run()\r\n        else:\r\n            self.batch_progress.reset_on_restart()\r\n        fn = trainer.state.fn\r\n        assert fn is not None\r\n        if fn != TrainerFn.FITTING:\r\n            self.batch_progress.reset_on_run()\r\n\r\n        assert trainer.state.stage is not None\r\n        data_fetcher = _select_data_fetcher(trainer, trainer.state.stage)\r\n        combined_loader = self._combined_loader\r\n        assert combined_loader is not None\r\n\r\n        if fn == TrainerFn.FITTING:\r\n            for i, dl in enumerate(combined_loader.flattened):\r\n                _set_sampler_epoch(dl, trainer.fit_loop.epoch_progress.current.processed)\r\n\r\n        combined_loader.limits = self.max_batches\r\n        data_fetcher.setup(combined_loader)\r\n        iter(data_fetcher)  # creates the iterator inside the fetcher\r\n\r\n        data_fetcher.fetched += self.batch_progress.current.ready\r\n        data_fetcher._start_profiler = self._on_before_fetch\r\n        data_fetcher._stop_profiler = self._on_after_fetch\r\n        self._data_fetcher = data_fetcher", "language": "python", "code": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop.\"\"\"\r\n        trainer = self.trainer\r\n\r\n        self._has_run = False\r\n        self._logged_outputs = []\r\n\r\n        if not self.restarting:\r\n            self.batch_progress.reset_on_run()\r\n        else:\r\n            self.batch_progress.reset_on_restart()\r\n        fn = trainer.state.fn\r\n        assert fn is not None\r\n        if fn != TrainerFn.FITTING:\r\n            self.batch_progress.reset_on_run()\r\n\r\n        assert trainer.state.stage is not None\r\n        data_fetcher = _select_data_fetcher(trainer, trainer.state.stage)\r\n        combined_loader = self._combined_loader\r\n        assert combined_loader is not None\r\n\r\n        if fn == TrainerFn.FITTING:\r\n            for i, dl in enumerate(combined_loader.flattened):\r\n                _set_sampler_epoch(dl, trainer.fit_loop.epoch_progress.current.processed)\r\n\r\n        combined_loader.limits = self.max_batches\r\n        data_fetcher.setup(combined_loader)\r\n        iter(data_fetcher)  # creates the iterator inside the fetcher\r\n\r\n        data_fetcher.fetched += self.batch_progress.current.ready\r\n        data_fetcher._start_profiler = self._on_before_fetch\r\n        data_fetcher._stop_profiler = self._on_after_fetch\r\n        self._data_fetcher = data_fetcher", "code_tokens": ["def", "reset", "(", "self", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "self", ".", "_has_run", "=", "False", "self", ".", "_logged_outputs", "=", "[", "]", "if", "not", "self", ".", "restarting", ":", "self", ".", "batch_progress", ".", "reset_on_run", "(", ")", "else", ":", "self", ".", "batch_progress", ".", "reset_on_restart", "(", ")", "fn", "=", "trainer", ".", "state", ".", "fn", "assert", "fn", "is", "not", "None", "if", "fn", "!", "=", "TrainerFn", ".", "FITTING", ":", "self", ".", "batch_progress", ".", "reset_on_run", "(", ")", "assert", "trainer", ".", "state", ".", "stage", "is", "not", "None", "data_fetcher", "=", "_select_data_fetcher", "(", "trainer", ",", "trainer", ".", "state", ".", "stage", ")", "combined_loader", "=", "self", ".", "_combined_loader", "assert", "combined_loader", "is", "not", "None", "if", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "for", "i", ",", "dl", "in", "enumerate", "(", "combined_loader", ".", "flattened", ")", ":", "_set_sampler_epoch", "(", "dl", ",", "trainer", ".", "fit_loop", ".", "epoch_progress", ".", "current", ".", "processed", ")", "combined_loader", ".", "limits", "=", "self", ".", "max_batches", "data_fetcher", ".", "setup", "(", "combined_loader", ")", "iter", "(", "data_fetcher", ")", "#", "creates", "the", "iterator", "inside", "the", "fetcher", "data_fetcher", ".", "fetched", "+", "=", "self", ".", "batch_progress", ".", "current", ".", "ready", "data_fetcher", ".", "_start_profiler", "=", "self", ".", "_on_before_fetch", "data_fetcher", ".", "_stop_profiler", "=", "self", ".", "_on_after_fetch", "self", ".", "_data_fetcher", "=", "data_fetcher"], "docstring": "when restarting, if we are running `validate` or `test` twice, since there's no concept of `max_epochs` we need to reset the current state when the loop has finished running some users want validation shuffling based on the training progress set the per-dataloader limits add the previous `fetched` value to properly track `is_last_batch` with no prefetching", "docstring_tokens": ["when", "restarting", "if", "we", "are", "running", "validate", "or", "test", "twice", "since", "there", "s", "no", "concept", "of", "max_epochs", "we", "need", "to", "reset", "the", "current", "state", "when", "the", "loop", "has", "finished", "running", "some", "users", "want", "validation", "shuffling", "based", "on", "the", "training", "progress", "set", "the", "per", "dataloader", "limits", "add", "the", "previous", "fetched", "value", "to", "properly", "track", "is_last_batch", "with", "no", "prefetching"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "start_line": 228, "end_line": 265, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "func_name": "function_168", "original_string": "def on_run_end(self) -> list[_OUT_DICT]:\r\n        \"\"\"Runs the ``_on_evaluation_epoch_end`` hook.\"\"\"\r\n        self.trainer._logger_connector.epoch_end_reached()\r\n        self.trainer._logger_connector._evaluation_epoch_end()\r\n\r\n        self._on_evaluation_epoch_end()\r\n\r\n        logged_outputs, self._logged_outputs = self._logged_outputs, []  # free memory\r\n        epoch_end_logged_outputs = self.trainer._logger_connector.update_eval_epoch_metrics()\r\n        all_logged_outputs = dict(ChainMap(*logged_outputs))  # list[dict] -> dict\r\n        all_logged_outputs.update(epoch_end_logged_outputs)\r\n        for dl_outputs in logged_outputs:\r\n            dl_outputs.update(epoch_end_logged_outputs)\r\n\r\n        self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)\r\n\r\n        self._on_evaluation_end()\r\n\r\n        self._on_evaluation_model_train()\r\n\r\n        if self.verbose and self.trainer.is_global_zero:\r\n            self._print_results(logged_outputs, self._stage.value)\r\n\r\n        now = time.monotonic()\r\n        self.trainer._last_val_time = now\r\n\r\n        return logged_outputs", "language": "python", "code": "def on_run_end(self) -> list[_OUT_DICT]:\r\n        \"\"\"Runs the ``_on_evaluation_epoch_end`` hook.\"\"\"\r\n        self.trainer._logger_connector.epoch_end_reached()\r\n        self.trainer._logger_connector._evaluation_epoch_end()\r\n\r\n        self._on_evaluation_epoch_end()\r\n\r\n        logged_outputs, self._logged_outputs = self._logged_outputs, []  # free memory\r\n        epoch_end_logged_outputs = self.trainer._logger_connector.update_eval_epoch_metrics()\r\n        all_logged_outputs = dict(ChainMap(*logged_outputs))  # list[dict] -> dict\r\n        all_logged_outputs.update(epoch_end_logged_outputs)\r\n        for dl_outputs in logged_outputs:\r\n            dl_outputs.update(epoch_end_logged_outputs)\r\n\r\n        self.trainer._logger_connector.log_eval_end_metrics(all_logged_outputs)\r\n\r\n        self._on_evaluation_end()\r\n\r\n        self._on_evaluation_model_train()\r\n\r\n        if self.verbose and self.trainer.is_global_zero:\r\n            self._print_results(logged_outputs, self._stage.value)\r\n\r\n        now = time.monotonic()\r\n        self.trainer._last_val_time = now\r\n\r\n        return logged_outputs", "code_tokens": ["def", "on_run_end", "(", "self", ")", "-", ">", "list", "[", "_OUT_DICT", "]", ":", "STRING", "self", ".", "trainer", ".", "_logger_connector", ".", "epoch_end_reached", "(", ")", "self", ".", "trainer", ".", "_logger_connector", ".", "_evaluation_epoch_end", "(", ")", "self", ".", "_on_evaluation_epoch_end", "(", ")", "logged_outputs", ",", "self", ".", "_logged_outputs", "=", "self", ".", "_logged_outputs", ",", "[", "]", "#", "free", "memory", "epoch_end_logged_outputs", "=", "self", ".", "trainer", ".", "_logger_connector", ".", "update_eval_epoch_metrics", "(", ")", "all_logged_outputs", "=", "dict", "(", "ChainMap", "(", "*", "logged_outputs", ")", ")", "#", "list", "[", "dict", "]", "-", ">", "dict", "all_logged_outputs", ".", "update", "(", "epoch_end_logged_outputs", ")", "for", "dl_outputs", "in", "logged_outputs", ":", "dl_outputs", ".", "update", "(", "epoch_end_logged_outputs", ")", "self", ".", "trainer", ".", "_logger_connector", ".", "log_eval_end_metrics", "(", "all_logged_outputs", ")", "self", ".", "_on_evaluation_end", "(", ")", "self", ".", "_on_evaluation_model_train", "(", ")", "if", "self", ".", "verbose", "and", "self", ".", "trainer", ".", "is_global_zero", ":", "self", ".", "_print_results", "(", "logged_outputs", ",", "self", ".", "_stage", ".", "value", ")", "now", "=", "time", ".", "monotonic", "(", ")", "self", ".", "trainer", ".", "_last_val_time", "=", "now", "return", "logged_outputs"], "docstring": "if `done` returned True before any iterations were done, this won't have been called in `on_advance_end` hook include any logged outputs on epoch_end log metrics hook enable train mode again", "docstring_tokens": ["if", "done", "returned", "true", "before", "any", "iterations", "were", "done", "this", "won", "t", "have", "been", "called", "in", "on_advance_end", "hook", "include", "any", "logged", "outputs", "on", "epoch_end", "log", "metrics", "hook", "enable", "train", "mode", "again"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "start_line": 288, "end_line": 320, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "func_name": "function_169", "original_string": "def _on_evaluation_end(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Runs ``on_{validation/test}_end`` hook.\"\"\"\r\n        trainer = self.trainer\r\n        hook_name = \"on_test_end\" if trainer.testing else \"on_validation_end\"\r\n        call._call_callback_hooks(trainer, hook_name, *args, **kwargs)\r\n        call._call_lightning_module_hook(trainer, hook_name, *args, **kwargs)\r\n        call._call_strategy_hook(trainer, hook_name, *args, **kwargs)\r\n\r\n        trainer._logger_connector.reset_results()", "language": "python", "code": "def _on_evaluation_end(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Runs ``on_{validation/test}_end`` hook.\"\"\"\r\n        trainer = self.trainer\r\n        hook_name = \"on_test_end\" if trainer.testing else \"on_validation_end\"\r\n        call._call_callback_hooks(trainer, hook_name, *args, **kwargs)\r\n        call._call_lightning_module_hook(trainer, hook_name, *args, **kwargs)\r\n        call._call_strategy_hook(trainer, hook_name, *args, **kwargs)\r\n\r\n        trainer._logger_connector.reset_results()", "code_tokens": ["def", "_on_evaluation_end", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "hook_name", "=", "STRING", "if", "trainer", ".", "testing", "else", "STRING", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "hook_name", ",", "*", "args", ",", "*", "*", "kwargs", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "hook_name", ",", "*", "args", ",", "*", "*", "kwargs", ")", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "hook_name", ",", "*", "args", ",", "*", "*", "kwargs", ")", "trainer", ".", "_logger_connector", ".", "reset_results", "(", ")"], "docstring": "reset the logger connector state", "docstring_tokens": ["reset", "the", "logger", "connector", "state"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "start_line": 353, "end_line": 362, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "func_name": "function_170", "original_string": "def _evaluation_step(\r\n        self, batch: Any, batch_idx: int, dataloader_idx: int, dataloader_iter: Optional[Iterator]\r\n    ) -> None:\r\n        \"\"\"Runs the actual evaluation step together with all the necessary bookkeeping and the hooks tied to it.\r\n\r\n        Args:\r\n            batch: The current batch to run through the step.\r\n            batch_idx: The index of the current batch.\r\n            dataloader_idx: the index of the dataloader producing the current batch.\r\n            dataloader_iter: The iterator if using this step flavor.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        data_fetcher = self._data_fetcher\r\n        assert data_fetcher is not None\r\n\r\n        if not (using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=dataloader_idx)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=dataloader_idx)\r\n\r\n        hook_kwargs = self._build_kwargs(\r\n            batch, batch_idx, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n        )\r\n\r\n        self.batch_progress.increment_ready()\r\n\r\n        trainer._logger_connector.on_batch_start(\r\n            batch, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n        )\r\n\r\n        hook_name = \"on_test_batch_start\" if trainer.testing else \"on_validation_batch_start\"\r\n        call._call_callback_hooks(trainer, hook_name, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, hook_name, *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_started()\r\n\r\n        hook_name = \"test_step\" if trainer.testing else \"validation_step\"\r\n        step_args = (\r\n            self._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\r\n            if not using_dataloader_iter\r\n            else (dataloader_iter,)\r\n        )\r\n        output = call._call_strategy_hook(trainer, hook_name, *step_args)\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            dataloader_idx = data_fetcher._dataloader_idx\r\n            hook_kwargs = self._build_kwargs(\r\n                batch, batch_idx, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n            )\r\n\r\n        hook_name = \"on_test_batch_end\" if trainer.testing else \"on_validation_batch_end\"\r\n        call._call_callback_hooks(trainer, hook_name, output, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, hook_name, output, *hook_kwargs.values())\r\n\r\n        trainer._logger_connector.on_batch_end()\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        if not trainer.sanity_checking:\r\n            self._has_run = True\r\n\r\n            trainer._logger_connector.update_eval_step_metrics(self._seen_batches_per_dataloader[dataloader_idx])\r\n            self._seen_batches_per_dataloader[dataloader_idx] += 1\r\n\r\n        if not self.batch_progress.is_last_batch and trainer.received_sigterm:\r\n            raise SIGTERMException", "language": "python", "code": "def _evaluation_step(\r\n        self, batch: Any, batch_idx: int, dataloader_idx: int, dataloader_iter: Optional[Iterator]\r\n    ) -> None:\r\n        \"\"\"Runs the actual evaluation step together with all the necessary bookkeeping and the hooks tied to it.\r\n\r\n        Args:\r\n            batch: The current batch to run through the step.\r\n            batch_idx: The index of the current batch.\r\n            dataloader_idx: the index of the dataloader producing the current batch.\r\n            dataloader_iter: The iterator if using this step flavor.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        data_fetcher = self._data_fetcher\r\n        assert data_fetcher is not None\r\n\r\n        if not (using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=dataloader_idx)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=dataloader_idx)\r\n\r\n        hook_kwargs = self._build_kwargs(\r\n            batch, batch_idx, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n        )\r\n\r\n        self.batch_progress.increment_ready()\r\n\r\n        trainer._logger_connector.on_batch_start(\r\n            batch, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n        )\r\n\r\n        hook_name = \"on_test_batch_start\" if trainer.testing else \"on_validation_batch_start\"\r\n        call._call_callback_hooks(trainer, hook_name, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, hook_name, *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_started()\r\n\r\n        hook_name = \"test_step\" if trainer.testing else \"validation_step\"\r\n        step_args = (\r\n            self._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\r\n            if not using_dataloader_iter\r\n            else (dataloader_iter,)\r\n        )\r\n        output = call._call_strategy_hook(trainer, hook_name, *step_args)\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            dataloader_idx = data_fetcher._dataloader_idx\r\n            hook_kwargs = self._build_kwargs(\r\n                batch, batch_idx, dataloader_idx if self._is_sequential and self.num_dataloaders > 1 else None\r\n            )\r\n\r\n        hook_name = \"on_test_batch_end\" if trainer.testing else \"on_validation_batch_end\"\r\n        call._call_callback_hooks(trainer, hook_name, output, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, hook_name, output, *hook_kwargs.values())\r\n\r\n        trainer._logger_connector.on_batch_end()\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        if not trainer.sanity_checking:\r\n            self._has_run = True\r\n\r\n            trainer._logger_connector.update_eval_step_metrics(self._seen_batches_per_dataloader[dataloader_idx])\r\n            self._seen_batches_per_dataloader[dataloader_idx] += 1\r\n\r\n        if not self.batch_progress.is_last_batch and trainer.received_sigterm:\r\n            raise SIGTERMException", "code_tokens": ["def", "_evaluation_step", "(", "self", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ",", "dataloader_idx", ":", "int", ",", "dataloader_iter", ":", "Optional", "[", "Iterator", "]", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "data_fetcher", "=", "self", ".", "_data_fetcher", "assert", "data_fetcher", "is", "not", "None", "if", "not", "(", "using_dataloader_iter", ":", "=", "isinstance", "(", "data_fetcher", ",", "_DataLoaderIterDataFetcher", ")", ")", ":", "batch", "=", "trainer", ".", "precision_plugin", ".", "convert_input", "(", "batch", ")", "batch", "=", "trainer", ".", "lightning_module", ".", "_on_before_batch_transfer", "(", "batch", ",", "dataloader_idx", "=", "dataloader_idx", ")", "batch", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "batch", ",", "dataloader_idx", "=", "dataloader_idx", ")", "hook_kwargs", "=", "self", ".", "_build_kwargs", "(", "batch", ",", "batch_idx", ",", "dataloader_idx", "if", "self", ".", "_is_sequential", "and", "self", ".", "num_dataloaders", ">", "1", "else", "None", ")", "self", ".", "batch_progress", ".", "increment_ready", "(", ")", "trainer", ".", "_logger_connector", ".", "on_batch_start", "(", "batch", ",", "dataloader_idx", "if", "self", ".", "_is_sequential", "and", "self", ".", "num_dataloaders", ">", "1", "else", "None", ")", "hook_name", "=", "STRING", "if", "trainer", ".", "testing", "else", "STRING", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "hook_name", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "hook_name", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "self", ".", "batch_progress", ".", "increment_started", "(", ")", "hook_name", "=", "STRING", "if", "trainer", ".", "testing", "else", "STRING", "step_args", "=", "(", "self", ".", "_build_step_args_from_hook_kwargs", "(", "hook_kwargs", ",", "hook_name", ")", "if", "not", "using_dataloader_iter", "else", "(", "dataloader_iter", ",", ")", ")", "output", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "hook_name", ",", "*", "step_args", ")", "self", ".", "batch_progress", ".", "increment_processed", "(", ")", "if", "using_dataloader_iter", ":", "batch", "=", "data_fetcher", ".", "_batch", "batch_idx", "=", "data_fetcher", ".", "_batch_idx", "dataloader_idx", "=", "data_fetcher", ".", "_dataloader_idx", "hook_kwargs", "=", "self", ".", "_build_kwargs", "(", "batch", ",", "batch_idx", ",", "dataloader_idx", "if", "self", ".", "_is_sequential", "and", "self", ".", "num_dataloaders", ">", "1", "else", "None", ")", "hook_name", "=", "STRING", "if", "trainer", ".", "testing", "else", "STRING", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "hook_name", ",", "output", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "hook_name", ",", "output", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "trainer", ".", "_logger_connector", ".", "on_batch_end", "(", ")", "self", ".", "batch_progress", ".", "increment_completed", "(", ")", "if", "not", "trainer", ".", "sanity_checking", ":", "self", ".", "_has_run", "=", "True", "trainer", ".", "_logger_connector", ".", "update_eval_step_metrics", "(", "self", ".", "_seen_batches_per_dataloader", "[", "dataloader_idx", "]", ")", "self", ".", "_seen_batches_per_dataloader", "[", "dataloader_idx", "]", "+", "=", "1", "if", "not", "self", ".", "batch_progress", ".", "is_last_batch", "and", "trainer", ".", "received_sigterm", ":", "raise", "SIGTERMException"], "docstring": "the `_step` methods don't take a batch_idx when `dataloader_iter` is used, but all other hooks still do, so we need different kwargs update the hook kwargs now that the step method might have consumed the iterator indicate the loop has run log batch metrics", "docstring_tokens": ["the", "_step", "methods", "don", "t", "take", "a", "batch_idx", "when", "dataloader_iter", "is", "used", "but", "all", "other", "hooks", "still", "do", "so", "we", "need", "different", "kwargs", "update", "the", "hook", "kwargs", "now", "that", "the", "step", "method", "might", "have", "consumed", "the", "iterator", "indicate", "the", "loop", "has", "run", "log", "batch", "metrics"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\evaluation_loop.py", "start_line": 395, "end_line": 470, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "func_name": "function_171", "original_string": "def done(self) -> bool:\r\n        \"\"\"Evaluates when to leave the loop.\"\"\"\r\n        if self.max_batches == 0:\r\n            rank_zero_info(\"`Trainer.fit` stopped: No training batches.\")\r\n            return True\r\n\r\n        stop_steps = _is_max_limit_reached(self.epoch_loop.global_step, self.max_steps)\r\n        if stop_steps:\r\n            rank_zero_info(f\"`Trainer.fit` stopped: `max_steps={self.max_steps!r}` reached.\")\r\n            return True\r\n\r\n        assert isinstance(self.max_epochs, int)\r\n        stop_epochs = _is_max_limit_reached(self.epoch_progress.current.processed, self.max_epochs)\r\n        if stop_epochs:\r\n            self.epoch_progress.current.completed = self.epoch_progress.current.processed\r\n            rank_zero_info(f\"`Trainer.fit` stopped: `max_epochs={self.max_epochs!r}` reached.\")\r\n            return True\r\n\r\n        if self.trainer.should_stop and self._can_stop_early:\r\n            rank_zero_debug(\"`Trainer.fit` stopped: `trainer.should_stop` was set.\")\r\n            return True\r\n\r\n        return False", "language": "python", "code": "def done(self) -> bool:\r\n        \"\"\"Evaluates when to leave the loop.\"\"\"\r\n        if self.max_batches == 0:\r\n            rank_zero_info(\"`Trainer.fit` stopped: No training batches.\")\r\n            return True\r\n\r\n        stop_steps = _is_max_limit_reached(self.epoch_loop.global_step, self.max_steps)\r\n        if stop_steps:\r\n            rank_zero_info(f\"`Trainer.fit` stopped: `max_steps={self.max_steps!r}` reached.\")\r\n            return True\r\n\r\n        assert isinstance(self.max_epochs, int)\r\n        stop_epochs = _is_max_limit_reached(self.epoch_progress.current.processed, self.max_epochs)\r\n        if stop_epochs:\r\n            self.epoch_progress.current.completed = self.epoch_progress.current.processed\r\n            rank_zero_info(f\"`Trainer.fit` stopped: `max_epochs={self.max_epochs!r}` reached.\")\r\n            return True\r\n\r\n        if self.trainer.should_stop and self._can_stop_early:\r\n            rank_zero_debug(\"`Trainer.fit` stopped: `trainer.should_stop` was set.\")\r\n            return True\r\n\r\n        return False", "code_tokens": ["def", "done", "(", "self", ")", "-", ">", "bool", ":", "STRING", "if", "self", ".", "max_batches", "=", "=", "0", ":", "rank_zero_info", "(", "STRING", ")", "return", "True", "stop_steps", "=", "_is_max_limit_reached", "(", "self", ".", "epoch_loop", ".", "global_step", ",", "self", ".", "max_steps", ")", "if", "stop_steps", ":", "rank_zero_info", "(", "fSTRING", ")", "return", "True", "assert", "isinstance", "(", "self", ".", "max_epochs", ",", "int", ")", "stop_epochs", "=", "_is_max_limit_reached", "(", "self", ".", "epoch_progress", ".", "current", ".", "processed", ",", "self", ".", "max_epochs", ")", "if", "stop_epochs", ":", "self", ".", "epoch_progress", ".", "current", ".", "completed", "=", "self", ".", "epoch_progress", ".", "current", ".", "processed", "rank_zero_info", "(", "fSTRING", ")", "return", "True", "if", "self", ".", "trainer", ".", "should_stop", "and", "self", ".", "_can_stop_early", ":", "rank_zero_debug", "(", "STRING", ")", "return", "True", "return", "False"], "docstring": "TODO: Move track steps inside training loop and move part of these condition inside training loop `processed` is increased before `on_train_epoch_end`, the hook where checkpoints are typically saved. we use it here because the checkpoint data won't have `completed` increased yet in case they are not equal, override so `trainer.current_epoch` has the expected value", "docstring_tokens": ["todo", "move", "track", "steps", "inside", "training", "loop", "and", "move", "part", "of", "these", "condition", "inside", "training", "loop", "processed", "is", "increased", "before", "on_train_epoch_end", "the", "hook", "where", "checkpoints", "are", "typically", "saved", "we", "use", "it", "here", "because", "the", "checkpoint", "data", "won", "t", "have", "completed", "increased", "yet", "in", "case", "they", "are", "not", "equal", "override", "so", "trainer", "current_epoch", "has", "the", "expected", "value"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "start_line": 172, "end_line": 198, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "func_name": "function_172", "original_string": "def skip(self) -> bool:\r\n        \"\"\"Whether we should skip the training and immediately return from the call to :meth:`run`.\"\"\"\r\n        return self.done or self.trainer.limit_train_batches == 0", "language": "python", "code": "def skip(self) -> bool:\r\n        \"\"\"Whether we should skip the training and immediately return from the call to :meth:`run`.\"\"\"\r\n        return self.done or self.trainer.limit_train_batches == 0", "code_tokens": ["def", "skip", "(", "self", ")", "-", ">", "bool", ":", "STRING", "return", "self", ".", "done", "or", "self", ".", "trainer", ".", "limit_train_batches", "=", "=", "0"], "docstring": "if `limit_train_batches == 0` then `setup_data` won't set the `self.max_batches` attribute (checked in `done`) so we cannot use it solely", "docstring_tokens": ["if", "limit_train_batches", "0", "then", "setup_data", "won", "t", "set", "the", "self", "max_batches", "attribute", "checked", "in", "done", "so", "we", "cannot", "use", "it", "solely"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "start_line": 201, "end_line": 205, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "func_name": "function_173", "original_string": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of this loop.\"\"\"\r\n        assert self.trainer.model is not None\r\n        torch.set_grad_enabled(True)\r\n\r\n        self.update_restart_stage()\r\n\r\n        if self.restarted_on_epoch_start:\r\n            self.epoch_progress.reset_on_restart()\r\n\r\n        if self.resumed_on_epoch_end:\r\n            self.epoch_progress.increment_completed()\r\n\r\n        if (\r\n            self.epoch_loop.restarted_on_train_batch_end\r\n            and self.restarted_mid_epoch\r\n            and self.epoch_loop.batch_progress.is_last_batch\r\n        ):\r\n            self.epoch_progress.increment_processed()\r\n            self.epoch_progress.increment_completed()\r\n\r\n        if (\r\n            self.epoch_loop.restarted_on_train_batch_end\r\n            and self.epoch_loop.batch_progress.is_last_batch\r\n            and not self.restarted_mid_epoch\r\n            and not self.epoch_loop.val_loop.batch_progress.is_last_batch\r\n        ):\r\n            self.epoch_progress.increment_completed()", "language": "python", "code": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of this loop.\"\"\"\r\n        assert self.trainer.model is not None\r\n        torch.set_grad_enabled(True)\r\n\r\n        self.update_restart_stage()\r\n\r\n        if self.restarted_on_epoch_start:\r\n            self.epoch_progress.reset_on_restart()\r\n\r\n        if self.resumed_on_epoch_end:\r\n            self.epoch_progress.increment_completed()\r\n\r\n        if (\r\n            self.epoch_loop.restarted_on_train_batch_end\r\n            and self.restarted_mid_epoch\r\n            and self.epoch_loop.batch_progress.is_last_batch\r\n        ):\r\n            self.epoch_progress.increment_processed()\r\n            self.epoch_progress.increment_completed()\r\n\r\n        if (\r\n            self.epoch_loop.restarted_on_train_batch_end\r\n            and self.epoch_loop.batch_progress.is_last_batch\r\n            and not self.restarted_mid_epoch\r\n            and not self.epoch_loop.val_loop.batch_progress.is_last_batch\r\n        ):\r\n            self.epoch_progress.increment_completed()", "code_tokens": ["def", "reset", "(", "self", ")", "-", ">", "None", ":", "STRING", "assert", "self", ".", "trainer", ".", "model", "is", "not", "None", "torch", ".", "set_grad_enabled", "(", "True", ")", "self", ".", "update_restart_stage", "(", ")", "if", "self", ".", "restarted_on_epoch_start", ":", "self", ".", "epoch_progress", ".", "reset_on_restart", "(", ")", "if", "self", ".", "resumed_on_epoch_end", ":", "self", ".", "epoch_progress", ".", "increment_completed", "(", ")", "if", "(", "self", ".", "epoch_loop", ".", "restarted_on_train_batch_end", "and", "self", ".", "restarted_mid_epoch", "and", "self", ".", "epoch_loop", ".", "batch_progress", ".", "is_last_batch", ")", ":", "self", ".", "epoch_progress", ".", "increment_processed", "(", ")", "self", ".", "epoch_progress", ".", "increment_completed", "(", ")", "if", "(", "self", ".", "epoch_loop", ".", "restarted_on_train_batch_end", "and", "self", ".", "epoch_loop", ".", "batch_progress", ".", "is_last_batch", "and", "not", "self", ".", "restarted_mid_epoch", "and", "not", "self", ".", "epoch_loop", ".", "val_loop", ".", "batch_progress", ".", "is_last_batch", ")", ":", "self", ".", "epoch_progress", ".", "increment_completed", "(", ")"], "docstring": "when restarting from last without validation at end of epoch, self.restarting is False but it's still resuming", "docstring_tokens": ["when", "restarting", "from", "last", "without", "validation", "at", "end", "of", "epoch", "self", "restarting", "is", "false", "but", "it", "s", "still", "resuming"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "start_line": 378, "end_line": 407, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "func_name": "function_174", "original_string": "def on_run_start(self) -> None:\r\n        \"\"\"Calls the ``on_train_start`` hook.\"\"\"\r\n        if not self._iteration_based_training():\r\n            self.epoch_progress.current.completed = self.epoch_progress.current.processed\r\n\r\n        trainer = self.trainer\r\n\r\n        if self.epoch_loop._should_check_val_epoch() and trainer.val_dataloaders is None:\r\n            trainer.validating = True\r\n            self.epoch_loop.val_loop.setup_data()\r\n            trainer.training = True\r\n\r\n        self._warn_if_modules_in_eval_mode()\r\n\r\n        call._call_callback_hooks(trainer, \"on_train_start\")\r\n        call._call_lightning_module_hook(trainer, \"on_train_start\")\r\n        call._call_strategy_hook(trainer, \"on_train_start\")", "language": "python", "code": "def on_run_start(self) -> None:\r\n        \"\"\"Calls the ``on_train_start`` hook.\"\"\"\r\n        if not self._iteration_based_training():\r\n            self.epoch_progress.current.completed = self.epoch_progress.current.processed\r\n\r\n        trainer = self.trainer\r\n\r\n        if self.epoch_loop._should_check_val_epoch() and trainer.val_dataloaders is None:\r\n            trainer.validating = True\r\n            self.epoch_loop.val_loop.setup_data()\r\n            trainer.training = True\r\n\r\n        self._warn_if_modules_in_eval_mode()\r\n\r\n        call._call_callback_hooks(trainer, \"on_train_start\")\r\n        call._call_lightning_module_hook(trainer, \"on_train_start\")\r\n        call._call_strategy_hook(trainer, \"on_train_start\")", "code_tokens": ["def", "on_run_start", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_iteration_based_training", "(", ")", ":", "self", ".", "epoch_progress", ".", "current", ".", "completed", "=", "self", ".", "epoch_progress", ".", "current", ".", "processed", "trainer", "=", "self", ".", "trainer", "if", "self", ".", "epoch_loop", ".", "_should_check_val_epoch", "(", ")", "and", "trainer", ".", "val_dataloaders", "is", "None", ":", "trainer", ".", "validating", "=", "True", "self", ".", "epoch_loop", ".", "val_loop", ".", "setup_data", "(", ")", "trainer", ".", "training", "=", "True", "self", ".", "_warn_if_modules_in_eval_mode", "(", ")", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ")", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ")"], "docstring": "update the current_epoch in-case of checkpoint reload reload the evaluation dataloaders too for proper display in the progress bar Check for modules in eval mode at training start", "docstring_tokens": ["update", "the", "current_epoch", "in", "case", "of", "checkpoint", "reload", "reload", "the", "evaluation", "dataloaders", "too", "for", "proper", "display", "in", "the", "progress", "bar", "check", "for", "modules", "in", "eval", "mode", "at", "training", "start"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "start_line": 409, "end_line": 428, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "func_name": "function_175", "original_string": "def on_advance_start(self) -> None:\r\n        \"\"\"Prepares the dataloader for training and calls the hook ``on_train_epoch_start``\"\"\"\r\n        trainer = self.trainer\r\n\r\n        self.setup_data()\r\n\r\n        assert self._combined_loader is not None\r\n        for i, dl in enumerate(self._combined_loader.flattened):\r\n            _set_sampler_epoch(dl, self.epoch_progress.current.processed)\r\n\r\n        if not self.restarted_mid_epoch and not self.restarted_on_epoch_end:\r\n            if not self.restarted_on_epoch_start:\r\n                self.epoch_progress.increment_ready()\r\n\r\n            call._call_callback_hooks(trainer, \"on_train_epoch_start\")\r\n            call._call_lightning_module_hook(trainer, \"on_train_epoch_start\")\r\n\r\n            self.epoch_progress.increment_started()", "language": "python", "code": "def on_advance_start(self) -> None:\r\n        \"\"\"Prepares the dataloader for training and calls the hook ``on_train_epoch_start``\"\"\"\r\n        trainer = self.trainer\r\n\r\n        self.setup_data()\r\n\r\n        assert self._combined_loader is not None\r\n        for i, dl in enumerate(self._combined_loader.flattened):\r\n            _set_sampler_epoch(dl, self.epoch_progress.current.processed)\r\n\r\n        if not self.restarted_mid_epoch and not self.restarted_on_epoch_end:\r\n            if not self.restarted_on_epoch_start:\r\n                self.epoch_progress.increment_ready()\r\n\r\n            call._call_callback_hooks(trainer, \"on_train_epoch_start\")\r\n            call._call_lightning_module_hook(trainer, \"on_train_epoch_start\")\r\n\r\n            self.epoch_progress.increment_started()", "code_tokens": ["def", "on_advance_start", "(", "self", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "self", ".", "setup_data", "(", ")", "assert", "self", ".", "_combined_loader", "is", "not", "None", "for", "i", ",", "dl", "in", "enumerate", "(", "self", ".", "_combined_loader", ".", "flattened", ")", ":", "_set_sampler_epoch", "(", "dl", ",", "self", ".", "epoch_progress", ".", "current", ".", "processed", ")", "if", "not", "self", ".", "restarted_mid_epoch", "and", "not", "self", ".", "restarted_on_epoch_end", ":", "if", "not", "self", ".", "restarted_on_epoch_start", ":", "self", ".", "epoch_progress", ".", "increment_ready", "(", ")", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ")", "self", ".", "epoch_progress", ".", "increment_started", "(", ")"], "docstring": "might need to setup data again depending on `trainer.reload_dataloaders_every_n_epochs` update the epoch value for all samplers", "docstring_tokens": ["might", "need", "to", "setup", "data", "again", "depending", "on", "trainer", "reload_dataloaders_every_n_epochs", "update", "the", "epoch", "value", "for", "all", "samplers"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\fit_loop.py", "start_line": 430, "end_line": 449, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "func_name": "function_176", "original_string": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop for a new run.\"\"\"\r\n        self.batch_progress.reset_on_run()\r\n\r\n        assert self.trainer.state.stage is not None\r\n        data_fetcher = _select_data_fetcher(self.trainer, self.trainer.state.stage)\r\n        combined_loader = self._combined_loader\r\n        assert combined_loader is not None\r\n        if combined_loader._mode != \"sequential\":\r\n            raise ValueError('`trainer.predict()` only supports the `CombinedLoader(mode=\"sequential\")` mode.')\r\n\r\n        combined_loader.limits = self.max_batches\r\n        data_fetcher.setup(combined_loader)\r\n        iter(data_fetcher)  # creates the iterator inside the fetcher\r\n\r\n        data_fetcher.fetched += self.batch_progress.current.ready\r\n        data_fetcher._start_profiler = self._on_before_fetch\r\n        data_fetcher._stop_profiler = self._on_after_fetch\r\n        self._data_fetcher = data_fetcher\r\n\r\n        num_dataloaders = self.num_dataloaders\r\n        self.epoch_batch_indices = [[] for _ in range(num_dataloaders)]\r\n        self._predictions = [[] for _ in range(num_dataloaders)]", "language": "python", "code": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop for a new run.\"\"\"\r\n        self.batch_progress.reset_on_run()\r\n\r\n        assert self.trainer.state.stage is not None\r\n        data_fetcher = _select_data_fetcher(self.trainer, self.trainer.state.stage)\r\n        combined_loader = self._combined_loader\r\n        assert combined_loader is not None\r\n        if combined_loader._mode != \"sequential\":\r\n            raise ValueError('`trainer.predict()` only supports the `CombinedLoader(mode=\"sequential\")` mode.')\r\n\r\n        combined_loader.limits = self.max_batches\r\n        data_fetcher.setup(combined_loader)\r\n        iter(data_fetcher)  # creates the iterator inside the fetcher\r\n\r\n        data_fetcher.fetched += self.batch_progress.current.ready\r\n        data_fetcher._start_profiler = self._on_before_fetch\r\n        data_fetcher._stop_profiler = self._on_after_fetch\r\n        self._data_fetcher = data_fetcher\r\n\r\n        num_dataloaders = self.num_dataloaders\r\n        self.epoch_batch_indices = [[] for _ in range(num_dataloaders)]\r\n        self._predictions = [[] for _ in range(num_dataloaders)]", "code_tokens": ["def", "reset", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "batch_progress", ".", "reset_on_run", "(", ")", "assert", "self", ".", "trainer", ".", "state", ".", "stage", "is", "not", "None", "data_fetcher", "=", "_select_data_fetcher", "(", "self", ".", "trainer", ",", "self", ".", "trainer", ".", "state", ".", "stage", ")", "combined_loader", "=", "self", ".", "_combined_loader", "assert", "combined_loader", "is", "not", "None", "if", "combined_loader", ".", "_mode", "!", "=", "STRING", ":", "raise", "ValueError", "(", "STRING", ")", "combined_loader", ".", "limits", "=", "self", ".", "max_batches", "data_fetcher", ".", "setup", "(", "combined_loader", ")", "iter", "(", "data_fetcher", ")", "#", "creates", "the", "iterator", "inside", "the", "fetcher", "data_fetcher", ".", "fetched", "+", "=", "self", ".", "batch_progress", ".", "current", ".", "ready", "data_fetcher", ".", "_start_profiler", "=", "self", ".", "_on_before_fetch", "data_fetcher", ".", "_stop_profiler", "=", "self", ".", "_on_after_fetch", "self", ".", "_data_fetcher", "=", "data_fetcher", "num_dataloaders", "=", "self", ".", "num_dataloaders", "self", ".", "epoch_batch_indices", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_dataloaders", ")", "]", "self", ".", "_predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_dataloaders", ")", "]"], "docstring": "set the per-dataloader limits add the previous `fetched` value to properly track `is_last_batch` with no prefetching", "docstring_tokens": ["set", "the", "per", "dataloader", "limits", "add", "the", "previous", "fetched", "value", "to", "properly", "track", "is_last_batch", "with", "no", "prefetching"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "start_line": 167, "end_line": 191, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "func_name": "function_177", "original_string": "def _predict_step(\r\n        self, batch: Any, batch_idx: int, dataloader_idx: int, dataloader_iter: Optional[Iterator]\r\n    ) -> None:\r\n        \"\"\"Runs the actual predict step together with all the necessary bookkeeping and the hooks tied to it.\r\n\r\n        Args:\r\n            batch: the current batch to run the prediction on\r\n            batch_idx: The index of the current batch.\r\n            dataloader_idx: the index of the dataloader producing the current batch.\r\n            dataloader_iter: The iterator if using this step flavor.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        data_fetcher = self._data_fetcher\r\n        assert data_fetcher is not None\r\n\r\n        if not (using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=dataloader_idx)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=dataloader_idx)\r\n\r\n        self.batch_progress.increment_ready()\r\n\r\n        any_on_epoch = (\r\n            self._store_data_for_prediction_writer(batch_idx, dataloader_idx) if not using_dataloader_iter else False\r\n        )\r\n\r\n        hook_kwargs = self._build_kwargs(batch, batch_idx, dataloader_idx if self.num_dataloaders > 1 else None)\r\n\r\n        call._call_callback_hooks(trainer, \"on_predict_batch_start\", *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, \"on_predict_batch_start\", *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_started()\r\n\r\n        step_args = (\r\n            self._build_step_args_from_hook_kwargs(hook_kwargs, \"predict_step\")\r\n            if not using_dataloader_iter\r\n            else (dataloader_iter,)\r\n        )\r\n        predictions = call._call_strategy_hook(trainer, \"predict_step\", *step_args)\r\n        if predictions is None:\r\n            self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            dataloader_idx = data_fetcher._dataloader_idx\r\n            hook_kwargs = self._build_kwargs(batch, batch_idx, dataloader_idx if self.num_dataloaders > 1 else None)\r\n\r\n        call._call_callback_hooks(trainer, \"on_predict_batch_end\", predictions, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, \"on_predict_batch_end\", predictions, *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        if self._return_predictions or any_on_epoch:\r\n            self._predictions[dataloader_idx].append(move_data_to_device(predictions, torch.device(\"cpu\")))", "language": "python", "code": "def _predict_step(\r\n        self, batch: Any, batch_idx: int, dataloader_idx: int, dataloader_iter: Optional[Iterator]\r\n    ) -> None:\r\n        \"\"\"Runs the actual predict step together with all the necessary bookkeeping and the hooks tied to it.\r\n\r\n        Args:\r\n            batch: the current batch to run the prediction on\r\n            batch_idx: The index of the current batch.\r\n            dataloader_idx: the index of the dataloader producing the current batch.\r\n            dataloader_iter: The iterator if using this step flavor.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        data_fetcher = self._data_fetcher\r\n        assert data_fetcher is not None\r\n\r\n        if not (using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=dataloader_idx)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=dataloader_idx)\r\n\r\n        self.batch_progress.increment_ready()\r\n\r\n        any_on_epoch = (\r\n            self._store_data_for_prediction_writer(batch_idx, dataloader_idx) if not using_dataloader_iter else False\r\n        )\r\n\r\n        hook_kwargs = self._build_kwargs(batch, batch_idx, dataloader_idx if self.num_dataloaders > 1 else None)\r\n\r\n        call._call_callback_hooks(trainer, \"on_predict_batch_start\", *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, \"on_predict_batch_start\", *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_started()\r\n\r\n        step_args = (\r\n            self._build_step_args_from_hook_kwargs(hook_kwargs, \"predict_step\")\r\n            if not using_dataloader_iter\r\n            else (dataloader_iter,)\r\n        )\r\n        predictions = call._call_strategy_hook(trainer, \"predict_step\", *step_args)\r\n        if predictions is None:\r\n            self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            dataloader_idx = data_fetcher._dataloader_idx\r\n            hook_kwargs = self._build_kwargs(batch, batch_idx, dataloader_idx if self.num_dataloaders > 1 else None)\r\n\r\n        call._call_callback_hooks(trainer, \"on_predict_batch_end\", predictions, *hook_kwargs.values())\r\n        call._call_lightning_module_hook(trainer, \"on_predict_batch_end\", predictions, *hook_kwargs.values())\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        if self._return_predictions or any_on_epoch:\r\n            self._predictions[dataloader_idx].append(move_data_to_device(predictions, torch.device(\"cpu\")))", "code_tokens": ["def", "_predict_step", "(", "self", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ",", "dataloader_idx", ":", "int", ",", "dataloader_iter", ":", "Optional", "[", "Iterator", "]", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "data_fetcher", "=", "self", ".", "_data_fetcher", "assert", "data_fetcher", "is", "not", "None", "if", "not", "(", "using_dataloader_iter", ":", "=", "isinstance", "(", "data_fetcher", ",", "_DataLoaderIterDataFetcher", ")", ")", ":", "batch", "=", "trainer", ".", "precision_plugin", ".", "convert_input", "(", "batch", ")", "batch", "=", "trainer", ".", "lightning_module", ".", "_on_before_batch_transfer", "(", "batch", ",", "dataloader_idx", "=", "dataloader_idx", ")", "batch", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "batch", ",", "dataloader_idx", "=", "dataloader_idx", ")", "self", ".", "batch_progress", ".", "increment_ready", "(", ")", "any_on_epoch", "=", "(", "self", ".", "_store_data_for_prediction_writer", "(", "batch_idx", ",", "dataloader_idx", ")", "if", "not", "using_dataloader_iter", "else", "False", ")", "hook_kwargs", "=", "self", ".", "_build_kwargs", "(", "batch", ",", "batch_idx", ",", "dataloader_idx", "if", "self", ".", "num_dataloaders", ">", "1", "else", "None", ")", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "self", ".", "batch_progress", ".", "increment_started", "(", ")", "step_args", "=", "(", "self", ".", "_build_step_args_from_hook_kwargs", "(", "hook_kwargs", ",", "STRING", ")", "if", "not", "using_dataloader_iter", "else", "(", "dataloader_iter", ",", ")", ")", "predictions", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "*", "step_args", ")", "if", "predictions", "is", "None", ":", "self", ".", "_warning_cache", ".", "warn", "(", "STRING", ")", "self", ".", "batch_progress", ".", "increment_processed", "(", ")", "if", "using_dataloader_iter", ":", "batch", "=", "data_fetcher", ".", "_batch", "batch_idx", "=", "data_fetcher", ".", "_batch_idx", "dataloader_idx", "=", "data_fetcher", ".", "_dataloader_idx", "hook_kwargs", "=", "self", ".", "_build_kwargs", "(", "batch", ",", "batch_idx", ",", "dataloader_idx", "if", "self", ".", "num_dataloaders", ">", "1", "else", "None", ")", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ",", "predictions", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "predictions", ",", "*", "hook_kwargs", ".", "values", "(", ")", ")", "self", ".", "batch_progress", ".", "increment_completed", "(", ")", "if", "self", ".", "_return_predictions", "or", "any_on_epoch", ":", "self", ".", "_predictions", "[", "dataloader_idx", "]", ".", "append", "(", "move_data_to_device", "(", "predictions", ",", "torch", ".", "device", "(", "STRING", ")", ")", ")"], "docstring": "the `_step` methods don't take a batch_idx when `dataloader_iter` is used, but all other hooks still do, so we need different kwargs configure step_kwargs update the hook kwargs now that the step method might have consumed the iterator", "docstring_tokens": ["the", "_step", "methods", "don", "t", "take", "a", "batch_idx", "when", "dataloader_iter", "is", "used", "but", "all", "other", "hooks", "still", "do", "so", "we", "need", "different", "kwargs", "configure", "step_kwargs", "update", "the", "hook", "kwargs", "now", "that", "the", "step", "method", "might", "have", "consumed", "the", "iterator"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "start_line": 212, "end_line": 273, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "func_name": "function_178", "original_string": "def _on_predict_end(self) -> None:\r\n        \"\"\"Resets previous gradient status and calls ``on_predict_end`` hook.\"\"\"\r\n        if not self.return_predictions:\r\n            self._predictions = []\r\n        self.epoch_batch_indices = []\r\n\r\n        trainer = self.trainer\r\n        call._call_callback_hooks(trainer, \"on_predict_end\")\r\n        call._call_lightning_module_hook(trainer, \"on_predict_end\")\r\n        call._call_strategy_hook(trainer, \"on_predict_end\")", "language": "python", "code": "def _on_predict_end(self) -> None:\r\n        \"\"\"Resets previous gradient status and calls ``on_predict_end`` hook.\"\"\"\r\n        if not self.return_predictions:\r\n            self._predictions = []\r\n        self.epoch_batch_indices = []\r\n\r\n        trainer = self.trainer\r\n        call._call_callback_hooks(trainer, \"on_predict_end\")\r\n        call._call_lightning_module_hook(trainer, \"on_predict_end\")\r\n        call._call_strategy_hook(trainer, \"on_predict_end\")", "code_tokens": ["def", "_on_predict_end", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "return_predictions", ":", "self", ".", "_predictions", "=", "[", "]", "self", ".", "epoch_batch_indices", "=", "[", "]", "trainer", "=", "self", ".", "trainer", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ")", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ")"], "docstring": "hook", "docstring_tokens": ["hook"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\prediction_loop.py", "start_line": 375, "end_line": 385, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_179", "original_string": "def total_batch_idx(self) -> int:\r\n        \"\"\"Returns the current batch index (across epochs)\"\"\"\r\n        return self.batch_progress.total.ready - 1", "language": "python", "code": "def total_batch_idx(self) -> int:\r\n        \"\"\"Returns the current batch index (across epochs)\"\"\"\r\n        return self.batch_progress.total.ready - 1", "code_tokens": ["def", "total_batch_idx", "(", "self", ")", "-", ">", "int", ":", "STRING", "return", "self", ".", "batch_progress", ".", "total", ".", "ready", "-", "1"], "docstring": "use `ready` instead of `completed` in case this is accessed after `completed` has been increased but before the next `ready` increase", "docstring_tokens": ["use", "ready", "instead", "of", "completed", "in", "case", "this", "is", "accessed", "after", "completed", "has", "been", "increased", "but", "before", "the", "next", "ready", "increase"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 98, "end_line": 102, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_180", "original_string": "def batch_idx(self) -> int:\r\n        \"\"\"Returns the current batch index (within this epoch)\"\"\"\r\n        return self.batch_progress.current.ready - 1", "language": "python", "code": "def batch_idx(self) -> int:\r\n        \"\"\"Returns the current batch index (within this epoch)\"\"\"\r\n        return self.batch_progress.current.ready - 1", "code_tokens": ["def", "batch_idx", "(", "self", ")", "-", ">", "int", ":", "STRING", "return", "self", ".", "batch_progress", ".", "current", ".", "ready", "-", "1"], "docstring": "use `ready` instead of `completed` in case this is accessed after `completed` has been increased but before the next `ready` increase", "docstring_tokens": ["use", "ready", "instead", "of", "completed", "in", "case", "this", "is", "accessed", "after", "completed", "has", "been", "increased", "but", "before", "the", "next", "ready", "increase"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 105, "end_line": 109, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_181", "original_string": "def done(self) -> bool:\r\n        \"\"\"Evaluates when to leave the loop.\"\"\"\r\n        if self._is_training_done and self._is_validation_done:\r\n            return True\r\n\r\n        if self.trainer.should_stop:\r\n            min_epochs = self.trainer.fit_loop.min_epochs\r\n            can_stop_early = self.trainer.fit_loop._can_stop_early\r\n            if not can_stop_early:\r\n                self._warning_cache.info(\r\n                    f\"Trainer was signaled to stop but the required `min_epochs={min_epochs!r}` or\"\r\n                    f\" `min_steps={self.min_steps!r}` has not been met. Training will continue...\"\r\n                )\r\n            return can_stop_early\r\n\r\n        return False", "language": "python", "code": "def done(self) -> bool:\r\n        \"\"\"Evaluates when to leave the loop.\"\"\"\r\n        if self._is_training_done and self._is_validation_done:\r\n            return True\r\n\r\n        if self.trainer.should_stop:\r\n            min_epochs = self.trainer.fit_loop.min_epochs\r\n            can_stop_early = self.trainer.fit_loop._can_stop_early\r\n            if not can_stop_early:\r\n                self._warning_cache.info(\r\n                    f\"Trainer was signaled to stop but the required `min_epochs={min_epochs!r}` or\"\r\n                    f\" `min_steps={self.min_steps!r}` has not been met. Training will continue...\"\r\n                )\r\n            return can_stop_early\r\n\r\n        return False", "code_tokens": ["def", "done", "(", "self", ")", "-", ">", "bool", ":", "STRING", "if", "self", ".", "_is_training_done", "and", "self", ".", "_is_validation_done", ":", "return", "True", "if", "self", ".", "trainer", ".", "should_stop", ":", "min_epochs", "=", "self", ".", "trainer", ".", "fit_loop", ".", "min_epochs", "can_stop_early", "=", "self", ".", "trainer", ".", "fit_loop", ".", "_can_stop_early", "if", "not", "can_stop_early", ":", "self", ".", "_warning_cache", ".", "info", "(", "fSTRING", "fSTRING", ")", "return", "can_stop_early", "return", "False"], "docstring": "early stopping", "docstring_tokens": ["early", "stopping"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 129, "end_line": 145, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_182", "original_string": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop for a new run.\"\"\"\r\n        if (\r\n            self.restarting\r\n            and not self._should_accumulate()\r\n            and (self.restarted_on_train_batch_end or not self.restarted_on_last)\r\n        ):\r\n            self._batches_that_stepped += 1\r\n\r\n        if self.restarted_on_train_batch_end:\r\n            self.batch_progress.increment_completed()\r\n            if self.batch_progress.current.completed >= self.trainer.num_training_batches:\r\n                self.batch_progress.reset_on_run()\r\n                self.scheduler_progress.reset_on_run()\r\n                self.automatic_optimization.optim_progress.reset_on_run()\r\n                self.val_loop.batch_progress.total.reset()\r\n\r\n        if self.restarting:\r\n            self.batch_progress.reset_on_restart()\r\n            self.scheduler_progress.reset_on_restart()\r\n            self.automatic_optimization.optim_progress.reset_on_restart()\r\n\r\n            trainer = self.trainer\r\n            if trainer.num_training_batches != float(\"inf\"):\r\n                expected_steps = math.ceil(trainer.num_training_batches / trainer.accumulate_grad_batches)\r\n                loader = trainer.fit_loop._combined_loader\r\n                assert loader is not None\r\n                is_resumable_loader = all(isinstance(loader, _Stateful) for loader in loader.flattened)\r\n                if self.global_step % expected_steps != 0 and not is_resumable_loader:\r\n                    rank_zero_warn(\r\n                        \"You're resuming from a checkpoint that ended before the epoch ended and your dataloader is\"\r\n                        \" not resumable. This can cause unreliable results if further training is done.\"\r\n                        \" Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing\"\r\n                        \" the `state_dict` / `load_state_dict` interface.\",\r\n                        category=PossibleUserWarning,\r\n                    )\r\n        else:\r\n            self.batch_progress.reset_on_run()\r\n            self.scheduler_progress.reset_on_run()\r\n            self.automatic_optimization.optim_progress.reset_on_run()\r\n            self.val_loop.batch_progress.total.reset()", "language": "python", "code": "def reset(self) -> None:\r\n        \"\"\"Resets the internal state of the loop for a new run.\"\"\"\r\n        if (\r\n            self.restarting\r\n            and not self._should_accumulate()\r\n            and (self.restarted_on_train_batch_end or not self.restarted_on_last)\r\n        ):\r\n            self._batches_that_stepped += 1\r\n\r\n        if self.restarted_on_train_batch_end:\r\n            self.batch_progress.increment_completed()\r\n            if self.batch_progress.current.completed >= self.trainer.num_training_batches:\r\n                self.batch_progress.reset_on_run()\r\n                self.scheduler_progress.reset_on_run()\r\n                self.automatic_optimization.optim_progress.reset_on_run()\r\n                self.val_loop.batch_progress.total.reset()\r\n\r\n        if self.restarting:\r\n            self.batch_progress.reset_on_restart()\r\n            self.scheduler_progress.reset_on_restart()\r\n            self.automatic_optimization.optim_progress.reset_on_restart()\r\n\r\n            trainer = self.trainer\r\n            if trainer.num_training_batches != float(\"inf\"):\r\n                expected_steps = math.ceil(trainer.num_training_batches / trainer.accumulate_grad_batches)\r\n                loader = trainer.fit_loop._combined_loader\r\n                assert loader is not None\r\n                is_resumable_loader = all(isinstance(loader, _Stateful) for loader in loader.flattened)\r\n                if self.global_step % expected_steps != 0 and not is_resumable_loader:\r\n                    rank_zero_warn(\r\n                        \"You're resuming from a checkpoint that ended before the epoch ended and your dataloader is\"\r\n                        \" not resumable. This can cause unreliable results if further training is done.\"\r\n                        \" Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing\"\r\n                        \" the `state_dict` / `load_state_dict` interface.\",\r\n                        category=PossibleUserWarning,\r\n                    )\r\n        else:\r\n            self.batch_progress.reset_on_run()\r\n            self.scheduler_progress.reset_on_run()\r\n            self.automatic_optimization.optim_progress.reset_on_run()\r\n            self.val_loop.batch_progress.total.reset()", "code_tokens": ["def", "reset", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "(", "self", ".", "restarting", "and", "not", "self", ".", "_should_accumulate", "(", ")", "and", "(", "self", ".", "restarted_on_train_batch_end", "or", "not", "self", ".", "restarted_on_last", ")", ")", ":", "self", ".", "_batches_that_stepped", "+", "=", "1", "if", "self", ".", "restarted_on_train_batch_end", ":", "self", ".", "batch_progress", ".", "increment_completed", "(", ")", "if", "self", ".", "batch_progress", ".", "current", ".", "completed", ">", "=", "self", ".", "trainer", ".", "num_training_batches", ":", "self", ".", "batch_progress", ".", "reset_on_run", "(", ")", "self", ".", "scheduler_progress", ".", "reset_on_run", "(", ")", "self", ".", "automatic_optimization", ".", "optim_progress", ".", "reset_on_run", "(", ")", "self", ".", "val_loop", ".", "batch_progress", ".", "total", ".", "reset", "(", ")", "if", "self", ".", "restarting", ":", "self", ".", "batch_progress", ".", "reset_on_restart", "(", ")", "self", ".", "scheduler_progress", ".", "reset_on_restart", "(", ")", "self", ".", "automatic_optimization", ".", "optim_progress", ".", "reset_on_restart", "(", ")", "trainer", "=", "self", ".", "trainer", "if", "trainer", ".", "num_training_batches", "!", "=", "float", "(", "STRING", ")", ":", "expected_steps", "=", "math", ".", "ceil", "(", "trainer", ".", "num_training_batches", "/", "trainer", ".", "accumulate_grad_batches", ")", "loader", "=", "trainer", ".", "fit_loop", ".", "_combined_loader", "assert", "loader", "is", "not", "None", "is_resumable_loader", "=", "all", "(", "isinstance", "(", "loader", ",", "_Stateful", ")", "for", "loader", "in", "loader", ".", "flattened", ")", "if", "self", ".", "global_step", "%", "expected_steps", "!", "=", "0", "and", "not", "is_resumable_loader", ":", "rank_zero_warn", "(", "STRING", "STRING", "STRING", "STRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "else", ":", "self", ".", "batch_progress", ".", "reset_on_run", "(", ")", "self", ".", "scheduler_progress", ".", "reset_on_run", "(", ")", "self", ".", "automatic_optimization", ".", "optim_progress", ".", "reset_on_run", "(", ")", "self", ".", "val_loop", ".", "batch_progress", ".", "total", ".", "reset", "(", ")"], "docstring": "batches_that_stepped is never set prior to saving a checkpoint, even when saving happens on_validation_end we could set it in the checkpoint but we prefer to keep checkpoints backward compatible handle situation in which save happened on_train_batch_end and epoch is at end when the epoch starts, the total val batch progress should be reset as it's supposed to count the batches seen per epoch, this is useful for tracking when validation is run multiple times per epoch", "docstring_tokens": ["batches_that_stepped", "is", "never", "set", "prior", "to", "saving", "a", "checkpoint", "even", "when", "saving", "happens", "on_validation_end", "we", "could", "set", "it", "in", "the", "checkpoint", "but", "we", "prefer", "to", "keep", "checkpoints", "backward", "compatible", "handle", "situation", "in", "which", "save", "happened", "on_train_batch_end", "and", "epoch", "is", "at", "end", "when", "the", "epoch", "starts", "the", "total", "val", "batch", "progress", "should", "be", "reset", "as", "it", "s", "supposed", "to", "count", "the", "batches", "seen", "per", "epoch", "this", "is", "useful", "for", "tracking", "when", "validation", "is", "run", "multiple", "times", "per", "epoch"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 190, "end_line": 236, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_183", "original_string": "def advance(self, data_fetcher: _DataFetcher) -> None:\r\n        \"\"\"Runs a single training batch.\r\n\r\n        Raises:\r\n            StopIteration: When the epoch is canceled by the user returning -1\r\n\r\n        \"\"\"\r\n        if self.restarting and self._should_check_val_fx(data_fetcher):\r\n            if self.val_loop.restarted_mid_evaluation:\r\n                return\r\n\r\n            if self.restarted_on_last:\r\n                self._skip_next_val = True\r\n                return\r\n\r\n            self.val_loop.increment_progress_to_evaluation_end()\r\n\r\n        self.val_loop.restarting = False\r\n\r\n\r\n        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.trainer.world_size > 1:\r\n            self._broadcast_sigterm_tensor()\r\n\r\n\r\n        if using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher):\r\n            dataloader_iter = next(data_fetcher)\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n        else:\r\n            dataloader_iter = None\r\n            batch, _, __ = next(data_fetcher)\r\n            batch_idx = self.batch_idx + 1\r\n        self.batch_progress.is_last_batch = data_fetcher.done\r\n\r\n        trainer = self.trainer\r\n        if not using_dataloader_iter:\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=0)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=0)\r\n\r\n        self.batch_progress.increment_ready()\r\n        trainer._logger_connector.on_batch_start(batch)\r\n\r\n        batch_output: _BATCH_OUTPUTS_TYPE = None  # for mypy\r\n        if batch is None and not using_dataloader_iter:\r\n            self._warning_cache.warn(\"train_dataloader yielded None. If this was on purpose, ignore this warning...\")\r\n        else:\r\n            call._call_callback_hooks(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            response = call._call_lightning_module_hook(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            call._call_strategy_hook(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            if response == -1:\r\n                self.batch_progress.increment_processed()\r\n                raise StopIteration\r\n\r\n            self.batch_progress.increment_started()\r\n\r\n            kwargs = (\r\n                self._build_kwargs(OrderedDict(), batch, batch_idx)\r\n                if not using_dataloader_iter\r\n                else OrderedDict(any=dataloader_iter)\r\n            )\r\n            with trainer.profiler.profile(\"run_training_batch\"):\r\n                if trainer.lightning_module.automatic_optimization:\r\n                    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\r\n                else:\r\n                    batch_output = self.manual_optimization.run(kwargs)\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        self.update_lr_schedulers(\"step\", update_plateau_schedulers=False)\r\n        if self._num_ready_batches_reached():\r\n            self.update_lr_schedulers(\"epoch\", update_plateau_schedulers=False)\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            self.batch_progress.is_last_batch = data_fetcher.done\r\n\r\n        call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\r\n        call._call_lightning_module_hook(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\r\n        trainer._logger_connector.on_batch_end()\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        trainer._logger_connector.update_train_step_metrics()", "language": "python", "code": "def advance(self, data_fetcher: _DataFetcher) -> None:\r\n        \"\"\"Runs a single training batch.\r\n\r\n        Raises:\r\n            StopIteration: When the epoch is canceled by the user returning -1\r\n\r\n        \"\"\"\r\n        if self.restarting and self._should_check_val_fx(data_fetcher):\r\n            if self.val_loop.restarted_mid_evaluation:\r\n                return\r\n\r\n            if self.restarted_on_last:\r\n                self._skip_next_val = True\r\n                return\r\n\r\n            self.val_loop.increment_progress_to_evaluation_end()\r\n\r\n        self.val_loop.restarting = False\r\n\r\n\r\n        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.trainer.world_size > 1:\r\n            self._broadcast_sigterm_tensor()\r\n\r\n\r\n        if using_dataloader_iter := isinstance(data_fetcher, _DataLoaderIterDataFetcher):\r\n            dataloader_iter = next(data_fetcher)\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n        else:\r\n            dataloader_iter = None\r\n            batch, _, __ = next(data_fetcher)\r\n            batch_idx = self.batch_idx + 1\r\n        self.batch_progress.is_last_batch = data_fetcher.done\r\n\r\n        trainer = self.trainer\r\n        if not using_dataloader_iter:\r\n            batch = trainer.precision_plugin.convert_input(batch)\r\n            batch = trainer.lightning_module._on_before_batch_transfer(batch, dataloader_idx=0)\r\n            batch = call._call_strategy_hook(trainer, \"batch_to_device\", batch, dataloader_idx=0)\r\n\r\n        self.batch_progress.increment_ready()\r\n        trainer._logger_connector.on_batch_start(batch)\r\n\r\n        batch_output: _BATCH_OUTPUTS_TYPE = None  # for mypy\r\n        if batch is None and not using_dataloader_iter:\r\n            self._warning_cache.warn(\"train_dataloader yielded None. If this was on purpose, ignore this warning...\")\r\n        else:\r\n            call._call_callback_hooks(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            response = call._call_lightning_module_hook(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            call._call_strategy_hook(trainer, \"on_train_batch_start\", batch, batch_idx)\r\n            if response == -1:\r\n                self.batch_progress.increment_processed()\r\n                raise StopIteration\r\n\r\n            self.batch_progress.increment_started()\r\n\r\n            kwargs = (\r\n                self._build_kwargs(OrderedDict(), batch, batch_idx)\r\n                if not using_dataloader_iter\r\n                else OrderedDict(any=dataloader_iter)\r\n            )\r\n            with trainer.profiler.profile(\"run_training_batch\"):\r\n                if trainer.lightning_module.automatic_optimization:\r\n                    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\r\n                else:\r\n                    batch_output = self.manual_optimization.run(kwargs)\r\n\r\n        self.batch_progress.increment_processed()\r\n\r\n        self.update_lr_schedulers(\"step\", update_plateau_schedulers=False)\r\n        if self._num_ready_batches_reached():\r\n            self.update_lr_schedulers(\"epoch\", update_plateau_schedulers=False)\r\n\r\n        if using_dataloader_iter:\r\n            batch = data_fetcher._batch\r\n            batch_idx = data_fetcher._batch_idx\r\n            self.batch_progress.is_last_batch = data_fetcher.done\r\n\r\n        call._call_callback_hooks(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\r\n        call._call_lightning_module_hook(trainer, \"on_train_batch_end\", batch_output, batch, batch_idx)\r\n        trainer._logger_connector.on_batch_end()\r\n\r\n        self.batch_progress.increment_completed()\r\n\r\n        trainer._logger_connector.update_train_step_metrics()", "code_tokens": ["def", "advance", "(", "self", ",", "data_fetcher", ":", "_DataFetcher", ")", "-", ">", "None", ":", "STRING", "if", "self", ".", "restarting", "and", "self", ".", "_should_check_val_fx", "(", "data_fetcher", ")", ":", "if", "self", ".", "val_loop", ".", "restarted_mid_evaluation", ":", "return", "if", "self", ".", "restarted_on_last", ":", "self", ".", "_skip_next_val", "=", "True", "return", "self", ".", "val_loop", ".", "increment_progress_to_evaluation_end", "(", ")", "self", ".", "val_loop", ".", "restarting", "=", "False", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "and", "self", ".", "trainer", ".", "world_size", ">", "1", ":", "self", ".", "_broadcast_sigterm_tensor", "(", ")", "if", "using_dataloader_iter", ":", "=", "isinstance", "(", "data_fetcher", ",", "_DataLoaderIterDataFetcher", ")", ":", "dataloader_iter", "=", "next", "(", "data_fetcher", ")", "batch", "=", "data_fetcher", ".", "_batch", "batch_idx", "=", "data_fetcher", ".", "_batch_idx", "else", ":", "dataloader_iter", "=", "None", "batch", ",", "_", ",", "__", "=", "next", "(", "data_fetcher", ")", "batch_idx", "=", "self", ".", "batch_idx", "+", "1", "self", ".", "batch_progress", ".", "is_last_batch", "=", "data_fetcher", ".", "done", "trainer", "=", "self", ".", "trainer", "if", "not", "using_dataloader_iter", ":", "batch", "=", "trainer", ".", "precision_plugin", ".", "convert_input", "(", "batch", ")", "batch", "=", "trainer", ".", "lightning_module", ".", "_on_before_batch_transfer", "(", "batch", ",", "dataloader_idx", "=", "0", ")", "batch", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "batch", ",", "dataloader_idx", "=", "0", ")", "self", ".", "batch_progress", ".", "increment_ready", "(", ")", "trainer", ".", "_logger_connector", ".", "on_batch_start", "(", "batch", ")", "batch_output", ":", "_BATCH_OUTPUTS_TYPE", "=", "None", "#", "for", "mypy", "if", "batch", "is", "None", "and", "not", "using_dataloader_iter", ":", "self", ".", "_warning_cache", ".", "warn", "(", "STRING", ")", "else", ":", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ",", "batch", ",", "batch_idx", ")", "response", "=", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "batch", ",", "batch_idx", ")", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "batch", ",", "batch_idx", ")", "if", "response", "=", "=", "-", "1", ":", "self", ".", "batch_progress", ".", "increment_processed", "(", ")", "raise", "StopIteration", "self", ".", "batch_progress", ".", "increment_started", "(", ")", "kwargs", "=", "(", "self", ".", "_build_kwargs", "(", "OrderedDict", "(", ")", ",", "batch", ",", "batch_idx", ")", "if", "not", "using_dataloader_iter", "else", "OrderedDict", "(", "any", "=", "dataloader_iter", ")", ")", "with", "trainer", ".", "profiler", ".", "profile", "(", "STRING", ")", ":", "if", "trainer", ".", "lightning_module", ".", "automatic_optimization", ":", "batch_output", "=", "self", ".", "automatic_optimization", ".", "run", "(", "trainer", ".", "optimizers", "[", "0", "]", ",", "batch_idx", ",", "kwargs", ")", "else", ":", "batch_output", "=", "self", ".", "manual_optimization", ".", "run", "(", "kwargs", ")", "self", ".", "batch_progress", ".", "increment_processed", "(", ")", "self", ".", "update_lr_schedulers", "(", "STRING", ",", "update_plateau_schedulers", "=", "False", ")", "if", "self", ".", "_num_ready_batches_reached", "(", ")", ":", "self", ".", "update_lr_schedulers", "(", "STRING", ",", "update_plateau_schedulers", "=", "False", ")", "if", "using_dataloader_iter", ":", "batch", "=", "data_fetcher", ".", "_batch", "batch_idx", "=", "data_fetcher", ".", "_batch_idx", "self", ".", "batch_progress", ".", "is_last_batch", "=", "data_fetcher", ".", "done", "call", ".", "_call_callback_hooks", "(", "trainer", ",", "STRING", ",", "batch_output", ",", "batch", ",", "batch_idx", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "batch_output", ",", "batch", ",", "batch_idx", ")", "trainer", ".", "_logger_connector", ".", "on_batch_end", "(", ")", "self", ".", "batch_progress", ".", "increment_completed", "(", ")", "trainer", ".", "_logger_connector", ".", "update_train_step_metrics", "(", ")"], "docstring": "Go back and finish running validation Avoid running validation again if we saved on last fast forward progress counters to end of validation we are going to train first so the val loop does not need to restart hook's batch_idx and dataloader_idx arguments correctness cannot be guaranteed in this setting TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the fetcher state so that the batch_idx is correct after restarting Note: `is_last_batch` is not yet determined if data fetcher is a `_DataLoaderIterDataFetcher` hook in automatic optimization, there can only be one optimizer update non-plateau LR schedulers update epoch-interval ones only when we are at the end of training epoch update the hook kwargs now that the step method might have consumed the iterator update `is_last_batch` again after dataloader_iter was fetched in `training_step()` ----------------------------------------- SAVE METRICS TO LOGGERS AND PROGRESS_BAR -----------------------------------------", "docstring_tokens": ["go", "back", "and", "finish", "running", "validation", "avoid", "running", "validation", "again", "if", "we", "saved", "on", "last", "fast", "forward", "progress", "counters", "to", "end", "of", "validation", "we", "are", "going", "to", "train", "first", "so", "the", "val", "loop", "does", "not", "need", "to", "restart", "hook", "s", "batch_idx", "and", "dataloader_idx", "arguments", "correctness", "cannot", "be", "guaranteed", "in", "this", "setting", "todo", "we", "should", "instead", "use", "the", "batch_idx", "returned", "by", "the", "fetcher", "however", "that", "will", "require", "saving", "the", "fetcher", "state", "so", "that", "the", "batch_idx", "is", "correct", "after", "restarting", "note", "is_last_batch", "is", "not", "yet", "determined", "if", "data", "fetcher", "is", "a", "_dataloaderiterdatafetcher", "hook", "in", "automatic", "optimization", "there", "can", "only", "be", "one", "optimizer", "update", "non", "plateau", "lr", "schedulers", "update", "epoch", "interval", "ones", "only", "when", "we", "are", "at", "the", "end", "of", "training", "epoch", "update", "the", "hook", "kwargs", "now", "that", "the", "step", "method", "might", "have", "consumed", "the", "iterator", "update", "is_last_batch", "again", "after", "dataloader_iter", "was", "fetched", "in", "training_step", "save", "metrics", "to", "loggers", "and", "progress_bar"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 273, "end_line": 376, "has_examples": false, "num_comments": 13, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_184", "original_string": "def _should_accumulate(self) -> bool:\r\n        \"\"\"Checks if the optimizer step should be performed or gradients should be accumulated for the current step.\"\"\"\r\n        accumulation_done = self._accumulated_batches_reached()\r\n        is_final_batch = self._num_ready_batches_reached()\r\n        strategy_accumulates_on_final_batch = self.trainer.strategy.handles_gradient_accumulation or not is_final_batch\r\n        return not accumulation_done and strategy_accumulates_on_final_batch", "language": "python", "code": "def _should_accumulate(self) -> bool:\r\n        \"\"\"Checks if the optimizer step should be performed or gradients should be accumulated for the current step.\"\"\"\r\n        accumulation_done = self._accumulated_batches_reached()\r\n        is_final_batch = self._num_ready_batches_reached()\r\n        strategy_accumulates_on_final_batch = self.trainer.strategy.handles_gradient_accumulation or not is_final_batch\r\n        return not accumulation_done and strategy_accumulates_on_final_batch", "code_tokens": ["def", "_should_accumulate", "(", "self", ")", "-", ">", "bool", ":", "STRING", "accumulation_done", "=", "self", ".", "_accumulated_batches_reached", "(", ")", "is_final_batch", "=", "self", ".", "_num_ready_batches_reached", "(", ")", "strategy_accumulates_on_final_batch", "=", "self", ".", "trainer", ".", "strategy", ".", "handles_gradient_accumulation", "or", "not", "is_final_batch", "return", "not", "accumulation_done", "and", "strategy_accumulates_on_final_batch"], "docstring": "Lightning steps on the final batch but the strategy might not", "docstring_tokens": ["lightning", "steps", "on", "the", "final", "batch", "but", "the", "strategy", "might", "not"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 439, "end_line": 446, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_185", "original_string": "def _update_learning_rates(self, interval: str, update_plateau_schedulers: bool) -> None:\r\n        \"\"\"Update learning rates.\r\n\r\n        Args:\r\n            interval: either 'epoch' or 'step'.\r\n            update_plateau_schedulers: control whether ``ReduceLROnPlateau`` or non-plateau schedulers get updated.\r\n                This is used so non-plateau schedulers can be updated before running validation. Checkpoints are\r\n                commonly saved during validation, however, on-plateau schedulers might monitor a validation metric\r\n                so they have to be updated separately.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        if not trainer.lr_scheduler_configs or not trainer.lightning_module.automatic_optimization:\r\n            return\r\n\r\n        for config in trainer.lr_scheduler_configs:\r\n            if update_plateau_schedulers ^ config.reduce_on_plateau:\r\n                continue\r\n\r\n            current_idx = self.batch_idx if interval == \"step\" else trainer.current_epoch\r\n            current_idx += 1  # account for both batch and epoch starts from 0\r\n            if config.interval == interval and current_idx % config.frequency == 0:\r\n                monitor_val = None\r\n                if config.reduce_on_plateau:\r\n                    monitor_key = config.monitor\r\n                    assert monitor_key is not None\r\n                    monitor_val = self._get_monitor_value(monitor_key)\r\n                    if monitor_val is None:\r\n                        if config.strict:\r\n                            avail_metrics = list(trainer.callback_metrics)\r\n                            raise MisconfigurationException(\r\n                                f\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\r\n                                f\" which is not available. Available metrics are: {avail_metrics}.\"\r\n                                \" Condition can be set using `monitor` key in lr scheduler dict\"\r\n                            )\r\n                        rank_zero_warn(\r\n                            f\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\r\n                            \" which is not available but strict is set to `False`.\"\r\n                            \" Skipping learning rate update.\",\r\n                            category=RuntimeWarning,\r\n                        )\r\n                        continue\r\n\r\n                self.scheduler_progress.increment_ready()\r\n\r\n                call._call_lightning_module_hook(\r\n                    trainer,\r\n                    \"lr_scheduler_step\",\r\n                    config.scheduler,\r\n                    monitor_val,\r\n                )\r\n                self.scheduler_progress.increment_completed()", "language": "python", "code": "def _update_learning_rates(self, interval: str, update_plateau_schedulers: bool) -> None:\r\n        \"\"\"Update learning rates.\r\n\r\n        Args:\r\n            interval: either 'epoch' or 'step'.\r\n            update_plateau_schedulers: control whether ``ReduceLROnPlateau`` or non-plateau schedulers get updated.\r\n                This is used so non-plateau schedulers can be updated before running validation. Checkpoints are\r\n                commonly saved during validation, however, on-plateau schedulers might monitor a validation metric\r\n                so they have to be updated separately.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        if not trainer.lr_scheduler_configs or not trainer.lightning_module.automatic_optimization:\r\n            return\r\n\r\n        for config in trainer.lr_scheduler_configs:\r\n            if update_plateau_schedulers ^ config.reduce_on_plateau:\r\n                continue\r\n\r\n            current_idx = self.batch_idx if interval == \"step\" else trainer.current_epoch\r\n            current_idx += 1  # account for both batch and epoch starts from 0\r\n            if config.interval == interval and current_idx % config.frequency == 0:\r\n                monitor_val = None\r\n                if config.reduce_on_plateau:\r\n                    monitor_key = config.monitor\r\n                    assert monitor_key is not None\r\n                    monitor_val = self._get_monitor_value(monitor_key)\r\n                    if monitor_val is None:\r\n                        if config.strict:\r\n                            avail_metrics = list(trainer.callback_metrics)\r\n                            raise MisconfigurationException(\r\n                                f\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\r\n                                f\" which is not available. Available metrics are: {avail_metrics}.\"\r\n                                \" Condition can be set using `monitor` key in lr scheduler dict\"\r\n                            )\r\n                        rank_zero_warn(\r\n                            f\"ReduceLROnPlateau conditioned on metric {monitor_key}\"\r\n                            \" which is not available but strict is set to `False`.\"\r\n                            \" Skipping learning rate update.\",\r\n                            category=RuntimeWarning,\r\n                        )\r\n                        continue\r\n\r\n                self.scheduler_progress.increment_ready()\r\n\r\n                call._call_lightning_module_hook(\r\n                    trainer,\r\n                    \"lr_scheduler_step\",\r\n                    config.scheduler,\r\n                    monitor_val,\r\n                )\r\n                self.scheduler_progress.increment_completed()", "code_tokens": ["def", "_update_learning_rates", "(", "self", ",", "interval", ":", "str", ",", "update_plateau_schedulers", ":", "bool", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "if", "not", "trainer", ".", "lr_scheduler_configs", "or", "not", "trainer", ".", "lightning_module", ".", "automatic_optimization", ":", "return", "for", "config", "in", "trainer", ".", "lr_scheduler_configs", ":", "if", "update_plateau_schedulers", "^", "config", ".", "reduce_on_plateau", ":", "continue", "current_idx", "=", "self", ".", "batch_idx", "if", "interval", "=", "=", "STRING", "else", "trainer", ".", "current_epoch", "current_idx", "+", "=", "1", "#", "account", "for", "both", "batch", "and", "epoch", "starts", "from", "0", "if", "config", ".", "interval", "=", "=", "interval", "and", "current_idx", "%", "config", ".", "frequency", "=", "=", "0", ":", "monitor_val", "=", "None", "if", "config", ".", "reduce_on_plateau", ":", "monitor_key", "=", "config", ".", "monitor", "assert", "monitor_key", "is", "not", "None", "monitor_val", "=", "self", ".", "_get_monitor_value", "(", "monitor_key", ")", "if", "monitor_val", "is", "None", ":", "if", "config", ".", "strict", ":", "avail_metrics", "=", "list", "(", "trainer", ".", "callback_metrics", ")", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", "STRING", ")", "rank_zero_warn", "(", "fSTRING", "STRING", "STRING", ",", "category", "=", "RuntimeWarning", ",", ")", "continue", "self", ".", "scheduler_progress", ".", "increment_ready", "(", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "config", ".", "scheduler", ",", "monitor_val", ",", ")", "self", ".", "scheduler_progress", ".", "increment_completed", "(", ")"], "docstring": "Take step if call to update_learning_rates matches the interval key and the current step modulo the schedulers frequency is zero update LR", "docstring_tokens": ["take", "step", "if", "call", "to", "update_learning_rates", "matches", "the", "interval", "key", "and", "the", "current", "step", "modulo", "the", "schedulers", "frequency", "is", "zero", "update", "lr"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 454, "end_line": 509, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_186", "original_string": "def _should_check_val_fx(self, data_fetcher: _DataFetcher) -> bool:\r\n        \"\"\"Decide if we should run validation.\"\"\"\r\n        if not self._should_check_val_epoch():\r\n            return False\r\n\r\n        is_infinite_dataset = self.trainer.val_check_batch == float(\"inf\")\r\n        is_last_batch = self.batch_progress.is_last_batch\r\n        if is_last_batch and (is_infinite_dataset or isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            return True\r\n\r\n        if self.trainer.should_stop and self.trainer.fit_loop._can_stop_early:\r\n            return True\r\n\r\n        interval = self.trainer._val_check_time_interval\r\n        if interval is not None:\r\n            now = time.monotonic()\r\n            return now - self.trainer._last_val_time >= interval\r\n        is_val_check_batch = is_last_batch\r\n        if isinstance(self.trainer.limit_train_batches, int) and is_infinite_dataset:\r\n            is_val_check_batch = (self.batch_idx + 1) % self.trainer.limit_train_batches == 0\r\n        elif self.trainer.val_check_batch != float(\"inf\"):\r\n            assert self.trainer.val_check_batch is not None\r\n            current_iteration = self.total_batch_idx if self.trainer.check_val_every_n_epoch is None else self.batch_idx\r\n            is_val_check_batch = (current_iteration + 1) % self.trainer.val_check_batch == 0\r\n\r\n        return is_val_check_batch", "language": "python", "code": "def _should_check_val_fx(self, data_fetcher: _DataFetcher) -> bool:\r\n        \"\"\"Decide if we should run validation.\"\"\"\r\n        if not self._should_check_val_epoch():\r\n            return False\r\n\r\n        is_infinite_dataset = self.trainer.val_check_batch == float(\"inf\")\r\n        is_last_batch = self.batch_progress.is_last_batch\r\n        if is_last_batch and (is_infinite_dataset or isinstance(data_fetcher, _DataLoaderIterDataFetcher)):\r\n            return True\r\n\r\n        if self.trainer.should_stop and self.trainer.fit_loop._can_stop_early:\r\n            return True\r\n\r\n        interval = self.trainer._val_check_time_interval\r\n        if interval is not None:\r\n            now = time.monotonic()\r\n            return now - self.trainer._last_val_time >= interval\r\n        is_val_check_batch = is_last_batch\r\n        if isinstance(self.trainer.limit_train_batches, int) and is_infinite_dataset:\r\n            is_val_check_batch = (self.batch_idx + 1) % self.trainer.limit_train_batches == 0\r\n        elif self.trainer.val_check_batch != float(\"inf\"):\r\n            assert self.trainer.val_check_batch is not None\r\n            current_iteration = self.total_batch_idx if self.trainer.check_val_every_n_epoch is None else self.batch_idx\r\n            is_val_check_batch = (current_iteration + 1) % self.trainer.val_check_batch == 0\r\n\r\n        return is_val_check_batch", "code_tokens": ["def", "_should_check_val_fx", "(", "self", ",", "data_fetcher", ":", "_DataFetcher", ")", "-", ">", "bool", ":", "STRING", "if", "not", "self", ".", "_should_check_val_epoch", "(", ")", ":", "return", "False", "is_infinite_dataset", "=", "self", ".", "trainer", ".", "val_check_batch", "=", "=", "float", "(", "STRING", ")", "is_last_batch", "=", "self", ".", "batch_progress", ".", "is_last_batch", "if", "is_last_batch", "and", "(", "is_infinite_dataset", "or", "isinstance", "(", "data_fetcher", ",", "_DataLoaderIterDataFetcher", ")", ")", ":", "return", "True", "if", "self", ".", "trainer", ".", "should_stop", "and", "self", ".", "trainer", ".", "fit_loop", ".", "_can_stop_early", ":", "return", "True", "interval", "=", "self", ".", "trainer", ".", "_val_check_time_interval", "if", "interval", "is", "not", "None", ":", "now", "=", "time", ".", "monotonic", "(", ")", "return", "now", "-", "self", ".", "trainer", ".", "_last_val_time", ">", "=", "interval", "is_val_check_batch", "=", "is_last_batch", "if", "isinstance", "(", "self", ".", "trainer", ".", "limit_train_batches", ",", "int", ")", "and", "is_infinite_dataset", ":", "is_val_check_batch", "=", "(", "self", ".", "batch_idx", "+", "1", ")", "%", "self", ".", "trainer", ".", "limit_train_batches", "=", "=", "0", "elif", "self", ".", "trainer", ".", "val_check_batch", "!", "=", "float", "(", "STRING", ")", ":", "assert", "self", ".", "trainer", ".", "val_check_batch", "is", "not", "None", "current_iteration", "=", "self", ".", "total_batch_idx", "if", "self", ".", "trainer", ".", "check_val_every_n_epoch", "is", "None", "else", "self", ".", "batch_idx", "is_val_check_batch", "=", "(", "current_iteration", "+", "1", ")", "%", "self", ".", "trainer", ".", "val_check_batch", "=", "=", "0", "return", "is_val_check_batch"], "docstring": "val_check_batch is inf for iterable datasets with no length defined allow validation if requesting to stop early through `Trainer.should_stop` (e.g. by early stopping) and when the loop allows to stop (min_epochs/steps met) if time\u2019s up \u2192 tell Trainer to validate TODO: let training/eval loop handle logic around limit_*_batches and val_check_batch if we got here, we\u2019re in batch-based mode, so this can\u2019t be None if `check_val_every_n_epoch is `None`, run a validation loop every n training batches else condition it based on the batch_idx of the current epoch", "docstring_tokens": ["val_check_batch", "is", "inf", "for", "iterable", "datasets", "with", "no", "length", "defined", "allow", "validation", "if", "requesting", "to", "stop", "early", "through", "trainer", "should_stop", "e", "g", "by", "early", "stopping", "and", "when", "the", "loop", "allows", "to", "stop", "min_epochs", "steps", "met", "if", "time", "s", "up", "tell", "trainer", "to", "validate", "todo", "let", "training", "eval", "loop", "handle", "logic", "around", "limit_", "_batches", "and", "val_check_batch", "if", "we", "got", "here", "we", "re", "in", "batch", "based", "mode", "so", "this", "can", "t", "be", "none", "if", "check_val_every_n_epoch", "is", "none", "run", "a", "validation", "loop", "every", "n", "training", "batches", "else", "condition", "it", "based", "on", "the", "batch_idx", "of", "the", "current", "epoch"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 521, "end_line": 554, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "func_name": "function_187", "original_string": "def _build_kwargs(self, kwargs: OrderedDict, batch: Any, batch_idx: int) -> OrderedDict:\r\n        \"\"\"Helper method to build the arguments for the current step.\r\n\r\n        Args:\r\n            kwargs: The kwargs passed down to the hooks.\r\n            batch: The current batch to run through the step.\r\n            batch_idx: the index of the current batch.\r\n\r\n        Returns:\r\n            The kwargs passed down to the hooks.\r\n\r\n        \"\"\"\r\n        kwargs[\"batch\"] = batch\r\n        training_step_fx = getattr(self.trainer.lightning_module, \"training_step\")\r\n        if is_param_in_hook_signature(training_step_fx, \"batch_idx\", min_args=2):\r\n            kwargs[\"batch_idx\"] = batch_idx\r\n        return kwargs", "language": "python", "code": "def _build_kwargs(self, kwargs: OrderedDict, batch: Any, batch_idx: int) -> OrderedDict:\r\n        \"\"\"Helper method to build the arguments for the current step.\r\n\r\n        Args:\r\n            kwargs: The kwargs passed down to the hooks.\r\n            batch: The current batch to run through the step.\r\n            batch_idx: the index of the current batch.\r\n\r\n        Returns:\r\n            The kwargs passed down to the hooks.\r\n\r\n        \"\"\"\r\n        kwargs[\"batch\"] = batch\r\n        training_step_fx = getattr(self.trainer.lightning_module, \"training_step\")\r\n        if is_param_in_hook_signature(training_step_fx, \"batch_idx\", min_args=2):\r\n            kwargs[\"batch_idx\"] = batch_idx\r\n        return kwargs", "code_tokens": ["def", "_build_kwargs", "(", "self", ",", "kwargs", ":", "OrderedDict", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ")", "-", ">", "OrderedDict", ":", "STRING", "kwargs", "[", "STRING", "]", "=", "batch", "training_step_fx", "=", "getattr", "(", "self", ".", "trainer", ".", "lightning_module", ",", "STRING", ")", "if", "is_param_in_hook_signature", "(", "training_step_fx", ",", "STRING", ",", "min_args", "=", "2", ")", ":", "kwargs", "[", "STRING", "]", "=", "batch_idx", "return", "kwargs"], "docstring": "the `batch_idx` is optional, but its name can be anything as long as there are two arguments after 'self', we assume they are the `batch` and `batch_idx`", "docstring_tokens": ["the", "batch_idx", "is", "optional", "but", "its", "name", "can", "be", "anything", "as", "long", "as", "there", "are", "two", "arguments", "after", "self", "we", "assume", "they", "are", "the", "batch", "and", "batch_idx"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\training_epoch_loop.py", "start_line": 562, "end_line": 580, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\utilities.py", "func_name": "function_188", "original_string": "def _parse_loop_limits(\r\n    min_steps: Optional[int],\r\n    max_steps: int,\r\n    min_epochs: Optional[int],\r\n    max_epochs: Optional[int],\r\n    trainer: \"pl.Trainer\",\r\n) -> tuple[int, int]:\r\n    \"\"\"This utility computes the default values for the minimum and maximum number of steps and epochs given the values\r\n    the user has selected.\r\n\r\n    Args:\r\n        min_steps: Minimum number of steps.\r\n        max_steps: Maximum number of steps.\r\n        min_epochs: Minimum number of epochs.\r\n        max_epochs: Maximum number of epochs.\r\n        trainer: Trainer instance.\r\n\r\n    Returns:\r\n        The parsed limits, with default values being set for the ones that the user did not specify.\r\n\r\n    \"\"\"\r\n    if max_epochs is None:\r\n        if max_steps == -1 and not any(isinstance(cb, Timer) for cb in trainer.callbacks):\r\n            rank_zero_warn(\r\n                \"`max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit,\"\r\n                \" set `max_epochs=-1`.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n            max_epochs = 1000\r\n        else:\r\n            max_epochs = -1\r\n\r\n    if min_epochs is None and min_steps is not None:\r\n        min_epochs = 1\r\n\r\n    if min_epochs is None:\r\n        min_epochs = 0\r\n\r\n    return min_epochs, max_epochs", "language": "python", "code": "def _parse_loop_limits(\r\n    min_steps: Optional[int],\r\n    max_steps: int,\r\n    min_epochs: Optional[int],\r\n    max_epochs: Optional[int],\r\n    trainer: \"pl.Trainer\",\r\n) -> tuple[int, int]:\r\n    \"\"\"This utility computes the default values for the minimum and maximum number of steps and epochs given the values\r\n    the user has selected.\r\n\r\n    Args:\r\n        min_steps: Minimum number of steps.\r\n        max_steps: Maximum number of steps.\r\n        min_epochs: Minimum number of epochs.\r\n        max_epochs: Maximum number of epochs.\r\n        trainer: Trainer instance.\r\n\r\n    Returns:\r\n        The parsed limits, with default values being set for the ones that the user did not specify.\r\n\r\n    \"\"\"\r\n    if max_epochs is None:\r\n        if max_steps == -1 and not any(isinstance(cb, Timer) for cb in trainer.callbacks):\r\n            rank_zero_warn(\r\n                \"`max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit,\"\r\n                \" set `max_epochs=-1`.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n            max_epochs = 1000\r\n        else:\r\n            max_epochs = -1\r\n\r\n    if min_epochs is None and min_steps is not None:\r\n        min_epochs = 1\r\n\r\n    if min_epochs is None:\r\n        min_epochs = 0\r\n\r\n    return min_epochs, max_epochs", "code_tokens": ["def", "_parse_loop_limits", "(", "min_steps", ":", "Optional", "[", "int", "]", ",", "max_steps", ":", "int", ",", "min_epochs", ":", "Optional", "[", "int", "]", ",", "max_epochs", ":", "Optional", "[", "int", "]", ",", "trainer", ":", "STRING", ",", ")", "-", ">", "tuple", "[", "int", ",", "int", "]", ":", "STRING", "if", "max_epochs", "is", "None", ":", "if", "max_steps", "=", "=", "-", "1", "and", "not", "any", "(", "isinstance", "(", "cb", ",", "Timer", ")", "for", "cb", "in", "trainer", ".", "callbacks", ")", ":", "rank_zero_warn", "(", "STRING", "STRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "max_epochs", "=", "1000", "else", ":", "max_epochs", "=", "-", "1", "if", "min_epochs", "is", "None", "and", "min_steps", "is", "not", "None", ":", "min_epochs", "=", "1", "if", "min_epochs", "is", "None", ":", "min_epochs", "=", "0", "return", "min_epochs", ",", "max_epochs"], "docstring": "setting this allows FitLoop.done to re-evaluate should_stop when it gets triggered `on_fit_start` the default value is 0 so no training will be done when should_stop is triggered `on_fit_start`", "docstring_tokens": ["setting", "this", "allows", "fitloop", "done", "to", "re", "evaluate", "should_stop", "when", "it", "gets", "triggered", "on_fit_start", "the", "default", "value", "is", "0", "so", "no", "training", "will", "be", "done", "when", "should_stop", "is", "triggered", "on_fit_start"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\utilities.py", "start_line": 49, "end_line": 89, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\optimization\\automatic.py", "func_name": "function_189", "original_string": "def run(self, optimizer: Optimizer, batch_idx: int, kwargs: OrderedDict) -> _OUTPUTS_TYPE:\r\n        \"\"\"Runs closure (train step + backward) together with optimization if necessary.\r\n\r\n        Args:\r\n            kwargs: the kwargs passed down to the hooks\r\n            batch_idx: the current batch index.\r\n            optimizer: the optimizer\r\n\r\n        \"\"\"\r\n        closure = self._make_closure(kwargs, optimizer, batch_idx)\r\n\r\n        if (\r\n            not self.trainer.strategy.handles_gradient_accumulation and self.trainer.fit_loop._should_accumulate()\r\n        ):\r\n\r\n            with _block_parallel_sync_behavior(self.trainer.strategy, block=True):\r\n                closure()\r\n\r\n        else:\r\n            self._optimizer_step(batch_idx, closure)\r\n\r\n        result = closure.consume_result()\r\n        if result.loss is None:\r\n            return {}\r\n        return result.asdict()", "language": "python", "code": "def run(self, optimizer: Optimizer, batch_idx: int, kwargs: OrderedDict) -> _OUTPUTS_TYPE:\r\n        \"\"\"Runs closure (train step + backward) together with optimization if necessary.\r\n\r\n        Args:\r\n            kwargs: the kwargs passed down to the hooks\r\n            batch_idx: the current batch index.\r\n            optimizer: the optimizer\r\n\r\n        \"\"\"\r\n        closure = self._make_closure(kwargs, optimizer, batch_idx)\r\n\r\n        if (\r\n            not self.trainer.strategy.handles_gradient_accumulation and self.trainer.fit_loop._should_accumulate()\r\n        ):\r\n\r\n            with _block_parallel_sync_behavior(self.trainer.strategy, block=True):\r\n                closure()\r\n\r\n        else:\r\n            self._optimizer_step(batch_idx, closure)\r\n\r\n        result = closure.consume_result()\r\n        if result.loss is None:\r\n            return {}\r\n        return result.asdict()", "code_tokens": ["def", "run", "(", "self", ",", "optimizer", ":", "Optimizer", ",", "batch_idx", ":", "int", ",", "kwargs", ":", "OrderedDict", ")", "-", ">", "_OUTPUTS_TYPE", ":", "STRING", "closure", "=", "self", ".", "_make_closure", "(", "kwargs", ",", "optimizer", ",", "batch_idx", ")", "if", "(", "not", "self", ".", "trainer", ".", "strategy", ".", "handles_gradient_accumulation", "and", "self", ".", "trainer", ".", "fit_loop", ".", "_should_accumulate", "(", ")", ")", ":", "with", "_block_parallel_sync_behavior", "(", "self", ".", "trainer", ".", "strategy", ",", "block", "=", "True", ")", ":", "closure", "(", ")", "else", ":", "self", ".", "_optimizer_step", "(", "batch_idx", ",", "closure", ")", "result", "=", "closure", ".", "consume_result", "(", ")", "if", "result", ".", "loss", "is", "None", ":", "return", "{", "}", "return", "result", ".", "asdict", "(", ")"], "docstring": "when the strategy handles accumulation, we want to always call the optimizer step ------------------- calculate loss (train step + train step end) ------------------- automatic_optimization=True: perform ddp sync only when performing optimizer_step ------------------------------ BACKWARD PASS ------------------------------ gradient update with accumulated gradients", "docstring_tokens": ["when", "the", "strategy", "handles", "accumulation", "we", "want", "to", "always", "call", "the", "optimizer", "step", "calculate", "loss", "train", "step", "train", "step", "end", "automatic_optimization", "true", "perform", "ddp", "sync", "only", "when", "performing", "optimizer_step", "backward", "pass", "gradient", "update", "with", "accumulated", "gradients"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\optimization\\automatic.py", "start_line": 162, "end_line": 196, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\optimization\\automatic.py", "func_name": "function_190", "original_string": "def _optimizer_step(\r\n        self,\r\n        batch_idx: int,\r\n        train_step_and_backward_closure: Callable[[], Optional[Tensor]],\r\n    ) -> None:\r\n        \"\"\"Performs the optimizer step and some sanity checking.\r\n\r\n        Args:\r\n            batch_idx: the index of the current batch\r\n            train_step_and_backward_closure: the closure function performing the train step and computing the\r\n                gradients. By default, called by the optimizer (if possible)\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        optimizer = trainer.strategy._lightning_optimizers[0]\r\n\r\n        should_accumulate = trainer.fit_loop._should_accumulate()\r\n        if not should_accumulate:\r\n            self.optim_progress.optimizer.step.increment_ready()\r\n\r\n        call._call_lightning_module_hook(\r\n            trainer,\r\n            \"optimizer_step\",\r\n            trainer.current_epoch,\r\n            batch_idx,\r\n            optimizer,\r\n            train_step_and_backward_closure,\r\n        )\r\n\r\n        if not should_accumulate:\r\n            self.optim_progress.optimizer.step.increment_completed()", "language": "python", "code": "def _optimizer_step(\r\n        self,\r\n        batch_idx: int,\r\n        train_step_and_backward_closure: Callable[[], Optional[Tensor]],\r\n    ) -> None:\r\n        \"\"\"Performs the optimizer step and some sanity checking.\r\n\r\n        Args:\r\n            batch_idx: the index of the current batch\r\n            train_step_and_backward_closure: the closure function performing the train step and computing the\r\n                gradients. By default, called by the optimizer (if possible)\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        optimizer = trainer.strategy._lightning_optimizers[0]\r\n\r\n        should_accumulate = trainer.fit_loop._should_accumulate()\r\n        if not should_accumulate:\r\n            self.optim_progress.optimizer.step.increment_ready()\r\n\r\n        call._call_lightning_module_hook(\r\n            trainer,\r\n            \"optimizer_step\",\r\n            trainer.current_epoch,\r\n            batch_idx,\r\n            optimizer,\r\n            train_step_and_backward_closure,\r\n        )\r\n\r\n        if not should_accumulate:\r\n            self.optim_progress.optimizer.step.increment_completed()", "code_tokens": ["def", "_optimizer_step", "(", "self", ",", "batch_idx", ":", "int", ",", "train_step_and_backward_closure", ":", "Callable", "[", "[", "]", ",", "Optional", "[", "Tensor", "]", "]", ",", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "optimizer", "=", "trainer", ".", "strategy", ".", "_lightning_optimizers", "[", "0", "]", "should_accumulate", "=", "trainer", ".", "fit_loop", ".", "_should_accumulate", "(", ")", "if", "not", "should_accumulate", ":", "self", ".", "optim_progress", ".", "optimizer", ".", "step", ".", "increment_ready", "(", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "trainer", ".", "current_epoch", ",", "batch_idx", ",", "optimizer", ",", "train_step_and_backward_closure", ",", ")", "if", "not", "should_accumulate", ":", "self", ".", "optim_progress", ".", "optimizer", ".", "step", ".", "increment_completed", "(", ")"], "docstring": "wraps into LightningOptimizer only for running step if `strategy.handles_gradient_accumulation`, this method will be called to route into the strategy, but we need to check again if `should_accumulate` before increasing the counters model hook", "docstring_tokens": ["wraps", "into", "lightningoptimizer", "only", "for", "running", "step", "if", "strategy", "handles_gradient_accumulation", "this", "method", "will", "be", "called", "to", "route", "into", "the", "strategy", "but", "we", "need", "to", "check", "again", "if", "should_accumulate", "before", "increasing", "the", "counters", "model", "hook"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\optimization\\automatic.py", "start_line": 244, "end_line": 279, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\optimization\\manual.py", "func_name": "function_191", "original_string": "def advance(self, kwargs: OrderedDict) -> None:\r\n        \"\"\"Performs the training step for manual optimization.\r\n\r\n        Args:\r\n            kwargs: The kwargs passed down to the hooks.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\r\n        del kwargs  # release the batch from memory\r\n        self.trainer.strategy.post_training_step()  # unused hook - call anyway for backward compatibility\r\n        result = self.output_result_cls.from_training_step_output(training_step_output)\r\n\r\n        self._output = result.asdict()", "language": "python", "code": "def advance(self, kwargs: OrderedDict) -> None:\r\n        \"\"\"Performs the training step for manual optimization.\r\n\r\n        Args:\r\n            kwargs: The kwargs passed down to the hooks.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\r\n        del kwargs  # release the batch from memory\r\n        self.trainer.strategy.post_training_step()  # unused hook - call anyway for backward compatibility\r\n        result = self.output_result_cls.from_training_step_output(training_step_output)\r\n\r\n        self._output = result.asdict()", "code_tokens": ["def", "advance", "(", "self", ",", "kwargs", ":", "OrderedDict", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "training_step_output", "=", "call", ".", "_call_strategy_hook", "(", "trainer", ",", "STRING", ",", "*", "kwargs", ".", "values", "(", ")", ")", "del", "kwargs", "#", "release", "the", "batch", "from", "memory", "self", ".", "trainer", ".", "strategy", ".", "post_training_step", "(", ")", "#", "unused", "hook", "-", "call", "anyway", "for", "backward", "compatibility", "result", "=", "self", ".", "output_result_cls", ".", "from_training_step_output", "(", "training_step_output", ")", "self", ".", "_output", "=", "result", ".", "asdict", "(", ")"], "docstring": "manually capture logged metrics", "docstring_tokens": ["manually", "capture", "logged", "metrics"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\optimization\\manual.py", "start_line": 104, "end_line": 119, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\loops\\optimization\\manual.py", "func_name": "function_192", "original_string": "def on_run_end(self) -> _OUTPUTS_TYPE:\r\n        \"\"\"Returns the result of this loop, i.e., the post-processed outputs from the training step.\"\"\"\r\n        output, self._output = self._output, {}  # free memory\r\n        for lightning_optimizer in self.trainer.strategy._lightning_optimizers:\r\n            lightning_optimizer._on_before_step = do_nothing_closure\r\n            lightning_optimizer._on_after_step = do_nothing_closure\r\n        return output", "language": "python", "code": "def on_run_end(self) -> _OUTPUTS_TYPE:\r\n        \"\"\"Returns the result of this loop, i.e., the post-processed outputs from the training step.\"\"\"\r\n        output, self._output = self._output, {}  # free memory\r\n        for lightning_optimizer in self.trainer.strategy._lightning_optimizers:\r\n            lightning_optimizer._on_before_step = do_nothing_closure\r\n            lightning_optimizer._on_after_step = do_nothing_closure\r\n        return output", "code_tokens": ["def", "on_run_end", "(", "self", ")", "-", ">", "_OUTPUTS_TYPE", ":", "STRING", "output", ",", "self", ".", "_output", "=", "self", ".", "_output", ",", "{", "}", "#", "free", "memory", "for", "lightning_optimizer", "in", "self", ".", "trainer", ".", "strategy", ".", "_lightning_optimizers", ":", "lightning_optimizer", ".", "_on_before_step", "=", "do_nothing_closure", "lightning_optimizer", ".", "_on_after_step", "=", "do_nothing_closure", "return", "output"], "docstring": "reset logic around the optimizer step", "docstring_tokens": ["reset", "logic", "around", "the", "optimizer", "step"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\loops\\optimization\\manual.py", "start_line": 121, "end_line": 128, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\overrides\\distributed.py", "func_name": "function_193", "original_string": "def _register_ddp_comm_hook(\r\n    model: DistributedDataParallel,\r\n    ddp_comm_state: Optional[object] = None,\r\n    ddp_comm_hook: Optional[Callable] = None,\r\n    ddp_comm_wrapper: Optional[Callable] = None,\r\n) -> None:\r\n    \"\"\"Function to register communication hook for DDP model https://pytorch.org/docs/master/ddp_comm_hooks.html.\r\n\r\n    Args:\r\n        model:\r\n            DDP model\r\n        ddp_comm_state:\r\n            state is passed to the hook and can be used to maintain\r\n            and update any state information that users would like to\r\n            maintain as part of the training process. Examples: error\r\n            feedback in gradient compression, peers to communicate with\r\n            next in GossipGrad etc.\r\n        ddp_comm_hook:\r\n            hook(state: object, bucket: dist._GradBucket) -> torch.futures.Future\r\n\r\n            This callable function is called once the bucket is ready. The\r\n            hook can perform whatever processing is needed and return\r\n            a Future indicating completion of any async work (ex: allreduce).\r\n            If the hook doesn't perform any communication, it can also\r\n            just return a completed Future. The Future should hold the\r\n            new value of grad bucket's tensors. Once a bucket is ready,\r\n            c10d reducer would call this hook and use the tensors returned\r\n            by the Future and copy grads to individual parameters.\r\n        ddp_comm_wrapper:\r\n            communication hook wrapper to support a communication hook such\r\n            as FP16 compression as wrapper, which could be combined with\r\n            ddp_comm_hook\r\n\r\n    Examples::\r\n\r\n        from torch.distributed.algorithms.ddp_comm_hooks import (\r\n            default_hooks as default,\r\n            powerSGD_hook as powerSGD,\r\n            post_localSGD_hook as post_localSGD,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_hook=default.fp16_compress_hook,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_state=powerSGD.PowerSGDState(\r\n                process_group=None,\r\n                matrix_approximation_rank=1,\r\n                start_powerSGD_iter=5000,\r\n            ),\r\n            ddp_comm_hook=powerSGD.powerSGD_hook,\r\n        )\r\n\r\n        subgroup, _ = torch.distributed.new_subgroups()\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            state=post_localSGD.PostLocalSGDState(\r\n                process_group=None,\r\n                subgroup=subgroup,\r\n                start_localSGD_iter=1_000,\r\n            ),\r\n            ddp_comm_hook=post_localSGD.post_localSGD_hook,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_state=powerSGD.PowerSGDState(\r\n                process_group=None,\r\n                matrix_approximation_rank=1,\r\n                start_powerSGD_iter=5000,\r\n            ),\r\n            ddp_comm_hook=powerSGD.powerSGD_hook,\r\n            ddp_comm_wrapper=default.fp16_compress_wrapper,\r\n        )\r\n\r\n    \"\"\"\r\n    if ddp_comm_hook is None:\r\n        return\r\n    ddp_comm_hook: Callable = ddp_comm_hook\r\n\r\n    if ddp_comm_wrapper is not None:\r\n        rank_zero_info(\r\n            f\"DDP comm wrapper is provided, apply {ddp_comm_wrapper.__qualname__}({ddp_comm_hook.__qualname__}).\"\r\n        )\r\n        ddp_comm_hook = ddp_comm_wrapper(ddp_comm_hook)\r\n\r\n    rank_zero_debug(f\"Registering DDP comm hook: {ddp_comm_hook.__qualname__}.\")\r\n    model.register_comm_hook(state=ddp_comm_state, hook=ddp_comm_hook)", "language": "python", "code": "def _register_ddp_comm_hook(\r\n    model: DistributedDataParallel,\r\n    ddp_comm_state: Optional[object] = None,\r\n    ddp_comm_hook: Optional[Callable] = None,\r\n    ddp_comm_wrapper: Optional[Callable] = None,\r\n) -> None:\r\n    \"\"\"Function to register communication hook for DDP model https://pytorch.org/docs/master/ddp_comm_hooks.html.\r\n\r\n    Args:\r\n        model:\r\n            DDP model\r\n        ddp_comm_state:\r\n            state is passed to the hook and can be used to maintain\r\n            and update any state information that users would like to\r\n            maintain as part of the training process. Examples: error\r\n            feedback in gradient compression, peers to communicate with\r\n            next in GossipGrad etc.\r\n        ddp_comm_hook:\r\n            hook(state: object, bucket: dist._GradBucket) -> torch.futures.Future\r\n\r\n            This callable function is called once the bucket is ready. The\r\n            hook can perform whatever processing is needed and return\r\n            a Future indicating completion of any async work (ex: allreduce).\r\n            If the hook doesn't perform any communication, it can also\r\n            just return a completed Future. The Future should hold the\r\n            new value of grad bucket's tensors. Once a bucket is ready,\r\n            c10d reducer would call this hook and use the tensors returned\r\n            by the Future and copy grads to individual parameters.\r\n        ddp_comm_wrapper:\r\n            communication hook wrapper to support a communication hook such\r\n            as FP16 compression as wrapper, which could be combined with\r\n            ddp_comm_hook\r\n\r\n    Examples::\r\n\r\n        from torch.distributed.algorithms.ddp_comm_hooks import (\r\n            default_hooks as default,\r\n            powerSGD_hook as powerSGD,\r\n            post_localSGD_hook as post_localSGD,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_hook=default.fp16_compress_hook,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_state=powerSGD.PowerSGDState(\r\n                process_group=None,\r\n                matrix_approximation_rank=1,\r\n                start_powerSGD_iter=5000,\r\n            ),\r\n            ddp_comm_hook=powerSGD.powerSGD_hook,\r\n        )\r\n\r\n        subgroup, _ = torch.distributed.new_subgroups()\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            state=post_localSGD.PostLocalSGDState(\r\n                process_group=None,\r\n                subgroup=subgroup,\r\n                start_localSGD_iter=1_000,\r\n            ),\r\n            ddp_comm_hook=post_localSGD.post_localSGD_hook,\r\n        )\r\n\r\n        ddp_model = ...\r\n        _register_ddp_comm_hook(\r\n            model=ddp_model,\r\n            ddp_comm_state=powerSGD.PowerSGDState(\r\n                process_group=None,\r\n                matrix_approximation_rank=1,\r\n                start_powerSGD_iter=5000,\r\n            ),\r\n            ddp_comm_hook=powerSGD.powerSGD_hook,\r\n            ddp_comm_wrapper=default.fp16_compress_wrapper,\r\n        )\r\n\r\n    \"\"\"\r\n    if ddp_comm_hook is None:\r\n        return\r\n    ddp_comm_hook: Callable = ddp_comm_hook\r\n\r\n    if ddp_comm_wrapper is not None:\r\n        rank_zero_info(\r\n            f\"DDP comm wrapper is provided, apply {ddp_comm_wrapper.__qualname__}({ddp_comm_hook.__qualname__}).\"\r\n        )\r\n        ddp_comm_hook = ddp_comm_wrapper(ddp_comm_hook)\r\n\r\n    rank_zero_debug(f\"Registering DDP comm hook: {ddp_comm_hook.__qualname__}.\")\r\n    model.register_comm_hook(state=ddp_comm_state, hook=ddp_comm_hook)", "code_tokens": ["def", "_register_ddp_comm_hook", "(", "model", ":", "DistributedDataParallel", ",", "ddp_comm_state", ":", "Optional", "[", "object", "]", "=", "None", ",", "ddp_comm_hook", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "ddp_comm_wrapper", ":", "Optional", "[", "Callable", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "ddp_comm_hook", "is", "None", ":", "return", "ddp_comm_hook", ":", "Callable", "=", "ddp_comm_hook", "if", "ddp_comm_wrapper", "is", "not", "None", ":", "rank_zero_info", "(", "fSTRING", ")", "ddp_comm_hook", "=", "ddp_comm_wrapper", "(", "ddp_comm_hook", ")", "rank_zero_debug", "(", "fSTRING", ")", "model", ".", "register_comm_hook", "(", "state", "=", "ddp_comm_state", ",", "hook", "=", "ddp_comm_hook", ")"], "docstring": "fp16_compress_hook for compress gradients powerSGD_hook post_localSGD_hook fp16_compress_wrapper combined with other communication hook inform mypy that ddp_comm_hook is callable", "docstring_tokens": ["fp16_compress_hook", "for", "compress", "gradients", "powersgd_hook", "post_localsgd_hook", "fp16_compress_wrapper", "combined", "with", "other", "communication", "hook", "inform", "mypy", "that", "ddp_comm_hook", "is", "callable"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\overrides\\distributed.py", "start_line": 61, "end_line": 160, "has_examples": true, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\plugins\\layer_sync.py", "func_name": "function_194", "original_string": "def revert(self, model: Module) -> Module:\r\n        \"\"\"Convert the wrapped batchnorm layers back to regular batchnorm layers.\r\n\r\n        Args:\r\n            model: Reference to the current LightningModule\r\n\r\n        Return:\r\n            LightningModule with regular batchnorm layers that will no longer sync across processes.\r\n\r\n        \"\"\"\r\n        converted_module = model\r\n        if isinstance(model, torch.nn.modules.batchnorm.SyncBatchNorm):\r\n            converted_module = _BatchNormXd(\r\n                model.num_features, model.eps, model.momentum, model.affine, model.track_running_stats\r\n            )\r\n            if model.affine:\r\n                with torch.no_grad():\r\n                    converted_module.weight = model.weight\r\n                    converted_module.bias = model.bias\r\n            converted_module.running_mean = model.running_mean\r\n            converted_module.running_var = model.running_var\r\n            converted_module.num_batches_tracked = model.num_batches_tracked\r\n            if hasattr(model, \"qconfig\"):\r\n                converted_module.qconfig = model.qconfig\r\n        for name, child in model.named_children():\r\n            converted_module.add_module(name, self.revert(child))\r\n        del model\r\n        return converted_module", "language": "python", "code": "def revert(self, model: Module) -> Module:\r\n        \"\"\"Convert the wrapped batchnorm layers back to regular batchnorm layers.\r\n\r\n        Args:\r\n            model: Reference to the current LightningModule\r\n\r\n        Return:\r\n            LightningModule with regular batchnorm layers that will no longer sync across processes.\r\n\r\n        \"\"\"\r\n        converted_module = model\r\n        if isinstance(model, torch.nn.modules.batchnorm.SyncBatchNorm):\r\n            converted_module = _BatchNormXd(\r\n                model.num_features, model.eps, model.momentum, model.affine, model.track_running_stats\r\n            )\r\n            if model.affine:\r\n                with torch.no_grad():\r\n                    converted_module.weight = model.weight\r\n                    converted_module.bias = model.bias\r\n            converted_module.running_mean = model.running_mean\r\n            converted_module.running_var = model.running_var\r\n            converted_module.num_batches_tracked = model.num_batches_tracked\r\n            if hasattr(model, \"qconfig\"):\r\n                converted_module.qconfig = model.qconfig\r\n        for name, child in model.named_children():\r\n            converted_module.add_module(name, self.revert(child))\r\n        del model\r\n        return converted_module", "code_tokens": ["def", "revert", "(", "self", ",", "model", ":", "Module", ")", "-", ">", "Module", ":", "STRING", "converted_module", "=", "model", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "SyncBatchNorm", ")", ":", "converted_module", "=", "_BatchNormXd", "(", "model", ".", "num_features", ",", "model", ".", "eps", ",", "model", ".", "momentum", ",", "model", ".", "affine", ",", "model", ".", "track_running_stats", ")", "if", "model", ".", "affine", ":", "with", "torch", ".", "no_grad", "(", ")", ":", "converted_module", ".", "weight", "=", "model", ".", "weight", "converted_module", ".", "bias", "=", "model", ".", "bias", "converted_module", ".", "running_mean", "=", "model", ".", "running_mean", "converted_module", ".", "running_var", "=", "model", ".", "running_var", "converted_module", ".", "num_batches_tracked", "=", "model", ".", "num_batches_tracked", "if", "hasattr", "(", "model", ",", "STRING", ")", ":", "converted_module", ".", "qconfig", "=", "model", ".", "qconfig", "for", "name", ",", "child", "in", "model", ".", "named_children", "(", ")", ":", "converted_module", ".", "add_module", "(", "name", ",", "self", ".", "revert", "(", "child", ")", ")", "del", "model", "return", "converted_module"], "docstring": "Code adapted from https://github.com/pytorch/pytorch/issues/41081#issuecomment-783961547 Original author: Kapil Yedidi (@kapily) Unfortunately, LayerSync does not store the original class - if it did we could return the one that was originally created.", "docstring_tokens": ["code", "adapted", "from", "https", "github", "com", "pytorch", "pytorch", "issues", "41081", "issuecomment", "783961547", "original", "author", "kapil", "yedidi", "kapily", "unfortunately", "layersync", "does", "not", "store", "the", "original", "class", "if", "it", "did", "we", "could", "return", "the", "one", "that", "was", "originally", "created"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\plugins\\layer_sync.py", "start_line": 59, "end_line": 90, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "func_name": "function_195", "original_string": "def save_checkpoint(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Uses the ``ThreadPoolExecutor`` to save the checkpoints using the base ``checkpoint_io``.\"\"\"\r\n\r\n        self._ensure_setup()\r\n\r\n        if \"checkpoint\" in kwargs:\r\n            kwargs = {**kwargs, \"checkpoint\": apply_to_collection(kwargs[\"checkpoint\"], torch.Tensor, _clone_tensor)}\r\n        elif len(args) >= 1:\r\n            args = (apply_to_collection(args[0], torch.Tensor, _clone_tensor), *args[1:])\r\n\r\n        def _save_checkpoint(*args: Any, **kwargs: Any) -> None:\r\n            try:\r\n                assert self.checkpoint_io is not None\r\n                self.checkpoint_io.save_checkpoint(*args, **kwargs)\r\n            except BaseException as ex:\r\n                self._error = ex\r\n\r\n        assert self._executor is not None\r\n        self._executor.submit(_save_checkpoint, *args, **kwargs)\r\n\r\n        if self._error:\r\n            raise self._error", "language": "python", "code": "def save_checkpoint(self, *args: Any, **kwargs: Any) -> None:\r\n        \"\"\"Uses the ``ThreadPoolExecutor`` to save the checkpoints using the base ``checkpoint_io``.\"\"\"\r\n\r\n        self._ensure_setup()\r\n\r\n        if \"checkpoint\" in kwargs:\r\n            kwargs = {**kwargs, \"checkpoint\": apply_to_collection(kwargs[\"checkpoint\"], torch.Tensor, _clone_tensor)}\r\n        elif len(args) >= 1:\r\n            args = (apply_to_collection(args[0], torch.Tensor, _clone_tensor), *args[1:])\r\n\r\n        def _save_checkpoint(*args: Any, **kwargs: Any) -> None:\r\n            try:\r\n                assert self.checkpoint_io is not None\r\n                self.checkpoint_io.save_checkpoint(*args, **kwargs)\r\n            except BaseException as ex:\r\n                self._error = ex\r\n\r\n        assert self._executor is not None\r\n        self._executor.submit(_save_checkpoint, *args, **kwargs)\r\n\r\n        if self._error:\r\n            raise self._error", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "STRING", "self", ".", "_ensure_setup", "(", ")", "if", "STRING", "in", "kwargs", ":", "kwargs", "=", "{", "*", "*", "kwargs", ",", "STRING", ":", "apply_to_collection", "(", "kwargs", "[", "STRING", "]", ",", "torch", ".", "Tensor", ",", "_clone_tensor", ")", "}", "elif", "len", "(", "args", ")", ">", "=", "1", ":", "args", "=", "(", "apply_to_collection", "(", "args", "[", "0", "]", ",", "torch", ".", "Tensor", ",", "_clone_tensor", ")", ",", "*", "args", "[", "1", ":", "]", ")", "def", "_save_checkpoint", "(", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "None", ":", "try", ":", "assert", "self", ".", "checkpoint_io", "is", "not", "None", "self", ".", "checkpoint_io", ".", "save_checkpoint", "(", "*", "args", ",", "*", "*", "kwargs", ")", "except", "BaseException", "as", "ex", ":", "self", ".", "_error", "=", "ex", "assert", "self", ".", "_executor", "is", "not", "None", "self", ".", "_executor", ".", "submit", "(", "_save_checkpoint", ",", "*", "args", ",", "*", "*", "kwargs", ")", "if", "self", ".", "_error", ":", "raise", "self", ".", "_error"], "docstring": "rebuild args/kwargs with a cloned checkpoint (supports positional or kw form) if an error was raised between the previous time `save_checkpoint`` was called and now, because `executor.submit` is not blocking", "docstring_tokens": ["rebuild", "args", "kwargs", "with", "a", "cloned", "checkpoint", "supports", "positional", "or", "kw", "form", "if", "an", "error", "was", "raised", "between", "the", "previous", "time", "save_checkpoint", "was", "called", "and", "now", "because", "executor", "submit", "is", "not", "blocking"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "start_line": 57, "end_line": 81, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "func_name": "function_196", "original_string": "def teardown(self) -> None:\r\n        \"\"\"This method is called to close the threads.\"\"\"\r\n        if self._executor is not None:\r\n            self._executor.shutdown(wait=True)\r\n            self._executor = None\r\n\r\n        if self._error:\r\n            raise self._error", "language": "python", "code": "def teardown(self) -> None:\r\n        \"\"\"This method is called to close the threads.\"\"\"\r\n        if self._executor is not None:\r\n            self._executor.shutdown(wait=True)\r\n            self._executor = None\r\n\r\n        if self._error:\r\n            raise self._error", "code_tokens": ["def", "teardown", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "self", ".", "_executor", "is", "not", "None", ":", "self", ".", "_executor", ".", "shutdown", "(", "wait", "=", "True", ")", "self", ".", "_executor", "=", "None", "if", "self", ".", "_error", ":", "raise", "self", ".", "_error"], "docstring": "if an error was raised anytime in any of the `executor.submit` calls", "docstring_tokens": ["if", "an", "error", "was", "raised", "anytime", "in", "any", "of", "the", "executor", "submit", "calls"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "start_line": 84, "end_line": 92, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "func_name": "function_197", "original_string": "def _clone_tensor(t: torch.Tensor) -> torch.Tensor:\r\n    \"\"\"Clones a tensor on the caller thread.\"\"\"\r\n    return t.detach().clone()", "language": "python", "code": "def _clone_tensor(t: torch.Tensor) -> torch.Tensor:\r\n    \"\"\"Clones a tensor on the caller thread.\"\"\"\r\n    return t.detach().clone()", "code_tokens": ["def", "_clone_tensor", "(", "t", ":", "torch", ".", "Tensor", ")", "-", ">", "torch", ".", "Tensor", ":", "STRING", "return", "t", ".", "detach", "(", ")", ".", "clone", "(", ")"], "docstring": "detach to avoid autograd history and clone to take a point-in-time copy", "docstring_tokens": ["detach", "to", "avoid", "autograd", "history", "and", "clone", "to", "take", "a", "point", "in", "time", "copy"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\plugins\\io\\async_plugin.py", "start_line": 96, "end_line": 99, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\profilers\\profiler.py", "func_name": "function_198", "original_string": "def describe(self) -> None:\r\n        \"\"\"Logs a profile report after the conclusion of run.\"\"\"\r\n        self._prepare_streams()\r\n        summary = self.summary()\r\n        if summary and self._write_stream is not None:\r\n            self._write_stream(summary)\r\n        if self._output_file is not None:\r\n            self._output_file.flush()\r\n        self.teardown(stage=self._stage)", "language": "python", "code": "def describe(self) -> None:\r\n        \"\"\"Logs a profile report after the conclusion of run.\"\"\"\r\n        self._prepare_streams()\r\n        summary = self.summary()\r\n        if summary and self._write_stream is not None:\r\n            self._write_stream(summary)\r\n        if self._output_file is not None:\r\n            self._output_file.flush()\r\n        self.teardown(stage=self._stage)", "code_tokens": ["def", "describe", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "_prepare_streams", "(", ")", "summary", "=", "self", ".", "summary", "(", ")", "if", "summary", "and", "self", ".", "_write_stream", "is", "not", "None", ":", "self", ".", "_write_stream", "(", "summary", ")", "if", "self", ".", "_output_file", "is", "not", "None", ":", "self", ".", "_output_file", ".", "flush", "(", ")", "self", ".", "teardown", "(", "stage", "=", "self", ".", "_stage", ")"], "docstring": "users might call `describe` directly as the profilers can be used by themselves. to allow this, we open and close the files within this function by calling `_prepare_streams` and `teardown` manually instead of letting the `Trainer` do it through `setup` and `teardown`", "docstring_tokens": ["users", "might", "call", "describe", "directly", "as", "the", "profilers", "can", "be", "used", "by", "themselves", "to", "allow", "this", "we", "open", "and", "close", "the", "files", "within", "this", "function", "by", "calling", "_prepare_streams", "and", "teardown", "manually", "instead", "of", "letting", "the", "trainer", "do", "it", "through", "setup", "and", "teardown"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\profilers\\profiler.py", "start_line": 105, "end_line": 116, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\serve\\servable_module_validator.py", "func_name": "function_199", "original_string": "def _start_server(servable_model: ServableModule, host: str, port: int, _: bool) -> None:\r\n        \"\"\"This method starts a server with a serve and ping endpoints.\"\"\"\r\n        from fastapi import Body, FastAPI\r\n        from uvicorn import run\r\n\r\n        app = FastAPI()\r\n\r\n        deserializers, serializers = servable_model.configure_serialization()\r\n\r\n        servable_model.eval()\r\n\r\n        @app.get(\"/ping\")\r\n        def ping() -> bool:\r\n            return True\r\n\r\n        @app.post(\"/serve\")\r\n        async def serve(payload: dict = Body(...)) -> dict[str, Any]:\r\n            body = payload[\"body\"]\r\n\r\n            for key, deserializer in deserializers.items():\r\n                body[key] = deserializer(body[key])\r\n\r\n            with torch.no_grad():\r\n                output = servable_model.serve_step(**body)\r\n\r\n            if not isinstance(output, dict):\r\n                raise Exception(f\"Please, return your outputs as a dictionary. Found {output}\")\r\n\r\n            for key, serializer in serializers.items():\r\n                output[key] = serializer(output[key])\r\n\r\n            return output\r\n\r\n        run(app, host=host, port=port, log_level=\"error\")", "language": "python", "code": "def _start_server(servable_model: ServableModule, host: str, port: int, _: bool) -> None:\r\n        \"\"\"This method starts a server with a serve and ping endpoints.\"\"\"\r\n        from fastapi import Body, FastAPI\r\n        from uvicorn import run\r\n\r\n        app = FastAPI()\r\n\r\n        deserializers, serializers = servable_model.configure_serialization()\r\n\r\n        servable_model.eval()\r\n\r\n        @app.get(\"/ping\")\r\n        def ping() -> bool:\r\n            return True\r\n\r\n        @app.post(\"/serve\")\r\n        async def serve(payload: dict = Body(...)) -> dict[str, Any]:\r\n            body = payload[\"body\"]\r\n\r\n            for key, deserializer in deserializers.items():\r\n                body[key] = deserializer(body[key])\r\n\r\n            with torch.no_grad():\r\n                output = servable_model.serve_step(**body)\r\n\r\n            if not isinstance(output, dict):\r\n                raise Exception(f\"Please, return your outputs as a dictionary. Found {output}\")\r\n\r\n            for key, serializer in serializers.items():\r\n                output[key] = serializer(output[key])\r\n\r\n            return output\r\n\r\n        run(app, host=host, port=port, log_level=\"error\")", "code_tokens": ["def", "_start_server", "(", "servable_model", ":", "ServableModule", ",", "host", ":", "str", ",", "port", ":", "int", ",", "_", ":", "bool", ")", "-", ">", "None", ":", "STRING", "from", "fastapi", "import", "Body", ",", "FastAPI", "from", "uvicorn", "import", "run", "app", "=", "FastAPI", "(", ")", "deserializers", ",", "serializers", "=", "servable_model", ".", "configure_serialization", "(", ")", "servable_model", ".", "eval", "(", ")", "@", "app", ".", "get", "(", "STRING", ")", "def", "ping", "(", ")", "-", ">", "bool", ":", "return", "True", "@", "app", ".", "post", "(", "STRING", ")", "async", "def", "serve", "(", "payload", ":", "dict", "=", "Body", "(", ".", ".", ".", ")", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "body", "=", "payload", "[", "STRING", "]", "for", "key", ",", "deserializer", "in", "deserializers", ".", "items", "(", ")", ":", "body", "[", "key", "]", "=", "deserializer", "(", "body", "[", "key", "]", ")", "with", "torch", ".", "no_grad", "(", ")", ":", "output", "=", "servable_model", ".", "serve_step", "(", "*", "*", "body", ")", "if", "not", "isinstance", "(", "output", ",", "dict", ")", ":", "raise", "Exception", "(", "fSTRING", ")", "for", "key", ",", "serializer", "in", "serializers", ".", "items", "(", ")", ":", "output", "[", "key", "]", "=", "serializer", "(", "output", "[", "key", "]", ")", "return", "output", "run", "(", "app", ",", "host", "=", "host", ",", "port", "=", "port", ",", "log_level", "=", "STRING", ")"], "docstring": "Note: This isn't the original version, but a copy.", "docstring_tokens": ["note", "this", "isn", "t", "the", "original", "version", "but", "a", "copy"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\serve\\servable_module_validator.py", "start_line": 142, "end_line": 176, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\ddp.py", "func_name": "function_200", "original_string": "def _setup_model(self, model: Module) -> DistributedDataParallel:\r\n        \"\"\"Wraps the model into a :class:`~torch.nn.parallel.distributed.DistributedDataParallel` module.\"\"\"\r\n        device_ids = self.determine_ddp_device_ids()\r\n        log.debug(f\"setting up DDP model with device ids: {device_ids}, kwargs: {self._ddp_kwargs}\")\r\n        ctx = torch.cuda.stream(torch.cuda.Stream()) if device_ids is not None else nullcontext()\r\n        with ctx:\r\n            return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)", "language": "python", "code": "def _setup_model(self, model: Module) -> DistributedDataParallel:\r\n        \"\"\"Wraps the model into a :class:`~torch.nn.parallel.distributed.DistributedDataParallel` module.\"\"\"\r\n        device_ids = self.determine_ddp_device_ids()\r\n        log.debug(f\"setting up DDP model with device ids: {device_ids}, kwargs: {self._ddp_kwargs}\")\r\n        ctx = torch.cuda.stream(torch.cuda.Stream()) if device_ids is not None else nullcontext()\r\n        with ctx:\r\n            return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)", "code_tokens": ["def", "_setup_model", "(", "self", ",", "model", ":", "Module", ")", "-", ">", "DistributedDataParallel", ":", "STRING", "device_ids", "=", "self", ".", "determine_ddp_device_ids", "(", ")", "log", ".", "debug", "(", "fSTRING", ")", "ctx", "=", "torch", ".", "cuda", ".", "stream", "(", "torch", ".", "cuda", ".", "Stream", "(", ")", ")", "if", "device_ids", "is", "not", "None", "else", "nullcontext", "(", ")", "with", "ctx", ":", "return", "DistributedDataParallel", "(", "module", "=", "model", ",", "device_ids", "=", "device_ids", ",", "*", "*", "self", ".", "_ddp_kwargs", ")"], "docstring": "https://pytorch.org/docs/stable/notes/cuda.html#id5", "docstring_tokens": ["https", "pytorch", "org", "docs", "stable", "notes", "cuda", "html", "id5"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\ddp.py", "start_line": 187, "end_line": 194, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "func_name": "function_201", "original_string": "def __init__(\r\n        self,\r\n        accelerator: Optional[\"pl.accelerators.Accelerator\"] = None,\r\n        zero_optimization: bool = True,\r\n        stage: int = 2,\r\n        remote_device: Optional[str] = None,\r\n        offload_optimizer: bool = False,\r\n        offload_parameters: bool = False,\r\n        offload_params_device: str = \"cpu\",\r\n        nvme_path: str = \"/local_nvme\",\r\n        params_buffer_count: int = 5,\r\n        params_buffer_size: int = 100_000_000,\r\n        max_in_cpu: int = 1_000_000_000,\r\n        offload_optimizer_device: str = \"cpu\",\r\n        optimizer_buffer_count: int = 4,\r\n        block_size: int = 1048576,\r\n        queue_depth: int = 8,\r\n        single_submit: bool = False,\r\n        overlap_events: bool = True,\r\n        thread_count: int = 1,\r\n        pin_memory: bool = False,\r\n        sub_group_size: int = 1_000_000_000_000,\r\n        contiguous_gradients: bool = True,\r\n        overlap_comm: bool = True,\r\n        allgather_partitions: bool = True,\r\n        reduce_scatter: bool = True,\r\n        allgather_bucket_size: int = 200_000_000,\r\n        reduce_bucket_size: int = 200_000_000,\r\n        zero_allow_untested_optimizer: bool = True,\r\n        logging_batch_size_per_gpu: Union[str, int] = \"auto\",\r\n        config: Optional[Union[_PATH, dict[str, Any]]] = None,\r\n        logging_level: int = logging.WARN,\r\n        parallel_devices: Optional[list[torch.device]] = None,\r\n        cluster_environment: Optional[ClusterEnvironment] = None,\r\n        loss_scale: float = 0,\r\n        initial_scale_power: int = 16,\r\n        loss_scale_window: int = 1000,\r\n        hysteresis: int = 2,\r\n        min_loss_scale: int = 1,\r\n        partition_activations: bool = False,\r\n        cpu_checkpointing: bool = False,\r\n        contiguous_memory_optimization: bool = False,\r\n        synchronize_checkpoint_boundary: bool = False,\r\n        load_full_weights: bool = False,\r\n        precision_plugin: Optional[Precision] = None,\r\n        process_group_backend: Optional[str] = None,\r\n        timeout: Optional[timedelta] = default_pg_timeout,\r\n        exclude_frozen_parameters: bool = False,\r\n    ) -> None:\r\n        \"\"\"Provides capabilities to run training using the DeepSpeed library, with training optimizations for large\r\n        billion parameter models. *For more information:* :ref:`deepspeed_advanced`.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        Defaults have been set to enable ZeRO-Offload and some have been taken from the link below.\r\n        These defaults have been set generally, but may require tuning for optimum performance based on your model size.\r\n        *For more information:* https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training.\r\n\r\n        Arguments:\r\n\r\n            zero_optimization: Enable ZeRO optimization. This is compatible with either `precision=\"16-mixed\"` or\r\n                `precision=\"bf16-mixed\"`.\r\n\r\n            stage: Different stages of the ZeRO Optimizer. 0 is disabled,\r\n                1 is optimizer state partitioning, 2 is optimizer+gradient state partitioning,\r\n                3 is optimizer+gradient_parameter partitioning using the infinity engine.\r\n\r\n            remote_device: Device to instantiate the model on initially (``cpu`` or ``nvme``). Defaults to GPU.\r\n\r\n            offload_optimizer: Enable offloading optimizer memory and computation to CPU or NVMe\r\n                based on ``offload_optimizer_device``.\r\n\r\n            offload_parameters: When using ZeRO Stage 3, Enable offloading parameter memory and computation\r\n                to CPU or NVMe based on ``offload_params_device``.\r\n\r\n            offload_params_device: When offloading parameters choose the device to offload to, ``cpu`` or ``nvme``.\r\n\r\n            offload_optimizer_device: When offloading optimizer state choose the device to offload to,\r\n                ``cpu`` or ``nvme``.\r\n\r\n            params_buffer_count: Number of buffers in buffer pool for\r\n                parameter offloading when ``offload_params_device`` is ``nvme``.\r\n\r\n            params_buffer_size: Size of buffers in buffer pool for parameter offloading\r\n                when ``offload_params_device`` is ``nvme``.\r\n\r\n            max_in_cpu: Number of parameter elements to maintain in CPU memory when offloading to NVMe is enabled.\r\n\r\n            nvme_path: Filesystem path for NVMe device for optimizer/parameter state offloading.\r\n\r\n            optimizer_buffer_count: Number of buffers in buffer pool for optimizer state offloading\r\n                when ``offload_optimizer_device`` is set to ``nvme``.\r\n                This should be at least the number of states maintained per parameter by the optimizer.\r\n                For example, Adam optimizer has 4 states (parameter, gradient, momentum, and variance).\r\n\r\n            block_size: When using NVMe Offloading, the I/O block size in bytes.\r\n\r\n            queue_depth: When using NVMe Offloading, the I/O queue depth.\r\n\r\n            single_submit: When using NVMe Offloading,\r\n                submit requests to storage device as multiple individual requests,\r\n                as opposed to one block of requests.\r\n\r\n            overlap_events: When using NVMe Offloading,\r\n                submit requests to storage device in an overlapped fashion\r\n                without waiting for completion of earlier requests.\r\n\r\n            thread_count: When using NVMe Offloading,\r\n                Intra-request parallelism for each read/write submitted by a user thread.\r\n\r\n            pin_memory: When using ZeRO stage 3, pin optimizer state memory on CPU.\r\n                This could boost throughput at the cost of extra memory overhead.\r\n\r\n            sub_group_size: When using ZeRO stage 3, defines the number of parameters\r\n                within a sub group to offload at a time.\r\n                Smaller numbers require more communication, but improve memory efficiency.\r\n\r\n            contiguous_gradients: Copies gradients to a continuous buffer as they are produced.\r\n                Avoids memory fragmentation during backwards. Useful when training large models.\r\n\r\n            overlap_comm: Overlap the reduction (synchronization) of gradients with the backwards computation.\r\n                This is a speed optimization when training across multiple GPUs/machines.\r\n\r\n            allgather_partitions: All gather updated parameters at the end of training step,\r\n                instead of using a series of broadcast collectives.\r\n\r\n            reduce_scatter: Use reduce/scatter instead of allreduce to average gradients.\r\n\r\n            allgather_bucket_size: Number of elements to allgather at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            reduce_bucket_size: Number of elements to reduce at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            zero_allow_untested_optimizer: Allow untested optimizers to be used with ZeRO. Currently only Adam is a\r\n                DeepSpeed supported optimizer when using ZeRO.\r\n\r\n            logging_batch_size_per_gpu: Config used in DeepSpeed to calculate verbose timing for logging\r\n                on a per sample per second basis (only displayed if logging=logging.INFO).\r\n                If set to \"auto\", the strategy tries to infer this from\r\n                the train DataLoader's BatchSampler, else defaults to 1.\r\n                To obtain accurate logs when using datasets that do not support batch samplers,\r\n                set this to the actual per gpu batch size (trainer.batch_size).\r\n\r\n            config: Pass in a deepspeed formatted config dict,\r\n                or path to a deepspeed config: https://www.deepspeed.ai/docs/config-json.\r\n                All defaults will be ignored if a config is passed in.\r\n\r\n            logging_level: Set logging level for deepspeed.\r\n\r\n            loss_scale: Loss scaling value for FP16 training.\r\n                0.0 results in dynamic loss scaling, otherwise static.\r\n\r\n            initial_scale_power: Power of the initial dynamic loss scale value. Loss scale is computed\r\n                by ``2^initial_scale_power``.\r\n\r\n            loss_scale_window: Window in which to raise/lower the dynamic FP16 loss scaling value.\r\n\r\n            hysteresis: FP16 Delay shift in Dynamic Loss scaling.\r\n\r\n            min_loss_scale: The minimum FP16 dynamic loss scaling value.\r\n\r\n            partition_activations: Enables partition activation when used with ZeRO stage 3 and model parallelism.\r\n                Still requires you to wrap your forward functions in deepspeed.checkpointing.checkpoint.\r\n                See `deepspeed tutorial\r\n                <https://www.deepspeed.ai/tutorials/megatron/#deepspeed-activation-checkpoints-optional>`_.\r\n\r\n            cpu_checkpointing: Offloads partitioned activations to CPU if ``partition_activations`` is enabled.\r\n\r\n            contiguous_memory_optimization: Copies partitioned activations so that they are contiguous in memory.\r\n                Not supported by all models.\r\n\r\n            synchronize_checkpoint_boundary: Insert :func:`torch.cuda.synchronize` at each checkpoint boundary.\r\n\r\n            load_full_weights: True when loading a single checkpoint file containing the model state dict\r\n                when using ZeRO Stage 3. This differs from the DeepSpeed checkpoint which contains shards\r\n                per worker.\r\n\r\n            exclude_frozen_parameters: Exclude frozen parameters when saving checkpoints.\r\n\r\n        \"\"\"\r\n        if not _DEEPSPEED_AVAILABLE:\r\n            raise MisconfigurationException(\r\n                \"To use the `DeepSpeedStrategy`, you must have DeepSpeed installed.\"\r\n                \" Install it by running `pip install -U deepspeed`.\"\r\n            )\r\n\r\n        if _TORCH_GREATER_EQUAL_2_6 and not _DEEPSPEED_GREATER_EQUAL_0_16:\r\n            import deepspeed\r\n\r\n            deepspeed_version = deepspeed.__version__\r\n\r\n            raise ImportError(\r\n                f\"PyTorch >= 2.6 requires DeepSpeed >= 0.16.0. \"\r\n                f\"Detected DeepSpeed version: {deepspeed_version}. \"\r\n                \"Please upgrade by running `pip install -U 'deepspeed>=0.16.0'`.\"\r\n            )\r\n\r\n        super().__init__(\r\n            accelerator=accelerator,\r\n            parallel_devices=parallel_devices,\r\n            cluster_environment=cluster_environment,\r\n            precision_plugin=precision_plugin,\r\n            process_group_backend=process_group_backend,\r\n        )\r\n        self._timeout: Optional[timedelta] = timeout\r\n\r\n        self.config = self._load_config(config)\r\n        if self.config is None:\r\n            self.config = self._create_default_config(\r\n                zero_optimization,\r\n                zero_allow_untested_optimizer,\r\n                logging_batch_size_per_gpu,\r\n                offload_optimizer=offload_optimizer,\r\n                offload_parameters=offload_parameters,\r\n                nvme_path=nvme_path,\r\n                offload_params_device=offload_params_device,\r\n                params_buffer_count=params_buffer_count,\r\n                params_buffer_size=params_buffer_size,\r\n                max_in_cpu=max_in_cpu,\r\n                pin_memory=pin_memory,\r\n                offload_optimizer_device=offload_optimizer_device,\r\n                optimizer_buffer_count=optimizer_buffer_count,\r\n                block_size=block_size,\r\n                queue_depth=queue_depth,\r\n                single_submit=single_submit,\r\n                overlap_events=overlap_events,\r\n                thread_count=thread_count,\r\n                partition_activations=partition_activations,\r\n                cpu_checkpointing=cpu_checkpointing,\r\n                contiguous_memory_optimization=contiguous_memory_optimization,\r\n                synchronize_checkpoint_boundary=synchronize_checkpoint_boundary,\r\n                stage=stage,\r\n                contiguous_gradients=contiguous_gradients,\r\n                overlap_comm=overlap_comm,\r\n                allgather_partitions=allgather_partitions,\r\n                reduce_scatter=reduce_scatter,\r\n                allgather_bucket_size=allgather_bucket_size,\r\n                reduce_bucket_size=reduce_bucket_size,\r\n                sub_group_size=sub_group_size,\r\n            )\r\n        import deepspeed\r\n\r\n        self._config_initialized = False\r\n        deepspeed.utils.logging.logger.setLevel(logging_level)\r\n\r\n        self.remote_device = remote_device\r\n        self.load_full_weights = load_full_weights\r\n        self.exclude_frozen_parameters = exclude_frozen_parameters\r\n\r\n        self.loss_scale = loss_scale\r\n        self.initial_scale_power = initial_scale_power\r\n        self.loss_scale_window = loss_scale_window\r\n        self.hysteresis = hysteresis\r\n        self.min_loss_scale = min_loss_scale", "language": "python", "code": "def __init__(\r\n        self,\r\n        accelerator: Optional[\"pl.accelerators.Accelerator\"] = None,\r\n        zero_optimization: bool = True,\r\n        stage: int = 2,\r\n        remote_device: Optional[str] = None,\r\n        offload_optimizer: bool = False,\r\n        offload_parameters: bool = False,\r\n        offload_params_device: str = \"cpu\",\r\n        nvme_path: str = \"/local_nvme\",\r\n        params_buffer_count: int = 5,\r\n        params_buffer_size: int = 100_000_000,\r\n        max_in_cpu: int = 1_000_000_000,\r\n        offload_optimizer_device: str = \"cpu\",\r\n        optimizer_buffer_count: int = 4,\r\n        block_size: int = 1048576,\r\n        queue_depth: int = 8,\r\n        single_submit: bool = False,\r\n        overlap_events: bool = True,\r\n        thread_count: int = 1,\r\n        pin_memory: bool = False,\r\n        sub_group_size: int = 1_000_000_000_000,\r\n        contiguous_gradients: bool = True,\r\n        overlap_comm: bool = True,\r\n        allgather_partitions: bool = True,\r\n        reduce_scatter: bool = True,\r\n        allgather_bucket_size: int = 200_000_000,\r\n        reduce_bucket_size: int = 200_000_000,\r\n        zero_allow_untested_optimizer: bool = True,\r\n        logging_batch_size_per_gpu: Union[str, int] = \"auto\",\r\n        config: Optional[Union[_PATH, dict[str, Any]]] = None,\r\n        logging_level: int = logging.WARN,\r\n        parallel_devices: Optional[list[torch.device]] = None,\r\n        cluster_environment: Optional[ClusterEnvironment] = None,\r\n        loss_scale: float = 0,\r\n        initial_scale_power: int = 16,\r\n        loss_scale_window: int = 1000,\r\n        hysteresis: int = 2,\r\n        min_loss_scale: int = 1,\r\n        partition_activations: bool = False,\r\n        cpu_checkpointing: bool = False,\r\n        contiguous_memory_optimization: bool = False,\r\n        synchronize_checkpoint_boundary: bool = False,\r\n        load_full_weights: bool = False,\r\n        precision_plugin: Optional[Precision] = None,\r\n        process_group_backend: Optional[str] = None,\r\n        timeout: Optional[timedelta] = default_pg_timeout,\r\n        exclude_frozen_parameters: bool = False,\r\n    ) -> None:\r\n        \"\"\"Provides capabilities to run training using the DeepSpeed library, with training optimizations for large\r\n        billion parameter models. *For more information:* :ref:`deepspeed_advanced`.\r\n\r\n        .. warning::  This is an :ref:`experimental <versioning:Experimental API>` feature.\r\n\r\n        Defaults have been set to enable ZeRO-Offload and some have been taken from the link below.\r\n        These defaults have been set generally, but may require tuning for optimum performance based on your model size.\r\n        *For more information:* https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training.\r\n\r\n        Arguments:\r\n\r\n            zero_optimization: Enable ZeRO optimization. This is compatible with either `precision=\"16-mixed\"` or\r\n                `precision=\"bf16-mixed\"`.\r\n\r\n            stage: Different stages of the ZeRO Optimizer. 0 is disabled,\r\n                1 is optimizer state partitioning, 2 is optimizer+gradient state partitioning,\r\n                3 is optimizer+gradient_parameter partitioning using the infinity engine.\r\n\r\n            remote_device: Device to instantiate the model on initially (``cpu`` or ``nvme``). Defaults to GPU.\r\n\r\n            offload_optimizer: Enable offloading optimizer memory and computation to CPU or NVMe\r\n                based on ``offload_optimizer_device``.\r\n\r\n            offload_parameters: When using ZeRO Stage 3, Enable offloading parameter memory and computation\r\n                to CPU or NVMe based on ``offload_params_device``.\r\n\r\n            offload_params_device: When offloading parameters choose the device to offload to, ``cpu`` or ``nvme``.\r\n\r\n            offload_optimizer_device: When offloading optimizer state choose the device to offload to,\r\n                ``cpu`` or ``nvme``.\r\n\r\n            params_buffer_count: Number of buffers in buffer pool for\r\n                parameter offloading when ``offload_params_device`` is ``nvme``.\r\n\r\n            params_buffer_size: Size of buffers in buffer pool for parameter offloading\r\n                when ``offload_params_device`` is ``nvme``.\r\n\r\n            max_in_cpu: Number of parameter elements to maintain in CPU memory when offloading to NVMe is enabled.\r\n\r\n            nvme_path: Filesystem path for NVMe device for optimizer/parameter state offloading.\r\n\r\n            optimizer_buffer_count: Number of buffers in buffer pool for optimizer state offloading\r\n                when ``offload_optimizer_device`` is set to ``nvme``.\r\n                This should be at least the number of states maintained per parameter by the optimizer.\r\n                For example, Adam optimizer has 4 states (parameter, gradient, momentum, and variance).\r\n\r\n            block_size: When using NVMe Offloading, the I/O block size in bytes.\r\n\r\n            queue_depth: When using NVMe Offloading, the I/O queue depth.\r\n\r\n            single_submit: When using NVMe Offloading,\r\n                submit requests to storage device as multiple individual requests,\r\n                as opposed to one block of requests.\r\n\r\n            overlap_events: When using NVMe Offloading,\r\n                submit requests to storage device in an overlapped fashion\r\n                without waiting for completion of earlier requests.\r\n\r\n            thread_count: When using NVMe Offloading,\r\n                Intra-request parallelism for each read/write submitted by a user thread.\r\n\r\n            pin_memory: When using ZeRO stage 3, pin optimizer state memory on CPU.\r\n                This could boost throughput at the cost of extra memory overhead.\r\n\r\n            sub_group_size: When using ZeRO stage 3, defines the number of parameters\r\n                within a sub group to offload at a time.\r\n                Smaller numbers require more communication, but improve memory efficiency.\r\n\r\n            contiguous_gradients: Copies gradients to a continuous buffer as they are produced.\r\n                Avoids memory fragmentation during backwards. Useful when training large models.\r\n\r\n            overlap_comm: Overlap the reduction (synchronization) of gradients with the backwards computation.\r\n                This is a speed optimization when training across multiple GPUs/machines.\r\n\r\n            allgather_partitions: All gather updated parameters at the end of training step,\r\n                instead of using a series of broadcast collectives.\r\n\r\n            reduce_scatter: Use reduce/scatter instead of allreduce to average gradients.\r\n\r\n            allgather_bucket_size: Number of elements to allgather at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            reduce_bucket_size: Number of elements to reduce at once.\r\n                Used to limit the memory required for larger model sizes, with a tradeoff with speed.\r\n\r\n            zero_allow_untested_optimizer: Allow untested optimizers to be used with ZeRO. Currently only Adam is a\r\n                DeepSpeed supported optimizer when using ZeRO.\r\n\r\n            logging_batch_size_per_gpu: Config used in DeepSpeed to calculate verbose timing for logging\r\n                on a per sample per second basis (only displayed if logging=logging.INFO).\r\n                If set to \"auto\", the strategy tries to infer this from\r\n                the train DataLoader's BatchSampler, else defaults to 1.\r\n                To obtain accurate logs when using datasets that do not support batch samplers,\r\n                set this to the actual per gpu batch size (trainer.batch_size).\r\n\r\n            config: Pass in a deepspeed formatted config dict,\r\n                or path to a deepspeed config: https://www.deepspeed.ai/docs/config-json.\r\n                All defaults will be ignored if a config is passed in.\r\n\r\n            logging_level: Set logging level for deepspeed.\r\n\r\n            loss_scale: Loss scaling value for FP16 training.\r\n                0.0 results in dynamic loss scaling, otherwise static.\r\n\r\n            initial_scale_power: Power of the initial dynamic loss scale value. Loss scale is computed\r\n                by ``2^initial_scale_power``.\r\n\r\n            loss_scale_window: Window in which to raise/lower the dynamic FP16 loss scaling value.\r\n\r\n            hysteresis: FP16 Delay shift in Dynamic Loss scaling.\r\n\r\n            min_loss_scale: The minimum FP16 dynamic loss scaling value.\r\n\r\n            partition_activations: Enables partition activation when used with ZeRO stage 3 and model parallelism.\r\n                Still requires you to wrap your forward functions in deepspeed.checkpointing.checkpoint.\r\n                See `deepspeed tutorial\r\n                <https://www.deepspeed.ai/tutorials/megatron/#deepspeed-activation-checkpoints-optional>`_.\r\n\r\n            cpu_checkpointing: Offloads partitioned activations to CPU if ``partition_activations`` is enabled.\r\n\r\n            contiguous_memory_optimization: Copies partitioned activations so that they are contiguous in memory.\r\n                Not supported by all models.\r\n\r\n            synchronize_checkpoint_boundary: Insert :func:`torch.cuda.synchronize` at each checkpoint boundary.\r\n\r\n            load_full_weights: True when loading a single checkpoint file containing the model state dict\r\n                when using ZeRO Stage 3. This differs from the DeepSpeed checkpoint which contains shards\r\n                per worker.\r\n\r\n            exclude_frozen_parameters: Exclude frozen parameters when saving checkpoints.\r\n\r\n        \"\"\"\r\n        if not _DEEPSPEED_AVAILABLE:\r\n            raise MisconfigurationException(\r\n                \"To use the `DeepSpeedStrategy`, you must have DeepSpeed installed.\"\r\n                \" Install it by running `pip install -U deepspeed`.\"\r\n            )\r\n\r\n        if _TORCH_GREATER_EQUAL_2_6 and not _DEEPSPEED_GREATER_EQUAL_0_16:\r\n            import deepspeed\r\n\r\n            deepspeed_version = deepspeed.__version__\r\n\r\n            raise ImportError(\r\n                f\"PyTorch >= 2.6 requires DeepSpeed >= 0.16.0. \"\r\n                f\"Detected DeepSpeed version: {deepspeed_version}. \"\r\n                \"Please upgrade by running `pip install -U 'deepspeed>=0.16.0'`.\"\r\n            )\r\n\r\n        super().__init__(\r\n            accelerator=accelerator,\r\n            parallel_devices=parallel_devices,\r\n            cluster_environment=cluster_environment,\r\n            precision_plugin=precision_plugin,\r\n            process_group_backend=process_group_backend,\r\n        )\r\n        self._timeout: Optional[timedelta] = timeout\r\n\r\n        self.config = self._load_config(config)\r\n        if self.config is None:\r\n            self.config = self._create_default_config(\r\n                zero_optimization,\r\n                zero_allow_untested_optimizer,\r\n                logging_batch_size_per_gpu,\r\n                offload_optimizer=offload_optimizer,\r\n                offload_parameters=offload_parameters,\r\n                nvme_path=nvme_path,\r\n                offload_params_device=offload_params_device,\r\n                params_buffer_count=params_buffer_count,\r\n                params_buffer_size=params_buffer_size,\r\n                max_in_cpu=max_in_cpu,\r\n                pin_memory=pin_memory,\r\n                offload_optimizer_device=offload_optimizer_device,\r\n                optimizer_buffer_count=optimizer_buffer_count,\r\n                block_size=block_size,\r\n                queue_depth=queue_depth,\r\n                single_submit=single_submit,\r\n                overlap_events=overlap_events,\r\n                thread_count=thread_count,\r\n                partition_activations=partition_activations,\r\n                cpu_checkpointing=cpu_checkpointing,\r\n                contiguous_memory_optimization=contiguous_memory_optimization,\r\n                synchronize_checkpoint_boundary=synchronize_checkpoint_boundary,\r\n                stage=stage,\r\n                contiguous_gradients=contiguous_gradients,\r\n                overlap_comm=overlap_comm,\r\n                allgather_partitions=allgather_partitions,\r\n                reduce_scatter=reduce_scatter,\r\n                allgather_bucket_size=allgather_bucket_size,\r\n                reduce_bucket_size=reduce_bucket_size,\r\n                sub_group_size=sub_group_size,\r\n            )\r\n        import deepspeed\r\n\r\n        self._config_initialized = False\r\n        deepspeed.utils.logging.logger.setLevel(logging_level)\r\n\r\n        self.remote_device = remote_device\r\n        self.load_full_weights = load_full_weights\r\n        self.exclude_frozen_parameters = exclude_frozen_parameters\r\n\r\n        self.loss_scale = loss_scale\r\n        self.initial_scale_power = initial_scale_power\r\n        self.loss_scale_window = loss_scale_window\r\n        self.hysteresis = hysteresis\r\n        self.min_loss_scale = min_loss_scale", "code_tokens": ["def", "__init__", "(", "self", ",", "accelerator", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "zero_optimization", ":", "bool", "=", "True", ",", "stage", ":", "int", "=", "2", ",", "remote_device", ":", "Optional", "[", "str", "]", "=", "None", ",", "offload_optimizer", ":", "bool", "=", "False", ",", "offload_parameters", ":", "bool", "=", "False", ",", "offload_params_device", ":", "str", "=", "STRING", ",", "nvme_path", ":", "str", "=", "STRING", ",", "params_buffer_count", ":", "int", "=", "5", ",", "params_buffer_size", ":", "int", "=", "100_000_000", ",", "max_in_cpu", ":", "int", "=", "1_000_000_000", ",", "offload_optimizer_device", ":", "str", "=", "STRING", ",", "optimizer_buffer_count", ":", "int", "=", "4", ",", "block_size", ":", "int", "=", "1048576", ",", "queue_depth", ":", "int", "=", "8", ",", "single_submit", ":", "bool", "=", "False", ",", "overlap_events", ":", "bool", "=", "True", ",", "thread_count", ":", "int", "=", "1", ",", "pin_memory", ":", "bool", "=", "False", ",", "sub_group_size", ":", "int", "=", "1_000_000_000_000", ",", "contiguous_gradients", ":", "bool", "=", "True", ",", "overlap_comm", ":", "bool", "=", "True", ",", "allgather_partitions", ":", "bool", "=", "True", ",", "reduce_scatter", ":", "bool", "=", "True", ",", "allgather_bucket_size", ":", "int", "=", "200_000_000", ",", "reduce_bucket_size", ":", "int", "=", "200_000_000", ",", "zero_allow_untested_optimizer", ":", "bool", "=", "True", ",", "logging_batch_size_per_gpu", ":", "Union", "[", "str", ",", "int", "]", "=", "STRING", ",", "config", ":", "Optional", "[", "Union", "[", "_PATH", ",", "dict", "[", "str", ",", "Any", "]", "]", "]", "=", "None", ",", "logging_level", ":", "int", "=", "logging", ".", "WARN", ",", "parallel_devices", ":", "Optional", "[", "list", "[", "torch", ".", "device", "]", "]", "=", "None", ",", "cluster_environment", ":", "Optional", "[", "ClusterEnvironment", "]", "=", "None", ",", "loss_scale", ":", "float", "=", "0", ",", "initial_scale_power", ":", "int", "=", "16", ",", "loss_scale_window", ":", "int", "=", "1000", ",", "hysteresis", ":", "int", "=", "2", ",", "min_loss_scale", ":", "int", "=", "1", ",", "partition_activations", ":", "bool", "=", "False", ",", "cpu_checkpointing", ":", "bool", "=", "False", ",", "contiguous_memory_optimization", ":", "bool", "=", "False", ",", "synchronize_checkpoint_boundary", ":", "bool", "=", "False", ",", "load_full_weights", ":", "bool", "=", "False", ",", "precision_plugin", ":", "Optional", "[", "Precision", "]", "=", "None", ",", "process_group_backend", ":", "Optional", "[", "str", "]", "=", "None", ",", "timeout", ":", "Optional", "[", "timedelta", "]", "=", "default_pg_timeout", ",", "exclude_frozen_parameters", ":", "bool", "=", "False", ",", ")", "-", ">", "None", ":", "STRING", "if", "not", "_DEEPSPEED_AVAILABLE", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", ")", "if", "_TORCH_GREATER_EQUAL_2_6", "and", "not", "_DEEPSPEED_GREATER_EQUAL_0_16", ":", "import", "deepspeed", "deepspeed_version", "=", "deepspeed", ".", "__version__", "raise", "ImportError", "(", "fSTRING", "fSTRING", "STRING", ")", "super", "(", ")", ".", "__init__", "(", "accelerator", "=", "accelerator", ",", "parallel_devices", "=", "parallel_devices", ",", "cluster_environment", "=", "cluster_environment", ",", "precision_plugin", "=", "precision_plugin", ",", "process_group_backend", "=", "process_group_backend", ",", ")", "self", ".", "_timeout", ":", "Optional", "[", "timedelta", "]", "=", "timeout", "self", ".", "config", "=", "self", ".", "_load_config", "(", "config", ")", "if", "self", ".", "config", "is", "None", ":", "self", ".", "config", "=", "self", ".", "_create_default_config", "(", "zero_optimization", ",", "zero_allow_untested_optimizer", ",", "logging_batch_size_per_gpu", ",", "offload_optimizer", "=", "offload_optimizer", ",", "offload_parameters", "=", "offload_parameters", ",", "nvme_path", "=", "nvme_path", ",", "offload_params_device", "=", "offload_params_device", ",", "params_buffer_count", "=", "params_buffer_count", ",", "params_buffer_size", "=", "params_buffer_size", ",", "max_in_cpu", "=", "max_in_cpu", ",", "pin_memory", "=", "pin_memory", ",", "offload_optimizer_device", "=", "offload_optimizer_device", ",", "optimizer_buffer_count", "=", "optimizer_buffer_count", ",", "block_size", "=", "block_size", ",", "queue_depth", "=", "queue_depth", ",", "single_submit", "=", "single_submit", ",", "overlap_events", "=", "overlap_events", ",", "thread_count", "=", "thread_count", ",", "partition_activations", "=", "partition_activations", ",", "cpu_checkpointing", "=", "cpu_checkpointing", ",", "contiguous_memory_optimization", "=", "contiguous_memory_optimization", ",", "synchronize_checkpoint_boundary", "=", "synchronize_checkpoint_boundary", ",", "stage", "=", "stage", ",", "contiguous_gradients"], "docstring": "Starting with PyTorch 2.6, `torch.load` defaults to `weights_only=True` when loading full checkpoints. DeepSpeed added support for this behavior in version 0.16.0. User has not overridden config, set defaults default FP16 parameters.", "docstring_tokens": ["starting", "with", "pytorch", "2", "6", "torch", "load", "defaults", "to", "weights_only", "true", "when", "loading", "full", "checkpoints", "deepspeed", "added", "support", "for", "this", "behavior", "in", "version", "0", "16", "0", "user", "has", "not", "overridden", "config", "set", "defaults", "default", "fp16", "parameters"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "start_line": 79, "end_line": 337, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "func_name": "function_202", "original_string": "def _setup_model_and_optimizers(\r\n        self, model: Module, optimizers: list[Optimizer]\r\n    ) -> tuple[\"deepspeed.DeepSpeedEngine\", list[Optimizer]]:\r\n        \"\"\"Setup a model and multiple optimizers together.\r\n\r\n        Currently only a single optimizer is supported.\r\n\r\n        Return:\r\n            The model wrapped into a :class:`deepspeed.DeepSpeedEngine` and a list with a single\r\n            deepspeed optimizer.\r\n\r\n        \"\"\"\r\n        if len(optimizers) != 1:\r\n            raise ValueError(\r\n                f\"Currently only one optimizer is supported with DeepSpeed. Got {len(optimizers)} optimizers instead.\"\r\n            )\r\n\r\n        assert self.config is not None\r\n        self.config.setdefault(\"train_micro_batch_size_per_gpu\", 1)\r\n        self.model, optimizer = self._setup_model_and_optimizer(model, optimizers[0])\r\n        self._set_deepspeed_activation_checkpointing()\r\n        return self.model, [optimizer]", "language": "python", "code": "def _setup_model_and_optimizers(\r\n        self, model: Module, optimizers: list[Optimizer]\r\n    ) -> tuple[\"deepspeed.DeepSpeedEngine\", list[Optimizer]]:\r\n        \"\"\"Setup a model and multiple optimizers together.\r\n\r\n        Currently only a single optimizer is supported.\r\n\r\n        Return:\r\n            The model wrapped into a :class:`deepspeed.DeepSpeedEngine` and a list with a single\r\n            deepspeed optimizer.\r\n\r\n        \"\"\"\r\n        if len(optimizers) != 1:\r\n            raise ValueError(\r\n                f\"Currently only one optimizer is supported with DeepSpeed. Got {len(optimizers)} optimizers instead.\"\r\n            )\r\n\r\n        assert self.config is not None\r\n        self.config.setdefault(\"train_micro_batch_size_per_gpu\", 1)\r\n        self.model, optimizer = self._setup_model_and_optimizer(model, optimizers[0])\r\n        self._set_deepspeed_activation_checkpointing()\r\n        return self.model, [optimizer]", "code_tokens": ["def", "_setup_model_and_optimizers", "(", "self", ",", "model", ":", "Module", ",", "optimizers", ":", "list", "[", "Optimizer", "]", ")", "-", ">", "tuple", "[", "STRING", ",", "list", "[", "Optimizer", "]", "]", ":", "STRING", "if", "len", "(", "optimizers", ")", "!", "=", "1", ":", "raise", "ValueError", "(", "fSTRING", ")", "assert", "self", ".", "config", "is", "not", "None", "self", ".", "config", ".", "setdefault", "(", "STRING", ",", "1", ")", "self", ".", "model", ",", "optimizer", "=", "self", ".", "_setup_model_and_optimizer", "(", "model", ",", "optimizers", "[", "0", "]", ")", "self", ".", "_set_deepspeed_activation_checkpointing", "(", ")", "return", "self", ".", "model", ",", "[", "optimizer", "]"], "docstring": "train_micro_batch_size_per_gpu is used for throughput logging purposes normally we set this to the batch size, but it is not available here unless the user provides it as part of the config", "docstring_tokens": ["train_micro_batch_size_per_gpu", "is", "used", "for", "throughput", "logging", "purposes", "normally", "we", "set", "this", "to", "the", "batch", "size", "but", "it", "is", "not", "available", "here", "unless", "the", "user", "provides", "it", "as", "part", "of", "the", "config"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "start_line": 406, "end_line": 430, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "func_name": "function_203", "original_string": "def setup_optimizers(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Creates optimizers and schedulers.\r\n\r\n        Args:\r\n            trainer: the Trainer, these optimizers should be connected to\r\n\r\n        \"\"\"\r\n        self.optimizers = []\r\n        self.lr_scheduler_configs = []", "language": "python", "code": "def setup_optimizers(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Creates optimizers and schedulers.\r\n\r\n        Args:\r\n            trainer: the Trainer, these optimizers should be connected to\r\n\r\n        \"\"\"\r\n        self.optimizers = []\r\n        self.lr_scheduler_configs = []", "code_tokens": ["def", "setup_optimizers", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "self", ".", "optimizers", "=", "[", "]", "self", ".", "lr_scheduler_configs", "=", "[", "]"], "docstring": "Skip initializing optimizers here as DeepSpeed handles optimizers via config. User may have specified config options instead in configure_optimizers, but this is handled via `_initialize_deepspeed_train` empty optimizers, schedulers", "docstring_tokens": ["skip", "initializing", "optimizers", "here", "as", "deepspeed", "handles", "optimizers", "via", "config", "user", "may", "have", "specified", "config", "options", "instead", "in", "configure_optimizers", "but", "this", "is", "handled", "via", "_initialize_deepspeed_train", "empty", "optimizers", "schedulers"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "start_line": 602, "end_line": 614, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "func_name": "function_204", "original_string": "def save_checkpoint(self, checkpoint: dict, filepath: _PATH, storage_options: Optional[Any] = None) -> None:\r\n        \"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\r\n\r\n        Args:\r\n            checkpoint: The checkpoint state dictionary\r\n            filepath: write-target file's path\r\n            storage_options: not used for ``DeepSpeedStrategy`` as ``CheckpointIO`` is not used\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``storage_options`` arg is passed in\r\n\r\n        \"\"\"\r\n        filepath = self.broadcast(filepath)\r\n\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`Trainer.save_checkpoint(..., storage_options=...)` with `storage_options` arg\"\r\n                f\" is not supported for `{self.__class__.__name__}` as `CheckpointIO` is not used.\"\r\n            )\r\n\r\n        if self.zero_stage_3 and self._multi_device and self.is_global_zero:\r\n            warning_cache.warn(\r\n                \"When saving the DeepSpeed Stage 3 checkpoint, \"\r\n                \"each worker will save a shard of the checkpoint within a directory. \"\r\n                \"If a single file is required after training, \"\r\n                \"see https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html#\"\r\n                \"deepspeed-zero-stage-3-single-file for instructions.\"\r\n            )\r\n        _exclude_keys = [\"state_dict\", \"optimizer_states\"]\r\n        checkpoint = {k: v for k, v in checkpoint.items() if k not in _exclude_keys}\r\n        self.deepspeed_engine.save_checkpoint(\r\n            filepath,\r\n            client_state=checkpoint,\r\n            tag=\"checkpoint\",\r\n            exclude_frozen_parameters=self.exclude_frozen_parameters,\r\n        )", "language": "python", "code": "def save_checkpoint(self, checkpoint: dict, filepath: _PATH, storage_options: Optional[Any] = None) -> None:\r\n        \"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\r\n\r\n        Args:\r\n            checkpoint: The checkpoint state dictionary\r\n            filepath: write-target file's path\r\n            storage_options: not used for ``DeepSpeedStrategy`` as ``CheckpointIO`` is not used\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``storage_options`` arg is passed in\r\n\r\n        \"\"\"\r\n        filepath = self.broadcast(filepath)\r\n\r\n        if storage_options is not None:\r\n            raise TypeError(\r\n                \"`Trainer.save_checkpoint(..., storage_options=...)` with `storage_options` arg\"\r\n                f\" is not supported for `{self.__class__.__name__}` as `CheckpointIO` is not used.\"\r\n            )\r\n\r\n        if self.zero_stage_3 and self._multi_device and self.is_global_zero:\r\n            warning_cache.warn(\r\n                \"When saving the DeepSpeed Stage 3 checkpoint, \"\r\n                \"each worker will save a shard of the checkpoint within a directory. \"\r\n                \"If a single file is required after training, \"\r\n                \"see https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html#\"\r\n                \"deepspeed-zero-stage-3-single-file for instructions.\"\r\n            )\r\n        _exclude_keys = [\"state_dict\", \"optimizer_states\"]\r\n        checkpoint = {k: v for k, v in checkpoint.items() if k not in _exclude_keys}\r\n        self.deepspeed_engine.save_checkpoint(\r\n            filepath,\r\n            client_state=checkpoint,\r\n            tag=\"checkpoint\",\r\n            exclude_frozen_parameters=self.exclude_frozen_parameters,\r\n        )", "code_tokens": ["def", "save_checkpoint", "(", "self", ",", "checkpoint", ":", "dict", ",", "filepath", ":", "_PATH", ",", "storage_options", ":", "Optional", "[", "Any", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "filepath", "=", "self", ".", "broadcast", "(", "filepath", ")", "if", "storage_options", "is", "not", "None", ":", "raise", "TypeError", "(", "STRING", "fSTRING", ")", "if", "self", ".", "zero_stage_3", "and", "self", ".", "_multi_device", "and", "self", ".", "is_global_zero", ":", "warning_cache", ".", "warn", "(", "STRING", "STRING", "STRING", "STRING", "STRING", ")", "_exclude_keys", "=", "[", "STRING", ",", "STRING", "]", "checkpoint", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "checkpoint", ".", "items", "(", ")", "if", "k", "not", "in", "_exclude_keys", "}", "self", ".", "deepspeed_engine", ".", "save_checkpoint", "(", "filepath", ",", "client_state", "=", "checkpoint", ",", "tag", "=", "STRING", ",", "exclude_frozen_parameters", "=", "self", ".", "exclude_frozen_parameters", ",", ")"], "docstring": "broadcast the filepath from rank 0 to ensure all the states are saved in a common filepath Use deepspeed's internal checkpointing function to handle partitioned weights across processes dump states as a checkpoint dictionary object", "docstring_tokens": ["broadcast", "the", "filepath", "from", "rank", "0", "to", "ensure", "all", "the", "states", "are", "saved", "in", "a", "common", "filepath", "use", "deepspeed", "s", "internal", "checkpointing", "function", "to", "handle", "partitioned", "weights", "across", "processes", "dump", "states", "as", "a", "checkpoint", "dictionary", "object"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "start_line": 634, "end_line": 673, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "func_name": "function_205", "original_string": "def _restore_zero_state(self, ckpt: Mapping[str, Any], strict: bool) -> None:\r\n        \"\"\"Overrides the normal load_state_dict behaviour in PyTorch to ensure we gather parameters that may be sharded\r\n        across processes before loading the state dictionary when using ZeRO stage 3. This is then automatically synced\r\n        across processes.\r\n\r\n        Args:\r\n            ckpt: The ckpt file.\r\n\r\n        \"\"\"\r\n        import deepspeed\r\n\r\n        assert self.lightning_module is not None\r\n\r\n        def load(module: torch.nn.Module, prefix: str = \"\") -> None:\r\n            missing_keys: list[str] = []\r\n            unexpected_keys: list[str] = []\r\n            error_msgs: list[str] = []\r\n            state_dict = ckpt[\"state_dict\"]\r\n\r\n            metadata = getattr(state_dict, \"_metadata\", None)\r\n            state_dict = state_dict.copy()\r\n            if metadata is not None:\r\n                state_dict._metadata = metadata\r\n\r\n            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\r\n            with deepspeed.zero.GatheredParameters(list(module.parameters(recurse=False)), modifier_rank=0):\r\n                if self.is_global_zero:\r\n                    module._load_from_state_dict(\r\n                        state_dict=state_dict,\r\n                        prefix=prefix,\r\n                        local_metadata=local_metadata,\r\n                        strict=strict,\r\n                        missing_keys=missing_keys,\r\n                        unexpected_keys=unexpected_keys,\r\n                        error_msgs=error_msgs,\r\n                    )\r\n\r\n            for name, child in module._modules.items():\r\n                if child is not None:\r\n                    load(child, prefix + name + \".\")\r\n\r\n        load(self.lightning_module, prefix=\"\")", "language": "python", "code": "def _restore_zero_state(self, ckpt: Mapping[str, Any], strict: bool) -> None:\r\n        \"\"\"Overrides the normal load_state_dict behaviour in PyTorch to ensure we gather parameters that may be sharded\r\n        across processes before loading the state dictionary when using ZeRO stage 3. This is then automatically synced\r\n        across processes.\r\n\r\n        Args:\r\n            ckpt: The ckpt file.\r\n\r\n        \"\"\"\r\n        import deepspeed\r\n\r\n        assert self.lightning_module is not None\r\n\r\n        def load(module: torch.nn.Module, prefix: str = \"\") -> None:\r\n            missing_keys: list[str] = []\r\n            unexpected_keys: list[str] = []\r\n            error_msgs: list[str] = []\r\n            state_dict = ckpt[\"state_dict\"]\r\n\r\n            metadata = getattr(state_dict, \"_metadata\", None)\r\n            state_dict = state_dict.copy()\r\n            if metadata is not None:\r\n                state_dict._metadata = metadata\r\n\r\n            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\r\n            with deepspeed.zero.GatheredParameters(list(module.parameters(recurse=False)), modifier_rank=0):\r\n                if self.is_global_zero:\r\n                    module._load_from_state_dict(\r\n                        state_dict=state_dict,\r\n                        prefix=prefix,\r\n                        local_metadata=local_metadata,\r\n                        strict=strict,\r\n                        missing_keys=missing_keys,\r\n                        unexpected_keys=unexpected_keys,\r\n                        error_msgs=error_msgs,\r\n                    )\r\n\r\n            for name, child in module._modules.items():\r\n                if child is not None:\r\n                    load(child, prefix + name + \".\")\r\n\r\n        load(self.lightning_module, prefix=\"\")", "code_tokens": ["def", "_restore_zero_state", "(", "self", ",", "ckpt", ":", "Mapping", "[", "str", ",", "Any", "]", ",", "strict", ":", "bool", ")", "-", ">", "None", ":", "STRING", "import", "deepspeed", "assert", "self", ".", "lightning_module", "is", "not", "None", "def", "load", "(", "module", ":", "torch", ".", "nn", ".", "Module", ",", "prefix", ":", "str", "=", "STRING", ")", "-", ">", "None", ":", "missing_keys", ":", "list", "[", "str", "]", "=", "[", "]", "unexpected_keys", ":", "list", "[", "str", "]", "=", "[", "]", "error_msgs", ":", "list", "[", "str", "]", "=", "[", "]", "state_dict", "=", "ckpt", "[", "STRING", "]", "metadata", "=", "getattr", "(", "state_dict", ",", "STRING", ",", "None", ")", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "if", "metadata", "is", "not", "None", ":", "state_dict", ".", "_metadata", "=", "metadata", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "with", "deepspeed", ".", "zero", ".", "GatheredParameters", "(", "list", "(", "module", ".", "parameters", "(", "recurse", "=", "False", ")", ")", ",", "modifier_rank", "=", "0", ")", ":", "if", "self", ".", "is_global_zero", ":", "module", ".", "_load_from_state_dict", "(", "state_dict", "=", "state_dict", ",", "prefix", "=", "prefix", ",", "local_metadata", "=", "local_metadata", ",", "strict", "=", "strict", ",", "missing_keys", "=", "missing_keys", ",", "unexpected_keys", "=", "unexpected_keys", ",", "error_msgs", "=", "error_msgs", ",", ")", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "if", "child", "is", "not", "None", ":", "load", "(", "child", ",", "prefix", "+", "name", "+", "STRING", ")", "load", "(", "self", ".", "lightning_module", ",", "prefix", "=", "STRING", ")"], "docstring": "copy state_dict so _load_from_state_dict can modify it because zero3 puts placeholders in model params, this context manager gathers (unpartitions) the params of the current layer, then loads from the state dict and then re-partitions them again", "docstring_tokens": ["copy", "state_dict", "so", "_load_from_state_dict", "can", "modify", "it", "because", "zero3", "puts", "placeholders", "in", "model", "params", "this", "context", "manager", "gathers", "unpartitions", "the", "params", "of", "the", "current", "layer", "then", "loads", "from", "the", "state", "dict", "and", "then", "re", "partitions", "them", "again"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\deepspeed.py", "start_line": 725, "end_line": 770, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\fsdp.py", "func_name": "function_206", "original_string": "def _setup_model(self, model: Module) -> Module:\r\n        \"\"\"Wraps the model into a :class:`~torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel`\r\n        module.\"\"\"\r\n        from torch.distributed.fsdp import FullyShardedDataParallel\r\n\r\n        if any(isinstance(mod, FullyShardedDataParallel) for mod in model.modules()):\r\n            if _has_meta_device_parameters_or_buffers(model):\r\n                rank_zero_warn(\r\n                    \"The model is already wrapped in `FSDP` but there are still parameters on the meta device.\"\r\n                )\r\n            if \"auto_wrap_policy\" in self.kwargs:\r\n                rank_zero_warn(\r\n                    \"A FSDP `auto_wrap_policy` is set, but the model is already wrapped. The policy will be ignored.\"\r\n                )\r\n                del self.kwargs[\"auto_wrap_policy\"]\r\n        else:\r\n            log.debug(f\"setting up FSDP model with device id: {self.root_device.index}, kwargs: {self.kwargs}\")\r\n            model = FullyShardedDataParallel(\r\n                module=model,\r\n                cpu_offload=self.cpu_offload,\r\n                mixed_precision=self.mixed_precision_config,\r\n                sharding_strategy=self.sharding_strategy,\r\n                device_id=self.root_device.index,\r\n                **self.kwargs,\r\n            )\r\n\r\n        _move_torchmetrics_to_device(model, self.root_device)\r\n\r\n        _setup_activation_checkpointing(model, self._activation_checkpointing_kwargs)\r\n\r\n        return model", "language": "python", "code": "def _setup_model(self, model: Module) -> Module:\r\n        \"\"\"Wraps the model into a :class:`~torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel`\r\n        module.\"\"\"\r\n        from torch.distributed.fsdp import FullyShardedDataParallel\r\n\r\n        if any(isinstance(mod, FullyShardedDataParallel) for mod in model.modules()):\r\n            if _has_meta_device_parameters_or_buffers(model):\r\n                rank_zero_warn(\r\n                    \"The model is already wrapped in `FSDP` but there are still parameters on the meta device.\"\r\n                )\r\n            if \"auto_wrap_policy\" in self.kwargs:\r\n                rank_zero_warn(\r\n                    \"A FSDP `auto_wrap_policy` is set, but the model is already wrapped. The policy will be ignored.\"\r\n                )\r\n                del self.kwargs[\"auto_wrap_policy\"]\r\n        else:\r\n            log.debug(f\"setting up FSDP model with device id: {self.root_device.index}, kwargs: {self.kwargs}\")\r\n            model = FullyShardedDataParallel(\r\n                module=model,\r\n                cpu_offload=self.cpu_offload,\r\n                mixed_precision=self.mixed_precision_config,\r\n                sharding_strategy=self.sharding_strategy,\r\n                device_id=self.root_device.index,\r\n                **self.kwargs,\r\n            )\r\n\r\n        _move_torchmetrics_to_device(model, self.root_device)\r\n\r\n        _setup_activation_checkpointing(model, self._activation_checkpointing_kwargs)\r\n\r\n        return model", "code_tokens": ["def", "_setup_model", "(", "self", ",", "model", ":", "Module", ")", "-", ">", "Module", ":", "STRING", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "if", "any", "(", "isinstance", "(", "mod", ",", "FullyShardedDataParallel", ")", "for", "mod", "in", "model", ".", "modules", "(", ")", ")", ":", "if", "_has_meta_device_parameters_or_buffers", "(", "model", ")", ":", "rank_zero_warn", "(", "STRING", ")", "if", "STRING", "in", "self", ".", "kwargs", ":", "rank_zero_warn", "(", "STRING", ")", "del", "self", ".", "kwargs", "[", "STRING", "]", "else", ":", "log", ".", "debug", "(", "fSTRING", ")", "model", "=", "FullyShardedDataParallel", "(", "module", "=", "model", ",", "cpu_offload", "=", "self", ".", "cpu_offload", ",", "mixed_precision", "=", "self", ".", "mixed_precision_config", ",", "sharding_strategy", "=", "self", ".", "sharding_strategy", ",", "device_id", "=", "self", ".", "root_device", ".", "index", ",", "*", "*", "self", ".", "kwargs", ",", ")", "_move_torchmetrics_to_device", "(", "model", ",", "self", ".", "root_device", ")", "_setup_activation_checkpointing", "(", "model", ",", "self", ".", "_activation_checkpointing_kwargs", ")", "return", "model"], "docstring": "The user has wrapped their submodules manually, don't apply the auto wrap policy. activation checkpointing needs to be set up after wrapping the model", "docstring_tokens": ["the", "user", "has", "wrapped", "their", "submodules", "manually", "don", "t", "apply", "the", "auto", "wrap", "policy", "activation", "checkpointing", "needs", "to", "be", "set", "up", "after", "wrapping", "the", "model"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\fsdp.py", "start_line": 291, "end_line": 323, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\model_parallel.py", "func_name": "function_207", "original_string": "def optimizer_state(self, optimizer: Optimizer) -> dict[str, Any]:\r\n        \"\"\"Collects the state of the given optimizer.\r\n\r\n        Only returns a non-empty state dict on rank 0 if ``save_distributed_checkpoint=False``.\r\n\r\n        \"\"\"\r\n        from torch.distributed.checkpoint.state_dict import StateDictOptions, get_optimizer_state_dict\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n        from torch.distributed.fsdp import OptimStateKeyType\r\n\r\n        state_dict_options = StateDictOptions(full_state_dict=(not self._save_distributed_checkpoint), cpu_offload=True)\r\n        if isinstance(optimizer, LightningOptimizer):\r\n            optimizer = optimizer._optimizer\r\n\r\n        assert self.model is not None\r\n\r\n        state_dict = get_optimizer_state_dict(self.model, optimizer, options=state_dict_options)\r\n        if not self._save_distributed_checkpoint and self.global_rank == 0:\r\n            state_dict = FSDP.rekey_optim_state_dict(state_dict, OptimStateKeyType.PARAM_ID, self.model)\r\n        return state_dict", "language": "python", "code": "def optimizer_state(self, optimizer: Optimizer) -> dict[str, Any]:\r\n        \"\"\"Collects the state of the given optimizer.\r\n\r\n        Only returns a non-empty state dict on rank 0 if ``save_distributed_checkpoint=False``.\r\n\r\n        \"\"\"\r\n        from torch.distributed.checkpoint.state_dict import StateDictOptions, get_optimizer_state_dict\r\n        from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\r\n        from torch.distributed.fsdp import OptimStateKeyType\r\n\r\n        state_dict_options = StateDictOptions(full_state_dict=(not self._save_distributed_checkpoint), cpu_offload=True)\r\n        if isinstance(optimizer, LightningOptimizer):\r\n            optimizer = optimizer._optimizer\r\n\r\n        assert self.model is not None\r\n\r\n        state_dict = get_optimizer_state_dict(self.model, optimizer, options=state_dict_options)\r\n        if not self._save_distributed_checkpoint and self.global_rank == 0:\r\n            state_dict = FSDP.rekey_optim_state_dict(state_dict, OptimStateKeyType.PARAM_ID, self.model)\r\n        return state_dict", "code_tokens": ["def", "optimizer_state", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "from", "torch", ".", "distributed", ".", "checkpoint", ".", "state_dict", "import", "StateDictOptions", ",", "get_optimizer_state_dict", "from", "torch", ".", "distributed", ".", "fsdp", "import", "FullyShardedDataParallel", "as", "FSDP", "from", "torch", ".", "distributed", ".", "fsdp", "import", "OptimStateKeyType", "state_dict_options", "=", "StateDictOptions", "(", "full_state_dict", "=", "(", "not", "self", ".", "_save_distributed_checkpoint", ")", ",", "cpu_offload", "=", "True", ")", "if", "isinstance", "(", "optimizer", ",", "LightningOptimizer", ")", ":", "optimizer", "=", "optimizer", ".", "_optimizer", "assert", "self", ".", "model", "is", "not", "None", "state_dict", "=", "get_optimizer_state_dict", "(", "self", ".", "model", ",", "optimizer", ",", "options", "=", "state_dict_options", ")", "if", "not", "self", ".", "_save_distributed_checkpoint", "and", "self", ".", "global_rank", "=", "=", "0", ":", "state_dict", "=", "FSDP", ".", "rekey_optim_state_dict", "(", "state_dict", ",", "OptimStateKeyType", ".", "PARAM_ID", ",", "self", ".", "model", ")", "return", "state_dict"], "docstring": "Store the optimizer state dict in standard format", "docstring_tokens": ["store", "the", "optimizer", "state", "dict", "in", "standard", "format"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\model_parallel.py", "start_line": 270, "end_line": 290, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_208", "original_string": "def connect(self, model: \"pl.LightningModule\") -> None:\r\n        \"\"\"Called by the Trainer to connect the strategy with the model.\"\"\"\r\n        self._lightning_module = model\r\n        self.model = model", "language": "python", "code": "def connect(self, model: \"pl.LightningModule\") -> None:\r\n        \"\"\"Called by the Trainer to connect the strategy with the model.\"\"\"\r\n        self._lightning_module = model\r\n        self.model = model", "code_tokens": ["def", "connect", "(", "self", ",", "model", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "self", ".", "_lightning_module", "=", "model", "self", ".", "model", "=", "model"], "docstring": "model conversions cannot be applied at this point because `LightningModule.{setup,configure_model}` haven't run yet", "docstring_tokens": ["model", "conversions", "cannot", "be", "applied", "at", "this", "point", "because", "lightningmodule", "setup", "configure_model", "haven", "t", "run", "yet"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 110, "end_line": 115, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_209", "original_string": "def setup(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Sets up the accelerator, plugins and initializes the optimizers (if needed).\r\n\r\n        Args:\r\n            trainer: the trainer instance\r\n\r\n        \"\"\"\r\n        assert self.accelerator is not None\r\n        self.accelerator.setup(trainer)\r\n\r\n        assert self.model is not None\r\n        self.model = self.precision_plugin.convert_module(self.model)\r\n        self.model_to_device()\r\n        self.model = self._setup_model(self.model)\r\n\r\n        if trainer.state.fn == TrainerFn.FITTING:\r\n            self.setup_optimizers(trainer)\r\n        self.setup_precision_plugin()\r\n        if trainer.state.fn == TrainerFn.FITTING:\r\n            _optimizers_to_device(self.optimizers, self.root_device)", "language": "python", "code": "def setup(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Sets up the accelerator, plugins and initializes the optimizers (if needed).\r\n\r\n        Args:\r\n            trainer: the trainer instance\r\n\r\n        \"\"\"\r\n        assert self.accelerator is not None\r\n        self.accelerator.setup(trainer)\r\n\r\n        assert self.model is not None\r\n        self.model = self.precision_plugin.convert_module(self.model)\r\n        self.model_to_device()\r\n        self.model = self._setup_model(self.model)\r\n\r\n        if trainer.state.fn == TrainerFn.FITTING:\r\n            self.setup_optimizers(trainer)\r\n        self.setup_precision_plugin()\r\n        if trainer.state.fn == TrainerFn.FITTING:\r\n            _optimizers_to_device(self.optimizers, self.root_device)", "code_tokens": ["def", "setup", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "assert", "self", ".", "accelerator", "is", "not", "None", "self", ".", "accelerator", ".", "setup", "(", "trainer", ")", "assert", "self", ".", "model", "is", "not", "None", "self", ".", "model", "=", "self", ".", "precision_plugin", ".", "convert_module", "(", "self", ".", "model", ")", "self", ".", "model_to_device", "(", ")", "self", ".", "model", "=", "self", ".", "_setup_model", "(", "self", ".", "model", ")", "if", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "self", ".", "setup_optimizers", "(", "trainer", ")", "self", ".", "setup_precision_plugin", "(", ")", "if", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "_optimizers_to_device", "(", "self", ".", "optimizers", ",", "self", ".", "root_device", ")"], "docstring": "let the precision plugin convert the module here so that this strategy hook can decide the order of operations", "docstring_tokens": ["let", "the", "precision", "plugin", "convert", "the", "module", "here", "so", "that", "this", "strategy", "hook", "can", "decide", "the", "order", "of", "operations"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 140, "end_line": 161, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_210", "original_string": "def optimizer_state(self, optimizer: Optimizer) -> dict[str, Tensor]:\r\n        \"\"\"Returns state of an optimizer.\r\n\r\n        Allows for syncing/collating optimizer state from processes in custom strategies.\r\n\r\n        \"\"\"\r\n        if isinstance(optimizer, LightningOptimizer):\r\n            optimizer = optimizer._optimizer\r\n\r\n        if hasattr(optimizer, \"consolidate_state_dict\"):\r\n            optimizer.consolidate_state_dict()\r\n            return optimizer.state_dict() if self.is_global_zero else {}\r\n\r\n        return optimizer.state_dict()", "language": "python", "code": "def optimizer_state(self, optimizer: Optimizer) -> dict[str, Tensor]:\r\n        \"\"\"Returns state of an optimizer.\r\n\r\n        Allows for syncing/collating optimizer state from processes in custom strategies.\r\n\r\n        \"\"\"\r\n        if isinstance(optimizer, LightningOptimizer):\r\n            optimizer = optimizer._optimizer\r\n\r\n        if hasattr(optimizer, \"consolidate_state_dict\"):\r\n            optimizer.consolidate_state_dict()\r\n            return optimizer.state_dict() if self.is_global_zero else {}\r\n\r\n        return optimizer.state_dict()", "code_tokens": ["def", "optimizer_state", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "dict", "[", "str", ",", "Tensor", "]", ":", "STRING", "if", "isinstance", "(", "optimizer", ",", "LightningOptimizer", ")", ":", "optimizer", "=", "optimizer", ".", "_optimizer", "if", "hasattr", "(", "optimizer", ",", "STRING", ")", ":", "optimizer", ".", "consolidate_state_dict", "(", ")", "return", "optimizer", ".", "state_dict", "(", ")", "if", "self", ".", "is_global_zero", "else", "{", "}", "return", "optimizer", ".", "state_dict", "(", ")"], "docstring": "there are optimizers like PyTorch's ZeroRedundancyOptimizer that shard their states, and to avoid OOM we consolidate the full state on rank 0 only for optimizers that are not sharded, we return the state dict on all ranks", "docstring_tokens": ["there", "are", "optimizers", "like", "pytorch", "s", "zeroredundancyoptimizer", "that", "shard", "their", "states", "and", "to", "avoid", "oom", "we", "consolidate", "the", "full", "state", "on", "rank", "0", "only", "for", "optimizers", "that", "are", "not", "sharded", "we", "return", "the", "state", "dict", "on", "all", "ranks"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 173, "end_line": 189, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_211", "original_string": "def optimizer_step(\r\n        self,\r\n        optimizer: Optimizer,\r\n        closure: Callable[[], Any],\r\n        model: Optional[Union[\"pl.LightningModule\", Module]] = None,\r\n        **kwargs: Any,\r\n    ) -> Any:\r\n        r\"\"\"Performs the actual optimizer step.\r\n\r\n        Args:\r\n            optimizer: the optimizer performing the step\r\n            closure: closure calculating the loss value\r\n            model: reference to the model, optionally defining optimizer step related hooks\r\n            \\**kwargs: Keyword arguments to ``optimizer.step``\r\n\r\n        \"\"\"\r\n        model = model or self.lightning_module\r\n        assert isinstance(model, pl.LightningModule)\r\n        return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)", "language": "python", "code": "def optimizer_step(\r\n        self,\r\n        optimizer: Optimizer,\r\n        closure: Callable[[], Any],\r\n        model: Optional[Union[\"pl.LightningModule\", Module]] = None,\r\n        **kwargs: Any,\r\n    ) -> Any:\r\n        r\"\"\"Performs the actual optimizer step.\r\n\r\n        Args:\r\n            optimizer: the optimizer performing the step\r\n            closure: closure calculating the loss value\r\n            model: reference to the model, optionally defining optimizer step related hooks\r\n            \\**kwargs: Keyword arguments to ``optimizer.step``\r\n\r\n        \"\"\"\r\n        model = model or self.lightning_module\r\n        assert isinstance(model, pl.LightningModule)\r\n        return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)", "code_tokens": ["def", "optimizer_step", "(", "self", ",", "optimizer", ":", "Optimizer", ",", "closure", ":", "Callable", "[", "[", "]", ",", "Any", "]", ",", "model", ":", "Optional", "[", "Union", "[", "STRING", ",", "Module", "]", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ",", ")", "-", ">", "Any", ":", "rSTRING", "model", "=", "model", "or", "self", ".", "lightning_module", "assert", "isinstance", "(", "model", ",", "pl", ".", "LightningModule", ")", "return", "self", ".", "precision_plugin", ".", "optimizer_step", "(", "optimizer", ",", "model", "=", "model", ",", "closure", "=", "closure", ",", "*", "*", "kwargs", ")"], "docstring": "TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed", "docstring_tokens": ["todo", "fabric", "remove", "assertion", "once", "strategy", "s", "optimizer_step", "typing", "is", "fixed"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 219, "end_line": 238, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_212", "original_string": "def _setup_model_and_optimizers(self, model: Module, optimizers: list[Optimizer]) -> tuple[Module, list[Optimizer]]:\r\n        \"\"\"Setup a model and multiple optimizers together.\r\n\r\n        The returned objects are expected to be in the same order they were passed in. The default implementation will\r\n        call :meth:`_setup_model` and :meth:`_setup_optimizer` on the inputs.\r\n\r\n        \"\"\"\r\n        model = self._setup_model(model)\r\n        optimizers = [self._setup_optimizer(optimizer) for optimizer in optimizers]\r\n        return model, optimizers", "language": "python", "code": "def _setup_model_and_optimizers(self, model: Module, optimizers: list[Optimizer]) -> tuple[Module, list[Optimizer]]:\r\n        \"\"\"Setup a model and multiple optimizers together.\r\n\r\n        The returned objects are expected to be in the same order they were passed in. The default implementation will\r\n        call :meth:`_setup_model` and :meth:`_setup_optimizer` on the inputs.\r\n\r\n        \"\"\"\r\n        model = self._setup_model(model)\r\n        optimizers = [self._setup_optimizer(optimizer) for optimizer in optimizers]\r\n        return model, optimizers", "code_tokens": ["def", "_setup_model_and_optimizers", "(", "self", ",", "model", ":", "Module", ",", "optimizers", ":", "list", "[", "Optimizer", "]", ")", "-", ">", "tuple", "[", "Module", ",", "list", "[", "Optimizer", "]", "]", ":", "STRING", "model", "=", "self", ".", "_setup_model", "(", "model", ")", "optimizers", "=", "[", "self", ".", "_setup_optimizer", "(", "optimizer", ")", "for", "optimizer", "in", "optimizers", "]", "return", "model", ",", "optimizers"], "docstring": "TODO: standardize this across all plugins in Lightning and Fabric. Related refactor: #7324", "docstring_tokens": ["todo", "standardize", "this", "across", "all", "plugins", "in", "lightning", "and", "fabric", "related", "refactor", "7324"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 240, "end_line": 250, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_213", "original_string": "def _setup_model(self, model: Module) -> Module:\r\n        \"\"\"Performs setup for the model, e.g., by wrapping it by another class.\"\"\"\r\n        return model", "language": "python", "code": "def _setup_model(self, model: Module) -> Module:\r\n        \"\"\"Performs setup for the model, e.g., by wrapping it by another class.\"\"\"\r\n        return model", "code_tokens": ["def", "_setup_model", "(", "self", ",", "model", ":", "Module", ")", "-", ">", "Module", ":", "STRING", "return", "model"], "docstring": "TODO: standardize this across all plugins in Lightning and Fabric. Related refactor: #7324", "docstring_tokens": ["todo", "standardize", "this", "across", "all", "plugins", "in", "lightning", "and", "fabric", "related", "refactor", "7324"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 252, "end_line": 255, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_214", "original_string": "def _setup_optimizer(self, optimizer: Optimizer) -> Optimizer:\r\n        \"\"\"Performs setup for the optimizer, e.g., by wrapping it by another class.\"\"\"\r\n        return optimizer", "language": "python", "code": "def _setup_optimizer(self, optimizer: Optimizer) -> Optimizer:\r\n        \"\"\"Performs setup for the optimizer, e.g., by wrapping it by another class.\"\"\"\r\n        return optimizer", "code_tokens": ["def", "_setup_optimizer", "(", "self", ",", "optimizer", ":", "Optimizer", ")", "-", ">", "Optimizer", ":", "STRING", "return", "optimizer"], "docstring": "TODO: standardize this across all plugins in Lightning and Fabric. Related refactor: #7324", "docstring_tokens": ["todo", "standardize", "this", "across", "all", "plugins", "in", "lightning", "and", "fabric", "related", "refactor", "7324"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 257, "end_line": 260, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\strategy.py", "func_name": "function_215", "original_string": "def __call__(\r\n        self, wrapper_module: Module, original_module: \"pl.LightningModule\", method_name: str, *args: Any, **kwargs: Any\r\n    ) -> STEP_OUTPUT:\r\n        \"\"\"Reroutes a method call through the `wrapper_module`'s `forward` method.\r\n\r\n        Args:\r\n            wrapper_module: The module that has `original_module` wrapped.\r\n            original_module: The module that was wrapped inside `wrapper_module`.\r\n            method_name: The name of the method that should be called on the `original_module` after inputs get\r\n                redirected through the `wrapper_module`'s `forward` method.\r\n            *args: The positional arguments to the method `method_name`. They will get passed to a patched\r\n                `forward` method instead.\r\n            **kwargs: The keyword arguments to the method `method_name`. They will get passed to a patched\r\n                `forward` method instead.\r\n\r\n        \"\"\"\r\n        assert method_name != \"forward\"\r\n        original_forward = original_module.forward\r\n\r\n        def wrapped_forward(*_args: Any, **_kwargs: Any) -> Any:\r\n            original_module.forward = original_forward  # type: ignore[method-assign]\r\n            method = getattr(original_module, method_name)\r\n            out = method(*_args, **_kwargs)\r\n            self.on_after_inner_forward(wrapper_module, original_module)\r\n            return out\r\n\r\n        original_module.forward = wrapped_forward  # type: ignore[method-assign]\r\n\r\n        wrapper_output = wrapper_module(*args, **kwargs)\r\n        self.on_after_outer_forward(wrapper_module, original_module)\r\n        return wrapper_output", "language": "python", "code": "def __call__(\r\n        self, wrapper_module: Module, original_module: \"pl.LightningModule\", method_name: str, *args: Any, **kwargs: Any\r\n    ) -> STEP_OUTPUT:\r\n        \"\"\"Reroutes a method call through the `wrapper_module`'s `forward` method.\r\n\r\n        Args:\r\n            wrapper_module: The module that has `original_module` wrapped.\r\n            original_module: The module that was wrapped inside `wrapper_module`.\r\n            method_name: The name of the method that should be called on the `original_module` after inputs get\r\n                redirected through the `wrapper_module`'s `forward` method.\r\n            *args: The positional arguments to the method `method_name`. They will get passed to a patched\r\n                `forward` method instead.\r\n            **kwargs: The keyword arguments to the method `method_name`. They will get passed to a patched\r\n                `forward` method instead.\r\n\r\n        \"\"\"\r\n        assert method_name != \"forward\"\r\n        original_forward = original_module.forward\r\n\r\n        def wrapped_forward(*_args: Any, **_kwargs: Any) -> Any:\r\n            original_module.forward = original_forward  # type: ignore[method-assign]\r\n            method = getattr(original_module, method_name)\r\n            out = method(*_args, **_kwargs)\r\n            self.on_after_inner_forward(wrapper_module, original_module)\r\n            return out\r\n\r\n        original_module.forward = wrapped_forward  # type: ignore[method-assign]\r\n\r\n        wrapper_output = wrapper_module(*args, **kwargs)\r\n        self.on_after_outer_forward(wrapper_module, original_module)\r\n        return wrapper_output", "code_tokens": ["def", "__call__", "(", "self", ",", "wrapper_module", ":", "Module", ",", "original_module", ":", "STRING", ",", "method_name", ":", "str", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "STEP_OUTPUT", ":", "STRING", "assert", "method_name", "!", "=", "STRING", "original_forward", "=", "original_module", ".", "forward", "def", "wrapped_forward", "(", "*", "_args", ":", "Any", ",", "*", "*", "_kwargs", ":", "Any", ")", "-", ">", "Any", ":", "original_module", ".", "forward", "=", "original_forward", "#", "type", ":", "ignore", "[", "method", "-", "assign", "]", "method", "=", "getattr", "(", "original_module", ",", "method_name", ")", "out", "=", "method", "(", "*", "_args", ",", "*", "*", "_kwargs", ")", "self", ".", "on_after_inner_forward", "(", "wrapper_module", ",", "original_module", ")", "return", "out", "original_module", ".", "forward", "=", "wrapped_forward", "#", "type", ":", "ignore", "[", "method", "-", "assign", "]", "wrapper_output", "=", "wrapper_module", "(", "*", "args", ",", "*", "*", "kwargs", ")", "self", ".", "on_after_outer_forward", "(", "wrapper_module", ",", "original_module", ")", "return", "wrapper_output"], "docstring": "Unpatch ourselves immediately before calling the method `method_name` because itself may want to call the real `forward` Call the actual method e.g. `.training_step(...)` Patch the original_module's forward so we can redirect the arguments back to the real method", "docstring_tokens": ["unpatch", "ourselves", "immediately", "before", "calling", "the", "method", "method_name", "because", "itself", "may", "want", "to", "call", "the", "real", "forward", "call", "the", "actual", "method", "e", "g", "training_step", "patch", "the", "original_module", "s", "forward", "so", "we", "can", "redirect", "the", "arguments", "back", "to", "the", "real", "method"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\strategy.py", "start_line": 608, "end_line": 642, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "func_name": "function_216", "original_string": "def launch(self, function: Callable, *args: Any, trainer: Optional[\"pl.Trainer\"] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            trainer: Optional reference to the :class:`~lightning.pytorch.trainer.trainer.Trainer` for which\r\n                a selected set of attributes get restored in the main process after processes join.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._start_method in (\"fork\", \"forkserver\"):\r\n            _check_bad_cuda_fork()\r\n        if self._start_method == \"spawn\":\r\n            _check_missing_main_guard()\r\n        if self._already_fit and trainer is not None and trainer.state.fn == TrainerFn.FITTING:\r\n            raise NotImplementedError(\r\n                \"Calling `trainer.fit()` twice on the same Trainer instance using a spawn-based strategy is not\"\r\n                \" supported. You can work around this limitation by creating a new Trainer instance and passing the\"\r\n                \" `fit(ckpt_path=...)` argument.\"\r\n            )\r\n\r\n        assert self._strategy.cluster_environment is not None\r\n        os.environ[\"MASTER_PORT\"] = str(self._strategy.cluster_environment.main_port)\r\n\r\n        context = mp.get_context(self._start_method)\r\n        return_queue = context.SimpleQueue()\r\n\r\n        if self._start_method == \"spawn\":\r\n            global_states = _GlobalStateSnapshot.capture()\r\n            process_args = [trainer, function, args, kwargs, return_queue, global_states]\r\n        else:\r\n            process_args = [trainer, function, args, kwargs, return_queue]\r\n\r\n        process_context = mp.start_processes(\r\n            self._wrapping_function,\r\n            args=process_args,\r\n            nprocs=self._strategy.num_processes,\r\n            start_method=self._start_method,\r\n            join=False,  # we will join ourselves to get the process references\r\n        )\r\n        self.procs = process_context.processes\r\n        while not process_context.join():\r\n            pass\r\n\r\n        worker_output = return_queue.get()\r\n        if trainer is None:\r\n            return worker_output\r\n\r\n        self._already_fit |= trainer.state.fn == TrainerFn.FITTING\r\n        self._recover_results_in_main_process(worker_output, trainer)\r\n        return worker_output.trainer_results", "language": "python", "code": "def launch(self, function: Callable, *args: Any, trainer: Optional[\"pl.Trainer\"] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            trainer: Optional reference to the :class:`~lightning.pytorch.trainer.trainer.Trainer` for which\r\n                a selected set of attributes get restored in the main process after processes join.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._start_method in (\"fork\", \"forkserver\"):\r\n            _check_bad_cuda_fork()\r\n        if self._start_method == \"spawn\":\r\n            _check_missing_main_guard()\r\n        if self._already_fit and trainer is not None and trainer.state.fn == TrainerFn.FITTING:\r\n            raise NotImplementedError(\r\n                \"Calling `trainer.fit()` twice on the same Trainer instance using a spawn-based strategy is not\"\r\n                \" supported. You can work around this limitation by creating a new Trainer instance and passing the\"\r\n                \" `fit(ckpt_path=...)` argument.\"\r\n            )\r\n\r\n        assert self._strategy.cluster_environment is not None\r\n        os.environ[\"MASTER_PORT\"] = str(self._strategy.cluster_environment.main_port)\r\n\r\n        context = mp.get_context(self._start_method)\r\n        return_queue = context.SimpleQueue()\r\n\r\n        if self._start_method == \"spawn\":\r\n            global_states = _GlobalStateSnapshot.capture()\r\n            process_args = [trainer, function, args, kwargs, return_queue, global_states]\r\n        else:\r\n            process_args = [trainer, function, args, kwargs, return_queue]\r\n\r\n        process_context = mp.start_processes(\r\n            self._wrapping_function,\r\n            args=process_args,\r\n            nprocs=self._strategy.num_processes,\r\n            start_method=self._start_method,\r\n            join=False,  # we will join ourselves to get the process references\r\n        )\r\n        self.procs = process_context.processes\r\n        while not process_context.join():\r\n            pass\r\n\r\n        worker_output = return_queue.get()\r\n        if trainer is None:\r\n            return worker_output\r\n\r\n        self._already_fit |= trainer.state.fn == TrainerFn.FITTING\r\n        self._recover_results_in_main_process(worker_output, trainer)\r\n        return worker_output.trainer_results", "code_tokens": ["def", "launch", "(", "self", ",", "function", ":", "Callable", ",", "*", "args", ":", "Any", ",", "trainer", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "if", "self", ".", "_start_method", "in", "(", "STRING", ",", "STRING", ")", ":", "_check_bad_cuda_fork", "(", ")", "if", "self", ".", "_start_method", "=", "=", "STRING", ":", "_check_missing_main_guard", "(", ")", "if", "self", ".", "_already_fit", "and", "trainer", "is", "not", "None", "and", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "raise", "NotImplementedError", "(", "STRING", "STRING", "STRING", ")", "assert", "self", ".", "_strategy", ".", "cluster_environment", "is", "not", "None", "os", ".", "environ", "[", "STRING", "]", "=", "str", "(", "self", ".", "_strategy", ".", "cluster_environment", ".", "main_port", ")", "context", "=", "mp", ".", "get_context", "(", "self", ".", "_start_method", ")", "return_queue", "=", "context", ".", "SimpleQueue", "(", ")", "if", "self", ".", "_start_method", "=", "=", "STRING", ":", "global_states", "=", "_GlobalStateSnapshot", ".", "capture", "(", ")", "process_args", "=", "[", "trainer", ",", "function", ",", "args", ",", "kwargs", ",", "return_queue", ",", "global_states", "]", "else", ":", "process_args", "=", "[", "trainer", ",", "function", ",", "args", ",", "kwargs", ",", "return_queue", "]", "process_context", "=", "mp", ".", "start_processes", "(", "self", ".", "_wrapping_function", ",", "args", "=", "process_args", ",", "nprocs", "=", "self", ".", "_strategy", ".", "num_processes", ",", "start_method", "=", "self", ".", "_start_method", ",", "join", "=", "False", ",", "#", "we", "will", "join", "ourselves", "to", "get", "the", "process", "references", ")", "self", ".", "procs", "=", "process_context", ".", "processes", "while", "not", "process_context", ".", "join", "(", ")", ":", "pass", "worker_output", "=", "return_queue", ".", "get", "(", ")", "if", "trainer", "is", "None", ":", "return", "worker_output", "self", ".", "_already_fit", "|", "=", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", "self", ".", "_recover_results_in_main_process", "(", "worker_output", ",", "trainer", ")", "return", "worker_output", ".", "trainer_results"], "docstring": "resolving https://github.com/Lightning-AI/pytorch-lightning/issues/18775 will lift this restriction The default cluster environment in Lightning chooses a random free port number This needs to be done in the main process here before starting processes to ensure each rank will connect through the same port", "docstring_tokens": ["resolving", "https", "github", "com", "lightning", "ai", "pytorch", "lightning", "issues", "18775", "will", "lift", "this", "restriction", "the", "default", "cluster", "environment", "in", "lightning", "chooses", "a", "random", "free", "port", "number", "this", "needs", "to", "be", "done", "in", "the", "main", "process", "here", "before", "starting", "processes", "to", "ensure", "each", "rank", "will", "connect", "through", "the", "same", "port"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "start_line": 94, "end_line": 152, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "func_name": "function_217", "original_string": "def get_extra_results(self, trainer: \"pl.Trainer\") -> dict[str, Any]:\r\n        \"\"\"Gather extra state from the Trainer and return it as a dictionary for sending back to the main process. To\r\n        avoid issues with memory sharing, we convert tensors to bytes.\r\n\r\n        Args:\r\n            trainer: reference to the Trainer.\r\n\r\n        Returns:\r\n            A dictionary with items to send back to the main process where :meth:`update_main_process_results` will\r\n            process this output.\r\n\r\n        \"\"\"\r\n        callback_metrics = apply_to_collection(trainer.callback_metrics, Tensor, lambda t: t.cpu())\r\n        buffer = io.BytesIO()\r\n        torch.save(callback_metrics, buffer)\r\n        return {\"callback_metrics_bytes\": buffer.getvalue()}", "language": "python", "code": "def get_extra_results(self, trainer: \"pl.Trainer\") -> dict[str, Any]:\r\n        \"\"\"Gather extra state from the Trainer and return it as a dictionary for sending back to the main process. To\r\n        avoid issues with memory sharing, we convert tensors to bytes.\r\n\r\n        Args:\r\n            trainer: reference to the Trainer.\r\n\r\n        Returns:\r\n            A dictionary with items to send back to the main process where :meth:`update_main_process_results` will\r\n            process this output.\r\n\r\n        \"\"\"\r\n        callback_metrics = apply_to_collection(trainer.callback_metrics, Tensor, lambda t: t.cpu())\r\n        buffer = io.BytesIO()\r\n        torch.save(callback_metrics, buffer)\r\n        return {\"callback_metrics_bytes\": buffer.getvalue()}", "code_tokens": ["def", "get_extra_results", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "callback_metrics", "=", "apply_to_collection", "(", "trainer", ".", "callback_metrics", ",", "Tensor", ",", "lambda", "t", ":", "t", ".", "cpu", "(", ")", ")", "buffer", "=", "io", ".", "BytesIO", "(", ")", "torch", ".", "save", "(", "callback_metrics", ",", "buffer", ")", "return", "{", "STRING", ":", "buffer", ".", "getvalue", "(", ")", "}"], "docstring": "send tensors as bytes to avoid issues with memory sharing", "docstring_tokens": ["send", "tensors", "as", "bytes", "to", "avoid", "issues", "with", "memory", "sharing"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "start_line": 226, "end_line": 242, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "func_name": "function_218", "original_string": "def update_main_process_results(self, trainer: \"pl.Trainer\", extra: dict[str, Any]) -> None:\r\n        \"\"\"Retrieve the :attr:`trainer.callback_metrics` dictionary from the given queue. To preserve consistency, we\r\n        convert bytes back to ``torch.Tensor``.\r\n\r\n        Args:\r\n            trainer: reference to the Trainer.\r\n            extra: A dictionary with trainer state that was sent from the worker process and needs to be restored\r\n                on the current trainer.\r\n\r\n        \"\"\"\r\n        callback_metrics_bytes = extra[\"callback_metrics_bytes\"]\r\n        callback_metrics = torch.load(io.BytesIO(callback_metrics_bytes), weights_only=True)\r\n        trainer.callback_metrics.update(callback_metrics)", "language": "python", "code": "def update_main_process_results(self, trainer: \"pl.Trainer\", extra: dict[str, Any]) -> None:\r\n        \"\"\"Retrieve the :attr:`trainer.callback_metrics` dictionary from the given queue. To preserve consistency, we\r\n        convert bytes back to ``torch.Tensor``.\r\n\r\n        Args:\r\n            trainer: reference to the Trainer.\r\n            extra: A dictionary with trainer state that was sent from the worker process and needs to be restored\r\n                on the current trainer.\r\n\r\n        \"\"\"\r\n        callback_metrics_bytes = extra[\"callback_metrics_bytes\"]\r\n        callback_metrics = torch.load(io.BytesIO(callback_metrics_bytes), weights_only=True)\r\n        trainer.callback_metrics.update(callback_metrics)", "code_tokens": ["def", "update_main_process_results", "(", "self", ",", "trainer", ":", "STRING", ",", "extra", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "STRING", "callback_metrics_bytes", "=", "extra", "[", "STRING", "]", "callback_metrics", "=", "torch", ".", "load", "(", "io", ".", "BytesIO", "(", "callback_metrics_bytes", ")", ",", "weights_only", "=", "True", ")", "trainer", ".", "callback_metrics", ".", "update", "(", "callback_metrics", ")"], "docstring": "NOTE: `get_extra_results` needs to be called before", "docstring_tokens": ["note", "get_extra_results", "needs", "to", "be", "called", "before"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\launchers\\multiprocessing.py", "start_line": 244, "end_line": 257, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\strategies\\launchers\\xla.py", "func_name": "function_219", "original_string": "def launch(self, function: Callable, *args: Any, trainer: Optional[\"pl.Trainer\"] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            trainer: Optional reference to the :class:`~lightning.pytorch.trainer.trainer.Trainer` for which\r\n                a selected set of attributes get restored in the main process after processes join.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._already_fit and trainer is not None and trainer.state.fn == TrainerFn.FITTING:\r\n            raise NotImplementedError(\r\n                \"Calling `trainer.fit()` twice on the same Trainer instance using a spawn-based strategy is not\"\r\n                \" supported. You can work around this by creating a new Trainer instance and passing the\"\r\n                \" `fit(ckpt_path=...)` argument.\"\r\n            )\r\n\r\n        return_queue = mp.Manager().Queue()\r\n\r\n        import torch_xla.distributed.xla_multiprocessing as xmp\r\n\r\n        spawn_kwargs = {}\r\n        nprocs = self._strategy.num_processes\r\n        if nprocs == 1:\r\n            spawn_kwargs[\"nprocs\"] = nprocs\r\n\r\n        process_context = xmp.spawn(\r\n            self._wrapping_function,\r\n            args=(trainer, function, args, kwargs, return_queue),\r\n            start_method=self._start_method,\r\n            join=False,  # we will join ourselves to get the process references\r\n            **spawn_kwargs,\r\n        )\r\n        if process_context is not None:\r\n            self.procs = process_context.processes\r\n            while not process_context.join():\r\n                pass\r\n\r\n        worker_output = return_queue.get()\r\n        if trainer is None:\r\n            return worker_output\r\n\r\n        self._already_fit |= trainer.state.fn == TrainerFn.FITTING\r\n        self._recover_results_in_main_process(worker_output, trainer)\r\n        return worker_output.trainer_results", "language": "python", "code": "def launch(self, function: Callable, *args: Any, trainer: Optional[\"pl.Trainer\"] = None, **kwargs: Any) -> Any:\r\n        \"\"\"Launches processes that run the given function in parallel.\r\n\r\n        The function is allowed to have a return value. However, when all processes join, only the return value\r\n        of worker process 0 gets returned from this `launch` method in the main process.\r\n\r\n        Arguments:\r\n            function: The entry point for all launched processes.\r\n            *args: Optional positional arguments to be passed to the given function.\r\n            trainer: Optional reference to the :class:`~lightning.pytorch.trainer.trainer.Trainer` for which\r\n                a selected set of attributes get restored in the main process after processes join.\r\n            **kwargs: Optional keyword arguments to be passed to the given function.\r\n\r\n        \"\"\"\r\n        if self._already_fit and trainer is not None and trainer.state.fn == TrainerFn.FITTING:\r\n            raise NotImplementedError(\r\n                \"Calling `trainer.fit()` twice on the same Trainer instance using a spawn-based strategy is not\"\r\n                \" supported. You can work around this by creating a new Trainer instance and passing the\"\r\n                \" `fit(ckpt_path=...)` argument.\"\r\n            )\r\n\r\n        return_queue = mp.Manager().Queue()\r\n\r\n        import torch_xla.distributed.xla_multiprocessing as xmp\r\n\r\n        spawn_kwargs = {}\r\n        nprocs = self._strategy.num_processes\r\n        if nprocs == 1:\r\n            spawn_kwargs[\"nprocs\"] = nprocs\r\n\r\n        process_context = xmp.spawn(\r\n            self._wrapping_function,\r\n            args=(trainer, function, args, kwargs, return_queue),\r\n            start_method=self._start_method,\r\n            join=False,  # we will join ourselves to get the process references\r\n            **spawn_kwargs,\r\n        )\r\n        if process_context is not None:\r\n            self.procs = process_context.processes\r\n            while not process_context.join():\r\n                pass\r\n\r\n        worker_output = return_queue.get()\r\n        if trainer is None:\r\n            return worker_output\r\n\r\n        self._already_fit |= trainer.state.fn == TrainerFn.FITTING\r\n        self._recover_results_in_main_process(worker_output, trainer)\r\n        return worker_output.trainer_results", "code_tokens": ["def", "launch", "(", "self", ",", "function", ":", "Callable", ",", "*", "args", ":", "Any", ",", "trainer", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "STRING", "if", "self", ".", "_already_fit", "and", "trainer", "is", "not", "None", "and", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "raise", "NotImplementedError", "(", "STRING", "STRING", "STRING", ")", "return_queue", "=", "mp", ".", "Manager", "(", ")", ".", "Queue", "(", ")", "import", "torch_xla", ".", "distributed", ".", "xla_multiprocessing", "as", "xmp", "spawn_kwargs", "=", "{", "}", "nprocs", "=", "self", ".", "_strategy", ".", "num_processes", "if", "nprocs", "=", "=", "1", ":", "spawn_kwargs", "[", "STRING", "]", "=", "nprocs", "process_context", "=", "xmp", ".", "spawn", "(", "self", ".", "_wrapping_function", ",", "args", "=", "(", "trainer", ",", "function", ",", "args", ",", "kwargs", ",", "return_queue", ")", ",", "start_method", "=", "self", ".", "_start_method", ",", "join", "=", "False", ",", "#", "we", "will", "join", "ourselves", "to", "get", "the", "process", "references", "*", "*", "spawn_kwargs", ",", ")", "if", "process_context", "is", "not", "None", ":", "self", ".", "procs", "=", "process_context", ".", "processes", "while", "not", "process_context", ".", "join", "(", ")", ":", "pass", "worker_output", "=", "return_queue", ".", "get", "(", ")", "if", "trainer", "is", "None", ":", "return", "worker_output", "self", ".", "_already_fit", "|", "=", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", "self", ".", "_recover_results_in_main_process", "(", "worker_output", ",", "trainer", ")", "return", "worker_output", ".", "trainer_results"], "docstring": "resolving https://github.com/Lightning-AI/pytorch-lightning/issues/18775 will lift this restriction pjrt requires that the queue is serializable avoid warning: \"Unsupported nprocs\". If it's 1, it will call the launched function directly. otherwise it will use all devices xla will not actually create processes if only 1 device", "docstring_tokens": ["resolving", "https", "github", "com", "lightning", "ai", "pytorch", "lightning", "issues", "18775", "will", "lift", "this", "restriction", "pjrt", "requires", "that", "the", "queue", "is", "serializable", "avoid", "warning", "unsupported", "nprocs", "if", "it", "s", "1", "it", "will", "call", "the", "launched", "function", "directly", "otherwise", "it", "will", "use", "all", "devices", "xla", "will", "not", "actually", "create", "processes", "if", "only", "1", "device"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\strategies\\launchers\\xla.py", "start_line": 63, "end_line": 116, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\call.py", "func_name": "function_220", "original_string": "def _call_and_handle_interrupt(trainer: \"pl.Trainer\", trainer_fn: Callable, *args: Any, **kwargs: Any) -> Any:\r\n    r\"\"\"Error handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\r\n    as all errors should funnel through them.\r\n\r\n    Args:\r\n        trainer_fn: one of (fit, validate, test, predict)\r\n        *args: positional arguments to be passed to the `trainer_fn`\r\n        **kwargs: keyword arguments to be passed to `trainer_fn`\r\n\r\n    \"\"\"\r\n    try:\r\n        if trainer.strategy.launcher is not None:\r\n            return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\r\n        return trainer_fn(*args, **kwargs)\r\n\r\n    except _TunerExitException:\r\n        _call_teardown_hook(trainer)\r\n        trainer._teardown()\r\n        trainer.state.status = TrainerStatus.FINISHED\r\n        trainer.state.stage = None\r\n\r\n    except KeyboardInterrupt as exception:\r\n        rank_zero_info(\"\\nDetected KeyboardInterrupt, attempting graceful shutdown ...\")\r\n        signal.signal(signal.SIGINT, signal.SIG_IGN)\r\n        _interrupt(trainer, exception)\r\n        trainer._teardown()\r\n        launcher = trainer.strategy.launcher\r\n        if isinstance(launcher, _SubprocessScriptLauncher):\r\n            launcher.kill(_get_sigkill_signal())\r\n        sys.exit(1)\r\n\r\n    except BaseException as exception:\r\n        _interrupt(trainer, exception)\r\n        trainer._teardown()\r\n        trainer.state.stage = None\r\n        raise", "language": "python", "code": "def _call_and_handle_interrupt(trainer: \"pl.Trainer\", trainer_fn: Callable, *args: Any, **kwargs: Any) -> Any:\r\n    r\"\"\"Error handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\r\n    as all errors should funnel through them.\r\n\r\n    Args:\r\n        trainer_fn: one of (fit, validate, test, predict)\r\n        *args: positional arguments to be passed to the `trainer_fn`\r\n        **kwargs: keyword arguments to be passed to `trainer_fn`\r\n\r\n    \"\"\"\r\n    try:\r\n        if trainer.strategy.launcher is not None:\r\n            return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\r\n        return trainer_fn(*args, **kwargs)\r\n\r\n    except _TunerExitException:\r\n        _call_teardown_hook(trainer)\r\n        trainer._teardown()\r\n        trainer.state.status = TrainerStatus.FINISHED\r\n        trainer.state.stage = None\r\n\r\n    except KeyboardInterrupt as exception:\r\n        rank_zero_info(\"\\nDetected KeyboardInterrupt, attempting graceful shutdown ...\")\r\n        signal.signal(signal.SIGINT, signal.SIG_IGN)\r\n        _interrupt(trainer, exception)\r\n        trainer._teardown()\r\n        launcher = trainer.strategy.launcher\r\n        if isinstance(launcher, _SubprocessScriptLauncher):\r\n            launcher.kill(_get_sigkill_signal())\r\n        sys.exit(1)\r\n\r\n    except BaseException as exception:\r\n        _interrupt(trainer, exception)\r\n        trainer._teardown()\r\n        trainer.state.stage = None\r\n        raise", "code_tokens": ["def", "_call_and_handle_interrupt", "(", "trainer", ":", "STRING", ",", "trainer_fn", ":", "Callable", ",", "*", "args", ":", "Any", ",", "*", "*", "kwargs", ":", "Any", ")", "-", ">", "Any", ":", "rSTRING", "try", ":", "if", "trainer", ".", "strategy", ".", "launcher", "is", "not", "None", ":", "return", "trainer", ".", "strategy", ".", "launcher", ".", "launch", "(", "trainer_fn", ",", "*", "args", ",", "trainer", "=", "trainer", ",", "*", "*", "kwargs", ")", "return", "trainer_fn", "(", "*", "args", ",", "*", "*", "kwargs", ")", "except", "_TunerExitException", ":", "_call_teardown_hook", "(", "trainer", ")", "trainer", ".", "_teardown", "(", ")", "trainer", ".", "state", ".", "status", "=", "TrainerStatus", ".", "FINISHED", "trainer", ".", "state", ".", "stage", "=", "None", "except", "KeyboardInterrupt", "as", "exception", ":", "rank_zero_info", "(", "STRING", ")", "signal", ".", "signal", "(", "signal", ".", "SIGINT", ",", "signal", ".", "SIG_IGN", ")", "_interrupt", "(", "trainer", ",", "exception", ")", "trainer", ".", "_teardown", "(", ")", "launcher", "=", "trainer", ".", "strategy", ".", "launcher", "if", "isinstance", "(", "launcher", ",", "_SubprocessScriptLauncher", ")", ":", "launcher", ".", "kill", "(", "_get_sigkill_signal", "(", ")", ")", "sys", ".", "exit", "(", "1", ")", "except", "BaseException", "as", "exception", ":", "_interrupt", "(", "trainer", ",", "exception", ")", "trainer", ".", "_teardown", "(", ")", "trainer", ".", "state", ".", "stage", "=", "None", "raise"], "docstring": "user could press Ctrl+C many times, disable KeyboardInterrupt for shutdown teardown might access the stage so we reset it after", "docstring_tokens": ["user", "could", "press", "ctrl", "c", "many", "times", "disable", "keyboardinterrupt", "for", "shutdown", "teardown", "might", "access", "the", "stage", "so", "we", "reset", "it", "after"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\call.py", "start_line": 35, "end_line": 72, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\call.py", "func_name": "function_221", "original_string": "def _call_callbacks_on_save_checkpoint(trainer: \"pl.Trainer\", checkpoint: dict[str, Any]) -> None:\r\n    \"\"\"Called when saving a model checkpoint, calls every callback's `on_save_checkpoint` hook.\"\"\"\r\n    pl_module = trainer.lightning_module\r\n    if pl_module:\r\n        prev_fx_name = pl_module._current_fx_name\r\n        pl_module._current_fx_name = \"on_save_checkpoint\"\r\n\r\n    for callback in trainer.callbacks:\r\n        with trainer.profiler.profile(f\"[Callback]{callback.state_key}.on_save_checkpoint\"):\r\n            callback.on_save_checkpoint(trainer, trainer.lightning_module, checkpoint)\r\n\r\n    if pl_module:\r\n        pl_module._current_fx_name = prev_fx_name", "language": "python", "code": "def _call_callbacks_on_save_checkpoint(trainer: \"pl.Trainer\", checkpoint: dict[str, Any]) -> None:\r\n    \"\"\"Called when saving a model checkpoint, calls every callback's `on_save_checkpoint` hook.\"\"\"\r\n    pl_module = trainer.lightning_module\r\n    if pl_module:\r\n        prev_fx_name = pl_module._current_fx_name\r\n        pl_module._current_fx_name = \"on_save_checkpoint\"\r\n\r\n    for callback in trainer.callbacks:\r\n        with trainer.profiler.profile(f\"[Callback]{callback.state_key}.on_save_checkpoint\"):\r\n            callback.on_save_checkpoint(trainer, trainer.lightning_module, checkpoint)\r\n\r\n    if pl_module:\r\n        pl_module._current_fx_name = prev_fx_name", "code_tokens": ["def", "_call_callbacks_on_save_checkpoint", "(", "trainer", ":", "STRING", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "STRING", "pl_module", "=", "trainer", ".", "lightning_module", "if", "pl_module", ":", "prev_fx_name", "=", "pl_module", ".", "_current_fx_name", "pl_module", ".", "_current_fx_name", "=", "STRING", "for", "callback", "in", "trainer", ".", "callbacks", ":", "with", "trainer", ".", "profiler", ".", "profile", "(", "fSTRING", ")", ":", "callback", ".", "on_save_checkpoint", "(", "trainer", ",", "trainer", ".", "lightning_module", ",", "checkpoint", ")", "if", "pl_module", ":", "pl_module", ".", "_current_fx_name", "=", "prev_fx_name"], "docstring": "restore current_fx when nested context", "docstring_tokens": ["restore", "current_fx", "when", "nested", "context"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\call.py", "start_line": 245, "end_line": 258, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\call.py", "func_name": "function_222", "original_string": "def _call_callbacks_on_load_checkpoint(trainer: \"pl.Trainer\", checkpoint: dict[str, Any]) -> None:\r\n    \"\"\"Called when loading a model checkpoint.\r\n\r\n    Calls every callback's `on_load_checkpoint` hook. We have a dedicated function for this rather than using\r\n    `_call_callback_hooks` because we have special logic for getting callback_states.\r\n\r\n    \"\"\"\r\n    pl_module = trainer.lightning_module\r\n    if pl_module:\r\n        prev_fx_name = pl_module._current_fx_name\r\n        pl_module._current_fx_name = \"on_load_checkpoint\"\r\n\r\n    callback_states: Optional[dict[Union[type, str], dict]] = checkpoint.get(\"callbacks\")\r\n\r\n    if callback_states is None:\r\n        return\r\n\r\n    is_legacy_ckpt = Version(checkpoint[\"pytorch-lightning_version\"]) < Version(\"1.5.0dev\")\r\n    current_callbacks_keys = {cb._legacy_state_key if is_legacy_ckpt else cb.state_key for cb in trainer.callbacks}\r\n    difference = callback_states.keys() - current_callbacks_keys\r\n    if difference:\r\n        rank_zero_warn(\r\n            \"Be aware that when using `ckpt_path`,\"\r\n            \" callbacks used to create the checkpoint need to be provided during `Trainer` instantiation.\"\r\n            f\" Please add the following callbacks: {list(difference)}.\",\r\n        )\r\n\r\n    for callback in trainer.callbacks:\r\n        with trainer.profiler.profile(f\"[Callback]{callback.state_key}.on_load_checkpoint\"):\r\n            callback.on_load_checkpoint(trainer, trainer.lightning_module, checkpoint)\r\n\r\n    if pl_module:\r\n        pl_module._current_fx_name = prev_fx_name", "language": "python", "code": "def _call_callbacks_on_load_checkpoint(trainer: \"pl.Trainer\", checkpoint: dict[str, Any]) -> None:\r\n    \"\"\"Called when loading a model checkpoint.\r\n\r\n    Calls every callback's `on_load_checkpoint` hook. We have a dedicated function for this rather than using\r\n    `_call_callback_hooks` because we have special logic for getting callback_states.\r\n\r\n    \"\"\"\r\n    pl_module = trainer.lightning_module\r\n    if pl_module:\r\n        prev_fx_name = pl_module._current_fx_name\r\n        pl_module._current_fx_name = \"on_load_checkpoint\"\r\n\r\n    callback_states: Optional[dict[Union[type, str], dict]] = checkpoint.get(\"callbacks\")\r\n\r\n    if callback_states is None:\r\n        return\r\n\r\n    is_legacy_ckpt = Version(checkpoint[\"pytorch-lightning_version\"]) < Version(\"1.5.0dev\")\r\n    current_callbacks_keys = {cb._legacy_state_key if is_legacy_ckpt else cb.state_key for cb in trainer.callbacks}\r\n    difference = callback_states.keys() - current_callbacks_keys\r\n    if difference:\r\n        rank_zero_warn(\r\n            \"Be aware that when using `ckpt_path`,\"\r\n            \" callbacks used to create the checkpoint need to be provided during `Trainer` instantiation.\"\r\n            f\" Please add the following callbacks: {list(difference)}.\",\r\n        )\r\n\r\n    for callback in trainer.callbacks:\r\n        with trainer.profiler.profile(f\"[Callback]{callback.state_key}.on_load_checkpoint\"):\r\n            callback.on_load_checkpoint(trainer, trainer.lightning_module, checkpoint)\r\n\r\n    if pl_module:\r\n        pl_module._current_fx_name = prev_fx_name", "code_tokens": ["def", "_call_callbacks_on_load_checkpoint", "(", "trainer", ":", "STRING", ",", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "None", ":", "STRING", "pl_module", "=", "trainer", ".", "lightning_module", "if", "pl_module", ":", "prev_fx_name", "=", "pl_module", ".", "_current_fx_name", "pl_module", ".", "_current_fx_name", "=", "STRING", "callback_states", ":", "Optional", "[", "dict", "[", "Union", "[", "type", ",", "str", "]", ",", "dict", "]", "]", "=", "checkpoint", ".", "get", "(", "STRING", ")", "if", "callback_states", "is", "None", ":", "return", "is_legacy_ckpt", "=", "Version", "(", "checkpoint", "[", "STRING", "]", ")", "<", "Version", "(", "STRING", ")", "current_callbacks_keys", "=", "{", "cb", ".", "_legacy_state_key", "if", "is_legacy_ckpt", "else", "cb", ".", "state_key", "for", "cb", "in", "trainer", ".", "callbacks", "}", "difference", "=", "callback_states", ".", "keys", "(", ")", "-", "current_callbacks_keys", "if", "difference", ":", "rank_zero_warn", "(", "STRING", "STRING", "fSTRING", ",", ")", "for", "callback", "in", "trainer", ".", "callbacks", ":", "with", "trainer", ".", "profiler", ".", "profile", "(", "fSTRING", ")", ":", "callback", ".", "on_load_checkpoint", "(", "trainer", ",", "trainer", ".", "lightning_module", ",", "checkpoint", ")", "if", "pl_module", ":", "pl_module", ".", "_current_fx_name", "=", "prev_fx_name"], "docstring": "restore current_fx when nested context", "docstring_tokens": ["restore", "current_fx", "when", "nested", "context"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\call.py", "start_line": 261, "end_line": 294, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\setup.py", "func_name": "function_223", "original_string": "def _parse_time_interval_seconds(value: Union[str, timedelta, dict]) -> float:\r\n    \"\"\"Convert a time interval into seconds.\r\n\r\n    This helper parses different representations of a time interval and\r\n    normalizes them into a float number of seconds.\r\n\r\n    Supported input formats:\r\n      * `timedelta`: The total seconds are returned directly.\r\n      * `dict`: A dictionary of keyword arguments accepted by\r\n        `datetime.timedelta`, e.g. `{\"days\": 1, \"hours\": 2}`.\r\n      * `str`: A string in the format `\"DD:HH:MM:SS\"`, where each\r\n        component must be an integer.\r\n\r\n    Args:\r\n        value (Union[str, timedelta, dict]): The time interval to parse.\r\n\r\n    Returns:\r\n        float: The duration represented by `value` in seconds.\r\n\r\n    Raises:\r\n        MisconfigurationException: If the input type is unsupported, the\r\n        string format is invalid, or any string component is not an integer.\r\n\r\n    Examples:\r\n        >>> _parse_time_interval_seconds(\"01:02:03:04\")\r\n        93784.0\r\n\r\n        >>> _parse_time_interval_seconds({\"hours\": 2, \"minutes\": 30})\r\n        9000.0\r\n\r\n        >>> from datetime import timedelta\r\n        >>> _parse_time_interval_seconds(timedelta(days=1, seconds=30))\r\n        86430.0\r\n\r\n    \"\"\"\r\n    if isinstance(value, timedelta):\r\n        return value.total_seconds()\r\n    if isinstance(value, dict):\r\n        td = timedelta(**value)\r\n        return td.total_seconds()\r\n    if isinstance(value, str):\r\n        parts = value.split(\":\")\r\n        if len(parts) != 4:\r\n            raise MisconfigurationException(\r\n                f\"Invalid time format for `val_check_interval`: {value!r}. Expected 'DD:HH:MM:SS'.\"\r\n            )\r\n        d, h, m, s = parts\r\n        try:\r\n            days = int(d)\r\n            hours = int(h)\r\n            minutes = int(m)\r\n            seconds = int(s)\r\n        except ValueError:\r\n            raise MisconfigurationException(\r\n                f\"Non-integer component in `val_check_interval` string: {value!r}. Use 'DD:HH:MM:SS'.\"\r\n            )\r\n        td = timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)\r\n        return td.total_seconds()\r\n    raise MisconfigurationException(f\"Unsupported type for `val_check_interval`: {type(value)!r}\")", "language": "python", "code": "def _parse_time_interval_seconds(value: Union[str, timedelta, dict]) -> float:\r\n    \"\"\"Convert a time interval into seconds.\r\n\r\n    This helper parses different representations of a time interval and\r\n    normalizes them into a float number of seconds.\r\n\r\n    Supported input formats:\r\n      * `timedelta`: The total seconds are returned directly.\r\n      * `dict`: A dictionary of keyword arguments accepted by\r\n        `datetime.timedelta`, e.g. `{\"days\": 1, \"hours\": 2}`.\r\n      * `str`: A string in the format `\"DD:HH:MM:SS\"`, where each\r\n        component must be an integer.\r\n\r\n    Args:\r\n        value (Union[str, timedelta, dict]): The time interval to parse.\r\n\r\n    Returns:\r\n        float: The duration represented by `value` in seconds.\r\n\r\n    Raises:\r\n        MisconfigurationException: If the input type is unsupported, the\r\n        string format is invalid, or any string component is not an integer.\r\n\r\n    Examples:\r\n        >>> _parse_time_interval_seconds(\"01:02:03:04\")\r\n        93784.0\r\n\r\n        >>> _parse_time_interval_seconds({\"hours\": 2, \"minutes\": 30})\r\n        9000.0\r\n\r\n        >>> from datetime import timedelta\r\n        >>> _parse_time_interval_seconds(timedelta(days=1, seconds=30))\r\n        86430.0\r\n\r\n    \"\"\"\r\n    if isinstance(value, timedelta):\r\n        return value.total_seconds()\r\n    if isinstance(value, dict):\r\n        td = timedelta(**value)\r\n        return td.total_seconds()\r\n    if isinstance(value, str):\r\n        parts = value.split(\":\")\r\n        if len(parts) != 4:\r\n            raise MisconfigurationException(\r\n                f\"Invalid time format for `val_check_interval`: {value!r}. Expected 'DD:HH:MM:SS'.\"\r\n            )\r\n        d, h, m, s = parts\r\n        try:\r\n            days = int(d)\r\n            hours = int(h)\r\n            minutes = int(m)\r\n            seconds = int(s)\r\n        except ValueError:\r\n            raise MisconfigurationException(\r\n                f\"Non-integer component in `val_check_interval` string: {value!r}. Use 'DD:HH:MM:SS'.\"\r\n            )\r\n        td = timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)\r\n        return td.total_seconds()\r\n    raise MisconfigurationException(f\"Unsupported type for `val_check_interval`: {type(value)!r}\")", "code_tokens": ["def", "_parse_time_interval_seconds", "(", "value", ":", "Union", "[", "str", ",", "timedelta", ",", "dict", "]", ")", "-", ">", "float", ":", "STRING", "if", "isinstance", "(", "value", ",", "timedelta", ")", ":", "return", "value", ".", "total_seconds", "(", ")", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "td", "=", "timedelta", "(", "*", "*", "value", ")", "return", "td", ".", "total_seconds", "(", ")", "if", "isinstance", "(", "value", ",", "str", ")", ":", "parts", "=", "value", ".", "split", "(", "STRING", ")", "if", "len", "(", "parts", ")", "!", "=", "4", ":", "raise", "MisconfigurationException", "(", "fSTRING", ")", "d", ",", "h", ",", "m", ",", "s", "=", "parts", "try", ":", "days", "=", "int", "(", "d", ")", "hours", "=", "int", "(", "h", ")", "minutes", "=", "int", "(", "m", ")", "seconds", "=", "int", "(", "s", ")", "except", "ValueError", ":", "raise", "MisconfigurationException", "(", "fSTRING", ")", "td", "=", "timedelta", "(", "days", "=", "days", ",", "hours", "=", "hours", ",", "minutes", "=", "minutes", ",", "seconds", "=", "seconds", ")", "return", "td", ".", "total_seconds", "(", ")", "raise", "MisconfigurationException", "(", "fSTRING", ")"], "docstring": "Should not happen given the caller guards", "docstring_tokens": ["should", "not", "happen", "given", "the", "caller", "guards"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\setup.py", "start_line": 200, "end_line": 259, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_224", "original_string": "def __init__(\r\n        self,\r\n        *,\r\n        accelerator: Union[str, Accelerator] = \"auto\",\r\n        strategy: Union[str, Strategy] = \"auto\",\r\n        devices: Union[list[int], str, int] = \"auto\",\r\n        num_nodes: int = 1,\r\n        precision: Optional[_PRECISION_INPUT] = None,\r\n        logger: Optional[Union[Logger, Iterable[Logger], bool]] = None,\r\n        callbacks: Optional[Union[list[Callback], Callback]] = None,\r\n        fast_dev_run: Union[int, bool] = False,\r\n        max_epochs: Optional[int] = None,\r\n        min_epochs: Optional[int] = None,\r\n        max_steps: int = -1,\r\n        min_steps: Optional[int] = None,\r\n        max_time: Optional[Union[str, timedelta, dict[str, int]]] = None,\r\n        limit_train_batches: Optional[Union[int, float]] = None,\r\n        limit_val_batches: Optional[Union[int, float]] = None,\r\n        limit_test_batches: Optional[Union[int, float]] = None,\r\n        limit_predict_batches: Optional[Union[int, float]] = None,\r\n        overfit_batches: Union[int, float] = 0.0,\r\n        val_check_interval: Optional[Union[int, float, str, timedelta, dict[str, int]]] = None,\r\n        check_val_every_n_epoch: Optional[int] = 1,\r\n        num_sanity_val_steps: Optional[int] = None,\r\n        log_every_n_steps: Optional[int] = None,\r\n        enable_checkpointing: Optional[bool] = None,\r\n        enable_progress_bar: Optional[bool] = None,\r\n        enable_model_summary: Optional[bool] = None,\r\n        accumulate_grad_batches: int = 1,\r\n        gradient_clip_val: Optional[Union[int, float]] = None,\r\n        gradient_clip_algorithm: Optional[str] = None,\r\n        deterministic: Optional[Union[bool, _LITERAL_WARN]] = None,\r\n        benchmark: Optional[bool] = None,\r\n        inference_mode: bool = True,\r\n        use_distributed_sampler: bool = True,\r\n        profiler: Optional[Union[Profiler, str]] = None,\r\n        detect_anomaly: bool = False,\r\n        barebones: bool = False,\r\n        plugins: Optional[Union[_PLUGIN_INPUT, list[_PLUGIN_INPUT]]] = None,\r\n        sync_batchnorm: bool = False,\r\n        reload_dataloaders_every_n_epochs: int = 0,\r\n        default_root_dir: Optional[_PATH] = None,\r\n        enable_autolog_hparams: bool = True,\r\n        model_registry: Optional[str] = None,\r\n    ) -> None:\r\n        r\"\"\"Customize every aspect of training via flags.\r\n\r\n        Args:\r\n            accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"hpu\", \"mps\", \"auto\")\r\n                as well as custom accelerator instances.\r\n\r\n            strategy: Supports different training strategies with aliases as well custom strategies.\r\n                Default: ``\"auto\"``.\r\n\r\n            devices: The devices to use. Can be set to a positive number (int or str), a sequence of device indices\r\n                (list or str), the value ``-1`` to indicate all available devices should be used, or ``\"auto\"`` for\r\n                automatic selection based on the chosen accelerator. Default: ``\"auto\"``.\r\n\r\n            num_nodes: Number of GPU nodes for distributed training.\r\n                Default: ``1``.\r\n\r\n            precision: Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\r\n                16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\r\n                Can be used on CPU, GPU, TPUs, or HPUs.\r\n                Default: ``'32-true'``.\r\n\r\n            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\r\n                the default ``TensorBoardLogger`` if it is installed, otherwise ``CSVLogger``.\r\n                ``False`` will disable logging. If multiple loggers are provided, local files\r\n                (checkpoints, profiler traces, etc.) are saved in the ``log_dir`` of the first logger.\r\n                Default: ``True``.\r\n\r\n            callbacks: Add a callback or list of callbacks.\r\n                Default: ``None``.\r\n\r\n            fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\r\n                of train, val and test to find any bugs (ie: a sort of unit test).\r\n                Default: ``False``.\r\n\r\n            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\r\n                If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\r\n                To enable infinite training, set ``max_epochs = -1``.\r\n\r\n            min_epochs: Force training for at least these many epochs. Disabled by default (None).\r\n\r\n            max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\r\n                and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\r\n                ``max_epochs`` to ``-1``.\r\n\r\n            min_steps: Force training for at least these number of steps. Disabled by default (``None``).\r\n\r\n            max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\r\n                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\r\n                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\r\n                :class:`datetime.timedelta`.\r\n\r\n            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            overfit_batches: Overfit a fraction of training/validation data (float) or a set number of batches (int).\r\n                Default: ``0.0``.\r\n\r\n            val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\r\n                after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\r\n                batches. An ``int`` value can only be higher than the number of training batches when\r\n                ``check_val_every_n_epoch=None``, which validates after every ``N`` training batches\r\n                across epochs or during iteration-based training. Additionally, accepts a time-based duration\r\n                as a string \"DD:HH:MM:SS\", a :class:`datetime.timedelta`, or a dict of kwargs to\r\n                :class:`datetime.timedelta`. When time-based, validation triggers once the elapsed wall-clock time\r\n                since the last validation exceeds the interval; the check occurs after the current batch\r\n                completes, the validation loop runs, and the timer is reset.\r\n                Default: ``1.0``.\r\n\r\n            check_val_every_n_epoch: Perform a validation loop after every `N` training epochs. If ``None``,\r\n                validation will be done solely based on the number of training batches, requiring ``val_check_interval``\r\n                to be an integer value. When used together with a time-based ``val_check_interval`` and\r\n                ``check_val_every_n_epoch`` > 1, validation is aligned to epoch multiples: if the interval elapses\r\n                before the next multiple-N epoch, validation runs at the start of that epoch (after the first batch)\r\n                and the timer resets; if it elapses during a multiple-N epoch, validation runs after the current batch.\r\n                For ``None`` or ``1`` cases, the time-based behavior of ``val_check_interval`` applies without\r\n                additional alignment.\r\n                Default: ``1``.\r\n\r\n            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\r\n                Set it to `-1` to run all batches in all validation dataloaders.\r\n                Default: ``2``.\r\n\r\n            log_every_n_steps: How often to log within steps.\r\n                Default: ``50``.\r\n\r\n            enable_checkpointing: If ``True``, enable checkpointing.\r\n                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.callbacks`.\r\n                Default: ``True``.\r\n\r\n            enable_progress_bar: Whether to enable to progress bar by default.\r\n                Default: ``True``.\r\n\r\n            enable_model_summary: Whether to enable model summarization by default.\r\n                Default: ``True``.\r\n\r\n            accumulate_grad_batches: Accumulates gradients over k batches before stepping the optimizer.\r\n                Default: 1.\r\n\r\n            gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\r\n                gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\r\n                Default: ``None``.\r\n\r\n            gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\r\n                to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\r\n                be set to ``\"norm\"``.\r\n\r\n            deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\r\n                Set to ``\"warn\"`` to use deterministic algorithms whenever possible, throwing warnings on operations\r\n                that don't support deterministic mode. If not set, defaults to ``False``. Default: ``None``.\r\n\r\n            benchmark: The value (``True`` or ``False``) to set ``torch.backends.cudnn.benchmark`` to.\r\n                The value for ``torch.backends.cudnn.benchmark`` set in the current session will be used\r\n                (``False`` if not manually set). If :paramref:`~lightning.pytorch.trainer.trainer.Trainer.deterministic`\r\n                is set to ``True``, this will default to ``False``. Override to manually set a different value.\r\n                Default: ``None``.\r\n\r\n            inference_mode: Whether to use :func:`torch.inference_mode` or :func:`torch.no_grad` during\r\n                evaluation (``validate``/``test``/``predict``).\r\n\r\n            use_distributed_sampler: Whether to wrap the DataLoader's sampler with\r\n                :class:`torch.utils.data.DistributedSampler`. If not specified this is toggled automatically for\r\n                strategies that require it. By default, it will add ``shuffle=True`` for the train sampler and\r\n                ``shuffle=False`` for validation/test/predict samplers. If you want to disable this logic, you can pass\r\n                ``False`` and add your own distributed sampler in the dataloader hooks. If ``True`` and a distributed\r\n                sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,\r\n                we don't do this automatically.\r\n\r\n            profiler: To profile individual steps during training and assist in identifying bottlenecks.\r\n                Default: ``None``.\r\n\r\n            detect_anomaly: Enable anomaly detection for the autograd engine.\r\n                Default: ``False``.\r\n\r\n            barebones: Whether to run in \"barebones mode\", where all features that may impact raw speed are\r\n                disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training\r\n                runs. The following features are deactivated:\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_checkpointing`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.logger`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_progress_bar`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.log_every_n_steps`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_model_summary`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.num_sanity_val_steps`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.fast_dev_run`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.detect_anomaly`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.profiler`,\r\n                :meth:`~lightning.pytorch.core.LightningModule.log`,\r\n                :meth:`~lightning.pytorch.core.LightningModule.log_dict`.\r\n            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\r\n                Default: ``None``.\r\n\r\n            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\r\n                Default: ``False``.\r\n\r\n            reload_dataloaders_every_n_epochs: Set to a positive integer to reload dataloaders every n epochs.\r\n                Default: ``0``.\r\n\r\n            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\r\n                Default: ``os.getcwd()``.\r\n                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\r\n\r\n            enable_autolog_hparams: Whether to log hyperparameters at the start of a run.\r\n                Default: ``True``.\r\n\r\n            model_registry: The name of the model being uploaded to Model hub.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``gradient_clip_val`` is not an int or float.\r\n\r\n            MisconfigurationException:\r\n                If ``gradient_clip_algorithm`` is invalid.\r\n\r\n        \"\"\"\r\n        super().__init__()\r\n        log.debug(f\"{self.__class__.__name__}: Initializing trainer with parameters: {locals()}\")\r\n\r\n        if default_root_dir is not None:\r\n            default_root_dir = os.fspath(default_root_dir)\r\n\r\n        self._model_registry = model_registry.split(\":\")[0] if model_registry else None\r\n\r\n        self.barebones = barebones\r\n        if barebones:\r\n            if enable_checkpointing:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_checkpointing={enable_checkpointing!r})` was passed.\"\r\n                    \" Checkpointing can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_checkpointing = False\r\n            if logger is not None and logger is not False:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, logger={logger!r})` was passed.\"\r\n                    \" Logging can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            logger = False\r\n            if enable_progress_bar:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_progress_bar={enable_progress_bar!r})` was passed.\"\r\n                    \" The progress bar can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_progress_bar = False\r\n            if log_every_n_steps is not None and log_every_n_steps != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, log_every_n_steps={log_every_n_steps!r})` was passed.\"\r\n                    \" Logging can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            log_every_n_steps = 0\r\n            if enable_model_summary:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_model_summary={enable_model_summary!r})` was passed.\"\r\n                    \" Model summary can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_model_summary = False\r\n            if num_sanity_val_steps is not None and num_sanity_val_steps != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, num_sanity_val_steps={num_sanity_val_steps!r})` was passed.\"\r\n                    \" Sanity checking can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            num_sanity_val_steps = 0\r\n            if fast_dev_run is not False and fast_dev_run != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, fast_dev_run={fast_dev_run!r})` was passed.\"\r\n                    \" Development run is not meant for raw speed evaluation so it is disabled in barebones mode.\"\r\n                )\r\n            if detect_anomaly:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, detect_anomaly={detect_anomaly!r})` was passed.\"\r\n                    \" Anomaly detection can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            if profiler is not None:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, profiler={profiler!r})` was passed.\"\r\n                    \" Profiling can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            deactivated = (\r\n                \" - Checkpointing: `Trainer(enable_checkpointing=True)`\",\r\n                \" - Progress bar: `Trainer(enable_progress_bar=True)`\",\r\n                \" - Model summary: `Trainer(enable_model_summary=True)`\",\r\n                \" - Logging: `Trainer(logger=True)`, `Trainer(log_every_n_steps>0)`,\"\r\n                \" `LightningModule.log(...)`, `LightningModule.log_dict(...)`\",\r\n                \" - Sanity checking: `Trainer(num_sanity_val_steps>0)`\",\r\n                \" - Development run: `Trainer(fast_dev_run=True)`\",\r\n                \" - Anomaly detection: `Trainer(detect_anomaly=True)`\",\r\n                \" - Profiling: `Trainer(profiler=...)`\",\r\n            )\r\n            rank_zero_info(\r\n                \"You are running in `Trainer(barebones=True)` mode. All features that may impact raw speed have been\"\r\n                \" disabled to facilitate analyzing the Trainer overhead. Specifically, the following features are\"\r\n                f\" deactivated:{os.linesep}{os.linesep.join(deactivated)}\"\r\n            )\r\n        else:\r\n            if enable_checkpointing is None:\r\n                enable_checkpointing = True\r\n            if logger is None:\r\n                logger = True\r\n            if enable_progress_bar is None:\r\n                enable_progress_bar = True\r\n            if log_every_n_steps is None:\r\n                log_every_n_steps = 50\r\n            if enable_model_summary is None:\r\n                enable_model_summary = True\r\n            if num_sanity_val_steps is None:\r\n                num_sanity_val_steps = 2\r\n\r\n        self._data_connector = _DataConnector(self)\r\n\r\n        self._accelerator_connector = _AcceleratorConnector(\r\n            devices=devices,\r\n            accelerator=accelerator,\r\n            strategy=strategy,\r\n            num_nodes=num_nodes,\r\n            sync_batchnorm=sync_batchnorm,\r\n            benchmark=benchmark,\r\n            use_distributed_sampler=use_distributed_sampler,\r\n            deterministic=deterministic,\r\n            precision=precision,\r\n            plugins=plugins,\r\n        )\r\n        self._logger_connector = _LoggerConnector(self)\r\n        self._callback_connector = _CallbackConnector(self)\r\n        self._checkpoint_connector = _CheckpointConnector(self)\r\n        self._signal_connector = _SignalConnector(self)\r\n\r\n        self.fit_loop = _FitLoop(self, min_epochs=min_epochs, max_epochs=max_epochs)\r\n        self.fit_loop.epoch_loop = _TrainingEpochLoop(self, min_steps=min_steps, max_steps=max_steps)\r\n        self.validate_loop = _EvaluationLoop(\r\n            self, TrainerFn.VALIDATING, RunningStage.VALIDATING, inference_mode=inference_mode\r\n        )\r\n        self.test_loop = _EvaluationLoop(self, TrainerFn.TESTING, RunningStage.TESTING, inference_mode=inference_mode)\r\n        self.predict_loop = _PredictionLoop(self, inference_mode=inference_mode)\r\n\r\n        self.accumulate_grad_batches = accumulate_grad_batches\r\n\r\n        self._callback_connector.on_trainer_init(\r\n            callbacks,\r\n            enable_checkpointing,\r\n            enable_progress_bar,\r\n            default_root_dir,\r\n            enable_model_summary,\r\n            max_time,\r\n        )\r\n\r\n        self.check_val_every_n_epoch: Optional[int]\r\n        self._data_connector.on_trainer_init(\r\n            val_check_interval,\r\n            reload_dataloaders_every_n_epochs,\r\n            check_val_every_n_epoch,\r\n        )\r\n\r\n        if gradient_clip_val is not None and not isinstance(gradient_clip_val, (int, float)):\r\n            raise TypeError(f\"`gradient_clip_val` should be an int or a float. Got {gradient_clip_val}.\")\r\n\r\n        if gradient_clip_algorithm is not None and not GradClipAlgorithmType.supported_type(\r\n            gradient_clip_algorithm.lower()\r\n        ):\r\n            raise MisconfigurationException(\r\n                f\"`gradient_clip_algorithm` {gradient_clip_algorithm} is invalid. \"\r\n                f\"Allowed algorithms: {GradClipAlgorithmType.supported_types()}.\"\r\n            )\r\n\r\n        self.gradient_clip_val: Optional[Union[int, float]] = gradient_clip_val\r\n        self.gradient_clip_algorithm: Optional[GradClipAlgorithmType] = (\r\n            GradClipAlgorithmType(gradient_clip_algorithm.lower()) if gradient_clip_algorithm is not None else None\r\n        )\r\n\r\n        if detect_anomaly:\r\n            rank_zero_info(\r\n                \"You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and\"\r\n                \" is recommended only for model debugging.\"\r\n            )\r\n        self._detect_anomaly: bool = detect_anomaly\r\n\r\n        setup._log_device_info(self)\r\n\r\n        self.should_stop = False\r\n        self.state = TrainerState()\r\n\r\n        setup._init_profiler(self, profiler)\r\n\r\n        self._loggers: list[Logger]\r\n        self._logger_connector.on_trainer_init(logger, log_every_n_steps)\r\n\r\n        self.val_check_batch: Optional[Union[int, float]] = None\r\n        self.val_check_interval: Union[int, float]\r\n        self.num_sanity_val_steps: Union[int, float]\r\n        self.limit_train_batches: Union[int, float]\r\n        self.limit_val_batches: Union[int, float]\r\n        self.limit_test_batches: Union[int, float]\r\n        self.limit_predict_batches: Union[int, float]\r\n        setup._init_debugging_flags(\r\n            self,\r\n            limit_train_batches,\r\n            limit_val_batches,\r\n            limit_test_batches,\r\n            limit_predict_batches,\r\n            fast_dev_run,\r\n            overfit_batches,\r\n            val_check_interval,\r\n            num_sanity_val_steps,\r\n        )\r\n\r\n        self.enable_autolog_hparams = enable_autolog_hparams", "language": "python", "code": "def __init__(\r\n        self,\r\n        *,\r\n        accelerator: Union[str, Accelerator] = \"auto\",\r\n        strategy: Union[str, Strategy] = \"auto\",\r\n        devices: Union[list[int], str, int] = \"auto\",\r\n        num_nodes: int = 1,\r\n        precision: Optional[_PRECISION_INPUT] = None,\r\n        logger: Optional[Union[Logger, Iterable[Logger], bool]] = None,\r\n        callbacks: Optional[Union[list[Callback], Callback]] = None,\r\n        fast_dev_run: Union[int, bool] = False,\r\n        max_epochs: Optional[int] = None,\r\n        min_epochs: Optional[int] = None,\r\n        max_steps: int = -1,\r\n        min_steps: Optional[int] = None,\r\n        max_time: Optional[Union[str, timedelta, dict[str, int]]] = None,\r\n        limit_train_batches: Optional[Union[int, float]] = None,\r\n        limit_val_batches: Optional[Union[int, float]] = None,\r\n        limit_test_batches: Optional[Union[int, float]] = None,\r\n        limit_predict_batches: Optional[Union[int, float]] = None,\r\n        overfit_batches: Union[int, float] = 0.0,\r\n        val_check_interval: Optional[Union[int, float, str, timedelta, dict[str, int]]] = None,\r\n        check_val_every_n_epoch: Optional[int] = 1,\r\n        num_sanity_val_steps: Optional[int] = None,\r\n        log_every_n_steps: Optional[int] = None,\r\n        enable_checkpointing: Optional[bool] = None,\r\n        enable_progress_bar: Optional[bool] = None,\r\n        enable_model_summary: Optional[bool] = None,\r\n        accumulate_grad_batches: int = 1,\r\n        gradient_clip_val: Optional[Union[int, float]] = None,\r\n        gradient_clip_algorithm: Optional[str] = None,\r\n        deterministic: Optional[Union[bool, _LITERAL_WARN]] = None,\r\n        benchmark: Optional[bool] = None,\r\n        inference_mode: bool = True,\r\n        use_distributed_sampler: bool = True,\r\n        profiler: Optional[Union[Profiler, str]] = None,\r\n        detect_anomaly: bool = False,\r\n        barebones: bool = False,\r\n        plugins: Optional[Union[_PLUGIN_INPUT, list[_PLUGIN_INPUT]]] = None,\r\n        sync_batchnorm: bool = False,\r\n        reload_dataloaders_every_n_epochs: int = 0,\r\n        default_root_dir: Optional[_PATH] = None,\r\n        enable_autolog_hparams: bool = True,\r\n        model_registry: Optional[str] = None,\r\n    ) -> None:\r\n        r\"\"\"Customize every aspect of training via flags.\r\n\r\n        Args:\r\n            accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"hpu\", \"mps\", \"auto\")\r\n                as well as custom accelerator instances.\r\n\r\n            strategy: Supports different training strategies with aliases as well custom strategies.\r\n                Default: ``\"auto\"``.\r\n\r\n            devices: The devices to use. Can be set to a positive number (int or str), a sequence of device indices\r\n                (list or str), the value ``-1`` to indicate all available devices should be used, or ``\"auto\"`` for\r\n                automatic selection based on the chosen accelerator. Default: ``\"auto\"``.\r\n\r\n            num_nodes: Number of GPU nodes for distributed training.\r\n                Default: ``1``.\r\n\r\n            precision: Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\r\n                16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\r\n                Can be used on CPU, GPU, TPUs, or HPUs.\r\n                Default: ``'32-true'``.\r\n\r\n            logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\r\n                the default ``TensorBoardLogger`` if it is installed, otherwise ``CSVLogger``.\r\n                ``False`` will disable logging. If multiple loggers are provided, local files\r\n                (checkpoints, profiler traces, etc.) are saved in the ``log_dir`` of the first logger.\r\n                Default: ``True``.\r\n\r\n            callbacks: Add a callback or list of callbacks.\r\n                Default: ``None``.\r\n\r\n            fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\r\n                of train, val and test to find any bugs (ie: a sort of unit test).\r\n                Default: ``False``.\r\n\r\n            max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\r\n                If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\r\n                To enable infinite training, set ``max_epochs = -1``.\r\n\r\n            min_epochs: Force training for at least these many epochs. Disabled by default (None).\r\n\r\n            max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\r\n                and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\r\n                ``max_epochs`` to ``-1``.\r\n\r\n            min_steps: Force training for at least these number of steps. Disabled by default (``None``).\r\n\r\n            max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\r\n                The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\r\n                :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\r\n                :class:`datetime.timedelta`.\r\n\r\n            limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\r\n                Value is per device. Default: ``1.0``.\r\n\r\n            overfit_batches: Overfit a fraction of training/validation data (float) or a set number of batches (int).\r\n                Default: ``0.0``.\r\n\r\n            val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\r\n                after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\r\n                batches. An ``int`` value can only be higher than the number of training batches when\r\n                ``check_val_every_n_epoch=None``, which validates after every ``N`` training batches\r\n                across epochs or during iteration-based training. Additionally, accepts a time-based duration\r\n                as a string \"DD:HH:MM:SS\", a :class:`datetime.timedelta`, or a dict of kwargs to\r\n                :class:`datetime.timedelta`. When time-based, validation triggers once the elapsed wall-clock time\r\n                since the last validation exceeds the interval; the check occurs after the current batch\r\n                completes, the validation loop runs, and the timer is reset.\r\n                Default: ``1.0``.\r\n\r\n            check_val_every_n_epoch: Perform a validation loop after every `N` training epochs. If ``None``,\r\n                validation will be done solely based on the number of training batches, requiring ``val_check_interval``\r\n                to be an integer value. When used together with a time-based ``val_check_interval`` and\r\n                ``check_val_every_n_epoch`` > 1, validation is aligned to epoch multiples: if the interval elapses\r\n                before the next multiple-N epoch, validation runs at the start of that epoch (after the first batch)\r\n                and the timer resets; if it elapses during a multiple-N epoch, validation runs after the current batch.\r\n                For ``None`` or ``1`` cases, the time-based behavior of ``val_check_interval`` applies without\r\n                additional alignment.\r\n                Default: ``1``.\r\n\r\n            num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\r\n                Set it to `-1` to run all batches in all validation dataloaders.\r\n                Default: ``2``.\r\n\r\n            log_every_n_steps: How often to log within steps.\r\n                Default: ``50``.\r\n\r\n            enable_checkpointing: If ``True``, enable checkpointing.\r\n                It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.callbacks`.\r\n                Default: ``True``.\r\n\r\n            enable_progress_bar: Whether to enable to progress bar by default.\r\n                Default: ``True``.\r\n\r\n            enable_model_summary: Whether to enable model summarization by default.\r\n                Default: ``True``.\r\n\r\n            accumulate_grad_batches: Accumulates gradients over k batches before stepping the optimizer.\r\n                Default: 1.\r\n\r\n            gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\r\n                gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\r\n                Default: ``None``.\r\n\r\n            gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\r\n                to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\r\n                be set to ``\"norm\"``.\r\n\r\n            deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\r\n                Set to ``\"warn\"`` to use deterministic algorithms whenever possible, throwing warnings on operations\r\n                that don't support deterministic mode. If not set, defaults to ``False``. Default: ``None``.\r\n\r\n            benchmark: The value (``True`` or ``False``) to set ``torch.backends.cudnn.benchmark`` to.\r\n                The value for ``torch.backends.cudnn.benchmark`` set in the current session will be used\r\n                (``False`` if not manually set). If :paramref:`~lightning.pytorch.trainer.trainer.Trainer.deterministic`\r\n                is set to ``True``, this will default to ``False``. Override to manually set a different value.\r\n                Default: ``None``.\r\n\r\n            inference_mode: Whether to use :func:`torch.inference_mode` or :func:`torch.no_grad` during\r\n                evaluation (``validate``/``test``/``predict``).\r\n\r\n            use_distributed_sampler: Whether to wrap the DataLoader's sampler with\r\n                :class:`torch.utils.data.DistributedSampler`. If not specified this is toggled automatically for\r\n                strategies that require it. By default, it will add ``shuffle=True`` for the train sampler and\r\n                ``shuffle=False`` for validation/test/predict samplers. If you want to disable this logic, you can pass\r\n                ``False`` and add your own distributed sampler in the dataloader hooks. If ``True`` and a distributed\r\n                sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,\r\n                we don't do this automatically.\r\n\r\n            profiler: To profile individual steps during training and assist in identifying bottlenecks.\r\n                Default: ``None``.\r\n\r\n            detect_anomaly: Enable anomaly detection for the autograd engine.\r\n                Default: ``False``.\r\n\r\n            barebones: Whether to run in \"barebones mode\", where all features that may impact raw speed are\r\n                disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training\r\n                runs. The following features are deactivated:\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_checkpointing`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.logger`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_progress_bar`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.log_every_n_steps`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_model_summary`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.num_sanity_val_steps`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.fast_dev_run`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.detect_anomaly`,\r\n                :paramref:`~lightning.pytorch.trainer.trainer.Trainer.profiler`,\r\n                :meth:`~lightning.pytorch.core.LightningModule.log`,\r\n                :meth:`~lightning.pytorch.core.LightningModule.log_dict`.\r\n            plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\r\n                Default: ``None``.\r\n\r\n            sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\r\n                Default: ``False``.\r\n\r\n            reload_dataloaders_every_n_epochs: Set to a positive integer to reload dataloaders every n epochs.\r\n                Default: ``0``.\r\n\r\n            default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\r\n                Default: ``os.getcwd()``.\r\n                Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\r\n\r\n            enable_autolog_hparams: Whether to log hyperparameters at the start of a run.\r\n                Default: ``True``.\r\n\r\n            model_registry: The name of the model being uploaded to Model hub.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If ``gradient_clip_val`` is not an int or float.\r\n\r\n            MisconfigurationException:\r\n                If ``gradient_clip_algorithm`` is invalid.\r\n\r\n        \"\"\"\r\n        super().__init__()\r\n        log.debug(f\"{self.__class__.__name__}: Initializing trainer with parameters: {locals()}\")\r\n\r\n        if default_root_dir is not None:\r\n            default_root_dir = os.fspath(default_root_dir)\r\n\r\n        self._model_registry = model_registry.split(\":\")[0] if model_registry else None\r\n\r\n        self.barebones = barebones\r\n        if barebones:\r\n            if enable_checkpointing:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_checkpointing={enable_checkpointing!r})` was passed.\"\r\n                    \" Checkpointing can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_checkpointing = False\r\n            if logger is not None and logger is not False:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, logger={logger!r})` was passed.\"\r\n                    \" Logging can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            logger = False\r\n            if enable_progress_bar:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_progress_bar={enable_progress_bar!r})` was passed.\"\r\n                    \" The progress bar can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_progress_bar = False\r\n            if log_every_n_steps is not None and log_every_n_steps != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, log_every_n_steps={log_every_n_steps!r})` was passed.\"\r\n                    \" Logging can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            log_every_n_steps = 0\r\n            if enable_model_summary:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, enable_model_summary={enable_model_summary!r})` was passed.\"\r\n                    \" Model summary can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            enable_model_summary = False\r\n            if num_sanity_val_steps is not None and num_sanity_val_steps != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, num_sanity_val_steps={num_sanity_val_steps!r})` was passed.\"\r\n                    \" Sanity checking can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            num_sanity_val_steps = 0\r\n            if fast_dev_run is not False and fast_dev_run != 0:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, fast_dev_run={fast_dev_run!r})` was passed.\"\r\n                    \" Development run is not meant for raw speed evaluation so it is disabled in barebones mode.\"\r\n                )\r\n            if detect_anomaly:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, detect_anomaly={detect_anomaly!r})` was passed.\"\r\n                    \" Anomaly detection can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            if profiler is not None:\r\n                raise ValueError(\r\n                    f\"`Trainer(barebones=True, profiler={profiler!r})` was passed.\"\r\n                    \" Profiling can impact raw speed so it is disabled in barebones mode.\"\r\n                )\r\n            deactivated = (\r\n                \" - Checkpointing: `Trainer(enable_checkpointing=True)`\",\r\n                \" - Progress bar: `Trainer(enable_progress_bar=True)`\",\r\n                \" - Model summary: `Trainer(enable_model_summary=True)`\",\r\n                \" - Logging: `Trainer(logger=True)`, `Trainer(log_every_n_steps>0)`,\"\r\n                \" `LightningModule.log(...)`, `LightningModule.log_dict(...)`\",\r\n                \" - Sanity checking: `Trainer(num_sanity_val_steps>0)`\",\r\n                \" - Development run: `Trainer(fast_dev_run=True)`\",\r\n                \" - Anomaly detection: `Trainer(detect_anomaly=True)`\",\r\n                \" - Profiling: `Trainer(profiler=...)`\",\r\n            )\r\n            rank_zero_info(\r\n                \"You are running in `Trainer(barebones=True)` mode. All features that may impact raw speed have been\"\r\n                \" disabled to facilitate analyzing the Trainer overhead. Specifically, the following features are\"\r\n                f\" deactivated:{os.linesep}{os.linesep.join(deactivated)}\"\r\n            )\r\n        else:\r\n            if enable_checkpointing is None:\r\n                enable_checkpointing = True\r\n            if logger is None:\r\n                logger = True\r\n            if enable_progress_bar is None:\r\n                enable_progress_bar = True\r\n            if log_every_n_steps is None:\r\n                log_every_n_steps = 50\r\n            if enable_model_summary is None:\r\n                enable_model_summary = True\r\n            if num_sanity_val_steps is None:\r\n                num_sanity_val_steps = 2\r\n\r\n        self._data_connector = _DataConnector(self)\r\n\r\n        self._accelerator_connector = _AcceleratorConnector(\r\n            devices=devices,\r\n            accelerator=accelerator,\r\n            strategy=strategy,\r\n            num_nodes=num_nodes,\r\n            sync_batchnorm=sync_batchnorm,\r\n            benchmark=benchmark,\r\n            use_distributed_sampler=use_distributed_sampler,\r\n            deterministic=deterministic,\r\n            precision=precision,\r\n            plugins=plugins,\r\n        )\r\n        self._logger_connector = _LoggerConnector(self)\r\n        self._callback_connector = _CallbackConnector(self)\r\n        self._checkpoint_connector = _CheckpointConnector(self)\r\n        self._signal_connector = _SignalConnector(self)\r\n\r\n        self.fit_loop = _FitLoop(self, min_epochs=min_epochs, max_epochs=max_epochs)\r\n        self.fit_loop.epoch_loop = _TrainingEpochLoop(self, min_steps=min_steps, max_steps=max_steps)\r\n        self.validate_loop = _EvaluationLoop(\r\n            self, TrainerFn.VALIDATING, RunningStage.VALIDATING, inference_mode=inference_mode\r\n        )\r\n        self.test_loop = _EvaluationLoop(self, TrainerFn.TESTING, RunningStage.TESTING, inference_mode=inference_mode)\r\n        self.predict_loop = _PredictionLoop(self, inference_mode=inference_mode)\r\n\r\n        self.accumulate_grad_batches = accumulate_grad_batches\r\n\r\n        self._callback_connector.on_trainer_init(\r\n            callbacks,\r\n            enable_checkpointing,\r\n            enable_progress_bar,\r\n            default_root_dir,\r\n            enable_model_summary,\r\n            max_time,\r\n        )\r\n\r\n        self.check_val_every_n_epoch: Optional[int]\r\n        self._data_connector.on_trainer_init(\r\n            val_check_interval,\r\n            reload_dataloaders_every_n_epochs,\r\n            check_val_every_n_epoch,\r\n        )\r\n\r\n        if gradient_clip_val is not None and not isinstance(gradient_clip_val, (int, float)):\r\n            raise TypeError(f\"`gradient_clip_val` should be an int or a float. Got {gradient_clip_val}.\")\r\n\r\n        if gradient_clip_algorithm is not None and not GradClipAlgorithmType.supported_type(\r\n            gradient_clip_algorithm.lower()\r\n        ):\r\n            raise MisconfigurationException(\r\n                f\"`gradient_clip_algorithm` {gradient_clip_algorithm} is invalid. \"\r\n                f\"Allowed algorithms: {GradClipAlgorithmType.supported_types()}.\"\r\n            )\r\n\r\n        self.gradient_clip_val: Optional[Union[int, float]] = gradient_clip_val\r\n        self.gradient_clip_algorithm: Optional[GradClipAlgorithmType] = (\r\n            GradClipAlgorithmType(gradient_clip_algorithm.lower()) if gradient_clip_algorithm is not None else None\r\n        )\r\n\r\n        if detect_anomaly:\r\n            rank_zero_info(\r\n                \"You have turned on `Trainer(detect_anomaly=True)`. This will significantly slow down compute speed and\"\r\n                \" is recommended only for model debugging.\"\r\n            )\r\n        self._detect_anomaly: bool = detect_anomaly\r\n\r\n        setup._log_device_info(self)\r\n\r\n        self.should_stop = False\r\n        self.state = TrainerState()\r\n\r\n        setup._init_profiler(self, profiler)\r\n\r\n        self._loggers: list[Logger]\r\n        self._logger_connector.on_trainer_init(logger, log_every_n_steps)\r\n\r\n        self.val_check_batch: Optional[Union[int, float]] = None\r\n        self.val_check_interval: Union[int, float]\r\n        self.num_sanity_val_steps: Union[int, float]\r\n        self.limit_train_batches: Union[int, float]\r\n        self.limit_val_batches: Union[int, float]\r\n        self.limit_test_batches: Union[int, float]\r\n        self.limit_predict_batches: Union[int, float]\r\n        setup._init_debugging_flags(\r\n            self,\r\n            limit_train_batches,\r\n            limit_val_batches,\r\n            limit_test_batches,\r\n            limit_predict_batches,\r\n            fast_dev_run,\r\n            overfit_batches,\r\n            val_check_interval,\r\n            num_sanity_val_steps,\r\n        )\r\n\r\n        self.enable_autolog_hparams = enable_autolog_hparams", "code_tokens": ["def", "__init__", "(", "self", ",", "*", ",", "accelerator", ":", "Union", "[", "str", ",", "Accelerator", "]", "=", "STRING", ",", "strategy", ":", "Union", "[", "str", ",", "Strategy", "]", "=", "STRING", ",", "devices", ":", "Union", "[", "list", "[", "int", "]", ",", "str", ",", "int", "]", "=", "STRING", ",", "num_nodes", ":", "int", "=", "1", ",", "precision", ":", "Optional", "[", "_PRECISION_INPUT", "]", "=", "None", ",", "logger", ":", "Optional", "[", "Union", "[", "Logger", ",", "Iterable", "[", "Logger", "]", ",", "bool", "]", "]", "=", "None", ",", "callbacks", ":", "Optional", "[", "Union", "[", "list", "[", "Callback", "]", ",", "Callback", "]", "]", "=", "None", ",", "fast_dev_run", ":", "Union", "[", "int", ",", "bool", "]", "=", "False", ",", "max_epochs", ":", "Optional", "[", "int", "]", "=", "None", ",", "min_epochs", ":", "Optional", "[", "int", "]", "=", "None", ",", "max_steps", ":", "int", "=", "-", "1", ",", "min_steps", ":", "Optional", "[", "int", "]", "=", "None", ",", "max_time", ":", "Optional", "[", "Union", "[", "str", ",", "timedelta", ",", "dict", "[", "str", ",", "int", "]", "]", "]", "=", "None", ",", "limit_train_batches", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "limit_val_batches", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "limit_test_batches", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "limit_predict_batches", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "overfit_batches", ":", "Union", "[", "int", ",", "float", "]", "=", "0", ".", "0", ",", "val_check_interval", ":", "Optional", "[", "Union", "[", "int", ",", "float", ",", "str", ",", "timedelta", ",", "dict", "[", "str", ",", "int", "]", "]", "]", "=", "None", ",", "check_val_every_n_epoch", ":", "Optional", "[", "int", "]", "=", "1", ",", "num_sanity_val_steps", ":", "Optional", "[", "int", "]", "=", "None", ",", "log_every_n_steps", ":", "Optional", "[", "int", "]", "=", "None", ",", "enable_checkpointing", ":", "Optional", "[", "bool", "]", "=", "None", ",", "enable_progress_bar", ":", "Optional", "[", "bool", "]", "=", "None", ",", "enable_model_summary", ":", "Optional", "[", "bool", "]", "=", "None", ",", "accumulate_grad_batches", ":", "int", "=", "1", ",", "gradient_clip_val", ":", "Optional", "[", "Union", "[", "int", ",", "float", "]", "]", "=", "None", ",", "gradient_clip_algorithm", ":", "Optional", "[", "str", "]", "=", "None", ",", "deterministic", ":", "Optional", "[", "Union", "[", "bool", ",", "_LITERAL_WARN", "]", "]", "=", "None", ",", "benchmark", ":", "Optional", "[", "bool", "]", "=", "None", ",", "inference_mode", ":", "bool", "=", "True", ",", "use_distributed_sampler", ":", "bool", "=", "True", ",", "profiler", ":", "Optional", "[", "Union", "[", "Profiler", ",", "str", "]", "]", "=", "None", ",", "detect_anomaly", ":", "bool", "=", "False", ",", "barebones", ":", "bool", "=", "False", ",", "plugins", ":", "Optional", "[", "Union", "[", "_PLUGIN_INPUT", ",", "list", "[", "_PLUGIN_INPUT", "]", "]", "]", "=", "None", ",", "sync_batchnorm", ":", "bool", "=", "False", ",", "reload_dataloaders_every_n_epochs", ":", "int", "=", "0", ",", "default_root_dir", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "enable_autolog_hparams", ":", "bool", "=", "True", ",", "model_registry", ":", "Optional", "[", "str", "]", "=", "None", ",", ")", "-", ">", "None", ":", "rSTRING", "super", "(", ")", ".", "__init__", "(", ")", "log", ".", "debug", "(", "fSTRING", ")", "if", "default_root_dir", "is", "not", "None", ":", "default_root_dir", "=", "os", ".", "fspath", "(", "default_root_dir", ")", "self", ".", "_model_registry", "=", "model_registry", ".", "split", "(", "STRING", ")", "[", "0", "]", "if", "model_registry", "else", "None", "self", ".", "barebones", "=", "barebones", "if", "barebones", ":", "if"], "docstring": "remove version if accidentally passed opt-outs opt-ins set the opt-out defaults init connectors init loops init callbacks Declare attributes to be set in _callback_connector on_trainer_init init data flags gradient clipping configure profiler init logger flags init debugging flags", "docstring_tokens": ["remove", "version", "if", "accidentally", "passed", "opt", "outs", "opt", "ins", "set", "the", "opt", "out", "defaults", "init", "connectors", "init", "loops", "init", "callbacks", "declare", "attributes", "to", "be", "set", "in", "_callback_connector", "on_trainer_init", "init", "data", "flags", "gradient", "clipping", "configure", "profiler", "init", "logger", "flags", "init", "debugging", "flags"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 90, "end_line": 519, "has_examples": false, "num_comments": 12, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_225", "original_string": "def validate(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n        verbose: bool = True,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n    ) -> _EVALUATE_OUTPUT:\r\n        r\"\"\"Perform one evaluation epoch over the validation set.\r\n\r\n        Args:\r\n            model: The model to validate.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying validation samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.val_dataloader` hook.\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to validate. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n            verbose: If True, prints the validation results.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.val_dataloader` hook.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks\r\n            like :meth:`~lightning.pytorch.LightningModule.validation_step` etc.\r\n            The length of the list corresponds to the number of validation dataloaders used.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.validate()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.VALIDATING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.validating = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._validate_impl, model, dataloaders, ckpt_path, verbose, datamodule\r\n        )", "language": "python", "code": "def validate(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n        verbose: bool = True,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n    ) -> _EVALUATE_OUTPUT:\r\n        r\"\"\"Perform one evaluation epoch over the validation set.\r\n\r\n        Args:\r\n            model: The model to validate.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying validation samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.val_dataloader` hook.\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to validate. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n            verbose: If True, prints the validation results.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.val_dataloader` hook.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            List of dictionaries with metrics logged during the validation phase, e.g., in model- or callback hooks\r\n            like :meth:`~lightning.pytorch.LightningModule.validation_step` etc.\r\n            The length of the list corresponds to the number of validation dataloaders used.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.validate()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.VALIDATING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.validating = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._validate_impl, model, dataloaders, ckpt_path, verbose, datamodule\r\n        )", "code_tokens": ["def", "validate", "(", "self", ",", "model", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "dataloaders", ":", "Optional", "[", "Union", "[", "EVAL_DATALOADERS", ",", "LightningDataModule", "]", "]", "=", "None", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "verbose", ":", "bool", "=", "True", ",", "datamodule", ":", "Optional", "[", "LightningDataModule", "]", "=", "None", ",", ")", "-", ">", "_EVALUATE_OUTPUT", ":", "rSTRING", "if", "model", "is", "None", ":", "if", "self", ".", "lightning_module", "is", "None", ":", "raise", "TypeError", "(", "STRING", ")", "else", ":", "model", "=", "_maybe_unwrap_optimized", "(", "model", ")", "self", ".", "strategy", ".", "_lightning_module", "=", "model", "_verify_strategy_supports_compile", "(", "self", ".", "lightning_module", ",", "self", ".", "strategy", ")", "self", ".", "state", ".", "fn", "=", "TrainerFn", ".", "VALIDATING", "self", ".", "state", ".", "status", "=", "TrainerStatus", ".", "RUNNING", "self", ".", "validating", "=", "True", "return", "call", ".", "_call_and_handle_interrupt", "(", "self", ",", "self", ".", "_validate_impl", ",", "model", ",", "dataloaders", ",", "ckpt_path", ",", "verbose", ",", "datamodule", ")"], "docstring": "do we still have a reference from a previous call?", "docstring_tokens": ["do", "we", "still", "have", "a", "reference", "from", "a", "previous", "call"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 618, "end_line": 679, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_226", "original_string": "def test(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n        verbose: bool = True,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n    ) -> _EVALUATE_OUTPUT:\r\n        r\"\"\"Perform one evaluation epoch over the test set. It's separated from fit to make sure you never run on your\r\n        test set until you want to.\r\n\r\n        Args:\r\n            model: The model to test.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying test samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to test. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n            verbose: If True, prints the test results.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks\r\n            like :meth:`~lightning.pytorch.LightningModule.test_step` etc.\r\n            The length of the list corresponds to the number of test dataloaders used.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.test()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.TESTING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.testing = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._test_impl, model, dataloaders, ckpt_path, verbose, datamodule\r\n        )", "language": "python", "code": "def test(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n        verbose: bool = True,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n    ) -> _EVALUATE_OUTPUT:\r\n        r\"\"\"Perform one evaluation epoch over the test set. It's separated from fit to make sure you never run on your\r\n        test set until you want to.\r\n\r\n        Args:\r\n            model: The model to test.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying test samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to test. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n            verbose: If True, prints the test results.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.test_dataloader` hook.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            List of dictionaries with metrics logged during the test phase, e.g., in model- or callback hooks\r\n            like :meth:`~lightning.pytorch.LightningModule.test_step` etc.\r\n            The length of the list corresponds to the number of test dataloaders used.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.test()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.TESTING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.testing = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._test_impl, model, dataloaders, ckpt_path, verbose, datamodule\r\n        )", "code_tokens": ["def", "test", "(", "self", ",", "model", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "dataloaders", ":", "Optional", "[", "Union", "[", "EVAL_DATALOADERS", ",", "LightningDataModule", "]", "]", "=", "None", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", "verbose", ":", "bool", "=", "True", ",", "datamodule", ":", "Optional", "[", "LightningDataModule", "]", "=", "None", ",", ")", "-", ">", "_EVALUATE_OUTPUT", ":", "rSTRING", "if", "model", "is", "None", ":", "if", "self", ".", "lightning_module", "is", "None", ":", "raise", "TypeError", "(", "STRING", ")", "else", ":", "model", "=", "_maybe_unwrap_optimized", "(", "model", ")", "self", ".", "strategy", ".", "_lightning_module", "=", "model", "_verify_strategy_supports_compile", "(", "self", ".", "lightning_module", ",", "self", ".", "strategy", ")", "self", ".", "state", ".", "fn", "=", "TrainerFn", ".", "TESTING", "self", ".", "state", ".", "status", "=", "TrainerStatus", ".", "RUNNING", "self", ".", "testing", "=", "True", "return", "call", ".", "_call_and_handle_interrupt", "(", "self", ",", "self", ".", "_test_impl", ",", "model", ",", "dataloaders", ",", "ckpt_path", ",", "verbose", ",", "datamodule", ")"], "docstring": "do we still have a reference from a previous call?", "docstring_tokens": ["do", "we", "still", "have", "a", "reference", "from", "a", "previous", "call"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 728, "end_line": 790, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_227", "original_string": "def predict(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n        return_predictions: Optional[bool] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n    ) -> Optional[_PREDICT_OUTPUT]:\r\n        r\"\"\"Run inference on your data. This will call the model forward function to compute predictions. Useful to\r\n        perform distributed and batched predictions. Logging is disabled in the predict hooks.\r\n\r\n        Args:\r\n            model: The model to predict with.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying predict samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.predict_dataloader` hook.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.predict_dataloader` hook.\r\n\r\n            return_predictions: Whether to return predictions.\r\n                ``True`` by default except when an accelerator that spawns processes is used (not supported).\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to predict. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        See :ref:`Lightning inference section<deploy/production_basic:Predict step with your LightningModule>` for more.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.predict()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.PREDICTING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.predicting = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\r\n        )", "language": "python", "code": "def predict(\r\n        self,\r\n        model: Optional[\"pl.LightningModule\"] = None,\r\n        dataloaders: Optional[Union[EVAL_DATALOADERS, LightningDataModule]] = None,\r\n        datamodule: Optional[LightningDataModule] = None,\r\n        return_predictions: Optional[bool] = None,\r\n        ckpt_path: Optional[_PATH] = None,\r\n    ) -> Optional[_PREDICT_OUTPUT]:\r\n        r\"\"\"Run inference on your data. This will call the model forward function to compute predictions. Useful to\r\n        perform distributed and batched predictions. Logging is disabled in the predict hooks.\r\n\r\n        Args:\r\n            model: The model to predict with.\r\n\r\n            dataloaders: An iterable or collection of iterables specifying predict samples.\r\n                Alternatively, a :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.predict_dataloader` hook.\r\n\r\n            datamodule: A :class:`~lightning.pytorch.core.datamodule.LightningDataModule` that defines\r\n                the :class:`~lightning.pytorch.core.hooks.DataHooks.predict_dataloader` hook.\r\n\r\n            return_predictions: Whether to return predictions.\r\n                ``True`` by default except when an accelerator that spawns processes is used (not supported).\r\n\r\n            ckpt_path: Either ``\"best\"``, ``\"last\"``, ``\"hpc\"``, ``\"registry\"`` or path to the checkpoint you wish\r\n                to predict. If ``None`` and the model instance was passed, use the current weights.\r\n                Otherwise, the best model checkpoint from the previous ``trainer.fit`` call will be loaded\r\n                if a checkpoint callback is configured.\r\n\r\n        For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.\r\n\r\n        Returns:\r\n            Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\r\n\r\n        Raises:\r\n            TypeError:\r\n                If no ``model`` is passed and there was no ``LightningModule`` passed in the previous run.\r\n                If ``model`` passed is not `LightningModule` or `torch._dynamo.OptimizedModule`.\r\n\r\n            MisconfigurationException:\r\n                If both ``dataloaders`` and ``datamodule`` are passed. Pass only one of these.\r\n\r\n            RuntimeError:\r\n                If a compiled ``model`` is passed and the strategy is not supported.\r\n\r\n        See :ref:`Lightning inference section<deploy/production_basic:Predict step with your LightningModule>` for more.\r\n\r\n        \"\"\"\r\n        if model is None:\r\n            if self.lightning_module is None:\r\n                raise TypeError(\r\n                    \"`Trainer.predict()` requires a `LightningModule` when it hasn't been passed in a previous run\"\r\n                )\r\n        else:\r\n            model = _maybe_unwrap_optimized(model)\r\n            self.strategy._lightning_module = model\r\n        _verify_strategy_supports_compile(self.lightning_module, self.strategy)\r\n        self.state.fn = TrainerFn.PREDICTING\r\n        self.state.status = TrainerStatus.RUNNING\r\n        self.predicting = True\r\n        return call._call_and_handle_interrupt(\r\n            self, self._predict_impl, model, dataloaders, datamodule, return_predictions, ckpt_path\r\n        )", "code_tokens": ["def", "predict", "(", "self", ",", "model", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "dataloaders", ":", "Optional", "[", "Union", "[", "EVAL_DATALOADERS", ",", "LightningDataModule", "]", "]", "=", "None", ",", "datamodule", ":", "Optional", "[", "LightningDataModule", "]", "=", "None", ",", "return_predictions", ":", "Optional", "[", "bool", "]", "=", "None", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", "=", "None", ",", ")", "-", ">", "Optional", "[", "_PREDICT_OUTPUT", "]", ":", "rSTRING", "if", "model", "is", "None", ":", "if", "self", ".", "lightning_module", "is", "None", ":", "raise", "TypeError", "(", "STRING", ")", "else", ":", "model", "=", "_maybe_unwrap_optimized", "(", "model", ")", "self", ".", "strategy", ".", "_lightning_module", "=", "model", "_verify_strategy_supports_compile", "(", "self", ".", "lightning_module", ",", "self", ".", "strategy", ")", "self", ".", "state", ".", "fn", "=", "TrainerFn", ".", "PREDICTING", "self", ".", "state", ".", "status", "=", "TrainerStatus", ".", "RUNNING", "self", ".", "predicting", "=", "True", "return", "call", ".", "_call_and_handle_interrupt", "(", "self", ",", "self", ".", "_predict_impl", ",", "model", ",", "dataloaders", ",", "datamodule", ",", "return_predictions", ",", "ckpt_path", ")"], "docstring": "do we still have a reference from a previous call?", "docstring_tokens": ["do", "we", "still", "have", "a", "reference", "from", "a", "previous", "call"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 839, "end_line": 902, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_228", "original_string": "def _teardown(self) -> None:\r\n        \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\r\n        those are handled by :meth:`_call_teardown_hook`.\"\"\"\r\n        self.strategy.teardown()\r\n        loop = self._active_loop\r\n        if loop is not None:\r\n            loop.teardown()\r\n        self._logger_connector.teardown()\r\n        self._signal_connector.teardown()", "language": "python", "code": "def _teardown(self) -> None:\r\n        \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\r\n        those are handled by :meth:`_call_teardown_hook`.\"\"\"\r\n        self.strategy.teardown()\r\n        loop = self._active_loop\r\n        if loop is not None:\r\n            loop.teardown()\r\n        self._logger_connector.teardown()\r\n        self._signal_connector.teardown()", "code_tokens": ["def", "_teardown", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "strategy", ".", "teardown", "(", ")", "loop", "=", "self", ".", "_active_loop", "if", "loop", "is", "not", "None", ":", "loop", ".", "teardown", "(", ")", "self", ".", "_logger_connector", ".", "teardown", "(", ")", "self", ".", "_signal_connector", ".", "teardown", "(", ")"], "docstring": "loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`", "docstring_tokens": ["loop", "should", "never", "be", "none", "here", "but", "it", "can", "because", "we", "don", "t", "know", "the", "trainer", "stage", "with", "ddp_spawn"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1047, "end_line": 1056, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_229", "original_string": "def init_module(self, empty_init: Optional[bool] = None) -> Generator:\r\n        \"\"\"Tensors that you instantiate under this context manager will be created on the device right away and have\r\n        the right data type depending on the precision setting in the Trainer.\r\n\r\n        The parameters and tensors get created on the device and with the right data type right away without wasting\r\n        memory being allocated unnecessarily.\r\n\r\n        Args:\r\n            empty_init: Whether to initialize the model with empty weights (uninitialized memory).\r\n                If ``None``, the strategy will decide. Some strategies may not support all options.\r\n                Set this to ``True`` if you are loading a checkpoint into a large model.\r\n\r\n        \"\"\"\r\n        if is_overridden(\"model_sharded_context\", self.strategy, parent=Strategy):\r\n            rank_zero_warn(\r\n                f\"`trainer.init_module` cannot fully support proper instantiation of your model with the\"\r\n                f\" `{type(self.strategy).__name__}` strategy. Please instantiate your model inside the\"\r\n                f\"`LightningModule.configure_model` hook instead\",\r\n                category=PossibleUserWarning,\r\n            )\r\n        with self.strategy.tensor_init_context(empty_init=empty_init):\r\n            yield", "language": "python", "code": "def init_module(self, empty_init: Optional[bool] = None) -> Generator:\r\n        \"\"\"Tensors that you instantiate under this context manager will be created on the device right away and have\r\n        the right data type depending on the precision setting in the Trainer.\r\n\r\n        The parameters and tensors get created on the device and with the right data type right away without wasting\r\n        memory being allocated unnecessarily.\r\n\r\n        Args:\r\n            empty_init: Whether to initialize the model with empty weights (uninitialized memory).\r\n                If ``None``, the strategy will decide. Some strategies may not support all options.\r\n                Set this to ``True`` if you are loading a checkpoint into a large model.\r\n\r\n        \"\"\"\r\n        if is_overridden(\"model_sharded_context\", self.strategy, parent=Strategy):\r\n            rank_zero_warn(\r\n                f\"`trainer.init_module` cannot fully support proper instantiation of your model with the\"\r\n                f\" `{type(self.strategy).__name__}` strategy. Please instantiate your model inside the\"\r\n                f\"`LightningModule.configure_model` hook instead\",\r\n                category=PossibleUserWarning,\r\n            )\r\n        with self.strategy.tensor_init_context(empty_init=empty_init):\r\n            yield", "code_tokens": ["def", "init_module", "(", "self", ",", "empty_init", ":", "Optional", "[", "bool", "]", "=", "None", ")", "-", ">", "Generator", ":", "STRING", "if", "is_overridden", "(", "STRING", ",", "self", ".", "strategy", ",", "parent", "=", "Strategy", ")", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", "fSTRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "with", "self", ".", "strategy", ".", "tensor_init_context", "(", "empty_init", "=", "empty_init", ")", ":", "yield"], "docstring": "warning instead of error so that code changes are not required when changing strategies this is a limitation because processes are not expected to have been launched when this is called ideally we would check if `configure_model` is already overridden, but we don't have a reliable reference to the model yet", "docstring_tokens": ["warning", "instead", "of", "error", "so", "that", "code", "changes", "are", "not", "required", "when", "changing", "strategies", "this", "is", "a", "limitation", "because", "processes", "are", "not", "expected", "to", "have", "been", "launched", "when", "this", "is", "called", "ideally", "we", "would", "check", "if", "configure_model", "is", "already", "overridden", "but", "we", "don", "t", "have", "a", "reliable", "reference", "to", "the", "model", "yet"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1120, "end_line": 1145, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_230", "original_string": "def ckpt_path(self, ckpt_path: Optional[_PATH]) -> None:\r\n        \"\"\"Allows you to manage which checkpoint is loaded statefully.\r\n\r\n        .. code-block:: python\r\n\r\n            trainer = Trainer()\r\n            trainer.ckpt_path = \"my/checkpoint/file.ckpt\"\r\n            trainer.fit(model)\r\n            ...\r\n\r\n            trainer.ckpt_path = None\r\n            trainer.test(model)\r\n\r\n        \"\"\"\r\n        self._checkpoint_connector._ckpt_path = ckpt_path\r\n        self._checkpoint_connector._user_managed = bool(ckpt_path)", "language": "python", "code": "def ckpt_path(self, ckpt_path: Optional[_PATH]) -> None:\r\n        \"\"\"Allows you to manage which checkpoint is loaded statefully.\r\n\r\n        .. code-block:: python\r\n\r\n            trainer = Trainer()\r\n            trainer.ckpt_path = \"my/checkpoint/file.ckpt\"\r\n            trainer.fit(model)\r\n            ...\r\n\r\n            trainer.ckpt_path = None\r\n            trainer.test(model)\r\n\r\n        \"\"\"\r\n        self._checkpoint_connector._ckpt_path = ckpt_path\r\n        self._checkpoint_connector._user_managed = bool(ckpt_path)", "code_tokens": ["def", "ckpt_path", "(", "self", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ")", "-", ">", "None", ":", "STRING", "self", ".", "_checkpoint_connector", ".", "_ckpt_path", "=", "ckpt_path", "self", ".", "_checkpoint_connector", ".", "_user_managed", "=", "bool", "(", "ckpt_path", ")"], "docstring": "you will be in charge of resetting this", "docstring_tokens": ["you", "will", "be", "in", "charge", "of", "resetting", "this"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1369, "end_line": 1385, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_231", "original_string": "def num_sanity_val_batches(self) -> list[Union[int, float]]:\r\n        \"\"\"The number of validation batches that will be used during the sanity-checking part of ``trainer.fit()``.\"\"\"\r\n        max_batches = self.fit_loop.epoch_loop.val_loop.max_batches\r\n        return [min(self.num_sanity_val_steps, batches) for batches in max_batches]", "language": "python", "code": "def num_sanity_val_batches(self) -> list[Union[int, float]]:\r\n        \"\"\"The number of validation batches that will be used during the sanity-checking part of ``trainer.fit()``.\"\"\"\r\n        max_batches = self.fit_loop.epoch_loop.val_loop.max_batches\r\n        return [min(self.num_sanity_val_steps, batches) for batches in max_batches]", "code_tokens": ["def", "num_sanity_val_batches", "(", "self", ")", "-", ">", "list", "[", "Union", "[", "int", ",", "float", "]", "]", ":", "STRING", "max_batches", "=", "self", ".", "fit_loop", ".", "epoch_loop", ".", "val_loop", ".", "max_batches", "return", "[", "min", "(", "self", ".", "num_sanity_val_steps", ",", "batches", ")", "for", "batches", "in", "max_batches", "]"], "docstring": "re-compute the `min` in case this is called outside the sanity-checking stage", "docstring_tokens": ["re", "compute", "the", "min", "in", "case", "this", "is", "called", "outside", "the", "sanity", "checking", "stage"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1571, "end_line": 1575, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_232", "original_string": "def num_val_batches(self) -> list[Union[int, float]]:\r\n        \"\"\"The number of validation batches that will be used during ``trainer.fit()`` or ``trainer.validate()``.\"\"\"\r\n        if self.state.fn == TrainerFn.VALIDATING:\r\n            return self.validate_loop.max_batches\r\n        return self.fit_loop.epoch_loop.val_loop._max_batches", "language": "python", "code": "def num_val_batches(self) -> list[Union[int, float]]:\r\n        \"\"\"The number of validation batches that will be used during ``trainer.fit()`` or ``trainer.validate()``.\"\"\"\r\n        if self.state.fn == TrainerFn.VALIDATING:\r\n            return self.validate_loop.max_batches\r\n        return self.fit_loop.epoch_loop.val_loop._max_batches", "code_tokens": ["def", "num_val_batches", "(", "self", ")", "-", ">", "list", "[", "Union", "[", "int", ",", "float", "]", "]", ":", "STRING", "if", "self", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "VALIDATING", ":", "return", "self", ".", "validate_loop", ".", "max_batches", "return", "self", ".", "fit_loop", ".", "epoch_loop", ".", "val_loop", ".", "_max_batches"], "docstring": "if no trainer.fn is set, assume fit's validation use the protected access, because it shouldn't return the sanity_val batches", "docstring_tokens": ["if", "no", "trainer", "fn", "is", "set", "assume", "fit", "s", "validation", "use", "the", "protected", "access", "because", "it", "shouldn", "t", "return", "the", "sanity_val", "batches"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1578, "end_line": 1584, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\trainer.py", "func_name": "function_233", "original_string": "def estimated_stepping_batches(self) -> Union[int, float]:\r\n        r\"\"\"The estimated number of batches that will ``optimizer.step()`` during training.\r\n\r\n        This accounts for gradient accumulation and the current trainer configuration. This might be used when setting\r\n        up your training dataloader, if it hasn't been set up already.\r\n\r\n        .. code-block:: python\r\n\r\n            def configure_optimizers(self):\r\n                optimizer = ...\r\n                stepping_batches = self.trainer.estimated_stepping_batches\r\n                scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=stepping_batches)\r\n                return [optimizer], [scheduler]\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If estimated stepping batches cannot be computed due to different `accumulate_grad_batches`\r\n                at different epochs.\r\n\r\n        \"\"\"\r\n        if self.max_epochs == -1:\r\n            return float(\"inf\") if self.max_steps == -1 else self.max_steps\r\n\r\n        if self.train_dataloader is None:\r\n            rank_zero_info(\"Loading `train_dataloader` to estimate number of stepping batches.\")\r\n            self.fit_loop.setup_data()\r\n\r\n        total_batches = self.num_training_batches\r\n\r\n        if total_batches == float(\"inf\"):\r\n            return self.max_steps\r\n\r\n        assert self.max_epochs is not None\r\n        max_estimated_steps = math.ceil(total_batches / self.accumulate_grad_batches) * max(self.max_epochs, 1)\r\n\r\n        max_estimated_steps = min(max_estimated_steps, self.max_steps) if self.max_steps != -1 else max_estimated_steps\r\n        return max_estimated_steps", "language": "python", "code": "def estimated_stepping_batches(self) -> Union[int, float]:\r\n        r\"\"\"The estimated number of batches that will ``optimizer.step()`` during training.\r\n\r\n        This accounts for gradient accumulation and the current trainer configuration. This might be used when setting\r\n        up your training dataloader, if it hasn't been set up already.\r\n\r\n        .. code-block:: python\r\n\r\n            def configure_optimizers(self):\r\n                optimizer = ...\r\n                stepping_batches = self.trainer.estimated_stepping_batches\r\n                scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, total_steps=stepping_batches)\r\n                return [optimizer], [scheduler]\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If estimated stepping batches cannot be computed due to different `accumulate_grad_batches`\r\n                at different epochs.\r\n\r\n        \"\"\"\r\n        if self.max_epochs == -1:\r\n            return float(\"inf\") if self.max_steps == -1 else self.max_steps\r\n\r\n        if self.train_dataloader is None:\r\n            rank_zero_info(\"Loading `train_dataloader` to estimate number of stepping batches.\")\r\n            self.fit_loop.setup_data()\r\n\r\n        total_batches = self.num_training_batches\r\n\r\n        if total_batches == float(\"inf\"):\r\n            return self.max_steps\r\n\r\n        assert self.max_epochs is not None\r\n        max_estimated_steps = math.ceil(total_batches / self.accumulate_grad_batches) * max(self.max_epochs, 1)\r\n\r\n        max_estimated_steps = min(max_estimated_steps, self.max_steps) if self.max_steps != -1 else max_estimated_steps\r\n        return max_estimated_steps", "code_tokens": ["def", "estimated_stepping_batches", "(", "self", ")", "-", ">", "Union", "[", "int", ",", "float", "]", ":", "rSTRING", "if", "self", ".", "max_epochs", "=", "=", "-", "1", ":", "return", "float", "(", "STRING", ")", "if", "self", ".", "max_steps", "=", "=", "-", "1", "else", "self", ".", "max_steps", "if", "self", ".", "train_dataloader", "is", "None", ":", "rank_zero_info", "(", "STRING", ")", "self", ".", "fit_loop", ".", "setup_data", "(", ")", "total_batches", "=", "self", ".", "num_training_batches", "if", "total_batches", "=", "=", "float", "(", "STRING", ")", ":", "return", "self", ".", "max_steps", "assert", "self", ".", "max_epochs", "is", "not", "None", "max_estimated_steps", "=", "math", ".", "ceil", "(", "total_batches", "/", "self", ".", "accumulate_grad_batches", ")", "*", "max", "(", "self", ".", "max_epochs", ",", "1", ")", "max_estimated_steps", "=", "min", "(", "max_estimated_steps", ",", "self", ".", "max_steps", ")", "if", "self", ".", "max_steps", "!", "=", "-", "1", "else", "max_estimated_steps", "return", "max_estimated_steps"], "docstring": "infinite training iterable dataset", "docstring_tokens": ["infinite", "training", "iterable", "dataset"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\trainer.py", "start_line": 1696, "end_line": 1734, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_234", "original_string": "def __init__(\r\n        self,\r\n        devices: Union[list[int], str, int] = \"auto\",\r\n        num_nodes: int = 1,\r\n        accelerator: Union[str, Accelerator] = \"auto\",\r\n        strategy: Union[str, Strategy] = \"auto\",\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]] = None,\r\n        precision: Optional[_PRECISION_INPUT] = None,\r\n        sync_batchnorm: bool = False,\r\n        benchmark: Optional[bool] = None,\r\n        use_distributed_sampler: bool = True,\r\n        deterministic: Optional[Union[bool, _LITERAL_WARN]] = None,\r\n    ) -> None:\r\n        \"\"\"The AcceleratorConnector parses several Trainer arguments and instantiates the Strategy including other\r\n        components such as the Accelerator and Precision plugins.\r\n\r\n            A. accelerator flag could be:\r\n                1. accelerator class\r\n                2. accelerator str\r\n                3. accelerator auto\r\n\r\n            B. strategy flag could be:\r\n                1. strategy class\r\n                2. strategy str registered with StrategyRegistry\r\n\r\n            C. plugins flag could be:\r\n                1. precision class (should be removed, and precision flag should allow user pass classes)\r\n                2. checkpoint_io class\r\n                3. cluster_environment class\r\n\r\n        priorities which to take when:\r\n            A. Class > str\r\n            B. Strategy > Accelerator/precision/plugins\r\n\r\n        \"\"\"\r\n        self.use_distributed_sampler = use_distributed_sampler\r\n        _set_torch_flags(deterministic=deterministic, benchmark=benchmark)\r\n\r\n        _register_external_accelerators_and_strategies()\r\n        self._registered_strategies = StrategyRegistry.available_strategies()\r\n        self._accelerator_types = AcceleratorRegistry.available_accelerators()\r\n\r\n        self._strategy_flag: Union[Strategy, str] = \"auto\"\r\n        self._accelerator_flag: Union[Accelerator, str] = \"auto\"\r\n        self._precision_flag: _PRECISION_INPUT_STR = \"32-true\"\r\n        self._precision_plugin_flag: Optional[Precision] = None\r\n        self._cluster_environment_flag: Optional[Union[ClusterEnvironment, str]] = None\r\n        self._parallel_devices: list[Union[int, torch.device, str]] = []\r\n        self._layer_sync: Optional[LayerSync] = TorchSyncBatchNorm() if sync_batchnorm else None\r\n        self.checkpoint_io: Optional[CheckpointIO] = None\r\n\r\n        self._check_config_and_set_final_flags(\r\n            strategy=strategy,\r\n            accelerator=accelerator,\r\n            precision=precision,\r\n            plugins=plugins,\r\n            sync_batchnorm=sync_batchnorm,\r\n        )\r\n\r\n        if self._accelerator_flag == \"auto\":\r\n            self._accelerator_flag = self._choose_auto_accelerator()\r\n        elif self._accelerator_flag == \"gpu\":\r\n            self._accelerator_flag = self._choose_gpu_accelerator_backend()\r\n\r\n        self._check_device_config_and_set_final_flags(devices=devices, num_nodes=num_nodes)\r\n        self._set_parallel_devices_and_init_accelerator()\r\n\r\n        self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()\r\n\r\n        if self._strategy_flag == \"auto\":\r\n            self._strategy_flag = self._choose_strategy()\r\n        self._check_strategy_and_fallback()\r\n        self._init_strategy()\r\n\r\n        self.precision_plugin = self._check_and_init_precision()\r\n\r\n        self._lazy_init_strategy()", "language": "python", "code": "def __init__(\r\n        self,\r\n        devices: Union[list[int], str, int] = \"auto\",\r\n        num_nodes: int = 1,\r\n        accelerator: Union[str, Accelerator] = \"auto\",\r\n        strategy: Union[str, Strategy] = \"auto\",\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]] = None,\r\n        precision: Optional[_PRECISION_INPUT] = None,\r\n        sync_batchnorm: bool = False,\r\n        benchmark: Optional[bool] = None,\r\n        use_distributed_sampler: bool = True,\r\n        deterministic: Optional[Union[bool, _LITERAL_WARN]] = None,\r\n    ) -> None:\r\n        \"\"\"The AcceleratorConnector parses several Trainer arguments and instantiates the Strategy including other\r\n        components such as the Accelerator and Precision plugins.\r\n\r\n            A. accelerator flag could be:\r\n                1. accelerator class\r\n                2. accelerator str\r\n                3. accelerator auto\r\n\r\n            B. strategy flag could be:\r\n                1. strategy class\r\n                2. strategy str registered with StrategyRegistry\r\n\r\n            C. plugins flag could be:\r\n                1. precision class (should be removed, and precision flag should allow user pass classes)\r\n                2. checkpoint_io class\r\n                3. cluster_environment class\r\n\r\n        priorities which to take when:\r\n            A. Class > str\r\n            B. Strategy > Accelerator/precision/plugins\r\n\r\n        \"\"\"\r\n        self.use_distributed_sampler = use_distributed_sampler\r\n        _set_torch_flags(deterministic=deterministic, benchmark=benchmark)\r\n\r\n        _register_external_accelerators_and_strategies()\r\n        self._registered_strategies = StrategyRegistry.available_strategies()\r\n        self._accelerator_types = AcceleratorRegistry.available_accelerators()\r\n\r\n        self._strategy_flag: Union[Strategy, str] = \"auto\"\r\n        self._accelerator_flag: Union[Accelerator, str] = \"auto\"\r\n        self._precision_flag: _PRECISION_INPUT_STR = \"32-true\"\r\n        self._precision_plugin_flag: Optional[Precision] = None\r\n        self._cluster_environment_flag: Optional[Union[ClusterEnvironment, str]] = None\r\n        self._parallel_devices: list[Union[int, torch.device, str]] = []\r\n        self._layer_sync: Optional[LayerSync] = TorchSyncBatchNorm() if sync_batchnorm else None\r\n        self.checkpoint_io: Optional[CheckpointIO] = None\r\n\r\n        self._check_config_and_set_final_flags(\r\n            strategy=strategy,\r\n            accelerator=accelerator,\r\n            precision=precision,\r\n            plugins=plugins,\r\n            sync_batchnorm=sync_batchnorm,\r\n        )\r\n\r\n        if self._accelerator_flag == \"auto\":\r\n            self._accelerator_flag = self._choose_auto_accelerator()\r\n        elif self._accelerator_flag == \"gpu\":\r\n            self._accelerator_flag = self._choose_gpu_accelerator_backend()\r\n\r\n        self._check_device_config_and_set_final_flags(devices=devices, num_nodes=num_nodes)\r\n        self._set_parallel_devices_and_init_accelerator()\r\n\r\n        self.cluster_environment: ClusterEnvironment = self._choose_and_init_cluster_environment()\r\n\r\n        if self._strategy_flag == \"auto\":\r\n            self._strategy_flag = self._choose_strategy()\r\n        self._check_strategy_and_fallback()\r\n        self._init_strategy()\r\n\r\n        self.precision_plugin = self._check_and_init_precision()\r\n\r\n        self._lazy_init_strategy()", "code_tokens": ["def", "__init__", "(", "self", ",", "devices", ":", "Union", "[", "list", "[", "int", "]", ",", "str", ",", "int", "]", "=", "STRING", ",", "num_nodes", ":", "int", "=", "1", ",", "accelerator", ":", "Union", "[", "str", ",", "Accelerator", "]", "=", "STRING", ",", "strategy", ":", "Union", "[", "str", ",", "Strategy", "]", "=", "STRING", ",", "plugins", ":", "Optional", "[", "Union", "[", "_PLUGIN_INPUT", ",", "Iterable", "[", "_PLUGIN_INPUT", "]", "]", "]", "=", "None", ",", "precision", ":", "Optional", "[", "_PRECISION_INPUT", "]", "=", "None", ",", "sync_batchnorm", ":", "bool", "=", "False", ",", "benchmark", ":", "Optional", "[", "bool", "]", "=", "None", ",", "use_distributed_sampler", ":", "bool", "=", "True", ",", "deterministic", ":", "Optional", "[", "Union", "[", "bool", ",", "_LITERAL_WARN", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "self", ".", "use_distributed_sampler", "=", "use_distributed_sampler", "_set_torch_flags", "(", "deterministic", "=", "deterministic", ",", "benchmark", "=", "benchmark", ")", "_register_external_accelerators_and_strategies", "(", ")", "self", ".", "_registered_strategies", "=", "StrategyRegistry", ".", "available_strategies", "(", ")", "self", ".", "_accelerator_types", "=", "AcceleratorRegistry", ".", "available_accelerators", "(", ")", "self", ".", "_strategy_flag", ":", "Union", "[", "Strategy", ",", "str", "]", "=", "STRING", "self", ".", "_accelerator_flag", ":", "Union", "[", "Accelerator", ",", "str", "]", "=", "STRING", "self", ".", "_precision_flag", ":", "_PRECISION_INPUT_STR", "=", "STRING", "self", ".", "_precision_plugin_flag", ":", "Optional", "[", "Precision", "]", "=", "None", "self", ".", "_cluster_environment_flag", ":", "Optional", "[", "Union", "[", "ClusterEnvironment", ",", "str", "]", "]", "=", "None", "self", ".", "_parallel_devices", ":", "list", "[", "Union", "[", "int", ",", "torch", ".", "device", ",", "str", "]", "]", "=", "[", "]", "self", ".", "_layer_sync", ":", "Optional", "[", "LayerSync", "]", "=", "TorchSyncBatchNorm", "(", ")", "if", "sync_batchnorm", "else", "None", "self", ".", "checkpoint_io", ":", "Optional", "[", "CheckpointIO", "]", "=", "None", "self", ".", "_check_config_and_set_final_flags", "(", "strategy", "=", "strategy", ",", "accelerator", "=", "accelerator", ",", "precision", "=", "precision", ",", "plugins", "=", "plugins", ",", "sync_batchnorm", "=", "sync_batchnorm", ",", ")", "if", "self", ".", "_accelerator_flag", "=", "=", "STRING", ":", "self", ".", "_accelerator_flag", "=", "self", ".", "_choose_auto_accelerator", "(", ")", "elif", "self", ".", "_accelerator_flag", "=", "=", "STRING", ":", "self", ".", "_accelerator_flag", "=", "self", ".", "_choose_gpu_accelerator_backend", "(", ")", "self", ".", "_check_device_config_and_set_final_flags", "(", "devices", "=", "devices", ",", "num_nodes", "=", "num_nodes", ")", "self", ".", "_set_parallel_devices_and_init_accelerator", "(", ")", "self", ".", "cluster_environment", ":", "ClusterEnvironment", "=", "self", ".", "_choose_and_init_cluster_environment", "(", ")", "if", "self", ".", "_strategy_flag", "=", "=", "STRING", ":", "self", ".", "_strategy_flag", "=", "self", ".", "_choose_strategy", "(", ")", "self", ".", "_check_strategy_and_fallback", "(", ")", "self", ".", "_init_strategy", "(", ")", "self", ".", "precision_plugin", "=", "self", ".", "_check_and_init_precision", "(", ")", "self", ".", "_lazy_init_strategy", "(", ")"], "docstring": "1. Parsing flags Get registered strategies, built-in accelerators and precision plugins Raise an exception if there are conflicts between flags Set each valid flag to `self._x_flag` after validation 2. Instantiate Accelerator handle `auto`, `None` and `gpu` 3. Instantiate ClusterEnvironment 4. Instantiate Strategy - Part 1 In specific cases, ignore user selection and fall back to a different strategy 5. Instantiate Precision Plugin 6. Instantiate Strategy - Part 2", "docstring_tokens": ["1", "parsing", "flags", "get", "registered", "strategies", "built", "in", "accelerators", "and", "precision", "plugins", "raise", "an", "exception", "if", "there", "are", "conflicts", "between", "flags", "set", "each", "valid", "flag", "to", "self", "_x_flag", "after", "validation", "2", "instantiate", "accelerator", "handle", "auto", "none", "and", "gpu", "3", "instantiate", "clusterenvironment", "4", "instantiate", "strategy", "part", "1", "in", "specific", "cases", "ignore", "user", "selection", "and", "fall", "back", "to", "a", "different", "strategy", "5", "instantiate", "precision", "plugin", "6", "instantiate", "strategy", "part", "2"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 75, "end_line": 162, "has_examples": false, "num_comments": 8, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_235", "original_string": "def _check_config_and_set_final_flags(\r\n        self,\r\n        strategy: Union[str, Strategy],\r\n        accelerator: Union[str, Accelerator],\r\n        precision: Optional[_PRECISION_INPUT],\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]],\r\n        sync_batchnorm: bool,\r\n    ) -> None:\r\n        \"\"\"This method checks:\r\n\r\n        1. strategy: whether the strategy name is valid, and sets the internal flags if it is.\r\n        2. accelerator: if the value of the accelerator argument is a type of accelerator (instance or string),\r\n            set self._accelerator_flag accordingly.\r\n        3. precision: The final value of the precision flag may be determined either by the precision argument or\r\n            by a plugin instance.\r\n        4. plugins: The list of plugins may contain a Precision plugin, CheckpointIO, ClusterEnvironment and others.\r\n            Additionally, other flags such as `precision` or `sync_batchnorm` can populate the list with the\r\n            corresponding plugin instances.\r\n\r\n        \"\"\"\r\n        if plugins is not None:\r\n            plugins = [plugins] if not isinstance(plugins, Iterable) else plugins\r\n\r\n        if isinstance(strategy, str):\r\n            strategy = strategy.lower()\r\n\r\n        self._strategy_flag = strategy\r\n\r\n        if strategy != \"auto\" and strategy not in self._registered_strategies and not isinstance(strategy, Strategy):\r\n            raise ValueError(\r\n                f\"You selected an invalid strategy name: `strategy={strategy!r}`.\"\r\n                \" It must be either a string or an instance of `lightning.pytorch.strategies.Strategy`.\"\r\n                \" Example choices: auto, ddp, ddp_spawn, deepspeed, ...\"\r\n                \" Find a complete list of options in our documentation at https://lightning.ai\"\r\n            )\r\n\r\n        if (\r\n            accelerator not in self._accelerator_types\r\n            and accelerator not in (\"auto\", \"gpu\")\r\n            and not isinstance(accelerator, Accelerator)\r\n        ):\r\n            raise ValueError(\r\n                f\"You selected an invalid accelerator name: `accelerator={accelerator!r}`.\"\r\n                f\" Available names are: auto, {', '.join(self._accelerator_types)}.\"\r\n            )\r\n\r\n        is_ddp_str = isinstance(strategy, str) and \"ddp\" in strategy\r\n        is_deepspeed_str = isinstance(strategy, str) and \"deepspeed\" in strategy\r\n        is_parallel_strategy = isinstance(strategy, ParallelStrategy) or is_ddp_str or is_deepspeed_str\r\n        is_mps_accelerator = MPSAccelerator.is_available() and (\r\n            accelerator in (\"mps\", \"auto\", \"gpu\", None) or isinstance(accelerator, MPSAccelerator)\r\n        )\r\n        if is_mps_accelerator and is_parallel_strategy:\r\n            raise ValueError(\r\n                f\"You set `strategy={strategy}` but strategies from the DDP family are not supported on the\"\r\n                f\" MPS accelerator. Either explicitly set `accelerator='cpu'` or change the strategy.\"\r\n            )\r\n\r\n        self._accelerator_flag = accelerator\r\n\r\n        precision_flag = _convert_precision_to_unified_args(precision)\r\n\r\n        if plugins:\r\n            plugins_flags_types: dict[str, int] = Counter()\r\n            for plugin in plugins:\r\n                if isinstance(plugin, Precision):\r\n                    self._precision_plugin_flag = plugin\r\n                    plugins_flags_types[Precision.__name__] += 1\r\n                elif isinstance(plugin, CheckpointIO):\r\n                    self.checkpoint_io = plugin\r\n                    plugins_flags_types[CheckpointIO.__name__] += 1\r\n                elif isinstance(plugin, ClusterEnvironment):\r\n                    self._cluster_environment_flag = plugin\r\n                    plugins_flags_types[ClusterEnvironment.__name__] += 1\r\n                elif isinstance(plugin, LayerSync):\r\n                    if sync_batchnorm and not isinstance(plugin, TorchSyncBatchNorm):\r\n                        raise MisconfigurationException(\r\n                            f\"You set `Trainer(sync_batchnorm=True)` and provided a `{plugin.__class__.__name__}`\"\r\n                            \" plugin, but this is not allowed. Choose one or the other.\"\r\n                        )\r\n                    self._layer_sync = plugin\r\n                    plugins_flags_types[TorchSyncBatchNorm.__name__] += 1\r\n                else:\r\n                    raise MisconfigurationException(\r\n                        f\"Found invalid type for plugin {plugin}. Expected one of: Precision, \"\r\n                        \"CheckpointIO, ClusterEnvironment, or LayerSync.\"\r\n                    )\r\n\r\n            duplicated_plugin_key = [k for k, v in plugins_flags_types.items() if v > 1]\r\n            if duplicated_plugin_key:\r\n                raise MisconfigurationException(\r\n                    f\"Received multiple values for {', '.join(duplicated_plugin_key)} flags in `plugins`.\"\r\n                    \" Expected one value for each type at most.\"\r\n                )\r\n\r\n            if plugins_flags_types.get(Precision.__name__) and precision_flag is not None:\r\n                raise ValueError(\r\n                    f\"Received both `precision={precision_flag}` and `plugins={self._precision_plugin_flag}`.\"\r\n                    f\" Choose one.\"\r\n                )\r\n\r\n        self._precision_flag = \"32-true\" if precision_flag is None else precision_flag\r\n\r\n        if self._strategy_flag and isinstance(self._strategy_flag, Strategy):\r\n            if self._strategy_flag._accelerator:\r\n                if self._accelerator_flag != \"auto\":\r\n                    raise MisconfigurationException(\r\n                        \"accelerator set through both strategy class and accelerator flag, choose one\"\r\n                    )\r\n                self._accelerator_flag = self._strategy_flag._accelerator\r\n            if self._strategy_flag._precision_plugin:\r\n                if self._precision_plugin_flag:\r\n                    raise MisconfigurationException(\"precision set through both strategy class and plugins, choose one\")\r\n                self._precision_plugin_flag = self._strategy_flag._precision_plugin\r\n            if self._strategy_flag._checkpoint_io:\r\n                if self.checkpoint_io:\r\n                    raise MisconfigurationException(\r\n                        \"checkpoint_io set through both strategy class and plugins, choose one\"\r\n                    )\r\n                self.checkpoint_io = self._strategy_flag._checkpoint_io\r\n            if getattr(self._strategy_flag, \"cluster_environment\", None):\r\n                if self._cluster_environment_flag:\r\n                    raise MisconfigurationException(\r\n                        \"cluster_environment set through both strategy class and plugins, choose one\"\r\n                    )\r\n                self._cluster_environment_flag = getattr(self._strategy_flag, \"cluster_environment\")\r\n\r\n            if hasattr(self._strategy_flag, \"parallel_devices\") and self._strategy_flag.parallel_devices:\r\n                if self._strategy_flag.parallel_devices[0].type == \"cpu\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cpu\"):\r\n                        raise MisconfigurationException(\r\n                            f\"CPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cpu\"\r\n                if self._strategy_flag.parallel_devices[0].type == \"cuda\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cuda\", \"gpu\"):\r\n                        raise MisconfigurationException(\r\n                            f\"GPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cuda\"\r\n                self._parallel_devices = self._strategy_flag.parallel_devices", "language": "python", "code": "def _check_config_and_set_final_flags(\r\n        self,\r\n        strategy: Union[str, Strategy],\r\n        accelerator: Union[str, Accelerator],\r\n        precision: Optional[_PRECISION_INPUT],\r\n        plugins: Optional[Union[_PLUGIN_INPUT, Iterable[_PLUGIN_INPUT]]],\r\n        sync_batchnorm: bool,\r\n    ) -> None:\r\n        \"\"\"This method checks:\r\n\r\n        1. strategy: whether the strategy name is valid, and sets the internal flags if it is.\r\n        2. accelerator: if the value of the accelerator argument is a type of accelerator (instance or string),\r\n            set self._accelerator_flag accordingly.\r\n        3. precision: The final value of the precision flag may be determined either by the precision argument or\r\n            by a plugin instance.\r\n        4. plugins: The list of plugins may contain a Precision plugin, CheckpointIO, ClusterEnvironment and others.\r\n            Additionally, other flags such as `precision` or `sync_batchnorm` can populate the list with the\r\n            corresponding plugin instances.\r\n\r\n        \"\"\"\r\n        if plugins is not None:\r\n            plugins = [plugins] if not isinstance(plugins, Iterable) else plugins\r\n\r\n        if isinstance(strategy, str):\r\n            strategy = strategy.lower()\r\n\r\n        self._strategy_flag = strategy\r\n\r\n        if strategy != \"auto\" and strategy not in self._registered_strategies and not isinstance(strategy, Strategy):\r\n            raise ValueError(\r\n                f\"You selected an invalid strategy name: `strategy={strategy!r}`.\"\r\n                \" It must be either a string or an instance of `lightning.pytorch.strategies.Strategy`.\"\r\n                \" Example choices: auto, ddp, ddp_spawn, deepspeed, ...\"\r\n                \" Find a complete list of options in our documentation at https://lightning.ai\"\r\n            )\r\n\r\n        if (\r\n            accelerator not in self._accelerator_types\r\n            and accelerator not in (\"auto\", \"gpu\")\r\n            and not isinstance(accelerator, Accelerator)\r\n        ):\r\n            raise ValueError(\r\n                f\"You selected an invalid accelerator name: `accelerator={accelerator!r}`.\"\r\n                f\" Available names are: auto, {', '.join(self._accelerator_types)}.\"\r\n            )\r\n\r\n        is_ddp_str = isinstance(strategy, str) and \"ddp\" in strategy\r\n        is_deepspeed_str = isinstance(strategy, str) and \"deepspeed\" in strategy\r\n        is_parallel_strategy = isinstance(strategy, ParallelStrategy) or is_ddp_str or is_deepspeed_str\r\n        is_mps_accelerator = MPSAccelerator.is_available() and (\r\n            accelerator in (\"mps\", \"auto\", \"gpu\", None) or isinstance(accelerator, MPSAccelerator)\r\n        )\r\n        if is_mps_accelerator and is_parallel_strategy:\r\n            raise ValueError(\r\n                f\"You set `strategy={strategy}` but strategies from the DDP family are not supported on the\"\r\n                f\" MPS accelerator. Either explicitly set `accelerator='cpu'` or change the strategy.\"\r\n            )\r\n\r\n        self._accelerator_flag = accelerator\r\n\r\n        precision_flag = _convert_precision_to_unified_args(precision)\r\n\r\n        if plugins:\r\n            plugins_flags_types: dict[str, int] = Counter()\r\n            for plugin in plugins:\r\n                if isinstance(plugin, Precision):\r\n                    self._precision_plugin_flag = plugin\r\n                    plugins_flags_types[Precision.__name__] += 1\r\n                elif isinstance(plugin, CheckpointIO):\r\n                    self.checkpoint_io = plugin\r\n                    plugins_flags_types[CheckpointIO.__name__] += 1\r\n                elif isinstance(plugin, ClusterEnvironment):\r\n                    self._cluster_environment_flag = plugin\r\n                    plugins_flags_types[ClusterEnvironment.__name__] += 1\r\n                elif isinstance(plugin, LayerSync):\r\n                    if sync_batchnorm and not isinstance(plugin, TorchSyncBatchNorm):\r\n                        raise MisconfigurationException(\r\n                            f\"You set `Trainer(sync_batchnorm=True)` and provided a `{plugin.__class__.__name__}`\"\r\n                            \" plugin, but this is not allowed. Choose one or the other.\"\r\n                        )\r\n                    self._layer_sync = plugin\r\n                    plugins_flags_types[TorchSyncBatchNorm.__name__] += 1\r\n                else:\r\n                    raise MisconfigurationException(\r\n                        f\"Found invalid type for plugin {plugin}. Expected one of: Precision, \"\r\n                        \"CheckpointIO, ClusterEnvironment, or LayerSync.\"\r\n                    )\r\n\r\n            duplicated_plugin_key = [k for k, v in plugins_flags_types.items() if v > 1]\r\n            if duplicated_plugin_key:\r\n                raise MisconfigurationException(\r\n                    f\"Received multiple values for {', '.join(duplicated_plugin_key)} flags in `plugins`.\"\r\n                    \" Expected one value for each type at most.\"\r\n                )\r\n\r\n            if plugins_flags_types.get(Precision.__name__) and precision_flag is not None:\r\n                raise ValueError(\r\n                    f\"Received both `precision={precision_flag}` and `plugins={self._precision_plugin_flag}`.\"\r\n                    f\" Choose one.\"\r\n                )\r\n\r\n        self._precision_flag = \"32-true\" if precision_flag is None else precision_flag\r\n\r\n        if self._strategy_flag and isinstance(self._strategy_flag, Strategy):\r\n            if self._strategy_flag._accelerator:\r\n                if self._accelerator_flag != \"auto\":\r\n                    raise MisconfigurationException(\r\n                        \"accelerator set through both strategy class and accelerator flag, choose one\"\r\n                    )\r\n                self._accelerator_flag = self._strategy_flag._accelerator\r\n            if self._strategy_flag._precision_plugin:\r\n                if self._precision_plugin_flag:\r\n                    raise MisconfigurationException(\"precision set through both strategy class and plugins, choose one\")\r\n                self._precision_plugin_flag = self._strategy_flag._precision_plugin\r\n            if self._strategy_flag._checkpoint_io:\r\n                if self.checkpoint_io:\r\n                    raise MisconfigurationException(\r\n                        \"checkpoint_io set through both strategy class and plugins, choose one\"\r\n                    )\r\n                self.checkpoint_io = self._strategy_flag._checkpoint_io\r\n            if getattr(self._strategy_flag, \"cluster_environment\", None):\r\n                if self._cluster_environment_flag:\r\n                    raise MisconfigurationException(\r\n                        \"cluster_environment set through both strategy class and plugins, choose one\"\r\n                    )\r\n                self._cluster_environment_flag = getattr(self._strategy_flag, \"cluster_environment\")\r\n\r\n            if hasattr(self._strategy_flag, \"parallel_devices\") and self._strategy_flag.parallel_devices:\r\n                if self._strategy_flag.parallel_devices[0].type == \"cpu\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cpu\"):\r\n                        raise MisconfigurationException(\r\n                            f\"CPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cpu\"\r\n                if self._strategy_flag.parallel_devices[0].type == \"cuda\":\r\n                    if self._accelerator_flag and self._accelerator_flag not in (\"auto\", \"cuda\", \"gpu\"):\r\n                        raise MisconfigurationException(\r\n                            f\"GPU parallel_devices set through {self._strategy_flag.__class__.__name__} class,\"\r\n                            f\" but accelerator set to {self._accelerator_flag}, please choose one device type\"\r\n                        )\r\n                    self._accelerator_flag = \"cuda\"\r\n                self._parallel_devices = self._strategy_flag.parallel_devices", "code_tokens": ["def", "_check_config_and_set_final_flags", "(", "self", ",", "strategy", ":", "Union", "[", "str", ",", "Strategy", "]", ",", "accelerator", ":", "Union", "[", "str", ",", "Accelerator", "]", ",", "precision", ":", "Optional", "[", "_PRECISION_INPUT", "]", ",", "plugins", ":", "Optional", "[", "Union", "[", "_PLUGIN_INPUT", ",", "Iterable", "[", "_PLUGIN_INPUT", "]", "]", "]", ",", "sync_batchnorm", ":", "bool", ",", ")", "-", ">", "None", ":", "STRING", "if", "plugins", "is", "not", "None", ":", "plugins", "=", "[", "plugins", "]", "if", "not", "isinstance", "(", "plugins", ",", "Iterable", ")", "else", "plugins", "if", "isinstance", "(", "strategy", ",", "str", ")", ":", "strategy", "=", "strategy", ".", "lower", "(", ")", "self", ".", "_strategy_flag", "=", "strategy", "if", "strategy", "!", "=", "STRING", "and", "strategy", "not", "in", "self", ".", "_registered_strategies", "and", "not", "isinstance", "(", "strategy", ",", "Strategy", ")", ":", "raise", "ValueError", "(", "fSTRING", "STRING", "STRING", "STRING", ")", "if", "(", "accelerator", "not", "in", "self", ".", "_accelerator_types", "and", "accelerator", "not", "in", "(", "STRING", ",", "STRING", ")", "and", "not", "isinstance", "(", "accelerator", ",", "Accelerator", ")", ")", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "is_ddp_str", "=", "isinstance", "(", "strategy", ",", "str", ")", "and", "STRING", "in", "strategy", "is_deepspeed_str", "=", "isinstance", "(", "strategy", ",", "str", ")", "and", "STRING", "in", "strategy", "is_parallel_strategy", "=", "isinstance", "(", "strategy", ",", "ParallelStrategy", ")", "or", "is_ddp_str", "or", "is_deepspeed_str", "is_mps_accelerator", "=", "MPSAccelerator", ".", "is_available", "(", ")", "and", "(", "accelerator", "in", "(", "STRING", ",", "STRING", ",", "STRING", ",", "None", ")", "or", "isinstance", "(", "accelerator", ",", "MPSAccelerator", ")", ")", "if", "is_mps_accelerator", "and", "is_parallel_strategy", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "self", ".", "_accelerator_flag", "=", "accelerator", "precision_flag", "=", "_convert_precision_to_unified_args", "(", "precision", ")", "if", "plugins", ":", "plugins_flags_types", ":", "dict", "[", "str", ",", "int", "]", "=", "Counter", "(", ")", "for", "plugin", "in", "plugins", ":", "if", "isinstance", "(", "plugin", ",", "Precision", ")", ":", "self", ".", "_precision_plugin_flag", "=", "plugin", "plugins_flags_types", "[", "Precision", ".", "__name__", "]", "+", "=", "1", "elif", "isinstance", "(", "plugin", ",", "CheckpointIO", ")", ":", "self", ".", "checkpoint_io", "=", "plugin", "plugins_flags_types", "[", "CheckpointIO", ".", "__name__", "]", "+", "=", "1", "elif", "isinstance", "(", "plugin", ",", "ClusterEnvironment", ")", ":", "self", ".", "_cluster_environment_flag", "=", "plugin", "plugins_flags_types", "[", "ClusterEnvironment", ".", "__name__", "]", "+", "=", "1", "elif", "isinstance", "(", "plugin", ",", "LayerSync", ")", ":", "if", "sync_batchnorm", "and", "not", "isinstance", "(", "plugin", ",", "TorchSyncBatchNorm", ")", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", ")", "self", ".", "_layer_sync", "=", "plugin", "plugins_flags_types", "[", "TorchSyncBatchNorm", ".", "__name__", "]", "+", "=", "1", "else", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", ")", "duplicated_plugin_key", "=", "[", "k", "for", "k", ",", "v", "in", "plugins_flags_types", ".", "items", "(", ")", "if", "v", ">", "1", "]", "if", "duplicated_plugin_key", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", ")", "if", "plugins_flags_types", ".", "get", "(", "Precision", ".", "__name__", ")", "and", "precision_flag", "is", "not", "None", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "self", ".", "_precision_flag", "=", "STRING", "if", "precision_flag", "is", "None", "else", "precision_flag", "if", "self", ".", "_strategy_flag", "and", "isinstance", "(", "self", ".", "_strategy_flag", ",", "Strategy", ")", ":", "if", "self", ".", "_strategy_flag", ".", "_accelerator", ":", "if", "self", ".", "_accelerator_flag", "!", "=", "STRING", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "self", ".", "_accelerator_flag", "=", "self", ".", "_strategy_flag", ".", "_accelerator", "if", "self", ".", "_strategy_flag", ".", "_precision_plugin", ":", "if", "self", ".", "_precision_plugin_flag", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "self", ".", "_precision_plugin_flag", "=", "self", ".", "_strategy_flag", ".", "_precision_plugin", "if", "self", ".", "_strategy_flag", ".", "_checkpoint_io"], "docstring": "MPS accelerator is incompatible with DDP family of strategies. It supports single-device operation only. handle the case when the user passes in a strategy instance which has an accelerator, precision, checkpoint io or cluster env set up TODO: improve the error messages below [RFC] handle precision plugin set up conflict?", "docstring_tokens": ["mps", "accelerator", "is", "incompatible", "with", "ddp", "family", "of", "strategies", "it", "supports", "single", "device", "operation", "only", "handle", "the", "case", "when", "the", "user", "passes", "in", "a", "strategy", "instance", "which", "has", "an", "accelerator", "precision", "checkpoint", "io", "or", "cluster", "env", "set", "up", "todo", "improve", "the", "error", "messages", "below", "rfc", "handle", "precision", "plugin", "set", "up", "conflict"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 164, "end_line": 311, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_236", "original_string": "def _check_strategy_and_fallback(self) -> None:\r\n        \"\"\"Checks edge cases when the strategy selection was a string input, and we need to fall back to a different\r\n        choice depending on other parameters or the environment.\"\"\"\r\n        strategy_flag = \"\" if isinstance(self._strategy_flag, Strategy) else self._strategy_flag\r\n\r\n        if (\r\n            strategy_flag in FSDPStrategy.get_registered_strategies() or type(self._strategy_flag) is FSDPStrategy\r\n        ) and not (self._accelerator_flag in (\"cuda\", \"gpu\") or isinstance(self._accelerator_flag, CUDAAccelerator)):\r\n            raise ValueError(\r\n                f\"The strategy `{FSDPStrategy.strategy_name}` requires a GPU accelerator, but received \"\r\n                f\"`accelerator={self._accelerator_flag!r}`. Please set `accelerator='cuda'`, `accelerator='gpu'`,\"\r\n                \" or pass a `CUDAAccelerator()` instance to use FSDP.\"\r\n            )\r\n        if strategy_flag in _DDP_FORK_ALIASES and \"fork\" not in torch.multiprocessing.get_all_start_methods():\r\n            raise ValueError(\r\n                f\"You selected `Trainer(strategy='{strategy_flag}')` but process forking is not supported on this\"\r\n                f\" platform. We recommend `Trainer(strategy='ddp_spawn')` instead.\"\r\n            )\r\n        if strategy_flag:\r\n            self._strategy_flag = strategy_flag", "language": "python", "code": "def _check_strategy_and_fallback(self) -> None:\r\n        \"\"\"Checks edge cases when the strategy selection was a string input, and we need to fall back to a different\r\n        choice depending on other parameters or the environment.\"\"\"\r\n        strategy_flag = \"\" if isinstance(self._strategy_flag, Strategy) else self._strategy_flag\r\n\r\n        if (\r\n            strategy_flag in FSDPStrategy.get_registered_strategies() or type(self._strategy_flag) is FSDPStrategy\r\n        ) and not (self._accelerator_flag in (\"cuda\", \"gpu\") or isinstance(self._accelerator_flag, CUDAAccelerator)):\r\n            raise ValueError(\r\n                f\"The strategy `{FSDPStrategy.strategy_name}` requires a GPU accelerator, but received \"\r\n                f\"`accelerator={self._accelerator_flag!r}`. Please set `accelerator='cuda'`, `accelerator='gpu'`,\"\r\n                \" or pass a `CUDAAccelerator()` instance to use FSDP.\"\r\n            )\r\n        if strategy_flag in _DDP_FORK_ALIASES and \"fork\" not in torch.multiprocessing.get_all_start_methods():\r\n            raise ValueError(\r\n                f\"You selected `Trainer(strategy='{strategy_flag}')` but process forking is not supported on this\"\r\n                f\" platform. We recommend `Trainer(strategy='ddp_spawn')` instead.\"\r\n            )\r\n        if strategy_flag:\r\n            self._strategy_flag = strategy_flag", "code_tokens": ["def", "_check_strategy_and_fallback", "(", "self", ")", "-", ">", "None", ":", "STRING", "strategy_flag", "=", "STRING", "if", "isinstance", "(", "self", ".", "_strategy_flag", ",", "Strategy", ")", "else", "self", ".", "_strategy_flag", "if", "(", "strategy_flag", "in", "FSDPStrategy", ".", "get_registered_strategies", "(", ")", "or", "type", "(", "self", ".", "_strategy_flag", ")", "is", "FSDPStrategy", ")", "and", "not", "(", "self", ".", "_accelerator_flag", "in", "(", "STRING", ",", "STRING", ")", "or", "isinstance", "(", "self", ".", "_accelerator_flag", ",", "CUDAAccelerator", ")", ")", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", "STRING", ")", "if", "strategy_flag", "in", "_DDP_FORK_ALIASES", "and", "STRING", "not", "in", "torch", ".", "multiprocessing", ".", "get_all_start_methods", "(", ")", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "if", "strategy_flag", ":", "self", ".", "_strategy_flag", "=", "strategy_flag"], "docstring": "current fallback and check logic only apply to user pass in str config and object config TODO this logic should apply to both str and object config", "docstring_tokens": ["current", "fallback", "and", "check", "logic", "only", "apply", "to", "user", "pass", "in", "str", "config", "and", "object", "config", "todo", "this", "logic", "should", "apply", "to", "both", "str", "and", "object", "config"], "partition": "train", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 446, "end_line": 467, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_237", "original_string": "def _init_strategy(self) -> None:\r\n        \"\"\"Instantiate the Strategy given depending on the setting of ``_strategy_flag``.\"\"\"\r\n        assert isinstance(self._strategy_flag, (str, Strategy))\r\n        if isinstance(self._strategy_flag, str):\r\n            self.strategy = StrategyRegistry.get(self._strategy_flag)\r\n        else:\r\n            self.strategy = self._strategy_flag", "language": "python", "code": "def _init_strategy(self) -> None:\r\n        \"\"\"Instantiate the Strategy given depending on the setting of ``_strategy_flag``.\"\"\"\r\n        assert isinstance(self._strategy_flag, (str, Strategy))\r\n        if isinstance(self._strategy_flag, str):\r\n            self.strategy = StrategyRegistry.get(self._strategy_flag)\r\n        else:\r\n            self.strategy = self._strategy_flag", "code_tokens": ["def", "_init_strategy", "(", "self", ")", "-", ">", "None", ":", "STRING", "assert", "isinstance", "(", "self", ".", "_strategy_flag", ",", "(", "str", ",", "Strategy", ")", ")", "if", "isinstance", "(", "self", ".", "_strategy_flag", ",", "str", ")", ":", "self", ".", "strategy", "=", "StrategyRegistry", ".", "get", "(", "self", ".", "_strategy_flag", ")", "else", ":", "self", ".", "strategy", "=", "self", ".", "_strategy_flag"], "docstring": "The validation of `_strategy_flag` already happened earlier on in the connector", "docstring_tokens": ["the", "validation", "of", "_strategy_flag", "already", "happened", "earlier", "on", "in", "the", "connector"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 469, "end_line": 476, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_238", "original_string": "def _lazy_init_strategy(self) -> None:\r\n        \"\"\"Lazily set missing attributes on the previously instantiated strategy.\"\"\"\r\n        self.strategy.accelerator = self.accelerator\r\n        if self.precision_plugin:\r\n            self.strategy.precision_plugin = self.precision_plugin\r\n        if self.checkpoint_io:\r\n            self.strategy.checkpoint_io = self.checkpoint_io\r\n        if hasattr(self.strategy, \"cluster_environment\"):\r\n            if self.strategy.cluster_environment is None:\r\n                self.strategy.cluster_environment = self.cluster_environment\r\n            self.cluster_environment = self.strategy.cluster_environment\r\n        if hasattr(self.strategy, \"parallel_devices\"):\r\n            if self.strategy.parallel_devices:\r\n                self._parallel_devices = self.strategy.parallel_devices\r\n            else:\r\n                self.strategy.parallel_devices = self._parallel_devices\r\n        if hasattr(self.strategy, \"num_nodes\"):\r\n            self.strategy.num_nodes = self._num_nodes_flag\r\n        if hasattr(self.strategy, \"_layer_sync\"):\r\n            self.strategy._layer_sync = self._layer_sync\r\n        if hasattr(self.strategy, \"set_world_ranks\"):\r\n            self.strategy.set_world_ranks()\r\n        self.strategy._configure_launcher()\r\n\r\n        if _IS_INTERACTIVE and self.strategy.launcher and not self.strategy.launcher.is_interactive_compatible:\r\n            raise MisconfigurationException(\r\n                f\"`Trainer(strategy={self._strategy_flag!r})` is not compatible with an interactive\"\r\n                \" environment. Run your code as a script, or choose a notebook-compatible strategy:\"\r\n                f\" `Trainer(strategy='ddp_notebook')`.\"\r\n                \" In case you are spawning processes yourself, make sure to include the Trainer\"\r\n                \" creation inside the worker function.\"\r\n            )\r\n\r\n        if isinstance(self.accelerator, XLAAccelerator) and not isinstance(\r\n            self.strategy, (SingleDeviceXLAStrategy, XLAStrategy)\r\n        ):\r\n            raise ValueError(\r\n                \"The `XLAAccelerator` can only be used with a `SingleDeviceXLAStrategy` or `XLAStrategy`,\"\r\n                f\" found {self.strategy.__class__.__name__}.\"\r\n            )\r\n\r\n        if _habana_available_and_importable():\r\n            from lightning_habana import HPUAccelerator, HPUParallelStrategy, SingleHPUStrategy\r\n\r\n            if isinstance(self.accelerator, HPUAccelerator) and not isinstance(\r\n                self.strategy, (SingleHPUStrategy, HPUParallelStrategy)\r\n            ):\r\n                raise ValueError(\r\n                    \"The `HPUAccelerator` can only be used with a `SingleHPUStrategy` or `HPUParallelStrategy`,\"\r\n                    f\" found {self.strategy.__class__.__name__}.\"\r\n                )", "language": "python", "code": "def _lazy_init_strategy(self) -> None:\r\n        \"\"\"Lazily set missing attributes on the previously instantiated strategy.\"\"\"\r\n        self.strategy.accelerator = self.accelerator\r\n        if self.precision_plugin:\r\n            self.strategy.precision_plugin = self.precision_plugin\r\n        if self.checkpoint_io:\r\n            self.strategy.checkpoint_io = self.checkpoint_io\r\n        if hasattr(self.strategy, \"cluster_environment\"):\r\n            if self.strategy.cluster_environment is None:\r\n                self.strategy.cluster_environment = self.cluster_environment\r\n            self.cluster_environment = self.strategy.cluster_environment\r\n        if hasattr(self.strategy, \"parallel_devices\"):\r\n            if self.strategy.parallel_devices:\r\n                self._parallel_devices = self.strategy.parallel_devices\r\n            else:\r\n                self.strategy.parallel_devices = self._parallel_devices\r\n        if hasattr(self.strategy, \"num_nodes\"):\r\n            self.strategy.num_nodes = self._num_nodes_flag\r\n        if hasattr(self.strategy, \"_layer_sync\"):\r\n            self.strategy._layer_sync = self._layer_sync\r\n        if hasattr(self.strategy, \"set_world_ranks\"):\r\n            self.strategy.set_world_ranks()\r\n        self.strategy._configure_launcher()\r\n\r\n        if _IS_INTERACTIVE and self.strategy.launcher and not self.strategy.launcher.is_interactive_compatible:\r\n            raise MisconfigurationException(\r\n                f\"`Trainer(strategy={self._strategy_flag!r})` is not compatible with an interactive\"\r\n                \" environment. Run your code as a script, or choose a notebook-compatible strategy:\"\r\n                f\" `Trainer(strategy='ddp_notebook')`.\"\r\n                \" In case you are spawning processes yourself, make sure to include the Trainer\"\r\n                \" creation inside the worker function.\"\r\n            )\r\n\r\n        if isinstance(self.accelerator, XLAAccelerator) and not isinstance(\r\n            self.strategy, (SingleDeviceXLAStrategy, XLAStrategy)\r\n        ):\r\n            raise ValueError(\r\n                \"The `XLAAccelerator` can only be used with a `SingleDeviceXLAStrategy` or `XLAStrategy`,\"\r\n                f\" found {self.strategy.__class__.__name__}.\"\r\n            )\r\n\r\n        if _habana_available_and_importable():\r\n            from lightning_habana import HPUAccelerator, HPUParallelStrategy, SingleHPUStrategy\r\n\r\n            if isinstance(self.accelerator, HPUAccelerator) and not isinstance(\r\n                self.strategy, (SingleHPUStrategy, HPUParallelStrategy)\r\n            ):\r\n                raise ValueError(\r\n                    \"The `HPUAccelerator` can only be used with a `SingleHPUStrategy` or `HPUParallelStrategy`,\"\r\n                    f\" found {self.strategy.__class__.__name__}.\"\r\n                )", "code_tokens": ["def", "_lazy_init_strategy", "(", "self", ")", "-", ">", "None", ":", "STRING", "self", ".", "strategy", ".", "accelerator", "=", "self", ".", "accelerator", "if", "self", ".", "precision_plugin", ":", "self", ".", "strategy", ".", "precision_plugin", "=", "self", ".", "precision_plugin", "if", "self", ".", "checkpoint_io", ":", "self", ".", "strategy", ".", "checkpoint_io", "=", "self", ".", "checkpoint_io", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "if", "self", ".", "strategy", ".", "cluster_environment", "is", "None", ":", "self", ".", "strategy", ".", "cluster_environment", "=", "self", ".", "cluster_environment", "self", ".", "cluster_environment", "=", "self", ".", "strategy", ".", "cluster_environment", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "if", "self", ".", "strategy", ".", "parallel_devices", ":", "self", ".", "_parallel_devices", "=", "self", ".", "strategy", ".", "parallel_devices", "else", ":", "self", ".", "strategy", ".", "parallel_devices", "=", "self", ".", "_parallel_devices", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "self", ".", "strategy", ".", "num_nodes", "=", "self", ".", "_num_nodes_flag", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "self", ".", "strategy", ".", "_layer_sync", "=", "self", ".", "_layer_sync", "if", "hasattr", "(", "self", ".", "strategy", ",", "STRING", ")", ":", "self", ".", "strategy", ".", "set_world_ranks", "(", ")", "self", ".", "strategy", ".", "_configure_launcher", "(", ")", "if", "_IS_INTERACTIVE", "and", "self", ".", "strategy", ".", "launcher", "and", "not", "self", ".", "strategy", ".", "launcher", ".", "is_interactive_compatible", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", "fSTRING", "STRING", "STRING", ")", "if", "isinstance", "(", "self", ".", "accelerator", ",", "XLAAccelerator", ")", "and", "not", "isinstance", "(", "self", ".", "strategy", ",", "(", "SingleDeviceXLAStrategy", ",", "XLAStrategy", ")", ")", ":", "raise", "ValueError", "(", "STRING", "fSTRING", ")", "if", "_habana_available_and_importable", "(", ")", ":", "from", "lightning_habana", "import", "HPUAccelerator", ",", "HPUParallelStrategy", ",", "SingleHPUStrategy", "if", "isinstance", "(", "self", ".", "accelerator", ",", "HPUAccelerator", ")", "and", "not", "isinstance", "(", "self", ".", "strategy", ",", "(", "SingleHPUStrategy", ",", "HPUParallelStrategy", ")", ")", ":", "raise", "ValueError", "(", "STRING", "fSTRING", ")"], "docstring": "TODO: should be moved to _check_strategy_and_fallback(). Current test check precision first, so keep this check here to meet error order", "docstring_tokens": ["todo", "should", "be", "moved", "to", "_check_strategy_and_fallback", "current", "test", "check", "precision", "first", "so", "keep", "this", "check", "here", "to", "meet", "error", "order"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 550, "end_line": 602, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "func_name": "function_239", "original_string": "def _register_external_accelerators_and_strategies() -> None:\r\n    \"\"\"Registers all known strategies in other packages.\"\"\"\r\n    if _habana_available_and_importable():\r\n        from lightning_habana import HPUAccelerator, HPUParallelStrategy, SingleHPUStrategy\r\n\r\n        if \"hpu\" not in AcceleratorRegistry:\r\n            HPUAccelerator.register_accelerators(AcceleratorRegistry)\r\n        if \"hpu_parallel\" not in StrategyRegistry:\r\n            HPUParallelStrategy.register_strategies(StrategyRegistry)\r\n        if \"hpu_single\" not in StrategyRegistry:\r\n            SingleHPUStrategy.register_strategies(StrategyRegistry)", "language": "python", "code": "def _register_external_accelerators_and_strategies() -> None:\r\n    \"\"\"Registers all known strategies in other packages.\"\"\"\r\n    if _habana_available_and_importable():\r\n        from lightning_habana import HPUAccelerator, HPUParallelStrategy, SingleHPUStrategy\r\n\r\n        if \"hpu\" not in AcceleratorRegistry:\r\n            HPUAccelerator.register_accelerators(AcceleratorRegistry)\r\n        if \"hpu_parallel\" not in StrategyRegistry:\r\n            HPUParallelStrategy.register_strategies(StrategyRegistry)\r\n        if \"hpu_single\" not in StrategyRegistry:\r\n            SingleHPUStrategy.register_strategies(StrategyRegistry)", "code_tokens": ["def", "_register_external_accelerators_and_strategies", "(", ")", "-", ">", "None", ":", "STRING", "if", "_habana_available_and_importable", "(", ")", ":", "from", "lightning_habana", "import", "HPUAccelerator", ",", "HPUParallelStrategy", ",", "SingleHPUStrategy", "if", "STRING", "not", "in", "AcceleratorRegistry", ":", "HPUAccelerator", ".", "register_accelerators", "(", "AcceleratorRegistry", ")", "if", "STRING", "not", "in", "StrategyRegistry", ":", "HPUParallelStrategy", ".", "register_strategies", "(", "StrategyRegistry", ")", "if", "STRING", "not", "in", "StrategyRegistry", ":", "SingleHPUStrategy", ".", "register_strategies", "(", "StrategyRegistry", ")"], "docstring": "TODO: Prevent registering multiple times", "docstring_tokens": ["todo", "prevent", "registering", "multiple", "times"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py", "start_line": 650, "end_line": 661, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\callback_connector.py", "func_name": "function_240", "original_string": "def _attach_model_callbacks(self) -> None:\r\n        \"\"\"Attaches the callbacks defined in the model.\r\n\r\n        If a callback returned by the model's configure_callback method has the same type as one or several\r\n        callbacks already present in the trainer callbacks list, it will replace them.\r\n        In addition, all :class:`~lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint` callbacks\r\n        will be pushed to the end of the list, ensuring they run last.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        model_callbacks = call._call_lightning_module_hook(trainer, \"configure_callbacks\")\r\n        if not model_callbacks:\r\n            return\r\n\r\n        model_callbacks = [model_callbacks] if not isinstance(model_callbacks, Sequence) else model_callbacks\r\n        model_callback_types = {type(c) for c in model_callbacks}\r\n        trainer_callback_types = {type(c) for c in trainer.callbacks}\r\n        trainer_callback_types.discard(Callback)\r\n        override_types = set()\r\n        for model_cb in model_callback_types:\r\n            for trainer_cb in trainer_callback_types:\r\n                if issubclass(model_cb, trainer_cb):\r\n                    override_types.add(trainer_cb)\r\n                    break\r\n        if override_types:\r\n            rank_zero_info(\r\n                \"The following callbacks returned in `LightningModule.configure_callbacks` will override\"\r\n                \" existing callbacks passed to Trainer:\"\r\n                f\" {', '.join(sorted(t.__name__ for t in override_types))}\"\r\n            )\r\n        all_callbacks = [c for c in trainer.callbacks if type(c) not in override_types]\r\n        all_callbacks.extend(model_callbacks)\r\n        all_callbacks = _CallbackConnector._reorder_callbacks(all_callbacks)\r\n        trainer.callbacks = all_callbacks", "language": "python", "code": "def _attach_model_callbacks(self) -> None:\r\n        \"\"\"Attaches the callbacks defined in the model.\r\n\r\n        If a callback returned by the model's configure_callback method has the same type as one or several\r\n        callbacks already present in the trainer callbacks list, it will replace them.\r\n        In addition, all :class:`~lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint` callbacks\r\n        will be pushed to the end of the list, ensuring they run last.\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n\r\n        model_callbacks = call._call_lightning_module_hook(trainer, \"configure_callbacks\")\r\n        if not model_callbacks:\r\n            return\r\n\r\n        model_callbacks = [model_callbacks] if not isinstance(model_callbacks, Sequence) else model_callbacks\r\n        model_callback_types = {type(c) for c in model_callbacks}\r\n        trainer_callback_types = {type(c) for c in trainer.callbacks}\r\n        trainer_callback_types.discard(Callback)\r\n        override_types = set()\r\n        for model_cb in model_callback_types:\r\n            for trainer_cb in trainer_callback_types:\r\n                if issubclass(model_cb, trainer_cb):\r\n                    override_types.add(trainer_cb)\r\n                    break\r\n        if override_types:\r\n            rank_zero_info(\r\n                \"The following callbacks returned in `LightningModule.configure_callbacks` will override\"\r\n                \" existing callbacks passed to Trainer:\"\r\n                f\" {', '.join(sorted(t.__name__ for t in override_types))}\"\r\n            )\r\n        all_callbacks = [c for c in trainer.callbacks if type(c) not in override_types]\r\n        all_callbacks.extend(model_callbacks)\r\n        all_callbacks = _CallbackConnector._reorder_callbacks(all_callbacks)\r\n        trainer.callbacks = all_callbacks", "code_tokens": ["def", "_attach_model_callbacks", "(", "self", ")", "-", ">", "None", ":", "STRING", "trainer", "=", "self", ".", "trainer", "model_callbacks", "=", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ")", "if", "not", "model_callbacks", ":", "return", "model_callbacks", "=", "[", "model_callbacks", "]", "if", "not", "isinstance", "(", "model_callbacks", ",", "Sequence", ")", "else", "model_callbacks", "model_callback_types", "=", "{", "type", "(", "c", ")", "for", "c", "in", "model_callbacks", "}", "trainer_callback_types", "=", "{", "type", "(", "c", ")", "for", "c", "in", "trainer", ".", "callbacks", "}", "trainer_callback_types", ".", "discard", "(", "Callback", ")", "override_types", "=", "set", "(", ")", "for", "model_cb", "in", "model_callback_types", ":", "for", "trainer_cb", "in", "trainer_callback_types", ":", "if", "issubclass", "(", "model_cb", ",", "trainer_cb", ")", ":", "override_types", ".", "add", "(", "trainer_cb", ")", "break", "if", "override_types", ":", "rank_zero_info", "(", "STRING", "STRING", "fSTRING", ")", "all_callbacks", "=", "[", "c", "for", "c", "in", "trainer", ".", "callbacks", "if", "type", "(", "c", ")", "not", "in", "override_types", "]", "all_callbacks", ".", "extend", "(", "model_callbacks", ")", "all_callbacks", "=", "_CallbackConnector", ".", "_reorder_callbacks", "(", "all_callbacks", ")", "trainer", ".", "callbacks", "=", "all_callbacks"], "docstring": "edge case: if an unmodified callback was added, the logic below would filter it exclude trainer callbacks of the same class or subclass remove all callbacks with a type that occurs in model callbacks TODO: connectors refactor: move callbacks list to connector and do not write Trainer state", "docstring_tokens": ["edge", "case", "if", "an", "unmodified", "callback", "was", "added", "the", "logic", "below", "would", "filter", "it", "exclude", "trainer", "callbacks", "of", "the", "same", "class", "or", "subclass", "remove", "all", "callbacks", "with", "a", "type", "that", "occurs", "in", "model", "callbacks", "todo", "connectors", "refactor", "move", "callbacks", "list", "to", "connector", "and", "do", "not", "write", "trainer", "state"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\callback_connector.py", "start_line": 172, "end_line": 210, "has_examples": false, "num_comments": 4, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_241", "original_string": "def _select_ckpt_path(\r\n        self, state_fn: TrainerFn, ckpt_path: Optional[_PATH], model_provided: bool, model_connected: bool\r\n    ) -> Optional[_PATH]:\r\n        \"\"\"Called by the ``Trainer`` to select the checkpoint path source.\"\"\"\r\n        if self._user_managed:\r\n            if ckpt_path:\r\n                rank_zero_warn(\r\n                    f\"`trainer.ckpt_path = {self._ckpt_path!r}` was called but then you\"\r\n                    f\" passed `trainer.fit(ckpt_path={ckpt_path!r})`. The latter will be loaded.\"\r\n                )\r\n                self._ckpt_path = None\r\n                self._user_managed = False\r\n                ckpt_path = self._parse_ckpt_path(\r\n                    state_fn,\r\n                    ckpt_path,\r\n                    model_provided=model_provided,\r\n                    model_connected=model_connected,\r\n                )\r\n            else:\r\n                ckpt_path = self._ckpt_path\r\n        else:\r\n            ckpt_path = self._parse_ckpt_path(\r\n                state_fn,\r\n                ckpt_path,\r\n                model_provided=model_provided,\r\n                model_connected=model_connected,\r\n            )\r\n        return ckpt_path", "language": "python", "code": "def _select_ckpt_path(\r\n        self, state_fn: TrainerFn, ckpt_path: Optional[_PATH], model_provided: bool, model_connected: bool\r\n    ) -> Optional[_PATH]:\r\n        \"\"\"Called by the ``Trainer`` to select the checkpoint path source.\"\"\"\r\n        if self._user_managed:\r\n            if ckpt_path:\r\n                rank_zero_warn(\r\n                    f\"`trainer.ckpt_path = {self._ckpt_path!r}` was called but then you\"\r\n                    f\" passed `trainer.fit(ckpt_path={ckpt_path!r})`. The latter will be loaded.\"\r\n                )\r\n                self._ckpt_path = None\r\n                self._user_managed = False\r\n                ckpt_path = self._parse_ckpt_path(\r\n                    state_fn,\r\n                    ckpt_path,\r\n                    model_provided=model_provided,\r\n                    model_connected=model_connected,\r\n                )\r\n            else:\r\n                ckpt_path = self._ckpt_path\r\n        else:\r\n            ckpt_path = self._parse_ckpt_path(\r\n                state_fn,\r\n                ckpt_path,\r\n                model_provided=model_provided,\r\n                model_connected=model_connected,\r\n            )\r\n        return ckpt_path", "code_tokens": ["def", "_select_ckpt_path", "(", "self", ",", "state_fn", ":", "TrainerFn", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ",", "model_provided", ":", "bool", ",", "model_connected", ":", "bool", ")", "-", ">", "Optional", "[", "_PATH", "]", ":", "STRING", "if", "self", ".", "_user_managed", ":", "if", "ckpt_path", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", ")", "self", ".", "_ckpt_path", "=", "None", "self", ".", "_user_managed", "=", "False", "ckpt_path", "=", "self", ".", "_parse_ckpt_path", "(", "state_fn", ",", "ckpt_path", ",", "model_provided", "=", "model_provided", ",", "model_connected", "=", "model_connected", ",", ")", "else", ":", "ckpt_path", "=", "self", ".", "_ckpt_path", "else", ":", "ckpt_path", "=", "self", ".", "_parse_ckpt_path", "(", "state_fn", ",", "ckpt_path", ",", "model_provided", "=", "model_provided", ",", "model_connected", "=", "model_connected", ",", ")", "return", "ckpt_path"], "docstring": "reset the previous path", "docstring_tokens": ["reset", "the", "previous", "path"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 85, "end_line": 113, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_242", "original_string": "def _parse_ckpt_path(\r\n        self, state_fn: TrainerFn, ckpt_path: Optional[_PATH], model_provided: bool, model_connected: bool\r\n    ) -> Optional[_PATH]:\r\n        \"\"\"Converts the ``ckpt_path`` special values into an actual filepath, depending on the trainer\r\n        configuration.\"\"\"\r\n        if ckpt_path is None and SLURMEnvironment.detect() and self._hpc_resume_path is not None:\r\n            ckpt_path = \"hpc\"\r\n\r\n        from lightning.pytorch.callbacks.on_exception_checkpoint import OnExceptionCheckpoint\r\n\r\n        ft_checkpoints = [cb for cb in self.trainer.callbacks if isinstance(cb, OnExceptionCheckpoint)]\r\n        fn = state_fn.value\r\n        if ckpt_path is None and ft_checkpoints and self.trainer.state.fn == TrainerFn.FITTING:\r\n            ckpt_path = \"last\"\r\n            rank_zero_warn(\r\n                f\"`.{fn}(ckpt_path=None)` was called without a model.\"\r\n                \" The last model of the previous `fit` call will be used.\"\r\n                f\" You can pass `{fn}(ckpt_path='best')` to use the best model or\"\r\n                f\" `{fn}(ckpt_path='last')` to use the last model.\"\r\n                \" If you pass a value, this warning will be silenced.\"\r\n            )\r\n\r\n        if model_provided and ckpt_path is None:\r\n            return None\r\n\r\n        if model_connected and ckpt_path is None:\r\n            ckpt_path = \"best\"\r\n            ft_tip = (\r\n                \" There is also an on-exception checkpoint available, however it is used by default only when fitting.\"\r\n                if ft_checkpoints\r\n                else \"\"\r\n            )\r\n            rank_zero_warn(\r\n                f\"`.{fn}(ckpt_path=None)` was called without a model.\"\r\n                \" The best model of the previous `fit` call will be used.\"\r\n                + ft_tip\r\n                + f\" You can pass `.{fn}(ckpt_path='best')` to use the best model or\"\r\n                f\" `.{fn}(ckpt_path='last')` to use the last model.\"\r\n                \" If you pass a value, this warning will be silenced.\"\r\n            )\r\n\r\n        if ckpt_path == \"best\":\r\n            if len(self.trainer.checkpoint_callbacks) > 1:\r\n                rank_zero_warn(\r\n                    f'`.{fn}(ckpt_path=\"best\")` is called with Trainer configured with multiple `ModelCheckpoint`'\r\n                    \" callbacks. It will use the best checkpoint path from first checkpoint callback.\"\r\n                )\r\n\r\n            if not self.trainer.checkpoint_callback:\r\n                raise ValueError(f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured.')\r\n\r\n            has_best_model_path = self.trainer.checkpoint_callback.best_model_path\r\n            if hasattr(self.trainer.checkpoint_callback, \"best_model_path\") and not has_best_model_path:\r\n                if self.trainer.fast_dev_run:\r\n                    raise ValueError(\r\n                        f'You cannot execute `.{fn}(ckpt_path=\"best\")` with `fast_dev_run=True`.'\r\n                        f\" Please pass an exact checkpoint path to `.{fn}(ckpt_path=...)`\"\r\n                    )\r\n                raise ValueError(\r\n                    f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.'\r\n                )\r\n            ckpt_path = getattr(self.trainer.checkpoint_callback, \"best_model_path\", None)\r\n\r\n        elif ckpt_path == \"last\":\r\n            candidates = {getattr(ft, \"ckpt_path\", None) for ft in ft_checkpoints}\r\n            for callback in self.trainer.checkpoint_callbacks:\r\n                if isinstance(callback, ModelCheckpoint):\r\n                    candidates |= callback._find_last_checkpoints(self.trainer)\r\n            candidates_fs = {path: get_filesystem(path) for path in candidates if path}\r\n            candidates_ts = {path: fs.modified(path) for path, fs in candidates_fs.items() if fs.exists(path)}\r\n            if not candidates_ts:\r\n                rank_zero_warn(\r\n                    f'.{fn}(ckpt_path=\"last\") is set, but there is no last checkpoint available.'\r\n                    \" No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\"\r\n                )\r\n                return None\r\n            ckpt_path = max(candidates_ts, key=candidates_ts.get)  # type: ignore[arg-type]\r\n\r\n        elif ckpt_path == \"hpc\":\r\n            if not self._hpc_resume_path:\r\n                raise ValueError(\r\n                    f'`.{fn}(ckpt_path=\"hpc\")` is set but no HPC checkpoint was found.'\r\n                    f\" Please pass an exact checkpoint path to `.{fn}(ckpt_path=...)`\"\r\n                )\r\n            ckpt_path = self._hpc_resume_path\r\n\r\n        elif _is_registry(ckpt_path) and module_available(\"litmodels\"):\r\n            ckpt_path = find_model_local_ckpt_path(\r\n                ckpt_path,\r\n                default_model_registry=self.trainer._model_registry,\r\n                default_root_dir=self.trainer.default_root_dir,\r\n            )\r\n\r\n        if not ckpt_path:\r\n            raise ValueError(\r\n                f\"`.{fn}()` found no path for the best weights: {ckpt_path!r}. Please\"\r\n                f\" specify a path for a checkpoint `.{fn}(ckpt_path=PATH)`\"\r\n            )\r\n        return ckpt_path", "language": "python", "code": "def _parse_ckpt_path(\r\n        self, state_fn: TrainerFn, ckpt_path: Optional[_PATH], model_provided: bool, model_connected: bool\r\n    ) -> Optional[_PATH]:\r\n        \"\"\"Converts the ``ckpt_path`` special values into an actual filepath, depending on the trainer\r\n        configuration.\"\"\"\r\n        if ckpt_path is None and SLURMEnvironment.detect() and self._hpc_resume_path is not None:\r\n            ckpt_path = \"hpc\"\r\n\r\n        from lightning.pytorch.callbacks.on_exception_checkpoint import OnExceptionCheckpoint\r\n\r\n        ft_checkpoints = [cb for cb in self.trainer.callbacks if isinstance(cb, OnExceptionCheckpoint)]\r\n        fn = state_fn.value\r\n        if ckpt_path is None and ft_checkpoints and self.trainer.state.fn == TrainerFn.FITTING:\r\n            ckpt_path = \"last\"\r\n            rank_zero_warn(\r\n                f\"`.{fn}(ckpt_path=None)` was called without a model.\"\r\n                \" The last model of the previous `fit` call will be used.\"\r\n                f\" You can pass `{fn}(ckpt_path='best')` to use the best model or\"\r\n                f\" `{fn}(ckpt_path='last')` to use the last model.\"\r\n                \" If you pass a value, this warning will be silenced.\"\r\n            )\r\n\r\n        if model_provided and ckpt_path is None:\r\n            return None\r\n\r\n        if model_connected and ckpt_path is None:\r\n            ckpt_path = \"best\"\r\n            ft_tip = (\r\n                \" There is also an on-exception checkpoint available, however it is used by default only when fitting.\"\r\n                if ft_checkpoints\r\n                else \"\"\r\n            )\r\n            rank_zero_warn(\r\n                f\"`.{fn}(ckpt_path=None)` was called without a model.\"\r\n                \" The best model of the previous `fit` call will be used.\"\r\n                + ft_tip\r\n                + f\" You can pass `.{fn}(ckpt_path='best')` to use the best model or\"\r\n                f\" `.{fn}(ckpt_path='last')` to use the last model.\"\r\n                \" If you pass a value, this warning will be silenced.\"\r\n            )\r\n\r\n        if ckpt_path == \"best\":\r\n            if len(self.trainer.checkpoint_callbacks) > 1:\r\n                rank_zero_warn(\r\n                    f'`.{fn}(ckpt_path=\"best\")` is called with Trainer configured with multiple `ModelCheckpoint`'\r\n                    \" callbacks. It will use the best checkpoint path from first checkpoint callback.\"\r\n                )\r\n\r\n            if not self.trainer.checkpoint_callback:\r\n                raise ValueError(f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured.')\r\n\r\n            has_best_model_path = self.trainer.checkpoint_callback.best_model_path\r\n            if hasattr(self.trainer.checkpoint_callback, \"best_model_path\") and not has_best_model_path:\r\n                if self.trainer.fast_dev_run:\r\n                    raise ValueError(\r\n                        f'You cannot execute `.{fn}(ckpt_path=\"best\")` with `fast_dev_run=True`.'\r\n                        f\" Please pass an exact checkpoint path to `.{fn}(ckpt_path=...)`\"\r\n                    )\r\n                raise ValueError(\r\n                    f'`.{fn}(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.'\r\n                )\r\n            ckpt_path = getattr(self.trainer.checkpoint_callback, \"best_model_path\", None)\r\n\r\n        elif ckpt_path == \"last\":\r\n            candidates = {getattr(ft, \"ckpt_path\", None) for ft in ft_checkpoints}\r\n            for callback in self.trainer.checkpoint_callbacks:\r\n                if isinstance(callback, ModelCheckpoint):\r\n                    candidates |= callback._find_last_checkpoints(self.trainer)\r\n            candidates_fs = {path: get_filesystem(path) for path in candidates if path}\r\n            candidates_ts = {path: fs.modified(path) for path, fs in candidates_fs.items() if fs.exists(path)}\r\n            if not candidates_ts:\r\n                rank_zero_warn(\r\n                    f'.{fn}(ckpt_path=\"last\") is set, but there is no last checkpoint available.'\r\n                    \" No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\"\r\n                )\r\n                return None\r\n            ckpt_path = max(candidates_ts, key=candidates_ts.get)  # type: ignore[arg-type]\r\n\r\n        elif ckpt_path == \"hpc\":\r\n            if not self._hpc_resume_path:\r\n                raise ValueError(\r\n                    f'`.{fn}(ckpt_path=\"hpc\")` is set but no HPC checkpoint was found.'\r\n                    f\" Please pass an exact checkpoint path to `.{fn}(ckpt_path=...)`\"\r\n                )\r\n            ckpt_path = self._hpc_resume_path\r\n\r\n        elif _is_registry(ckpt_path) and module_available(\"litmodels\"):\r\n            ckpt_path = find_model_local_ckpt_path(\r\n                ckpt_path,\r\n                default_model_registry=self.trainer._model_registry,\r\n                default_root_dir=self.trainer.default_root_dir,\r\n            )\r\n\r\n        if not ckpt_path:\r\n            raise ValueError(\r\n                f\"`.{fn}()` found no path for the best weights: {ckpt_path!r}. Please\"\r\n                f\" specify a path for a checkpoint `.{fn}(ckpt_path=PATH)`\"\r\n            )\r\n        return ckpt_path", "code_tokens": ["def", "_parse_ckpt_path", "(", "self", ",", "state_fn", ":", "TrainerFn", ",", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ",", "model_provided", ":", "bool", ",", "model_connected", ":", "bool", ")", "-", ">", "Optional", "[", "_PATH", "]", ":", "STRING", "if", "ckpt_path", "is", "None", "and", "SLURMEnvironment", ".", "detect", "(", ")", "and", "self", ".", "_hpc_resume_path", "is", "not", "None", ":", "ckpt_path", "=", "STRING", "from", "lightning", ".", "pytorch", ".", "callbacks", ".", "on_exception_checkpoint", "import", "OnExceptionCheckpoint", "ft_checkpoints", "=", "[", "cb", "for", "cb", "in", "self", ".", "trainer", ".", "callbacks", "if", "isinstance", "(", "cb", ",", "OnExceptionCheckpoint", ")", "]", "fn", "=", "state_fn", ".", "value", "if", "ckpt_path", "is", "None", "and", "ft_checkpoints", "and", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "ckpt_path", "=", "STRING", "rank_zero_warn", "(", "fSTRING", "STRING", "fSTRING", "fSTRING", "STRING", ")", "if", "model_provided", "and", "ckpt_path", "is", "None", ":", "return", "None", "if", "model_connected", "and", "ckpt_path", "is", "None", ":", "ckpt_path", "=", "STRING", "ft_tip", "=", "(", "STRING", "if", "ft_checkpoints", "else", "STRING", ")", "rank_zero_warn", "(", "fSTRING", "STRING", "+", "ft_tip", "+", "fSTRING", "fSTRING", "STRING", ")", "if", "ckpt_path", "=", "=", "STRING", ":", "if", "len", "(", "self", ".", "trainer", ".", "checkpoint_callbacks", ")", ">", "1", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ")", "if", "not", "self", ".", "trainer", ".", "checkpoint_callback", ":", "raise", "ValueError", "(", "fSTRING", ")", "has_best_model_path", "=", "self", ".", "trainer", ".", "checkpoint_callback", ".", "best_model_path", "if", "hasattr", "(", "self", ".", "trainer", ".", "checkpoint_callback", ",", "STRING", ")", "and", "not", "has_best_model_path", ":", "if", "self", ".", "trainer", ".", "fast_dev_run", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "raise", "ValueError", "(", "fSTRING", ")", "ckpt_path", "=", "getattr", "(", "self", ".", "trainer", ".", "checkpoint_callback", ",", "STRING", ",", "None", ")", "elif", "ckpt_path", "=", "=", "STRING", ":", "candidates", "=", "{", "getattr", "(", "ft", ",", "STRING", ",", "None", ")", "for", "ft", "in", "ft_checkpoints", "}", "for", "callback", "in", "self", ".", "trainer", ".", "checkpoint_callbacks", ":", "if", "isinstance", "(", "callback", ",", "ModelCheckpoint", ")", ":", "candidates", "|", "=", "callback", ".", "_find_last_checkpoints", "(", "self", ".", "trainer", ")", "candidates_fs", "=", "{", "path", ":", "get_filesystem", "(", "path", ")", "for", "path", "in", "candidates", "if", "path", "}", "candidates_ts", "=", "{", "path", ":", "fs", ".", "modified", "(", "path", ")", "for", "path", ",", "fs", "in", "candidates_fs", ".", "items", "(", ")", "if", "fs", ".", "exists", "(", "path", ")", "}", "if", "not", "candidates_ts", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ")", "return", "None", "ckpt_path", "=", "max", "(", "candidates_ts", ",", "key", "=", "candidates_ts", ".", "get", ")", "#", "type", ":", "ignore", "[", "arg", "-", "type", "]", "elif", "ckpt_path", "=", "=", "STRING", ":", "if", "not", "self", ".", "_hpc_resume_path", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "ckpt_path", "=", "self", ".", "_hpc_resume_path", "elif", "_is_registry", "(", "ckpt_path", ")", "and", "module_available", "(", "STRING", ")", ":", "ckpt_path", "=", "find_model_local_ckpt_path", "(", "ckpt_path", ",", "default_model_registry", "=", "self", ".", "trainer", ".", "_model_registry", ",", "default_root_dir", "=", "self", ".", "trainer", ".", "default_root_dir", ",", ")", "if", "not", "ckpt_path", ":", "raise", "ValueError", "(", "fSTRING", "fSTRING", ")", "return", "ckpt_path"], "docstring": "use passed model to function without loading weights load best weights not an error so it can be set and forget before the first `fit` run", "docstring_tokens": ["use", "passed", "model", "to", "function", "without", "loading", "weights", "load", "best", "weights", "not", "an", "error", "so", "it", "can", "be", "set", "and", "forget", "before", "the", "first", "fit", "run"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 115, "end_line": 216, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_243", "original_string": "def resume_end(self) -> None:\r\n        \"\"\"Signal the connector that all states have resumed and memory for the checkpoint object can be released.\"\"\"\r\n        assert self.trainer.state.fn is not None\r\n        if self._ckpt_path:\r\n            message = \"Restored all states\" if self.trainer.state.fn == TrainerFn.FITTING else \"Loaded model weights\"\r\n            rank_zero_info(f\"{message} from the checkpoint at {self._ckpt_path}\")\r\n\r\n        self._loaded_checkpoint = {}\r\n        torch.cuda.empty_cache()\r\n\r\n        self.trainer.strategy.barrier(\"_CheckpointConnector.resume_end\")", "language": "python", "code": "def resume_end(self) -> None:\r\n        \"\"\"Signal the connector that all states have resumed and memory for the checkpoint object can be released.\"\"\"\r\n        assert self.trainer.state.fn is not None\r\n        if self._ckpt_path:\r\n            message = \"Restored all states\" if self.trainer.state.fn == TrainerFn.FITTING else \"Loaded model weights\"\r\n            rank_zero_info(f\"{message} from the checkpoint at {self._ckpt_path}\")\r\n\r\n        self._loaded_checkpoint = {}\r\n        torch.cuda.empty_cache()\r\n\r\n        self.trainer.strategy.barrier(\"_CheckpointConnector.resume_end\")", "code_tokens": ["def", "resume_end", "(", "self", ")", "-", ">", "None", ":", "STRING", "assert", "self", ".", "trainer", ".", "state", ".", "fn", "is", "not", "None", "if", "self", ".", "_ckpt_path", ":", "message", "=", "STRING", "if", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", "else", "STRING", "rank_zero_info", "(", "fSTRING", ")", "self", ".", "_loaded_checkpoint", "=", "{", "}", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "self", ".", "trainer", ".", "strategy", ".", "barrier", "(", "STRING", ")"], "docstring": "free memory wait for all to catch up", "docstring_tokens": ["free", "memory", "wait", "for", "all", "to", "catch", "up"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 218, "end_line": 230, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_244", "original_string": "def restore(self, checkpoint_path: Optional[_PATH] = None) -> None:\r\n        \"\"\"Attempt to restore everything at once from a 'PyTorch-Lightning checkpoint' file through file-read and\r\n        state-restore, in this priority:\r\n\r\n        1. from HPC weights if found\r\n        2. from `checkpoint_path` file if provided\r\n        3. don't restore\r\n\r\n        All restored states are listed in return value description of `dump_checkpoint`.\r\n\r\n        Args:\r\n            checkpoint_path: Path to a PyTorch Lightning checkpoint file.\r\n\r\n        \"\"\"\r\n        self.resume_start(checkpoint_path)\r\n\r\n        self.restore_datamodule()\r\n        self.restore_model()\r\n\r\n        self.restore_callbacks()\r\n\r\n        self.restore_training_state()\r\n        self.resume_end()", "language": "python", "code": "def restore(self, checkpoint_path: Optional[_PATH] = None) -> None:\r\n        \"\"\"Attempt to restore everything at once from a 'PyTorch-Lightning checkpoint' file through file-read and\r\n        state-restore, in this priority:\r\n\r\n        1. from HPC weights if found\r\n        2. from `checkpoint_path` file if provided\r\n        3. don't restore\r\n\r\n        All restored states are listed in return value description of `dump_checkpoint`.\r\n\r\n        Args:\r\n            checkpoint_path: Path to a PyTorch Lightning checkpoint file.\r\n\r\n        \"\"\"\r\n        self.resume_start(checkpoint_path)\r\n\r\n        self.restore_datamodule()\r\n        self.restore_model()\r\n\r\n        self.restore_callbacks()\r\n\r\n        self.restore_training_state()\r\n        self.resume_end()", "code_tokens": ["def", "restore", "(", "self", ",", "checkpoint_path", ":", "Optional", "[", "_PATH", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "self", ".", "resume_start", "(", "checkpoint_path", ")", "self", ".", "restore_datamodule", "(", ")", "self", ".", "restore_model", "(", ")", "self", ".", "restore_callbacks", "(", ")", "self", ".", "restore_training_state", "(", ")", "self", ".", "resume_end", "(", ")"], "docstring": "restore module states restore callback states restore training state", "docstring_tokens": ["restore", "module", "states", "restore", "callback", "states", "restore", "training", "state"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 232, "end_line": 257, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_245", "original_string": "def restore_model(self) -> None:\r\n        \"\"\"Restores a model's weights from a PyTorch Lightning checkpoint.\r\n\r\n        Hooks are called first to give the LightningModule a chance to modify the contents, then finally the model gets\r\n        updated with the loaded weights.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        call._call_lightning_module_hook(self.trainer, \"on_load_checkpoint\", self._loaded_checkpoint)\r\n\r\n        self.trainer.strategy.load_model_state_dict(\r\n            self._loaded_checkpoint,\r\n            strict=self.trainer.lightning_module.strict_loading,\r\n        )", "language": "python", "code": "def restore_model(self) -> None:\r\n        \"\"\"Restores a model's weights from a PyTorch Lightning checkpoint.\r\n\r\n        Hooks are called first to give the LightningModule a chance to modify the contents, then finally the model gets\r\n        updated with the loaded weights.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        call._call_lightning_module_hook(self.trainer, \"on_load_checkpoint\", self._loaded_checkpoint)\r\n\r\n        self.trainer.strategy.load_model_state_dict(\r\n            self._loaded_checkpoint,\r\n            strict=self.trainer.lightning_module.strict_loading,\r\n        )", "code_tokens": ["def", "restore_model", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "call", ".", "_call_lightning_module_hook", "(", "self", ".", "trainer", ",", "STRING", ",", "self", ".", "_loaded_checkpoint", ")", "self", ".", "trainer", ".", "strategy", ".", "load_model_state_dict", "(", "self", ".", "_loaded_checkpoint", ",", "strict", "=", "self", ".", "trainer", ".", "lightning_module", ".", "strict_loading", ",", ")"], "docstring": "hook: give user access to checkpoint if needed. restore model state_dict", "docstring_tokens": ["hook", "give", "user", "access", "to", "checkpoint", "if", "needed", "restore", "model", "state_dict"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 271, "end_line": 288, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_246", "original_string": "def restore_training_state(self) -> None:\r\n        \"\"\"Restore the trainer state from the pre-loaded checkpoint.\r\n\r\n        This includes the precision settings, loop progress, optimizer states and learning rate scheduler states.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        self.restore_precision_plugin_state()\r\n\r\n        self.restore_loops()\r\n\r\n        assert self.trainer.state.fn is not None\r\n        if self.trainer.state.fn == TrainerFn.FITTING:\r\n            self.restore_optimizers_and_schedulers()", "language": "python", "code": "def restore_training_state(self) -> None:\r\n        \"\"\"Restore the trainer state from the pre-loaded checkpoint.\r\n\r\n        This includes the precision settings, loop progress, optimizer states and learning rate scheduler states.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        self.restore_precision_plugin_state()\r\n\r\n        self.restore_loops()\r\n\r\n        assert self.trainer.state.fn is not None\r\n        if self.trainer.state.fn == TrainerFn.FITTING:\r\n            self.restore_optimizers_and_schedulers()", "code_tokens": ["def", "restore_training_state", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "self", ".", "restore_precision_plugin_state", "(", ")", "self", ".", "restore_loops", "(", ")", "assert", "self", ".", "trainer", ".", "state", ".", "fn", "is", "not", "None", "if", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "self", ".", "restore_optimizers_and_schedulers", "(", ")"], "docstring": "restore precision plugin (scaler etc.) restore loops and their progress restore optimizers and schedulers state", "docstring_tokens": ["restore", "precision", "plugin", "scaler", "etc", "restore", "loops", "and", "their", "progress", "restore", "optimizers", "and", "schedulers", "state"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 290, "end_line": 308, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_247", "original_string": "def restore_precision_plugin_state(self) -> None:\r\n        \"\"\"Restore the precision plugin state from the pre-loaded checkpoint.\"\"\"\r\n        prec_plugin = self.trainer.precision_plugin\r\n        prec_plugin.on_load_checkpoint(self._loaded_checkpoint)\r\n        if prec_plugin.__class__.__qualname__ in self._loaded_checkpoint:\r\n            prec_plugin.load_state_dict(self._loaded_checkpoint[prec_plugin.__class__.__qualname__])\r\n\r\n        if \"native_amp_scaling_state\" in self._loaded_checkpoint and isinstance(prec_plugin, MixedPrecision):\r\n            prec_plugin.load_state_dict(self._loaded_checkpoint[\"native_amp_scaling_state\"])", "language": "python", "code": "def restore_precision_plugin_state(self) -> None:\r\n        \"\"\"Restore the precision plugin state from the pre-loaded checkpoint.\"\"\"\r\n        prec_plugin = self.trainer.precision_plugin\r\n        prec_plugin.on_load_checkpoint(self._loaded_checkpoint)\r\n        if prec_plugin.__class__.__qualname__ in self._loaded_checkpoint:\r\n            prec_plugin.load_state_dict(self._loaded_checkpoint[prec_plugin.__class__.__qualname__])\r\n\r\n        if \"native_amp_scaling_state\" in self._loaded_checkpoint and isinstance(prec_plugin, MixedPrecision):\r\n            prec_plugin.load_state_dict(self._loaded_checkpoint[\"native_amp_scaling_state\"])", "code_tokens": ["def", "restore_precision_plugin_state", "(", "self", ")", "-", ">", "None", ":", "STRING", "prec_plugin", "=", "self", ".", "trainer", ".", "precision_plugin", "prec_plugin", ".", "on_load_checkpoint", "(", "self", ".", "_loaded_checkpoint", ")", "if", "prec_plugin", ".", "__class__", ".", "__qualname__", "in", "self", ".", "_loaded_checkpoint", ":", "prec_plugin", ".", "load_state_dict", "(", "self", ".", "_loaded_checkpoint", "[", "prec_plugin", ".", "__class__", ".", "__qualname__", "]", ")", "if", "STRING", "in", "self", ".", "_loaded_checkpoint", "and", "isinstance", "(", "prec_plugin", ",", "MixedPrecision", ")", ":", "prec_plugin", ".", "load_state_dict", "(", "self", ".", "_loaded_checkpoint", "[", "STRING", "]", ")"], "docstring": "old checkpoints compatibility", "docstring_tokens": ["old", "checkpoints", "compatibility"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 310, "end_line": 319, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_248", "original_string": "def restore_loops(self) -> None:\r\n        \"\"\"Restores the loop progress from the pre-loaded checkpoint.\r\n\r\n        Calls hooks on the loops to give it a chance to restore its state from the checkpoint.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        fit_loop = self.trainer.fit_loop\r\n        assert self.trainer.state.fn is not None\r\n        state_dict = self._loaded_checkpoint.get(\"loops\")\r\n        if state_dict is not None:\r\n            if self.trainer.state.fn == TrainerFn.FITTING:\r\n                fit_loop.load_state_dict(state_dict[\"fit_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.VALIDATING:\r\n                self.trainer.validate_loop.load_state_dict(state_dict[\"validate_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.TESTING:\r\n                self.trainer.test_loop.load_state_dict(state_dict[\"test_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.PREDICTING:\r\n                self.trainer.predict_loop.load_state_dict(state_dict[\"predict_loop\"])\r\n\r\n        if self.trainer.state.fn != TrainerFn.FITTING:\r\n            return\r\n\r\n        if (\r\n            self.trainer.max_epochs != -1\r\n            and self.trainer.max_epochs is not None\r\n            and self.trainer.current_epoch > self.trainer.max_epochs\r\n        ):\r\n            raise MisconfigurationException(\r\n                f\"You restored a checkpoint with current_epoch={self.trainer.current_epoch},\"\r\n                f\" but you have set Trainer(max_epochs={self.trainer.max_epochs}).\"\r\n            )", "language": "python", "code": "def restore_loops(self) -> None:\r\n        \"\"\"Restores the loop progress from the pre-loaded checkpoint.\r\n\r\n        Calls hooks on the loops to give it a chance to restore its state from the checkpoint.\r\n\r\n        \"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        fit_loop = self.trainer.fit_loop\r\n        assert self.trainer.state.fn is not None\r\n        state_dict = self._loaded_checkpoint.get(\"loops\")\r\n        if state_dict is not None:\r\n            if self.trainer.state.fn == TrainerFn.FITTING:\r\n                fit_loop.load_state_dict(state_dict[\"fit_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.VALIDATING:\r\n                self.trainer.validate_loop.load_state_dict(state_dict[\"validate_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.TESTING:\r\n                self.trainer.test_loop.load_state_dict(state_dict[\"test_loop\"])\r\n            elif self.trainer.state.fn == TrainerFn.PREDICTING:\r\n                self.trainer.predict_loop.load_state_dict(state_dict[\"predict_loop\"])\r\n\r\n        if self.trainer.state.fn != TrainerFn.FITTING:\r\n            return\r\n\r\n        if (\r\n            self.trainer.max_epochs != -1\r\n            and self.trainer.max_epochs is not None\r\n            and self.trainer.current_epoch > self.trainer.max_epochs\r\n        ):\r\n            raise MisconfigurationException(\r\n                f\"You restored a checkpoint with current_epoch={self.trainer.current_epoch},\"\r\n                f\" but you have set Trainer(max_epochs={self.trainer.max_epochs}).\"\r\n            )", "code_tokens": ["def", "restore_loops", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "fit_loop", "=", "self", ".", "trainer", ".", "fit_loop", "assert", "self", ".", "trainer", ".", "state", ".", "fn", "is", "not", "None", "state_dict", "=", "self", ".", "_loaded_checkpoint", ".", "get", "(", "STRING", ")", "if", "state_dict", "is", "not", "None", ":", "if", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "FITTING", ":", "fit_loop", ".", "load_state_dict", "(", "state_dict", "[", "STRING", "]", ")", "elif", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "VALIDATING", ":", "self", ".", "trainer", ".", "validate_loop", ".", "load_state_dict", "(", "state_dict", "[", "STRING", "]", ")", "elif", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "TESTING", ":", "self", ".", "trainer", ".", "test_loop", ".", "load_state_dict", "(", "state_dict", "[", "STRING", "]", ")", "elif", "self", ".", "trainer", ".", "state", ".", "fn", "=", "=", "TrainerFn", ".", "PREDICTING", ":", "self", ".", "trainer", ".", "predict_loop", ".", "load_state_dict", "(", "state_dict", "[", "STRING", "]", ")", "if", "self", ".", "trainer", ".", "state", ".", "fn", "!", "=", "TrainerFn", ".", "FITTING", ":", "return", "if", "(", "self", ".", "trainer", ".", "max_epochs", "!", "=", "-", "1", "and", "self", ".", "trainer", ".", "max_epochs", "is", "not", "None", "and", "self", ".", "trainer", ".", "current_epoch", ">", "self", ".", "trainer", ".", "max_epochs", ")", ":", "raise", "MisconfigurationException", "(", "fSTRING", "fSTRING", ")"], "docstring": "crash if max_epochs is lower then the current epoch from the checkpoint", "docstring_tokens": ["crash", "if", "max_epochs", "is", "lower", "then", "the", "current", "epoch", "from", "the", "checkpoint"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 330, "end_line": 364, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_249", "original_string": "def restore_optimizers_and_schedulers(self) -> None:\r\n        \"\"\"Restores the optimizers and learning rate scheduler states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        if self.trainer.strategy.lightning_restore_optimizer:\r\n            if \"optimizer_states\" not in self._loaded_checkpoint:\r\n                raise KeyError(\r\n                    \"Trying to restore optimizer state but checkpoint contains only the model.\"\r\n                    \" This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\"\r\n                )\r\n            self.restore_optimizers()\r\n\r\n        if \"lr_schedulers\" not in self._loaded_checkpoint:\r\n            raise KeyError(\r\n                \"Trying to restore learning rate scheduler state but checkpoint contains only the model.\"\r\n                \" This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\"\r\n            )\r\n        self.restore_lr_schedulers()", "language": "python", "code": "def restore_optimizers_and_schedulers(self) -> None:\r\n        \"\"\"Restores the optimizers and learning rate scheduler states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        if self.trainer.strategy.lightning_restore_optimizer:\r\n            if \"optimizer_states\" not in self._loaded_checkpoint:\r\n                raise KeyError(\r\n                    \"Trying to restore optimizer state but checkpoint contains only the model.\"\r\n                    \" This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\"\r\n                )\r\n            self.restore_optimizers()\r\n\r\n        if \"lr_schedulers\" not in self._loaded_checkpoint:\r\n            raise KeyError(\r\n                \"Trying to restore learning rate scheduler state but checkpoint contains only the model.\"\r\n                \" This is probably due to `ModelCheckpoint.save_weights_only` being set to `True`.\"\r\n            )\r\n        self.restore_lr_schedulers()", "code_tokens": ["def", "restore_optimizers_and_schedulers", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "if", "self", ".", "trainer", ".", "strategy", ".", "lightning_restore_optimizer", ":", "if", "STRING", "not", "in", "self", ".", "_loaded_checkpoint", ":", "raise", "KeyError", "(", "STRING", "STRING", ")", "self", ".", "restore_optimizers", "(", ")", "if", "STRING", "not", "in", "self", ".", "_loaded_checkpoint", ":", "raise", "KeyError", "(", "STRING", "STRING", ")", "self", ".", "restore_lr_schedulers", "(", ")"], "docstring": "validation", "docstring_tokens": ["validation"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 366, "end_line": 385, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_250", "original_string": "def restore_optimizers(self) -> None:\r\n        \"\"\"Restores the optimizer states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)", "language": "python", "code": "def restore_optimizers(self) -> None:\r\n        \"\"\"Restores the optimizer states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)", "code_tokens": ["def", "restore_optimizers", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "self", ".", "trainer", ".", "strategy", ".", "load_optimizer_state_dict", "(", "self", ".", "_loaded_checkpoint", ")"], "docstring": "restore the optimizers", "docstring_tokens": ["restore", "the", "optimizers"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 387, "end_line": 393, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_251", "original_string": "def restore_lr_schedulers(self) -> None:\r\n        \"\"\"Restores the learning rate scheduler states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        lr_schedulers = self._loaded_checkpoint[\"lr_schedulers\"]\r\n        for config, lrs_state in zip(self.trainer.lr_scheduler_configs, lr_schedulers):\r\n            config.scheduler.load_state_dict(lrs_state)", "language": "python", "code": "def restore_lr_schedulers(self) -> None:\r\n        \"\"\"Restores the learning rate scheduler states from the pre-loaded checkpoint.\"\"\"\r\n        if not self._loaded_checkpoint:\r\n            return\r\n\r\n        lr_schedulers = self._loaded_checkpoint[\"lr_schedulers\"]\r\n        for config, lrs_state in zip(self.trainer.lr_scheduler_configs, lr_schedulers):\r\n            config.scheduler.load_state_dict(lrs_state)", "code_tokens": ["def", "restore_lr_schedulers", "(", "self", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "_loaded_checkpoint", ":", "return", "lr_schedulers", "=", "self", ".", "_loaded_checkpoint", "[", "STRING", "]", "for", "config", ",", "lrs_state", "in", "zip", "(", "self", ".", "trainer", ".", "lr_scheduler_configs", ",", "lr_schedulers", ")", ":", "config", ".", "scheduler", ".", "load_state_dict", "(", "lrs_state", ")"], "docstring": "restore the lr schedulers", "docstring_tokens": ["restore", "the", "lr", "schedulers"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 395, "end_line": 403, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_252", "original_string": "def dump_checkpoint(self, weights_only: bool = False) -> dict:\r\n        \"\"\"Creating a model checkpoint dictionary object from various component states.\r\n\r\n        Args:\r\n            weights_only: saving model weights only\r\n        Return:\r\n            structured dictionary: {\r\n                'epoch':                     training epoch\r\n                'global_step':               training global step\r\n                'pytorch-lightning_version': The version of PyTorch Lightning that produced this checkpoint\r\n                'callbacks':                 \"callback specific state\"[] # if not weights_only\r\n                'optimizer_states':          \"PT optim's state_dict\"[]   # if not weights_only\r\n                'lr_schedulers':             \"PT sched's state_dict\"[]   # if not weights_only\r\n                'state_dict':                Model's state_dict (e.g. network weights)\r\n                precision_plugin.__class__.__qualname__:  precision plugin state_dict # if not weights_only\r\n                CHECKPOINT_HYPER_PARAMS_NAME:\r\n                CHECKPOINT_HYPER_PARAMS_KEY:\r\n                CHECKPOINT_HYPER_PARAMS_TYPE:\r\n                something_cool_i_want_to_save: anything you define through model.on_save_checkpoint\r\n                LightningDataModule.__class__.__qualname__: pl DataModule's state\r\n            }\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        model = trainer.lightning_module\r\n        datamodule = trainer.datamodule\r\n\r\n        checkpoint = {\r\n            \"epoch\": trainer.current_epoch,\r\n            \"global_step\": trainer.global_step,\r\n            \"pytorch-lightning_version\": pl.__version__,\r\n            \"state_dict\": self._get_lightning_module_state_dict(),\r\n            \"loops\": self._get_loops_state_dict(),\r\n        }\r\n\r\n        if not weights_only:\r\n            checkpoint[\"callbacks\"] = call._call_callbacks_state_dict(trainer)\r\n\r\n            optimizer_states = []\r\n            for i, optimizer in enumerate(trainer.optimizers):\r\n                optimizer_state = trainer.strategy.optimizer_state(optimizer)\r\n                optimizer_states.append(optimizer_state)\r\n\r\n            checkpoint[\"optimizer_states\"] = optimizer_states\r\n\r\n            lr_schedulers = []\r\n            for config in trainer.lr_scheduler_configs:\r\n                lr_schedulers.append(config.scheduler.state_dict())\r\n            checkpoint[\"lr_schedulers\"] = lr_schedulers\r\n\r\n            prec_plugin = trainer.precision_plugin\r\n            prec_plugin_state_dict = prec_plugin.state_dict()\r\n            if prec_plugin_state_dict:\r\n                checkpoint[prec_plugin.__class__.__qualname__] = prec_plugin_state_dict\r\n            prec_plugin.on_save_checkpoint(checkpoint)\r\n\r\n        if _OMEGACONF_AVAILABLE:\r\n            from omegaconf import Container\r\n\r\n        for obj in (model, datamodule):\r\n            if obj and obj.hparams:\r\n                if hasattr(obj, \"_hparams_name\"):\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_NAME] = obj._hparams_name\r\n                if _OMEGACONF_AVAILABLE and isinstance(obj.hparams, Container):\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_KEY] = obj.hparams\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_TYPE] = type(obj.hparams)\r\n                else:\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_KEY] = dict(obj.hparams)\r\n\r\n        if datamodule is not None:\r\n            datamodule_state_dict = call._call_lightning_datamodule_hook(trainer, \"state_dict\")\r\n            if datamodule_state_dict:\r\n                checkpoint[datamodule.__class__.__qualname__] = datamodule_state_dict\r\n\r\n        if not weights_only:\r\n            call._call_callbacks_on_save_checkpoint(trainer, checkpoint)\r\n        call._call_lightning_module_hook(trainer, \"on_save_checkpoint\", checkpoint)\r\n        return checkpoint", "language": "python", "code": "def dump_checkpoint(self, weights_only: bool = False) -> dict:\r\n        \"\"\"Creating a model checkpoint dictionary object from various component states.\r\n\r\n        Args:\r\n            weights_only: saving model weights only\r\n        Return:\r\n            structured dictionary: {\r\n                'epoch':                     training epoch\r\n                'global_step':               training global step\r\n                'pytorch-lightning_version': The version of PyTorch Lightning that produced this checkpoint\r\n                'callbacks':                 \"callback specific state\"[] # if not weights_only\r\n                'optimizer_states':          \"PT optim's state_dict\"[]   # if not weights_only\r\n                'lr_schedulers':             \"PT sched's state_dict\"[]   # if not weights_only\r\n                'state_dict':                Model's state_dict (e.g. network weights)\r\n                precision_plugin.__class__.__qualname__:  precision plugin state_dict # if not weights_only\r\n                CHECKPOINT_HYPER_PARAMS_NAME:\r\n                CHECKPOINT_HYPER_PARAMS_KEY:\r\n                CHECKPOINT_HYPER_PARAMS_TYPE:\r\n                something_cool_i_want_to_save: anything you define through model.on_save_checkpoint\r\n                LightningDataModule.__class__.__qualname__: pl DataModule's state\r\n            }\r\n\r\n        \"\"\"\r\n        trainer = self.trainer\r\n        model = trainer.lightning_module\r\n        datamodule = trainer.datamodule\r\n\r\n        checkpoint = {\r\n            \"epoch\": trainer.current_epoch,\r\n            \"global_step\": trainer.global_step,\r\n            \"pytorch-lightning_version\": pl.__version__,\r\n            \"state_dict\": self._get_lightning_module_state_dict(),\r\n            \"loops\": self._get_loops_state_dict(),\r\n        }\r\n\r\n        if not weights_only:\r\n            checkpoint[\"callbacks\"] = call._call_callbacks_state_dict(trainer)\r\n\r\n            optimizer_states = []\r\n            for i, optimizer in enumerate(trainer.optimizers):\r\n                optimizer_state = trainer.strategy.optimizer_state(optimizer)\r\n                optimizer_states.append(optimizer_state)\r\n\r\n            checkpoint[\"optimizer_states\"] = optimizer_states\r\n\r\n            lr_schedulers = []\r\n            for config in trainer.lr_scheduler_configs:\r\n                lr_schedulers.append(config.scheduler.state_dict())\r\n            checkpoint[\"lr_schedulers\"] = lr_schedulers\r\n\r\n            prec_plugin = trainer.precision_plugin\r\n            prec_plugin_state_dict = prec_plugin.state_dict()\r\n            if prec_plugin_state_dict:\r\n                checkpoint[prec_plugin.__class__.__qualname__] = prec_plugin_state_dict\r\n            prec_plugin.on_save_checkpoint(checkpoint)\r\n\r\n        if _OMEGACONF_AVAILABLE:\r\n            from omegaconf import Container\r\n\r\n        for obj in (model, datamodule):\r\n            if obj and obj.hparams:\r\n                if hasattr(obj, \"_hparams_name\"):\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_NAME] = obj._hparams_name\r\n                if _OMEGACONF_AVAILABLE and isinstance(obj.hparams, Container):\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_KEY] = obj.hparams\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_TYPE] = type(obj.hparams)\r\n                else:\r\n                    checkpoint[obj.CHECKPOINT_HYPER_PARAMS_KEY] = dict(obj.hparams)\r\n\r\n        if datamodule is not None:\r\n            datamodule_state_dict = call._call_lightning_datamodule_hook(trainer, \"state_dict\")\r\n            if datamodule_state_dict:\r\n                checkpoint[datamodule.__class__.__qualname__] = datamodule_state_dict\r\n\r\n        if not weights_only:\r\n            call._call_callbacks_on_save_checkpoint(trainer, checkpoint)\r\n        call._call_lightning_module_hook(trainer, \"on_save_checkpoint\", checkpoint)\r\n        return checkpoint", "code_tokens": ["def", "dump_checkpoint", "(", "self", ",", "weights_only", ":", "bool", "=", "False", ")", "-", ">", "dict", ":", "STRING", "trainer", "=", "self", ".", "trainer", "model", "=", "trainer", ".", "lightning_module", "datamodule", "=", "trainer", ".", "datamodule", "checkpoint", "=", "{", "STRING", ":", "trainer", ".", "current_epoch", ",", "STRING", ":", "trainer", ".", "global_step", ",", "STRING", ":", "pl", ".", "__version__", ",", "STRING", ":", "self", ".", "_get_lightning_module_state_dict", "(", ")", ",", "STRING", ":", "self", ".", "_get_loops_state_dict", "(", ")", ",", "}", "if", "not", "weights_only", ":", "checkpoint", "[", "STRING", "]", "=", "call", ".", "_call_callbacks_state_dict", "(", "trainer", ")", "optimizer_states", "=", "[", "]", "for", "i", ",", "optimizer", "in", "enumerate", "(", "trainer", ".", "optimizers", ")", ":", "optimizer_state", "=", "trainer", ".", "strategy", ".", "optimizer_state", "(", "optimizer", ")", "optimizer_states", ".", "append", "(", "optimizer_state", ")", "checkpoint", "[", "STRING", "]", "=", "optimizer_states", "lr_schedulers", "=", "[", "]", "for", "config", "in", "trainer", ".", "lr_scheduler_configs", ":", "lr_schedulers", ".", "append", "(", "config", ".", "scheduler", ".", "state_dict", "(", ")", ")", "checkpoint", "[", "STRING", "]", "=", "lr_schedulers", "prec_plugin", "=", "trainer", ".", "precision_plugin", "prec_plugin_state_dict", "=", "prec_plugin", ".", "state_dict", "(", ")", "if", "prec_plugin_state_dict", ":", "checkpoint", "[", "prec_plugin", ".", "__class__", ".", "__qualname__", "]", "=", "prec_plugin_state_dict", "prec_plugin", ".", "on_save_checkpoint", "(", "checkpoint", ")", "if", "_OMEGACONF_AVAILABLE", ":", "from", "omegaconf", "import", "Container", "for", "obj", "in", "(", "model", ",", "datamodule", ")", ":", "if", "obj", "and", "obj", ".", "hparams", ":", "if", "hasattr", "(", "obj", ",", "STRING", ")", ":", "checkpoint", "[", "obj", ".", "CHECKPOINT_HYPER_PARAMS_NAME", "]", "=", "obj", ".", "_hparams_name", "if", "_OMEGACONF_AVAILABLE", "and", "isinstance", "(", "obj", ".", "hparams", ",", "Container", ")", ":", "checkpoint", "[", "obj", ".", "CHECKPOINT_HYPER_PARAMS_KEY", "]", "=", "obj", ".", "hparams", "checkpoint", "[", "obj", ".", "CHECKPOINT_HYPER_PARAMS_TYPE", "]", "=", "type", "(", "obj", ".", "hparams", ")", "else", ":", "checkpoint", "[", "obj", ".", "CHECKPOINT_HYPER_PARAMS_KEY", "]", "=", "dict", "(", "obj", ".", "hparams", ")", "if", "datamodule", "is", "not", "None", ":", "datamodule_state_dict", "=", "call", ".", "_call_lightning_datamodule_hook", "(", "trainer", ",", "STRING", ")", "if", "datamodule_state_dict", ":", "checkpoint", "[", "datamodule", ".", "__class__", ".", "__qualname__", "]", "=", "datamodule_state_dict", "if", "not", "weights_only", ":", "call", ".", "_call_callbacks_on_save_checkpoint", "(", "trainer", ",", "checkpoint", ")", "call", ".", "_call_lightning_module_hook", "(", "trainer", ",", "STRING", ",", "checkpoint", ")", "return", "checkpoint"], "docstring": "the epoch and global step are saved for compatibility but they are not relevant for restoration dump callbacks Rely on accelerator to dump optimizer state dump lr schedulers precision plugin dump hyper-parameters dump arguments dump stateful datamodule on_save_checkpoint hooks if state is returned from callback's on_save_checkpoint it overrides the returned state from callback's state_dict support for returning state in on_save_checkpoint will be removed in v1.8", "docstring_tokens": ["the", "epoch", "and", "global", "step", "are", "saved", "for", "compatibility", "but", "they", "are", "not", "relevant", "for", "restoration", "dump", "callbacks", "rely", "on", "accelerator", "to", "dump", "optimizer", "state", "dump", "lr", "schedulers", "precision", "plugin", "dump", "hyper", "parameters", "dump", "arguments", "dump", "stateful", "datamodule", "on_save_checkpoint", "hooks", "if", "state", "is", "returned", "from", "callback", "s", "on_save_checkpoint", "it", "overrides", "the", "returned", "state", "from", "callback", "s", "state_dict", "support", "for", "returning", "state", "in", "on_save_checkpoint", "will", "be", "removed", "in", "v1", "8"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 412, "end_line": 502, "has_examples": false, "num_comments": 10, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "func_name": "function_253", "original_string": "def __max_ckpt_version_in_folder(dir_path: _PATH, name_key: str = \"ckpt_\") -> Optional[int]:\r\n        \"\"\"List up files in `dir_path` with `name_key`, then yield maximum suffix number.\r\n\r\n        Args:\r\n            dir_path: path of directory which may contain files whose name include `name_key`\r\n            name_key: file name prefix\r\n        Returns:\r\n            None if no-corresponding-file else maximum suffix number\r\n\r\n        \"\"\"\r\n        fs, uri = url_to_fs(str(dir_path))\r\n        if not fs.exists(dir_path):\r\n            return None\r\n\r\n        files = [os.path.basename(f[\"name\"]) for f in fs.listdir(uri)]\r\n        files = [x for x in files if name_key in x]\r\n        if len(files) == 0:\r\n            return None\r\n\r\n        ckpt_vs = []\r\n        for name in files:\r\n            name = name.split(name_key)[-1]\r\n            name = re.sub(\"[^0-9]\", \"\", name)\r\n            ckpt_vs.append(int(name))\r\n\r\n        return max(ckpt_vs)", "language": "python", "code": "def __max_ckpt_version_in_folder(dir_path: _PATH, name_key: str = \"ckpt_\") -> Optional[int]:\r\n        \"\"\"List up files in `dir_path` with `name_key`, then yield maximum suffix number.\r\n\r\n        Args:\r\n            dir_path: path of directory which may contain files whose name include `name_key`\r\n            name_key: file name prefix\r\n        Returns:\r\n            None if no-corresponding-file else maximum suffix number\r\n\r\n        \"\"\"\r\n        fs, uri = url_to_fs(str(dir_path))\r\n        if not fs.exists(dir_path):\r\n            return None\r\n\r\n        files = [os.path.basename(f[\"name\"]) for f in fs.listdir(uri)]\r\n        files = [x for x in files if name_key in x]\r\n        if len(files) == 0:\r\n            return None\r\n\r\n        ckpt_vs = []\r\n        for name in files:\r\n            name = name.split(name_key)[-1]\r\n            name = re.sub(\"[^0-9]\", \"\", name)\r\n            ckpt_vs.append(int(name))\r\n\r\n        return max(ckpt_vs)", "code_tokens": ["def", "__max_ckpt_version_in_folder", "(", "dir_path", ":", "_PATH", ",", "name_key", ":", "str", "=", "STRING", ")", "-", ">", "Optional", "[", "int", "]", ":", "STRING", "fs", ",", "uri", "=", "url_to_fs", "(", "str", "(", "dir_path", ")", ")", "if", "not", "fs", ".", "exists", "(", "dir_path", ")", ":", "return", "None", "files", "=", "[", "os", ".", "path", ".", "basename", "(", "f", "[", "STRING", "]", ")", "for", "f", "in", "fs", ".", "listdir", "(", "uri", ")", "]", "files", "=", "[", "x", "for", "x", "in", "files", "if", "name_key", "in", "x", "]", "if", "len", "(", "files", ")", "=", "=", "0", ":", "return", "None", "ckpt_vs", "=", "[", "]", "for", "name", "in", "files", ":", "name", "=", "name", ".", "split", "(", "name_key", ")", "[", "-", "1", "]", "name", "=", "re", ".", "sub", "(", "STRING", ",", "STRING", ",", "name", ")", "ckpt_vs", ".", "append", "(", "int", "(", "name", ")", ")", "return", "max", "(", "ckpt_vs", ")"], "docstring": "check directory existence check corresponding file existence extract suffix number", "docstring_tokens": ["check", "directory", "existence", "check", "corresponding", "file", "existence", "extract", "suffix", "number"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\checkpoint_connector.py", "start_line": 516, "end_line": 544, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\data_connector.py", "func_name": "function_254", "original_string": "def _prepare_dataloader(self, dataloader: object, shuffle: bool, mode: RunningStage) -> object:\r\n        \"\"\"This function handles the following functionalities:\r\n\r\n        - Injecting a `DistributedDataSamplerWrapper` into the `DataLoader` if on a distributed environment\r\n        - Wrapping the dataloader based on strategy-specific logic\r\n\r\n        \"\"\"\r\n        if not isinstance(dataloader, DataLoader):\r\n            return dataloader\r\n        if (\r\n            self._requires_distributed_sampler(dataloader)  # sets the distributed sampler\r\n            or mode == RunningStage.PREDICTING  # to track indices for the predictions\r\n        ):\r\n            sampler = self._resolve_sampler(dataloader, shuffle=shuffle, mode=mode)\r\n            return _update_dataloader(dataloader, sampler, mode=mode)\r\n\r\n        return dataloader", "language": "python", "code": "def _prepare_dataloader(self, dataloader: object, shuffle: bool, mode: RunningStage) -> object:\r\n        \"\"\"This function handles the following functionalities:\r\n\r\n        - Injecting a `DistributedDataSamplerWrapper` into the `DataLoader` if on a distributed environment\r\n        - Wrapping the dataloader based on strategy-specific logic\r\n\r\n        \"\"\"\r\n        if not isinstance(dataloader, DataLoader):\r\n            return dataloader\r\n        if (\r\n            self._requires_distributed_sampler(dataloader)  # sets the distributed sampler\r\n            or mode == RunningStage.PREDICTING  # to track indices for the predictions\r\n        ):\r\n            sampler = self._resolve_sampler(dataloader, shuffle=shuffle, mode=mode)\r\n            return _update_dataloader(dataloader, sampler, mode=mode)\r\n\r\n        return dataloader", "code_tokens": ["def", "_prepare_dataloader", "(", "self", ",", "dataloader", ":", "object", ",", "shuffle", ":", "bool", ",", "mode", ":", "RunningStage", ")", "-", ">", "object", ":", "STRING", "if", "not", "isinstance", "(", "dataloader", ",", "DataLoader", ")", ":", "return", "dataloader", "if", "(", "self", ".", "_requires_distributed_sampler", "(", "dataloader", ")", "#", "sets", "the", "distributed", "sampler", "or", "mode", "=", "=", "RunningStage", ".", "PREDICTING", "#", "to", "track", "indices", "for", "the", "predictions", ")", ":", "sampler", "=", "self", ".", "_resolve_sampler", "(", "dataloader", ",", "shuffle", "=", "shuffle", ",", "mode", "=", "mode", ")", "return", "_update_dataloader", "(", "dataloader", ",", "sampler", ",", "mode", "=", "mode", ")", "return", "dataloader"], "docstring": "don't do anything if it's not a dataloader", "docstring_tokens": ["don", "t", "do", "anything", "if", "it", "s", "not", "a", "dataloader"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\data_connector.py", "start_line": 176, "end_line": 193, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\data_connector.py", "func_name": "function_255", "original_string": "def _request_dataloader(data_source: _DataLoaderSource) -> Union[TRAIN_DATALOADERS, EVAL_DATALOADERS]:\r\n    \"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\r\n\r\n    Returns:\r\n        The requested dataloader\r\n\r\n    \"\"\"\r\n    with _replace_dunder_methods(DataLoader, \"dataset\"), _replace_dunder_methods(BatchSampler):\r\n        return data_source.dataloader()", "language": "python", "code": "def _request_dataloader(data_source: _DataLoaderSource) -> Union[TRAIN_DATALOADERS, EVAL_DATALOADERS]:\r\n    \"\"\"Requests a dataloader by calling dataloader hooks corresponding to the given stage.\r\n\r\n    Returns:\r\n        The requested dataloader\r\n\r\n    \"\"\"\r\n    with _replace_dunder_methods(DataLoader, \"dataset\"), _replace_dunder_methods(BatchSampler):\r\n        return data_source.dataloader()", "code_tokens": ["def", "_request_dataloader", "(", "data_source", ":", "_DataLoaderSource", ")", "-", ">", "Union", "[", "TRAIN_DATALOADERS", ",", "EVAL_DATALOADERS", "]", ":", "STRING", "with", "_replace_dunder_methods", "(", "DataLoader", ",", "STRING", ")", ",", "_replace_dunder_methods", "(", "BatchSampler", ")", ":", "return", "data_source", ".", "dataloader", "(", ")"], "docstring": "under this context manager, the arguments passed to `DataLoader.__init__` will be captured and saved as attributes on the instance in case the dataloader needs to be re-instantiated later by Lightning. Also, it records all attribute setting and deletion using patched `__setattr__` and `__delattr__` methods so that the re-instantiated object is as close to the original as possible.", "docstring_tokens": ["under", "this", "context", "manager", "the", "arguments", "passed", "to", "dataloader", "__init__", "will", "be", "captured", "and", "saved", "as", "attributes", "on", "the", "instance", "in", "case", "the", "dataloader", "needs", "to", "be", "re", "instantiated", "later", "by", "lightning", "also", "it", "records", "all", "attribute", "setting", "and", "deletion", "using", "patched", "__setattr__", "and", "__delattr__", "methods", "so", "that", "the", "re", "instantiated", "object", "is", "as", "close", "to", "the", "original", "as", "possible"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\data_connector.py", "start_line": 322, "end_line": 334, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\signal_connector.py", "func_name": "function_256", "original_string": "def _get_current_signal_handlers() -> dict[_SIGNUM, _HANDLER]:\r\n        \"\"\"Collects the currently assigned signal handlers.\"\"\"\r\n        valid_signals = _SignalConnector._valid_signals()\r\n        if not _IS_WINDOWS:\r\n            valid_signals -= {signal.SIGKILL, signal.SIGSTOP}\r\n        return {signum: signal.getsignal(signum) for signum in valid_signals}", "language": "python", "code": "def _get_current_signal_handlers() -> dict[_SIGNUM, _HANDLER]:\r\n        \"\"\"Collects the currently assigned signal handlers.\"\"\"\r\n        valid_signals = _SignalConnector._valid_signals()\r\n        if not _IS_WINDOWS:\r\n            valid_signals -= {signal.SIGKILL, signal.SIGSTOP}\r\n        return {signum: signal.getsignal(signum) for signum in valid_signals}", "code_tokens": ["def", "_get_current_signal_handlers", "(", ")", "-", ">", "dict", "[", "_SIGNUM", ",", "_HANDLER", "]", ":", "STRING", "valid_signals", "=", "_SignalConnector", ".", "_valid_signals", "(", ")", "if", "not", "_IS_WINDOWS", ":", "valid_signals", "-", "=", "{", "signal", ".", "SIGKILL", ",", "signal", ".", "SIGSTOP", "}", "return", "{", "signum", ":", "signal", ".", "getsignal", "(", "signum", ")", "for", "signum", "in", "valid_signals", "}"], "docstring": "SIGKILL and SIGSTOP are not allowed to be modified by the user", "docstring_tokens": ["sigkill", "and", "sigstop", "are", "not", "allowed", "to", "be", "modified", "by", "the", "user"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\signal_connector.py", "start_line": 132, "end_line": 138, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py", "func_name": "function_257", "original_string": "def log_metrics(self, metrics: _OUT_DICT, step: Optional[int] = None) -> None:\r\n        \"\"\"Logs the metric dict passed in. If `step` parameter is None and `step` key is presented is metrics, uses\r\n        metrics[\"step\"] as a step.\r\n\r\n        Args:\r\n            metrics: Metric values\r\n            step: Step for which metrics should be logged. If a `step` metric is logged, this value will\r\n                be used else will default to `self.global_step` during training or the total log step count\r\n                during validation and testing.\r\n\r\n        \"\"\"\r\n        if not self.trainer.loggers or not metrics:\r\n            return\r\n\r\n        self._logged_metrics.update(metrics)\r\n\r\n        scalar_metrics = convert_tensors_to_scalars(metrics)\r\n\r\n        if step is None:\r\n            step_metric = scalar_metrics.pop(\"step\", None)\r\n            if step_metric is not None:\r\n                step = int(step_metric)\r\n            else:\r\n                scalar_metrics.setdefault(\"epoch\", self.trainer.current_epoch)\r\n                step = self.trainer.fit_loop.epoch_loop._batches_that_stepped\r\n\r\n        for logger in self.trainer.loggers:\r\n            logger.log_metrics(metrics=scalar_metrics, step=step)\r\n            logger.save()", "language": "python", "code": "def log_metrics(self, metrics: _OUT_DICT, step: Optional[int] = None) -> None:\r\n        \"\"\"Logs the metric dict passed in. If `step` parameter is None and `step` key is presented is metrics, uses\r\n        metrics[\"step\"] as a step.\r\n\r\n        Args:\r\n            metrics: Metric values\r\n            step: Step for which metrics should be logged. If a `step` metric is logged, this value will\r\n                be used else will default to `self.global_step` during training or the total log step count\r\n                during validation and testing.\r\n\r\n        \"\"\"\r\n        if not self.trainer.loggers or not metrics:\r\n            return\r\n\r\n        self._logged_metrics.update(metrics)\r\n\r\n        scalar_metrics = convert_tensors_to_scalars(metrics)\r\n\r\n        if step is None:\r\n            step_metric = scalar_metrics.pop(\"step\", None)\r\n            if step_metric is not None:\r\n                step = int(step_metric)\r\n            else:\r\n                scalar_metrics.setdefault(\"epoch\", self.trainer.current_epoch)\r\n                step = self.trainer.fit_loop.epoch_loop._batches_that_stepped\r\n\r\n        for logger in self.trainer.loggers:\r\n            logger.log_metrics(metrics=scalar_metrics, step=step)\r\n            logger.save()", "code_tokens": ["def", "log_metrics", "(", "self", ",", "metrics", ":", "_OUT_DICT", ",", "step", ":", "Optional", "[", "int", "]", "=", "None", ")", "-", ">", "None", ":", "STRING", "if", "not", "self", ".", "trainer", ".", "loggers", "or", "not", "metrics", ":", "return", "self", ".", "_logged_metrics", ".", "update", "(", "metrics", ")", "scalar_metrics", "=", "convert_tensors_to_scalars", "(", "metrics", ")", "if", "step", "is", "None", ":", "step_metric", "=", "scalar_metrics", ".", "pop", "(", "STRING", ",", "None", ")", "if", "step_metric", "is", "not", "None", ":", "step", "=", "int", "(", "step_metric", ")", "else", ":", "scalar_metrics", ".", "setdefault", "(", "STRING", ",", "self", ".", "trainer", ".", "current_epoch", ")", "step", "=", "self", ".", "trainer", ".", "fit_loop", ".", "epoch_loop", ".", "_batches_that_stepped", "for", "logger", "in", "self", ".", "trainer", ".", "loggers", ":", "logger", ".", "log_metrics", "(", "metrics", "=", "scalar_metrics", ",", "step", "=", "step", ")", "logger", ".", "save", "(", ")"], "docstring": "turn all tensors to scalars added metrics for convenience log actual metrics", "docstring_tokens": ["turn", "all", "tensors", "to", "scalars", "added", "metrics", "for", "convenience", "log", "actual", "metrics"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py", "start_line": 89, "end_line": 120, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py", "func_name": "function_258", "original_string": "def _generate_sync_fn(self) -> None:\r\n        \"\"\"Used to compute the syncing function and cache it.\"\"\"\r\n        fn = self.no_op if self.fn is None or not self.should or self.rank_zero_only else self.fn\r\n        self._fn: Callable = partial(fn, reduce_op=self.op, group=self.group)", "language": "python", "code": "def _generate_sync_fn(self) -> None:\r\n        \"\"\"Used to compute the syncing function and cache it.\"\"\"\r\n        fn = self.no_op if self.fn is None or not self.should or self.rank_zero_only else self.fn\r\n        self._fn: Callable = partial(fn, reduce_op=self.op, group=self.group)", "code_tokens": ["def", "_generate_sync_fn", "(", "self", ")", "-", ">", "None", ":", "STRING", "fn", "=", "self", ".", "no_op", "if", "self", ".", "fn", "is", "None", "or", "not", "self", ".", "should", "or", "self", ".", "rank_zero_only", "else", "self", ".", "fn", "self", ".", "_fn", ":", "Callable", "=", "partial", "(", "fn", ",", "reduce_op", "=", "self", ".", "op", ",", "group", "=", "self", ".", "group", ")"], "docstring": "save the function as `_fn` as the meta are being re-created and the object references need to match.", "docstring_tokens": ["save", "the", "function", "as", "_fn", "as", "the", "meta", "are", "being", "re", "created", "and", "the", "object", "references", "need", "to", "match"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py", "start_line": 89, "end_line": 93, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py", "func_name": "function_259", "original_string": "def log(\r\n        self,\r\n        fx: str,\r\n        name: str,\r\n        value: _VALUE,\r\n        prog_bar: bool = False,\r\n        logger: bool = True,\r\n        on_step: bool = False,\r\n        on_epoch: bool = True,\r\n        reduce_fx: Callable = torch.mean,\r\n        enable_graph: bool = False,\r\n        sync_dist: bool = False,\r\n        sync_dist_fn: Callable = _Sync.no_op,\r\n        sync_dist_group: Optional[Any] = None,\r\n        add_dataloader_idx: bool = True,\r\n        batch_size: Optional[int] = None,\r\n        metric_attribute: Optional[str] = None,\r\n        rank_zero_only: bool = False,\r\n    ) -> None:\r\n        \"\"\"See :meth:`~lightning.pytorch.core.LightningModule.log`\"\"\"\r\n        if not enable_graph:\r\n            value = recursive_detach(value)\r\n\r\n        key = f\"{fx}.{name}\"\r\n        if add_dataloader_idx and self.dataloader_idx is not None:\r\n            key += f\".{self.dataloader_idx}\"\r\n            fx += f\".{self.dataloader_idx}\"\r\n\r\n        meta = _Metadata(\r\n            fx=fx,\r\n            name=name,\r\n            prog_bar=prog_bar,\r\n            logger=logger,\r\n            on_step=on_step,\r\n            on_epoch=on_epoch,\r\n            reduce_fx=reduce_fx,\r\n            enable_graph=enable_graph,\r\n            add_dataloader_idx=add_dataloader_idx,\r\n            dataloader_idx=self.dataloader_idx,\r\n            metric_attribute=metric_attribute,\r\n        )\r\n        meta.sync = _Sync(_should=sync_dist, fn=sync_dist_fn, _group=sync_dist_group, rank_zero_only=rank_zero_only)\r\n\r\n        if key not in self:\r\n            metric = _ResultMetric(meta, isinstance(value, Tensor))\r\n            self[key] = metric\r\n\r\n        elif meta != self[key].meta:\r\n            raise MisconfigurationException(\r\n                f\"You called `self.log({name}, ...)` twice in `{fx}` with different arguments. This is not allowed\"\r\n            )\r\n        self[key].to(value.device)\r\n\r\n        batch_size = self._extract_batch_size(self[key], batch_size, meta)\r\n        self.update_metrics(key, value, batch_size)", "language": "python", "code": "def log(\r\n        self,\r\n        fx: str,\r\n        name: str,\r\n        value: _VALUE,\r\n        prog_bar: bool = False,\r\n        logger: bool = True,\r\n        on_step: bool = False,\r\n        on_epoch: bool = True,\r\n        reduce_fx: Callable = torch.mean,\r\n        enable_graph: bool = False,\r\n        sync_dist: bool = False,\r\n        sync_dist_fn: Callable = _Sync.no_op,\r\n        sync_dist_group: Optional[Any] = None,\r\n        add_dataloader_idx: bool = True,\r\n        batch_size: Optional[int] = None,\r\n        metric_attribute: Optional[str] = None,\r\n        rank_zero_only: bool = False,\r\n    ) -> None:\r\n        \"\"\"See :meth:`~lightning.pytorch.core.LightningModule.log`\"\"\"\r\n        if not enable_graph:\r\n            value = recursive_detach(value)\r\n\r\n        key = f\"{fx}.{name}\"\r\n        if add_dataloader_idx and self.dataloader_idx is not None:\r\n            key += f\".{self.dataloader_idx}\"\r\n            fx += f\".{self.dataloader_idx}\"\r\n\r\n        meta = _Metadata(\r\n            fx=fx,\r\n            name=name,\r\n            prog_bar=prog_bar,\r\n            logger=logger,\r\n            on_step=on_step,\r\n            on_epoch=on_epoch,\r\n            reduce_fx=reduce_fx,\r\n            enable_graph=enable_graph,\r\n            add_dataloader_idx=add_dataloader_idx,\r\n            dataloader_idx=self.dataloader_idx,\r\n            metric_attribute=metric_attribute,\r\n        )\r\n        meta.sync = _Sync(_should=sync_dist, fn=sync_dist_fn, _group=sync_dist_group, rank_zero_only=rank_zero_only)\r\n\r\n        if key not in self:\r\n            metric = _ResultMetric(meta, isinstance(value, Tensor))\r\n            self[key] = metric\r\n\r\n        elif meta != self[key].meta:\r\n            raise MisconfigurationException(\r\n                f\"You called `self.log({name}, ...)` twice in `{fx}` with different arguments. This is not allowed\"\r\n            )\r\n        self[key].to(value.device)\r\n\r\n        batch_size = self._extract_batch_size(self[key], batch_size, meta)\r\n        self.update_metrics(key, value, batch_size)", "code_tokens": ["def", "log", "(", "self", ",", "fx", ":", "str", ",", "name", ":", "str", ",", "value", ":", "_VALUE", ",", "prog_bar", ":", "bool", "=", "False", ",", "logger", ":", "bool", "=", "True", ",", "on_step", ":", "bool", "=", "False", ",", "on_epoch", ":", "bool", "=", "True", ",", "reduce_fx", ":", "Callable", "=", "torch", ".", "mean", ",", "enable_graph", ":", "bool", "=", "False", ",", "sync_dist", ":", "bool", "=", "False", ",", "sync_dist_fn", ":", "Callable", "=", "_Sync", ".", "no_op", ",", "sync_dist_group", ":", "Optional", "[", "Any", "]", "=", "None", ",", "add_dataloader_idx", ":", "bool", "=", "True", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "metric_attribute", ":", "Optional", "[", "str", "]", "=", "None", ",", "rank_zero_only", ":", "bool", "=", "False", ",", ")", "-", ">", "None", ":", "STRING", "if", "not", "enable_graph", ":", "value", "=", "recursive_detach", "(", "value", ")", "key", "=", "fSTRING", "if", "add_dataloader_idx", "and", "self", ".", "dataloader_idx", "is", "not", "None", ":", "key", "+", "=", "fSTRING", "fx", "+", "=", "fSTRING", "meta", "=", "_Metadata", "(", "fx", "=", "fx", ",", "name", "=", "name", ",", "prog_bar", "=", "prog_bar", ",", "logger", "=", "logger", ",", "on_step", "=", "on_step", ",", "on_epoch", "=", "on_epoch", ",", "reduce_fx", "=", "reduce_fx", ",", "enable_graph", "=", "enable_graph", ",", "add_dataloader_idx", "=", "add_dataloader_idx", ",", "dataloader_idx", "=", "self", ".", "dataloader_idx", ",", "metric_attribute", "=", "metric_attribute", ",", ")", "meta", ".", "sync", "=", "_Sync", "(", "_should", "=", "sync_dist", ",", "fn", "=", "sync_dist_fn", ",", "_group", "=", "sync_dist_group", ",", "rank_zero_only", "=", "rank_zero_only", ")", "if", "key", "not", "in", "self", ":", "metric", "=", "_ResultMetric", "(", "meta", ",", "isinstance", "(", "value", ",", "Tensor", ")", ")", "self", "[", "key", "]", "=", "metric", "elif", "meta", "!", "=", "self", "[", "key", "]", ".", "meta", ":", "raise", "MisconfigurationException", "(", "fSTRING", ")", "self", "[", "key", "]", ".", "to", "(", "value", ".", "device", ")", "batch_size", "=", "self", ".", "_extract_batch_size", "(", "self", "[", "key", "]", ",", "batch_size", ",", "meta", ")", "self", ".", "update_metrics", "(", "key", ",", "value", ",", "batch_size", ")"], "docstring": "https://github.com/pytorch/pytorch/issues/96197 no metrics should be logged with graphs storage key add dataloader_suffix to both key and fx register logged value if it doesn't exist check the stored metadata and the current one match", "docstring_tokens": ["https", "github", "com", "pytorch", "pytorch", "issues", "96197", "no", "metrics", "should", "be", "logged", "with", "graphs", "storage", "key", "add", "dataloader_suffix", "to", "both", "key", "and", "fx", "register", "logged", "value", "if", "it", "doesn", "t", "exist", "check", "the", "stored", "metadata", "and", "the", "current", "one", "match"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py", "start_line": 354, "end_line": 414, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "func_name": "function_260", "original_string": "def _scale_batch_size(\r\n    trainer: \"pl.Trainer\",\r\n    mode: str = \"power\",\r\n    steps_per_trial: int = 3,\r\n    init_val: int = 2,\r\n    max_trials: int = 25,\r\n    batch_arg_name: str = \"batch_size\",\r\n) -> Optional[int]:\r\n    \"\"\"Iteratively try to find the largest batch size for a given model that does not give an out of memory (OOM)\r\n    error.\r\n\r\n    Args:\r\n        trainer: A Trainer instance.\r\n        mode: Search strategy to update the batch size:\r\n\r\n            - ``'power'``: Keep multiplying the batch size by 2, until we get an OOM error.\r\n            - ``'binsearch'``: Initially keep multiplying by 2 and after encountering an OOM error\r\n                do a binary search between the last successful batch size and the batch size that failed.\r\n\r\n        steps_per_trial: number of steps to run with a given batch size.\r\n            Ideally 1 should be enough to test if an OOM error occurs,\r\n            however in practise a few are needed\r\n        init_val: initial batch size to start the search with\r\n        max_trials: max number of increases in batch size done before\r\n           algorithm is terminated\r\n        batch_arg_name: name of the attribute that stores the batch size.\r\n            It is expected that the user has provided a model or datamodule that has a hyperparameter\r\n            with that name. We will look for this attribute name in the following places\r\n\r\n            - ``model``\r\n            - ``model.hparams``\r\n            - ``trainer.datamodule`` (the datamodule passed to the tune method)\r\n\r\n    \"\"\"\r\n    if trainer.fast_dev_run:\r\n        rank_zero_warn(\"Skipping batch size scaler since `fast_dev_run` is enabled.\")\r\n        return None\r\n\r\n    ckpt_path = os.path.join(trainer.default_root_dir, f\".scale_batch_size_{uuid.uuid4()}.ckpt\")\r\n    trainer.save_checkpoint(ckpt_path)\r\n\r\n    params = __scale_batch_dump_params(trainer)\r\n\r\n    __scale_batch_reset_params(trainer, steps_per_trial)\r\n\r\n    if trainer.progress_bar_callback:\r\n        trainer.progress_bar_callback.disable()\r\n\r\n    try:\r\n        new_size, _ = _adjust_batch_size(trainer, batch_arg_name, value=init_val)\r\n\r\n        if mode == \"power\":\r\n            new_size = _run_power_scaling(trainer, new_size, batch_arg_name, max_trials, params)\r\n        elif mode == \"binsearch\":\r\n            new_size = _run_binary_scaling(trainer, new_size, batch_arg_name, max_trials, params)\r\n\r\n        garbage_collection_cuda()\r\n\r\n        log.info(f\"Finished batch size finder, will continue with full run using batch size {new_size}\")\r\n    except Exception as ex:\r\n        raise ex\r\n    finally:\r\n        __scale_batch_restore_params(trainer, params)\r\n\r\n        if trainer.progress_bar_callback:\r\n            trainer.progress_bar_callback.enable()\r\n\r\n        trainer._checkpoint_connector.restore(ckpt_path)\r\n        trainer.strategy.remove_checkpoint(ckpt_path)\r\n\r\n    return new_size", "language": "python", "code": "def _scale_batch_size(\r\n    trainer: \"pl.Trainer\",\r\n    mode: str = \"power\",\r\n    steps_per_trial: int = 3,\r\n    init_val: int = 2,\r\n    max_trials: int = 25,\r\n    batch_arg_name: str = \"batch_size\",\r\n) -> Optional[int]:\r\n    \"\"\"Iteratively try to find the largest batch size for a given model that does not give an out of memory (OOM)\r\n    error.\r\n\r\n    Args:\r\n        trainer: A Trainer instance.\r\n        mode: Search strategy to update the batch size:\r\n\r\n            - ``'power'``: Keep multiplying the batch size by 2, until we get an OOM error.\r\n            - ``'binsearch'``: Initially keep multiplying by 2 and after encountering an OOM error\r\n                do a binary search between the last successful batch size and the batch size that failed.\r\n\r\n        steps_per_trial: number of steps to run with a given batch size.\r\n            Ideally 1 should be enough to test if an OOM error occurs,\r\n            however in practise a few are needed\r\n        init_val: initial batch size to start the search with\r\n        max_trials: max number of increases in batch size done before\r\n           algorithm is terminated\r\n        batch_arg_name: name of the attribute that stores the batch size.\r\n            It is expected that the user has provided a model or datamodule that has a hyperparameter\r\n            with that name. We will look for this attribute name in the following places\r\n\r\n            - ``model``\r\n            - ``model.hparams``\r\n            - ``trainer.datamodule`` (the datamodule passed to the tune method)\r\n\r\n    \"\"\"\r\n    if trainer.fast_dev_run:\r\n        rank_zero_warn(\"Skipping batch size scaler since `fast_dev_run` is enabled.\")\r\n        return None\r\n\r\n    ckpt_path = os.path.join(trainer.default_root_dir, f\".scale_batch_size_{uuid.uuid4()}.ckpt\")\r\n    trainer.save_checkpoint(ckpt_path)\r\n\r\n    params = __scale_batch_dump_params(trainer)\r\n\r\n    __scale_batch_reset_params(trainer, steps_per_trial)\r\n\r\n    if trainer.progress_bar_callback:\r\n        trainer.progress_bar_callback.disable()\r\n\r\n    try:\r\n        new_size, _ = _adjust_batch_size(trainer, batch_arg_name, value=init_val)\r\n\r\n        if mode == \"power\":\r\n            new_size = _run_power_scaling(trainer, new_size, batch_arg_name, max_trials, params)\r\n        elif mode == \"binsearch\":\r\n            new_size = _run_binary_scaling(trainer, new_size, batch_arg_name, max_trials, params)\r\n\r\n        garbage_collection_cuda()\r\n\r\n        log.info(f\"Finished batch size finder, will continue with full run using batch size {new_size}\")\r\n    except Exception as ex:\r\n        raise ex\r\n    finally:\r\n        __scale_batch_restore_params(trainer, params)\r\n\r\n        if trainer.progress_bar_callback:\r\n            trainer.progress_bar_callback.enable()\r\n\r\n        trainer._checkpoint_connector.restore(ckpt_path)\r\n        trainer.strategy.remove_checkpoint(ckpt_path)\r\n\r\n    return new_size", "code_tokens": ["def", "_scale_batch_size", "(", "trainer", ":", "STRING", ",", "mode", ":", "str", "=", "STRING", ",", "steps_per_trial", ":", "int", "=", "3", ",", "init_val", ":", "int", "=", "2", ",", "max_trials", ":", "int", "=", "25", ",", "batch_arg_name", ":", "str", "=", "STRING", ",", ")", "-", ">", "Optional", "[", "int", "]", ":", "STRING", "if", "trainer", ".", "fast_dev_run", ":", "rank_zero_warn", "(", "STRING", ")", "return", "None", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "trainer", ".", "default_root_dir", ",", "fSTRING", ")", "trainer", ".", "save_checkpoint", "(", "ckpt_path", ")", "params", "=", "__scale_batch_dump_params", "(", "trainer", ")", "__scale_batch_reset_params", "(", "trainer", ",", "steps_per_trial", ")", "if", "trainer", ".", "progress_bar_callback", ":", "trainer", ".", "progress_bar_callback", ".", "disable", "(", ")", "try", ":", "new_size", ",", "_", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "value", "=", "init_val", ")", "if", "mode", "=", "=", "STRING", ":", "new_size", "=", "_run_power_scaling", "(", "trainer", ",", "new_size", ",", "batch_arg_name", ",", "max_trials", ",", "params", ")", "elif", "mode", "=", "=", "STRING", ":", "new_size", "=", "_run_binary_scaling", "(", "trainer", ",", "new_size", ",", "batch_arg_name", ",", "max_trials", ",", "params", ")", "garbage_collection_cuda", "(", ")", "log", ".", "info", "(", "fSTRING", ")", "except", "Exception", "as", "ex", ":", "raise", "ex", "finally", ":", "__scale_batch_restore_params", "(", "trainer", ",", "params", ")", "if", "trainer", ".", "progress_bar_callback", ":", "trainer", ".", "progress_bar_callback", ".", "enable", "(", ")", "trainer", ".", "_checkpoint_connector", ".", "restore", "(", "ckpt_path", ")", "trainer", ".", "strategy", ".", "remove_checkpoint", "(", "ckpt_path", ")", "return", "new_size"], "docstring": "Save initial model, that is loaded after batch size is found Arguments we adjust during the batch size finder, save for restoring Set to values that are required by the algorithm", "docstring_tokens": ["save", "initial", "model", "that", "is", "loaded", "after", "batch", "size", "is", "found", "arguments", "we", "adjust", "during", "the", "batch", "size", "finder", "save", "for", "restoring", "set", "to", "values", "that", "are", "required", "by", "the", "algorithm"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "start_line": 27, "end_line": 100, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "func_name": "function_261", "original_string": "def _run_power_scaling(\r\n    trainer: \"pl.Trainer\",\r\n    new_size: int,\r\n    batch_arg_name: str,\r\n    max_trials: int,\r\n    params: dict[str, Any],\r\n) -> int:\r\n    \"\"\"Batch scaling mode where the size is doubled at each iteration until an OOM error is encountered.\"\"\"\r\n    any_success = False\r\n    last_successful_size = new_size\r\n    for i in range(max_trials):\r\n        garbage_collection_cuda()\r\n\r\n        _reset_progress(trainer)\r\n\r\n        try:\r\n            _try_loop_run(trainer, params)\r\n            last_successful_size = new_size  # Store the current size before doubling\r\n\r\n            if i + 1 >= max_trials:\r\n                new_size = last_successful_size\r\n                break\r\n\r\n            new_size, changed = _adjust_batch_size(trainer, batch_arg_name, factor=2.0, desc=\"succeeded\")\r\n\r\n            if not changed:\r\n                break\r\n\r\n            _reset_dataloaders(trainer)\r\n            any_success = True\r\n        except RuntimeError as exception:\r\n            if is_oom_error(exception):\r\n                garbage_collection_cuda()\r\n                new_size, _ = _adjust_batch_size(trainer, batch_arg_name, factor=0.5, desc=\"failed\")\r\n                _reset_dataloaders(trainer)\r\n                if any_success:\r\n                    break\r\n            else:\r\n                raise  # some other error not memory related\r\n\r\n    return new_size", "language": "python", "code": "def _run_power_scaling(\r\n    trainer: \"pl.Trainer\",\r\n    new_size: int,\r\n    batch_arg_name: str,\r\n    max_trials: int,\r\n    params: dict[str, Any],\r\n) -> int:\r\n    \"\"\"Batch scaling mode where the size is doubled at each iteration until an OOM error is encountered.\"\"\"\r\n    any_success = False\r\n    last_successful_size = new_size\r\n    for i in range(max_trials):\r\n        garbage_collection_cuda()\r\n\r\n        _reset_progress(trainer)\r\n\r\n        try:\r\n            _try_loop_run(trainer, params)\r\n            last_successful_size = new_size  # Store the current size before doubling\r\n\r\n            if i + 1 >= max_trials:\r\n                new_size = last_successful_size\r\n                break\r\n\r\n            new_size, changed = _adjust_batch_size(trainer, batch_arg_name, factor=2.0, desc=\"succeeded\")\r\n\r\n            if not changed:\r\n                break\r\n\r\n            _reset_dataloaders(trainer)\r\n            any_success = True\r\n        except RuntimeError as exception:\r\n            if is_oom_error(exception):\r\n                garbage_collection_cuda()\r\n                new_size, _ = _adjust_batch_size(trainer, batch_arg_name, factor=0.5, desc=\"failed\")\r\n                _reset_dataloaders(trainer)\r\n                if any_success:\r\n                    break\r\n            else:\r\n                raise  # some other error not memory related\r\n\r\n    return new_size", "code_tokens": ["def", "_run_power_scaling", "(", "trainer", ":", "STRING", ",", "new_size", ":", "int", ",", "batch_arg_name", ":", "str", ",", "max_trials", ":", "int", ",", "params", ":", "dict", "[", "str", ",", "Any", "]", ",", ")", "-", ">", "int", ":", "STRING", "any_success", "=", "False", "last_successful_size", "=", "new_size", "for", "i", "in", "range", "(", "max_trials", ")", ":", "garbage_collection_cuda", "(", ")", "_reset_progress", "(", "trainer", ")", "try", ":", "_try_loop_run", "(", "trainer", ",", "params", ")", "last_successful_size", "=", "new_size", "#", "Store", "the", "current", "size", "before", "doubling", "if", "i", "+", "1", ">", "=", "max_trials", ":", "new_size", "=", "last_successful_size", "break", "new_size", ",", "changed", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "factor", "=", "2", ".", "0", ",", "desc", "=", "STRING", ")", "if", "not", "changed", ":", "break", "_reset_dataloaders", "(", "trainer", ")", "any_success", "=", "True", "except", "RuntimeError", "as", "exception", ":", "if", "is_oom_error", "(", "exception", ")", ":", "garbage_collection_cuda", "(", ")", "new_size", ",", "_", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "factor", "=", "0", ".", "5", ",", "desc", "=", "STRING", ")", "_reset_dataloaders", "(", "trainer", ")", "if", "any_success", ":", "break", "else", ":", "raise", "#", "some", "other", "error", "not", "memory", "related", "return", "new_size"], "docstring": "this flag is used to determine whether the previously scaled batch size, right before OOM, was a success or not if it was we exit, else we continue downscaling in case we haven't encountered a single optimal batch size reset after each try Check if this is the last trial before trying to double Force the train dataloader to reset as the batch size has changed If we fail in power mode, half the size and return Force the train dataloader to reset as the batch size has changed", "docstring_tokens": ["this", "flag", "is", "used", "to", "determine", "whether", "the", "previously", "scaled", "batch", "size", "right", "before", "oom", "was", "a", "success", "or", "not", "if", "it", "was", "we", "exit", "else", "we", "continue", "downscaling", "in", "case", "we", "haven", "t", "encountered", "a", "single", "optimal", "batch", "size", "reset", "after", "each", "try", "check", "if", "this", "is", "the", "last", "trial", "before", "trying", "to", "double", "force", "the", "train", "dataloader", "to", "reset", "as", "the", "batch", "size", "has", "changed", "if", "we", "fail", "in", "power", "mode", "half", "the", "size", "and", "return", "force", "the", "train", "dataloader", "to", "reset", "as", "the", "batch", "size", "has", "changed"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "start_line": 169, "end_line": 216, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "func_name": "function_262", "original_string": "def _run_binary_scaling(\r\n    trainer: \"pl.Trainer\",\r\n    new_size: int,\r\n    batch_arg_name: str,\r\n    max_trials: int,\r\n    params: dict[str, Any],\r\n) -> int:\r\n    \"\"\"Batch scaling mode where the size is initially is doubled at each iteration until an OOM error is encountered.\r\n\r\n    Hereafter, the batch size is further refined using a binary search\r\n\r\n    \"\"\"\r\n    low = 1\r\n    high = None\r\n    count = 0\r\n    last_successful_size = new_size\r\n    while True:\r\n        garbage_collection_cuda()\r\n\r\n        _reset_progress(trainer)\r\n\r\n        try:\r\n            _try_loop_run(trainer, params)\r\n            last_successful_size = new_size  # Store the current size before doubling\r\n            count += 1\r\n\r\n            if count >= max_trials:\r\n                new_size = last_successful_size\r\n                break\r\n\r\n            low = new_size\r\n            if high:\r\n                if high - low <= 1:\r\n                    break\r\n                midval = (high + low) // 2\r\n                new_size, changed = _adjust_batch_size(trainer, batch_arg_name, value=midval, desc=\"succeeded\")\r\n            else:\r\n                new_size, changed = _adjust_batch_size(trainer, batch_arg_name, factor=2.0, desc=\"succeeded\")\r\n\r\n            if not changed:\r\n                break\r\n\r\n            _reset_dataloaders(trainer)\r\n\r\n        except RuntimeError as exception:\r\n            if is_oom_error(exception):\r\n                garbage_collection_cuda()\r\n\r\n                high = new_size\r\n                midval = (high + low) // 2\r\n                new_size, _ = _adjust_batch_size(trainer, batch_arg_name, value=midval, desc=\"failed\")\r\n\r\n                _reset_dataloaders(trainer)\r\n\r\n                if high - low <= 1:\r\n                    break\r\n            else:\r\n                raise  # some other error not memory related\r\n\r\n    return new_size", "language": "python", "code": "def _run_binary_scaling(\r\n    trainer: \"pl.Trainer\",\r\n    new_size: int,\r\n    batch_arg_name: str,\r\n    max_trials: int,\r\n    params: dict[str, Any],\r\n) -> int:\r\n    \"\"\"Batch scaling mode where the size is initially is doubled at each iteration until an OOM error is encountered.\r\n\r\n    Hereafter, the batch size is further refined using a binary search\r\n\r\n    \"\"\"\r\n    low = 1\r\n    high = None\r\n    count = 0\r\n    last_successful_size = new_size\r\n    while True:\r\n        garbage_collection_cuda()\r\n\r\n        _reset_progress(trainer)\r\n\r\n        try:\r\n            _try_loop_run(trainer, params)\r\n            last_successful_size = new_size  # Store the current size before doubling\r\n            count += 1\r\n\r\n            if count >= max_trials:\r\n                new_size = last_successful_size\r\n                break\r\n\r\n            low = new_size\r\n            if high:\r\n                if high - low <= 1:\r\n                    break\r\n                midval = (high + low) // 2\r\n                new_size, changed = _adjust_batch_size(trainer, batch_arg_name, value=midval, desc=\"succeeded\")\r\n            else:\r\n                new_size, changed = _adjust_batch_size(trainer, batch_arg_name, factor=2.0, desc=\"succeeded\")\r\n\r\n            if not changed:\r\n                break\r\n\r\n            _reset_dataloaders(trainer)\r\n\r\n        except RuntimeError as exception:\r\n            if is_oom_error(exception):\r\n                garbage_collection_cuda()\r\n\r\n                high = new_size\r\n                midval = (high + low) // 2\r\n                new_size, _ = _adjust_batch_size(trainer, batch_arg_name, value=midval, desc=\"failed\")\r\n\r\n                _reset_dataloaders(trainer)\r\n\r\n                if high - low <= 1:\r\n                    break\r\n            else:\r\n                raise  # some other error not memory related\r\n\r\n    return new_size", "code_tokens": ["def", "_run_binary_scaling", "(", "trainer", ":", "STRING", ",", "new_size", ":", "int", ",", "batch_arg_name", ":", "str", ",", "max_trials", ":", "int", ",", "params", ":", "dict", "[", "str", ",", "Any", "]", ",", ")", "-", ">", "int", ":", "STRING", "low", "=", "1", "high", "=", "None", "count", "=", "0", "last_successful_size", "=", "new_size", "while", "True", ":", "garbage_collection_cuda", "(", ")", "_reset_progress", "(", "trainer", ")", "try", ":", "_try_loop_run", "(", "trainer", ",", "params", ")", "last_successful_size", "=", "new_size", "#", "Store", "the", "current", "size", "before", "doubling", "count", "+", "=", "1", "if", "count", ">", "=", "max_trials", ":", "new_size", "=", "last_successful_size", "break", "low", "=", "new_size", "if", "high", ":", "if", "high", "-", "low", "<", "=", "1", ":", "break", "midval", "=", "(", "high", "+", "low", ")", "/", "/", "2", "new_size", ",", "changed", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "value", "=", "midval", ",", "desc", "=", "STRING", ")", "else", ":", "new_size", ",", "changed", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "factor", "=", "2", ".", "0", ",", "desc", "=", "STRING", ")", "if", "not", "changed", ":", "break", "_reset_dataloaders", "(", "trainer", ")", "except", "RuntimeError", "as", "exception", ":", "if", "is_oom_error", "(", "exception", ")", ":", "garbage_collection_cuda", "(", ")", "high", "=", "new_size", "midval", "=", "(", "high", "+", "low", ")", "/", "/", "2", "new_size", ",", "_", "=", "_adjust_batch_size", "(", "trainer", ",", "batch_arg_name", ",", "value", "=", "midval", ",", "desc", "=", "STRING", ")", "_reset_dataloaders", "(", "trainer", ")", "if", "high", "-", "low", "<", "=", "1", ":", "break", "else", ":", "raise", "#", "some", "other", "error", "not", "memory", "related", "return", "new_size"], "docstring": "reset after each try run loop Check if we've reached max_trials before trying to adjust batch size Double in size Force the train dataloader to reset as the batch size has changed Only these errors should trigger an adjustment If we fail in power mode, half the size and return Force the train dataloader to reset as the batch size has changed", "docstring_tokens": ["reset", "after", "each", "try", "run", "loop", "check", "if", "we", "ve", "reached", "max_trials", "before", "trying", "to", "adjust", "batch", "size", "double", "in", "size", "force", "the", "train", "dataloader", "to", "reset", "as", "the", "batch", "size", "has", "changed", "only", "these", "errors", "should", "trigger", "an", "adjustment", "if", "we", "fail", "in", "power", "mode", "half", "the", "size", "and", "return", "force", "the", "train", "dataloader", "to", "reset", "as", "the", "batch", "size", "has", "changed"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "start_line": 219, "end_line": 286, "has_examples": false, "num_comments": 8, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "func_name": "function_263", "original_string": "def _adjust_batch_size(\r\n    trainer: \"pl.Trainer\",\r\n    batch_arg_name: str = \"batch_size\",\r\n    factor: float = 1.0,\r\n    value: Optional[int] = None,\r\n    desc: Optional[str] = None,\r\n) -> tuple[int, bool]:\r\n    \"\"\"Helper function for adjusting the batch size.\r\n\r\n    Args:\r\n        trainer: instance of lightning.pytorch.Trainer\r\n        factor: value which the old batch size is multiplied by to get the\r\n            new batch size\r\n        value: if a value is given, will override the batch size with this value.\r\n            Note that the value of `factor` will not have an effect in this case\r\n        desc: either ``\"succeeded\"`` or ``\"failed\"``. Used purely for logging\r\n\r\n    Returns:\r\n        The new batch size for the next trial and a bool that signals whether the\r\n        new value is different than the previous batch size.\r\n\r\n    \"\"\"\r\n    model = trainer.lightning_module\r\n    batch_size = lightning_getattr(model, batch_arg_name)\r\n    assert batch_size is not None\r\n\r\n    loop = trainer._active_loop\r\n    assert loop is not None\r\n    loop.setup_data()\r\n    combined_loader = loop._combined_loader\r\n    assert combined_loader is not None\r\n    try:\r\n        combined_dataset_length = combined_loader._dataset_length()\r\n        if batch_size >= combined_dataset_length:\r\n            rank_zero_info(f\"The batch size {batch_size} is greater or equal than the length of your dataset.\")\r\n            return batch_size, False\r\n    except NotImplementedError:\r\n        pass\r\n\r\n    new_size = value if value is not None else int(batch_size * factor)\r\n    if desc:\r\n        rank_zero_info(f\"Batch size {batch_size} {desc}, trying batch size {new_size}\")\r\n    changed = new_size != batch_size\r\n    lightning_setattr(model, batch_arg_name, new_size)\r\n    return new_size, changed", "language": "python", "code": "def _adjust_batch_size(\r\n    trainer: \"pl.Trainer\",\r\n    batch_arg_name: str = \"batch_size\",\r\n    factor: float = 1.0,\r\n    value: Optional[int] = None,\r\n    desc: Optional[str] = None,\r\n) -> tuple[int, bool]:\r\n    \"\"\"Helper function for adjusting the batch size.\r\n\r\n    Args:\r\n        trainer: instance of lightning.pytorch.Trainer\r\n        factor: value which the old batch size is multiplied by to get the\r\n            new batch size\r\n        value: if a value is given, will override the batch size with this value.\r\n            Note that the value of `factor` will not have an effect in this case\r\n        desc: either ``\"succeeded\"`` or ``\"failed\"``. Used purely for logging\r\n\r\n    Returns:\r\n        The new batch size for the next trial and a bool that signals whether the\r\n        new value is different than the previous batch size.\r\n\r\n    \"\"\"\r\n    model = trainer.lightning_module\r\n    batch_size = lightning_getattr(model, batch_arg_name)\r\n    assert batch_size is not None\r\n\r\n    loop = trainer._active_loop\r\n    assert loop is not None\r\n    loop.setup_data()\r\n    combined_loader = loop._combined_loader\r\n    assert combined_loader is not None\r\n    try:\r\n        combined_dataset_length = combined_loader._dataset_length()\r\n        if batch_size >= combined_dataset_length:\r\n            rank_zero_info(f\"The batch size {batch_size} is greater or equal than the length of your dataset.\")\r\n            return batch_size, False\r\n    except NotImplementedError:\r\n        pass\r\n\r\n    new_size = value if value is not None else int(batch_size * factor)\r\n    if desc:\r\n        rank_zero_info(f\"Batch size {batch_size} {desc}, trying batch size {new_size}\")\r\n    changed = new_size != batch_size\r\n    lightning_setattr(model, batch_arg_name, new_size)\r\n    return new_size, changed", "code_tokens": ["def", "_adjust_batch_size", "(", "trainer", ":", "STRING", ",", "batch_arg_name", ":", "str", "=", "STRING", ",", "factor", ":", "float", "=", "1", ".", "0", ",", "value", ":", "Optional", "[", "int", "]", "=", "None", ",", "desc", ":", "Optional", "[", "str", "]", "=", "None", ",", ")", "-", ">", "tuple", "[", "int", ",", "bool", "]", ":", "STRING", "model", "=", "trainer", ".", "lightning_module", "batch_size", "=", "lightning_getattr", "(", "model", ",", "batch_arg_name", ")", "assert", "batch_size", "is", "not", "None", "loop", "=", "trainer", ".", "_active_loop", "assert", "loop", "is", "not", "None", "loop", ".", "setup_data", "(", ")", "combined_loader", "=", "loop", ".", "_combined_loader", "assert", "combined_loader", "is", "not", "None", "try", ":", "combined_dataset_length", "=", "combined_loader", ".", "_dataset_length", "(", ")", "if", "batch_size", ">", "=", "combined_dataset_length", ":", "rank_zero_info", "(", "fSTRING", ")", "return", "batch_size", ",", "False", "except", "NotImplementedError", ":", "pass", "new_size", "=", "value", "if", "value", "is", "not", "None", "else", "int", "(", "batch_size", "*", "factor", ")", "if", "desc", ":", "rank_zero_info", "(", "fSTRING", ")", "changed", "=", "new_size", "!", "=", "batch_size", "lightning_setattr", "(", "model", ",", "batch_arg_name", ",", "new_size", ")", "return", "new_size", ",", "changed"], "docstring": "all datasets are iterable style", "docstring_tokens": ["all", "datasets", "are", "iterable", "style"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\batch_size_scaling.py", "start_line": 289, "end_line": 334, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "func_name": "function_264", "original_string": "def _exchange_scheduler(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Decorate `trainer.strategy.setup_optimizers` method such that it sets the user's originally specified\r\n        optimizer together with a new scheduler that takes care of the learning rate search.\"\"\"\r\n        from lightning.pytorch.core.optimizer import _validate_optimizers_attached\r\n\r\n        optimizers = trainer.strategy.optimizers\r\n\r\n        if len(optimizers) != 1:\r\n            raise MisconfigurationException(\r\n                f\"`model.configure_optimizers()` returned {len(optimizers)}, but\"\r\n                \" learning rate finder only works with single optimizer\"\r\n            )\r\n\r\n        optimizer = optimizers[0]\r\n\r\n        new_lrs = [self.lr_min] * len(optimizer.param_groups)\r\n        for param_group, new_lr in zip(optimizer.param_groups, new_lrs):\r\n            param_group[\"lr\"] = new_lr\r\n            param_group[\"initial_lr\"] = new_lr\r\n\r\n        args = (optimizer, self.lr_max, self.num_training)\r\n        scheduler = _LinearLR(*args) if self.mode == \"linear\" else _ExponentialLR(*args)\r\n\r\n        trainer.strategy.optimizers = [optimizer]\r\n        trainer.strategy.lr_scheduler_configs = [LRSchedulerConfig(scheduler, interval=\"step\")]\r\n        _validate_optimizers_attached(trainer.optimizers, trainer.lr_scheduler_configs)", "language": "python", "code": "def _exchange_scheduler(self, trainer: \"pl.Trainer\") -> None:\r\n        \"\"\"Decorate `trainer.strategy.setup_optimizers` method such that it sets the user's originally specified\r\n        optimizer together with a new scheduler that takes care of the learning rate search.\"\"\"\r\n        from lightning.pytorch.core.optimizer import _validate_optimizers_attached\r\n\r\n        optimizers = trainer.strategy.optimizers\r\n\r\n        if len(optimizers) != 1:\r\n            raise MisconfigurationException(\r\n                f\"`model.configure_optimizers()` returned {len(optimizers)}, but\"\r\n                \" learning rate finder only works with single optimizer\"\r\n            )\r\n\r\n        optimizer = optimizers[0]\r\n\r\n        new_lrs = [self.lr_min] * len(optimizer.param_groups)\r\n        for param_group, new_lr in zip(optimizer.param_groups, new_lrs):\r\n            param_group[\"lr\"] = new_lr\r\n            param_group[\"initial_lr\"] = new_lr\r\n\r\n        args = (optimizer, self.lr_max, self.num_training)\r\n        scheduler = _LinearLR(*args) if self.mode == \"linear\" else _ExponentialLR(*args)\r\n\r\n        trainer.strategy.optimizers = [optimizer]\r\n        trainer.strategy.lr_scheduler_configs = [LRSchedulerConfig(scheduler, interval=\"step\")]\r\n        _validate_optimizers_attached(trainer.optimizers, trainer.lr_scheduler_configs)", "code_tokens": ["def", "_exchange_scheduler", "(", "self", ",", "trainer", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "from", "lightning", ".", "pytorch", ".", "core", ".", "optimizer", "import", "_validate_optimizers_attached", "optimizers", "=", "trainer", ".", "strategy", ".", "optimizers", "if", "len", "(", "optimizers", ")", "!", "=", "1", ":", "raise", "MisconfigurationException", "(", "fSTRING", "STRING", ")", "optimizer", "=", "optimizers", "[", "0", "]", "new_lrs", "=", "[", "self", ".", "lr_min", "]", "*", "len", "(", "optimizer", ".", "param_groups", ")", "for", "param_group", ",", "new_lr", "in", "zip", "(", "optimizer", ".", "param_groups", ",", "new_lrs", ")", ":", "param_group", "[", "STRING", "]", "=", "new_lr", "param_group", "[", "STRING", "]", "=", "new_lr", "args", "=", "(", "optimizer", ",", "self", ".", "lr_max", ",", "self", ".", "num_training", ")", "scheduler", "=", "_LinearLR", "(", "*", "args", ")", "if", "self", ".", "mode", "=", "=", "STRING", "else", "_ExponentialLR", "(", "*", "args", ")", "trainer", ".", "strategy", ".", "optimizers", "=", "[", "optimizer", "]", "trainer", ".", "strategy", ".", "lr_scheduler_configs", "=", "[", "LRSchedulerConfig", "(", "scheduler", ",", "interval", "=", "STRING", ")", "]", "_validate_optimizers_attached", "(", "trainer", ".", "optimizers", ",", "trainer", ".", "lr_scheduler_configs", ")"], "docstring": "TODO: update docs here", "docstring_tokens": ["todo", "update", "docs", "here"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "start_line": 90, "end_line": 116, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "func_name": "function_265", "original_string": "def plot(\r\n        self, suggest: bool = False, show: bool = False, ax: Optional[\"Axes\"] = None\r\n    ) -> Optional[Union[\"plt.Figure\", \"plt.SubFigure\"]]:\r\n        \"\"\"Plot results from lr_find run\r\n        Args:\r\n            suggest: if True, will mark suggested lr to use with a red point\r\n            show: if True, will show figure\r\n            ax: Axes object to which the plot is to be drawn. If not provided, a new figure is created.\r\n\r\n        \"\"\"\r\n        if not _MATPLOTLIB_AVAILABLE:\r\n            raise MisconfigurationException(\r\n                \"To use the `plot` method, you must have Matplotlib installed.\"\r\n                \" Install it by running `pip install -U matplotlib`.\"\r\n            )\r\n        import matplotlib.pyplot as plt\r\n\r\n        lrs = self.results[\"lr\"]\r\n        losses = self.results[\"loss\"]\r\n\r\n        fig: Optional[Union[plt.Figure, plt.SubFigure]]\r\n        if ax is None:\r\n            fig, ax = plt.subplots()\r\n        else:\r\n            fig = ax.figure\r\n\r\n        ax.plot(lrs, losses)\r\n        if self.mode == \"exponential\":\r\n            ax.set_xscale(\"log\")\r\n        ax.set_xlabel(\"Learning rate\")\r\n        ax.set_ylabel(\"Loss\")\r\n\r\n        if suggest:\r\n            _ = self.suggestion()\r\n            if self._optimal_idx:\r\n                ax.plot(lrs[self._optimal_idx], losses[self._optimal_idx], markersize=10, marker=\"o\", color=\"red\")\r\n\r\n        if show:\r\n            plt.show()\r\n\r\n        return fig", "language": "python", "code": "def plot(\r\n        self, suggest: bool = False, show: bool = False, ax: Optional[\"Axes\"] = None\r\n    ) -> Optional[Union[\"plt.Figure\", \"plt.SubFigure\"]]:\r\n        \"\"\"Plot results from lr_find run\r\n        Args:\r\n            suggest: if True, will mark suggested lr to use with a red point\r\n            show: if True, will show figure\r\n            ax: Axes object to which the plot is to be drawn. If not provided, a new figure is created.\r\n\r\n        \"\"\"\r\n        if not _MATPLOTLIB_AVAILABLE:\r\n            raise MisconfigurationException(\r\n                \"To use the `plot` method, you must have Matplotlib installed.\"\r\n                \" Install it by running `pip install -U matplotlib`.\"\r\n            )\r\n        import matplotlib.pyplot as plt\r\n\r\n        lrs = self.results[\"lr\"]\r\n        losses = self.results[\"loss\"]\r\n\r\n        fig: Optional[Union[plt.Figure, plt.SubFigure]]\r\n        if ax is None:\r\n            fig, ax = plt.subplots()\r\n        else:\r\n            fig = ax.figure\r\n\r\n        ax.plot(lrs, losses)\r\n        if self.mode == \"exponential\":\r\n            ax.set_xscale(\"log\")\r\n        ax.set_xlabel(\"Learning rate\")\r\n        ax.set_ylabel(\"Loss\")\r\n\r\n        if suggest:\r\n            _ = self.suggestion()\r\n            if self._optimal_idx:\r\n                ax.plot(lrs[self._optimal_idx], losses[self._optimal_idx], markersize=10, marker=\"o\", color=\"red\")\r\n\r\n        if show:\r\n            plt.show()\r\n\r\n        return fig", "code_tokens": ["def", "plot", "(", "self", ",", "suggest", ":", "bool", "=", "False", ",", "show", ":", "bool", "=", "False", ",", "ax", ":", "Optional", "[", "STRING", "]", "=", "None", ")", "-", ">", "Optional", "[", "Union", "[", "STRING", ",", "STRING", "]", "]", ":", "STRING", "if", "not", "_MATPLOTLIB_AVAILABLE", ":", "raise", "MisconfigurationException", "(", "STRING", "STRING", ")", "import", "matplotlib", ".", "pyplot", "as", "plt", "lrs", "=", "self", ".", "results", "[", "STRING", "]", "losses", "=", "self", ".", "results", "[", "STRING", "]", "fig", ":", "Optional", "[", "Union", "[", "plt", ".", "Figure", ",", "plt", ".", "SubFigure", "]", "]", "if", "ax", "is", "None", ":", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "else", ":", "fig", "=", "ax", ".", "figure", "ax", ".", "plot", "(", "lrs", ",", "losses", ")", "if", "self", ".", "mode", "=", "=", "STRING", ":", "ax", ".", "set_xscale", "(", "STRING", ")", "ax", ".", "set_xlabel", "(", "STRING", ")", "ax", ".", "set_ylabel", "(", "STRING", ")", "if", "suggest", ":", "_", "=", "self", ".", "suggestion", "(", ")", "if", "self", ".", "_optimal_idx", ":", "ax", ".", "plot", "(", "lrs", "[", "self", ".", "_optimal_idx", "]", ",", "losses", "[", "self", ".", "_optimal_idx", "]", ",", "markersize", "=", "10", ",", "marker", "=", "STRING", ",", "color", "=", "STRING", ")", "if", "show", ":", "plt", ".", "show", "(", ")", "return", "fig"], "docstring": "Plot loss as a function of the learning rate", "docstring_tokens": ["plot", "loss", "as", "a", "function", "of", "the", "learning", "rate"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "start_line": 118, "end_line": 159, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "func_name": "function_266", "original_string": "def suggestion(self, skip_begin: int = 10, skip_end: int = 1) -> Optional[float]:\r\n        \"\"\"This will propose a suggestion for an initial learning rate based on the point with the steepest negative\r\n        gradient.\r\n\r\n        Args:\r\n            skip_begin: how many samples to skip in the beginning; helps to avoid too naive estimates\r\n            skip_end: how many samples to skip in the end; helps to avoid too optimistic estimates\r\n\r\n        Returns:\r\n            The suggested initial learning rate to use, or `None` if a suggestion is not possible due to too few\r\n            loss samples.\r\n\r\n        \"\"\"\r\n        losses = torch.tensor(self.results[\"loss\"][skip_begin:-skip_end])\r\n        lrs = torch.tensor(self.results[\"lr\"][skip_begin:-skip_end])\r\n        is_finite = torch.isfinite(losses)\r\n        losses = losses[is_finite]\r\n        lrs = lrs[is_finite]\r\n\r\n        if len(losses) < 2:\r\n            log.error(\r\n                \"Failed to compute suggestion for learning rate because there are not enough points. Increase the loop\"\r\n                \" iteration limits or the size of your dataset/dataloader.\"\r\n            )\r\n            self._optimal_idx = None\r\n            return None\r\n\r\n        gradients = torch.gradient(losses, spacing=[lrs])[0]  # Compute the gradient of losses w.r.t. learning rates\r\n        min_grad = torch.argmin(gradients).item()\r\n        all_losses_idx = torch.arange(len(self.results[\"loss\"]))\r\n        idx_non_skipped = all_losses_idx[skip_begin:-skip_end]\r\n        idx_finite = idx_non_skipped[is_finite]\r\n        self._optimal_idx = idx_finite[min_grad].item()  # type: ignore\r\n        return self.results[\"lr\"][self._optimal_idx]", "language": "python", "code": "def suggestion(self, skip_begin: int = 10, skip_end: int = 1) -> Optional[float]:\r\n        \"\"\"This will propose a suggestion for an initial learning rate based on the point with the steepest negative\r\n        gradient.\r\n\r\n        Args:\r\n            skip_begin: how many samples to skip in the beginning; helps to avoid too naive estimates\r\n            skip_end: how many samples to skip in the end; helps to avoid too optimistic estimates\r\n\r\n        Returns:\r\n            The suggested initial learning rate to use, or `None` if a suggestion is not possible due to too few\r\n            loss samples.\r\n\r\n        \"\"\"\r\n        losses = torch.tensor(self.results[\"loss\"][skip_begin:-skip_end])\r\n        lrs = torch.tensor(self.results[\"lr\"][skip_begin:-skip_end])\r\n        is_finite = torch.isfinite(losses)\r\n        losses = losses[is_finite]\r\n        lrs = lrs[is_finite]\r\n\r\n        if len(losses) < 2:\r\n            log.error(\r\n                \"Failed to compute suggestion for learning rate because there are not enough points. Increase the loop\"\r\n                \" iteration limits or the size of your dataset/dataloader.\"\r\n            )\r\n            self._optimal_idx = None\r\n            return None\r\n\r\n        gradients = torch.gradient(losses, spacing=[lrs])[0]  # Compute the gradient of losses w.r.t. learning rates\r\n        min_grad = torch.argmin(gradients).item()\r\n        all_losses_idx = torch.arange(len(self.results[\"loss\"]))\r\n        idx_non_skipped = all_losses_idx[skip_begin:-skip_end]\r\n        idx_finite = idx_non_skipped[is_finite]\r\n        self._optimal_idx = idx_finite[min_grad].item()  # type: ignore\r\n        return self.results[\"lr\"][self._optimal_idx]", "code_tokens": ["def", "suggestion", "(", "self", ",", "skip_begin", ":", "int", "=", "10", ",", "skip_end", ":", "int", "=", "1", ")", "-", ">", "Optional", "[", "float", "]", ":", "STRING", "losses", "=", "torch", ".", "tensor", "(", "self", ".", "results", "[", "STRING", "]", "[", "skip_begin", ":", "-", "skip_end", "]", ")", "lrs", "=", "torch", ".", "tensor", "(", "self", ".", "results", "[", "STRING", "]", "[", "skip_begin", ":", "-", "skip_end", "]", ")", "is_finite", "=", "torch", ".", "isfinite", "(", "losses", ")", "losses", "=", "losses", "[", "is_finite", "]", "lrs", "=", "lrs", "[", "is_finite", "]", "if", "len", "(", "losses", ")", "<", "2", ":", "log", ".", "error", "(", "STRING", "STRING", ")", "self", ".", "_optimal_idx", "=", "None", "return", "None", "gradients", "=", "torch", ".", "gradient", "(", "losses", ",", "spacing", "=", "[", "lrs", "]", ")", "[", "0", "]", "#", "Compute", "the", "gradient", "of", "losses", "w", ".", "r", ".", "t", ".", "learning", "rates", "min_grad", "=", "torch", ".", "argmin", "(", "gradients", ")", ".", "item", "(", ")", "all_losses_idx", "=", "torch", ".", "arange", "(", "len", "(", "self", ".", "results", "[", "STRING", "]", ")", ")", "idx_non_skipped", "=", "all_losses_idx", "[", "skip_begin", ":", "-", "skip_end", "]", "idx_finite", "=", "idx_non_skipped", "[", "is_finite", "]", "self", ".", "_optimal_idx", "=", "idx_finite", "[", "min_grad", "]", ".", "item", "(", ")", "#", "type", ":", "ignore", "return", "self", ".", "results", "[", "STRING", "]", "[", "self", ".", "_optimal_idx", "]"], "docstring": "computing torch.gradient requires at least 2 points", "docstring_tokens": ["computing", "torch", "gradient", "requires", "at", "least", "2", "points"], "partition": "valid", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "start_line": 161, "end_line": 195, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "func_name": "function_267", "original_string": "def _lr_find(\r\n    trainer: \"pl.Trainer\",\r\n    model: \"pl.LightningModule\",\r\n    min_lr: float = 1e-8,\r\n    max_lr: float = 1,\r\n    num_training: int = 100,\r\n    mode: str = \"exponential\",\r\n    early_stop_threshold: Optional[float] = 4.0,\r\n    update_attr: bool = False,\r\n    attr_name: str = \"\",\r\n) -> Optional[_LRFinder]:\r\n    \"\"\"Enables the user to do a range test of good initial learning rates, to reduce the amount of guesswork in picking\r\n    a good starting learning rate.\r\n\r\n    Args:\r\n        trainer: A Trainer instance.\r\n        model: Model to tune.\r\n        min_lr: minimum learning rate to investigate\r\n        max_lr: maximum learning rate to investigate\r\n        num_training: number of learning rates to test\r\n        mode: Search strategy to update learning rate after each batch:\r\n\r\n            - ``'exponential'``: Increases the learning rate exponentially.\r\n            - ``'linear'``: Increases the learning rate linearly.\r\n\r\n        early_stop_threshold: Threshold for stopping the search. If the\r\n            loss at any point is larger than early_stop_threshold*best_loss\r\n            then the search is stopped. To disable, set to None.\r\n        update_attr: Whether to update the learning rate attribute or not.\r\n        attr_name: Name of the attribute which stores the learning rate. The names 'learning_rate' or 'lr' get\r\n            automatically detected. Otherwise, set the name here.\r\n\r\n    \"\"\"\r\n    if trainer.fast_dev_run:\r\n        rank_zero_warn(\"Skipping learning rate finder since `fast_dev_run` is enabled.\")\r\n        return None\r\n\r\n    if update_attr:\r\n        attr_name = _determine_lr_attr_name(model, attr_name)\r\n\r\n    ckpt_path = os.path.join(trainer.default_root_dir, f\".lr_find_{uuid.uuid4()}.ckpt\")\r\n    ckpt_path = trainer.strategy.broadcast(ckpt_path)\r\n    trainer.save_checkpoint(ckpt_path)\r\n\r\n    start_steps = trainer.global_step\r\n\r\n    params = __lr_finder_dump_params(trainer)\r\n\r\n    __lr_finder_reset_params(trainer, num_training, early_stop_threshold)\r\n\r\n    if trainer.progress_bar_callback:\r\n        trainer.progress_bar_callback.disable()\r\n\r\n    lr_finder = _LRFinder(mode, min_lr, max_lr, num_training)\r\n\r\n    lr_finder_finished = False\r\n    try:\r\n        lr_finder._exchange_scheduler(trainer)\r\n\r\n        _try_loop_run(trainer, params)\r\n\r\n        if trainer.global_step != num_training + start_steps:\r\n            log.info(f\"LR finder stopped early after {trainer.global_step} steps due to diverging loss.\")\r\n\r\n        lr_finder.results.update({\"lr\": trainer.callbacks[0].lrs, \"loss\": trainer.callbacks[0].losses})\r\n        lr_finder._total_batch_idx = trainer.fit_loop.total_batch_idx  # for debug purpose\r\n\r\n        __lr_finder_restore_params(trainer, params)\r\n\r\n        if trainer.progress_bar_callback:\r\n            trainer.progress_bar_callback.enable()\r\n\r\n        lr_finder.results = trainer.strategy.broadcast(lr_finder.results)\r\n        lr_finder_finished = True\r\n    except Exception as ex:\r\n        raise ex\r\n    finally:\r\n        trainer._checkpoint_connector.restore(ckpt_path)\r\n        trainer.strategy.remove_checkpoint(ckpt_path)\r\n        trainer.fit_loop.restarting = False  # reset restarting flag as checkpoint restoring sets it to True\r\n        trainer.fit_loop.epoch_loop.restarting = False  # reset restarting flag as checkpoint restoring sets it to True\r\n        trainer.fit_loop.epoch_loop.val_loop._combined_loader = None\r\n        trainer.fit_loop._combined_loader = None  # reset data fetcher to avoid issues with the next fit\r\n        trainer.fit_loop.setup_data()\r\n\r\n    if update_attr and lr_finder_finished:\r\n        lr = lr_finder.suggestion()\r\n        if lr is not None:\r\n            lightning_setattr(model, attr_name, lr)\r\n            for opt in trainer.optimizers or []:\r\n                for pg in opt.param_groups:\r\n                    pg[\"lr\"] = lr\r\n            log.info(f\"Learning rate set to {lr}\")\r\n    return lr_finder", "language": "python", "code": "def _lr_find(\r\n    trainer: \"pl.Trainer\",\r\n    model: \"pl.LightningModule\",\r\n    min_lr: float = 1e-8,\r\n    max_lr: float = 1,\r\n    num_training: int = 100,\r\n    mode: str = \"exponential\",\r\n    early_stop_threshold: Optional[float] = 4.0,\r\n    update_attr: bool = False,\r\n    attr_name: str = \"\",\r\n) -> Optional[_LRFinder]:\r\n    \"\"\"Enables the user to do a range test of good initial learning rates, to reduce the amount of guesswork in picking\r\n    a good starting learning rate.\r\n\r\n    Args:\r\n        trainer: A Trainer instance.\r\n        model: Model to tune.\r\n        min_lr: minimum learning rate to investigate\r\n        max_lr: maximum learning rate to investigate\r\n        num_training: number of learning rates to test\r\n        mode: Search strategy to update learning rate after each batch:\r\n\r\n            - ``'exponential'``: Increases the learning rate exponentially.\r\n            - ``'linear'``: Increases the learning rate linearly.\r\n\r\n        early_stop_threshold: Threshold for stopping the search. If the\r\n            loss at any point is larger than early_stop_threshold*best_loss\r\n            then the search is stopped. To disable, set to None.\r\n        update_attr: Whether to update the learning rate attribute or not.\r\n        attr_name: Name of the attribute which stores the learning rate. The names 'learning_rate' or 'lr' get\r\n            automatically detected. Otherwise, set the name here.\r\n\r\n    \"\"\"\r\n    if trainer.fast_dev_run:\r\n        rank_zero_warn(\"Skipping learning rate finder since `fast_dev_run` is enabled.\")\r\n        return None\r\n\r\n    if update_attr:\r\n        attr_name = _determine_lr_attr_name(model, attr_name)\r\n\r\n    ckpt_path = os.path.join(trainer.default_root_dir, f\".lr_find_{uuid.uuid4()}.ckpt\")\r\n    ckpt_path = trainer.strategy.broadcast(ckpt_path)\r\n    trainer.save_checkpoint(ckpt_path)\r\n\r\n    start_steps = trainer.global_step\r\n\r\n    params = __lr_finder_dump_params(trainer)\r\n\r\n    __lr_finder_reset_params(trainer, num_training, early_stop_threshold)\r\n\r\n    if trainer.progress_bar_callback:\r\n        trainer.progress_bar_callback.disable()\r\n\r\n    lr_finder = _LRFinder(mode, min_lr, max_lr, num_training)\r\n\r\n    lr_finder_finished = False\r\n    try:\r\n        lr_finder._exchange_scheduler(trainer)\r\n\r\n        _try_loop_run(trainer, params)\r\n\r\n        if trainer.global_step != num_training + start_steps:\r\n            log.info(f\"LR finder stopped early after {trainer.global_step} steps due to diverging loss.\")\r\n\r\n        lr_finder.results.update({\"lr\": trainer.callbacks[0].lrs, \"loss\": trainer.callbacks[0].losses})\r\n        lr_finder._total_batch_idx = trainer.fit_loop.total_batch_idx  # for debug purpose\r\n\r\n        __lr_finder_restore_params(trainer, params)\r\n\r\n        if trainer.progress_bar_callback:\r\n            trainer.progress_bar_callback.enable()\r\n\r\n        lr_finder.results = trainer.strategy.broadcast(lr_finder.results)\r\n        lr_finder_finished = True\r\n    except Exception as ex:\r\n        raise ex\r\n    finally:\r\n        trainer._checkpoint_connector.restore(ckpt_path)\r\n        trainer.strategy.remove_checkpoint(ckpt_path)\r\n        trainer.fit_loop.restarting = False  # reset restarting flag as checkpoint restoring sets it to True\r\n        trainer.fit_loop.epoch_loop.restarting = False  # reset restarting flag as checkpoint restoring sets it to True\r\n        trainer.fit_loop.epoch_loop.val_loop._combined_loader = None\r\n        trainer.fit_loop._combined_loader = None  # reset data fetcher to avoid issues with the next fit\r\n        trainer.fit_loop.setup_data()\r\n\r\n    if update_attr and lr_finder_finished:\r\n        lr = lr_finder.suggestion()\r\n        if lr is not None:\r\n            lightning_setattr(model, attr_name, lr)\r\n            for opt in trainer.optimizers or []:\r\n                for pg in opt.param_groups:\r\n                    pg[\"lr\"] = lr\r\n            log.info(f\"Learning rate set to {lr}\")\r\n    return lr_finder", "code_tokens": ["def", "_lr_find", "(", "trainer", ":", "STRING", ",", "model", ":", "STRING", ",", "min_lr", ":", "float", "=", "1e", "-", "8", ",", "max_lr", ":", "float", "=", "1", ",", "num_training", ":", "int", "=", "100", ",", "mode", ":", "str", "=", "STRING", ",", "early_stop_threshold", ":", "Optional", "[", "float", "]", "=", "4", ".", "0", ",", "update_attr", ":", "bool", "=", "False", ",", "attr_name", ":", "str", "=", "STRING", ",", ")", "-", ">", "Optional", "[", "_LRFinder", "]", ":", "STRING", "if", "trainer", ".", "fast_dev_run", ":", "rank_zero_warn", "(", "STRING", ")", "return", "None", "if", "update_attr", ":", "attr_name", "=", "_determine_lr_attr_name", "(", "model", ",", "attr_name", ")", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "trainer", ".", "default_root_dir", ",", "fSTRING", ")", "ckpt_path", "=", "trainer", ".", "strategy", ".", "broadcast", "(", "ckpt_path", ")", "trainer", ".", "save_checkpoint", "(", "ckpt_path", ")", "start_steps", "=", "trainer", ".", "global_step", "params", "=", "__lr_finder_dump_params", "(", "trainer", ")", "__lr_finder_reset_params", "(", "trainer", ",", "num_training", ",", "early_stop_threshold", ")", "if", "trainer", ".", "progress_bar_callback", ":", "trainer", ".", "progress_bar_callback", ".", "disable", "(", ")", "lr_finder", "=", "_LRFinder", "(", "mode", ",", "min_lr", ",", "max_lr", ",", "num_training", ")", "lr_finder_finished", "=", "False", "try", ":", "lr_finder", ".", "_exchange_scheduler", "(", "trainer", ")", "_try_loop_run", "(", "trainer", ",", "params", ")", "if", "trainer", ".", "global_step", "!", "=", "num_training", "+", "start_steps", ":", "log", ".", "info", "(", "fSTRING", ")", "lr_finder", ".", "results", ".", "update", "(", "{", "STRING", ":", "trainer", ".", "callbacks", "[", "0", "]", ".", "lrs", ",", "STRING", ":", "trainer", ".", "callbacks", "[", "0", "]", ".", "losses", "}", ")", "lr_finder", ".", "_total_batch_idx", "=", "trainer", ".", "fit_loop", ".", "total_batch_idx", "#", "for", "debug", "purpose", "__lr_finder_restore_params", "(", "trainer", ",", "params", ")", "if", "trainer", ".", "progress_bar_callback", ":", "trainer", ".", "progress_bar_callback", ".", "enable", "(", ")", "lr_finder", ".", "results", "=", "trainer", ".", "strategy", ".", "broadcast", "(", "lr_finder", ".", "results", ")", "lr_finder_finished", "=", "True", "except", "Exception", "as", "ex", ":", "raise", "ex", "finally", ":", "trainer", ".", "_checkpoint_connector", ".", "restore", "(", "ckpt_path", ")", "trainer", ".", "strategy", ".", "remove_checkpoint", "(", "ckpt_path", ")", "trainer", ".", "fit_loop", ".", "restarting", "=", "False", "#", "reset", "restarting", "flag", "as", "checkpoint", "restoring", "sets", "it", "to", "True", "trainer", ".", "fit_loop", ".", "epoch_loop", ".", "restarting", "=", "False", "#", "reset", "restarting", "flag", "as", "checkpoint", "restoring", "sets", "it", "to", "True", "trainer", ".", "fit_loop", ".", "epoch_loop", ".", "val_loop", ".", "_combined_loader", "=", "None", "trainer", ".", "fit_loop", ".", "_combined_loader", "=", "None", "#", "reset", "data", "fetcher", "to", "avoid", "issues", "with", "the", "next", "fit", "trainer", ".", "fit_loop", ".", "setup_data", "(", ")", "if", "update_attr", "and", "lr_finder_finished", ":", "lr", "=", "lr_finder", ".", "suggestion", "(", ")", "if", "lr", "is", "not", "None", ":", "lightning_setattr", "(", "model", ",", "attr_name", ",", "lr", ")", "for", "opt", "in", "trainer", ".", "optimizers", "or", "[", "]", ":", "for", "pg", "in", "opt", ".", "param_groups", ":", "pg", "[", "STRING", "]", "=", "lr", "log", ".", "info", "(", "fSTRING", ")", "return", "lr_finder"], "docstring": "Determine lr attr Save initial model, that is loaded after learning rate is found Arguments we adjust during the lr finder, save for restoring Set to values that are required by the algorithm Disable standard progress bar for fit Initialize lr finder object (stores results) Configure optimizer and scheduler Fit, lr & loss logged in callback Prompt if we stopped early Transfer results from callback to lr finder object Update results across ranks Restore initial state of model (this will also restore the original optimizer state) Apply LR suggestion after restoring so it persists for the real training run When used as a callback, the suggestion would otherwise be lost due to checkpoint restore update the attribute on the LightningModule (e.g., lr or learning_rate) also update the currently active optimizer(s) so training continues with the suggested LR", "docstring_tokens": ["determine", "lr", "attr", "save", "initial", "model", "that", "is", "loaded", "after", "learning", "rate", "is", "found", "arguments", "we", "adjust", "during", "the", "lr", "finder", "save", "for", "restoring", "set", "to", "values", "that", "are", "required", "by", "the", "algorithm", "disable", "standard", "progress", "bar", "for", "fit", "initialize", "lr", "finder", "object", "stores", "results", "configure", "optimizer", "and", "scheduler", "fit", "lr", "loss", "logged", "in", "callback", "prompt", "if", "we", "stopped", "early", "transfer", "results", "from", "callback", "to", "lr", "finder", "object", "update", "results", "across", "ranks", "restore", "initial", "state", "of", "model", "this", "will", "also", "restore", "the", "original", "optimizer", "state", "apply", "lr", "suggestion", "after", "restoring", "so", "it", "persists", "for", "the", "real", "training", "run", "when", "used", "as", "a", "callback", "the", "suggestion", "would", "otherwise", "be", "lost", "due", "to", "checkpoint", "restore", "update", "the", "attribute", "on", "the", "lightningmodule", "e", "g", "lr", "or", "learning_rate", "also", "update", "the", "currently", "active", "optimizer", "s", "so", "training", "continues", "with", "the", "suggested", "lr"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "start_line": 198, "end_line": 307, "has_examples": false, "num_comments": 15, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "func_name": "function_268", "original_string": "def on_train_batch_end(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", outputs: STEP_OUTPUT, batch: Any, batch_idx: int\r\n    ) -> None:\r\n        \"\"\"Called when the training batch ends, logs the calculated loss.\"\"\"\r\n        if (trainer.fit_loop.batch_idx + 1) % trainer.accumulate_grad_batches != 0:\r\n            return\r\n\r\n        if not outputs:\r\n            self.losses.append(float(\"nan\"))\r\n            return\r\n\r\n        if self.progress_bar:\r\n            self.progress_bar.update()\r\n\r\n        loss_tensor = outputs if isinstance(outputs, torch.Tensor) else outputs[\"loss\"]\r\n        assert loss_tensor is not None\r\n        current_loss = loss_tensor.item()\r\n        current_step = trainer.global_step\r\n\r\n        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * current_loss\r\n        smoothed_loss = self.avg_loss / (1 - self.beta ** (current_step + 1))\r\n\r\n        if (\r\n            self.early_stop_threshold is not None\r\n            and current_step > 1\r\n            and smoothed_loss > self.early_stop_threshold * self.best_loss\r\n        ):\r\n            trainer.should_stop = True  # stop signal\r\n            if self.progress_bar:\r\n                self.progress_bar.close()\r\n\r\n        trainer.should_stop = trainer.strategy.broadcast(trainer.should_stop)\r\n\r\n        if smoothed_loss < self.best_loss or current_step == 1:\r\n            self.best_loss = smoothed_loss\r\n\r\n        self.losses.append(smoothed_loss)", "language": "python", "code": "def on_train_batch_end(\r\n        self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", outputs: STEP_OUTPUT, batch: Any, batch_idx: int\r\n    ) -> None:\r\n        \"\"\"Called when the training batch ends, logs the calculated loss.\"\"\"\r\n        if (trainer.fit_loop.batch_idx + 1) % trainer.accumulate_grad_batches != 0:\r\n            return\r\n\r\n        if not outputs:\r\n            self.losses.append(float(\"nan\"))\r\n            return\r\n\r\n        if self.progress_bar:\r\n            self.progress_bar.update()\r\n\r\n        loss_tensor = outputs if isinstance(outputs, torch.Tensor) else outputs[\"loss\"]\r\n        assert loss_tensor is not None\r\n        current_loss = loss_tensor.item()\r\n        current_step = trainer.global_step\r\n\r\n        self.avg_loss = self.beta * self.avg_loss + (1 - self.beta) * current_loss\r\n        smoothed_loss = self.avg_loss / (1 - self.beta ** (current_step + 1))\r\n\r\n        if (\r\n            self.early_stop_threshold is not None\r\n            and current_step > 1\r\n            and smoothed_loss > self.early_stop_threshold * self.best_loss\r\n        ):\r\n            trainer.should_stop = True  # stop signal\r\n            if self.progress_bar:\r\n                self.progress_bar.close()\r\n\r\n        trainer.should_stop = trainer.strategy.broadcast(trainer.should_stop)\r\n\r\n        if smoothed_loss < self.best_loss or current_step == 1:\r\n            self.best_loss = smoothed_loss\r\n\r\n        self.losses.append(smoothed_loss)", "code_tokens": ["def", "on_train_batch_end", "(", "self", ",", "trainer", ":", "STRING", ",", "pl_module", ":", "STRING", ",", "outputs", ":", "STEP_OUTPUT", ",", "batch", ":", "Any", ",", "batch_idx", ":", "int", ")", "-", ">", "None", ":", "STRING", "if", "(", "trainer", ".", "fit_loop", ".", "batch_idx", "+", "1", ")", "%", "trainer", ".", "accumulate_grad_batches", "!", "=", "0", ":", "return", "if", "not", "outputs", ":", "self", ".", "losses", ".", "append", "(", "float", "(", "STRING", ")", ")", "return", "if", "self", ".", "progress_bar", ":", "self", ".", "progress_bar", ".", "update", "(", ")", "loss_tensor", "=", "outputs", "if", "isinstance", "(", "outputs", ",", "torch", ".", "Tensor", ")", "else", "outputs", "[", "STRING", "]", "assert", "loss_tensor", "is", "not", "None", "current_loss", "=", "loss_tensor", ".", "item", "(", ")", "current_step", "=", "trainer", ".", "global_step", "self", ".", "avg_loss", "=", "self", ".", "beta", "*", "self", ".", "avg_loss", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "current_loss", "smoothed_loss", "=", "self", ".", "avg_loss", "/", "(", "1", "-", "self", ".", "beta", "*", "*", "(", "current_step", "+", "1", ")", ")", "if", "(", "self", ".", "early_stop_threshold", "is", "not", "None", "and", "current_step", ">", "1", "and", "smoothed_loss", ">", "self", ".", "early_stop_threshold", "*", "self", ".", "best_loss", ")", ":", "trainer", ".", "should_stop", "=", "True", "#", "stop", "signal", "if", "self", ".", "progress_bar", ":", "self", ".", "progress_bar", ".", "close", "(", ")", "trainer", ".", "should_stop", "=", "trainer", ".", "strategy", ".", "broadcast", "(", "trainer", ".", "should_stop", ")", "if", "smoothed_loss", "<", "self", ".", "best_loss", "or", "current_step", "=", "=", "1", ":", "self", ".", "best_loss", "=", "smoothed_loss", "self", ".", "losses", ".", "append", "(", "smoothed_loss", ")"], "docstring": "_AutomaticOptimization.run turns None STEP_OUTPUT into an empty dict need to add an element, because we also added one element to lrs in on_train_batch_start so add nan, because they are not considered when computing the suggestion Avg loss (loss with momentum) + smoothing Check if we diverging Save best loss for diverging checking", "docstring_tokens": ["_automaticoptimization", "run", "turns", "none", "step_output", "into", "an", "empty", "dict", "need", "to", "add", "an", "element", "because", "we", "also", "added", "one", "element", "to", "lrs", "in", "on_train_batch_start", "so", "add", "nan", "because", "they", "are", "not", "considered", "when", "computing", "the", "suggestion", "avg", "loss", "loss", "with", "momentum", "smoothing", "check", "if", "we", "diverging", "save", "best", "loss", "for", "diverging", "checking"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\lr_finder.py", "start_line": 397, "end_line": 439, "has_examples": false, "num_comments": 5, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\tuning.py", "func_name": "function_269", "original_string": "def scale_batch_size(\r\n        self,\r\n        model: \"pl.LightningModule\",\r\n        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, \"pl.LightningDataModule\"]] = None,\r\n        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        datamodule: Optional[\"pl.LightningDataModule\"] = None,\r\n        method: Literal[\"fit\", \"validate\", \"test\", \"predict\"] = \"fit\",\r\n        mode: str = \"power\",\r\n        steps_per_trial: int = 3,\r\n        init_val: int = 2,\r\n        max_trials: int = 25,\r\n        batch_arg_name: str = \"batch_size\",\r\n    ) -> Optional[int]:\r\n        \"\"\"Iteratively try to find the largest batch size for a given model that does not give an out of memory (OOM)\r\n        error.\r\n\r\n        Args:\r\n            model: Model to tune.\r\n            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\r\n                :class:`~lightning.pytorch.core.datamodule.LightningDataModule` specifying training samples.\r\n                In the case of multiple dataloaders, please see this :ref:`section <multiple-dataloaders>`.\r\n            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\r\n            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying val/test/predict\r\n                samples used for running tuner on validation/testing/prediction.\r\n            datamodule: An instance of :class:`~lightning.pytorch.core.datamodule.LightningDataModule`.\r\n            method: Method to run tuner on. It can be any of ``(\"fit\", \"validate\", \"test\", \"predict\")``.\r\n            mode: Search strategy to update the batch size:\r\n\r\n                - ``'power'``: Keep multiplying the batch size by 2, until we get an OOM error.\r\n                - ``'binsearch'``: Initially keep multiplying by 2 and after encountering an OOM error\r\n                    do a binary search between the last successful batch size and the batch size that failed.\r\n\r\n            steps_per_trial: number of steps to run with a given batch size.\r\n                Ideally 1 should be enough to test if an OOM error occurs,\r\n                however in practise a few are needed\r\n            init_val: initial batch size to start the search with\r\n            max_trials: max number of increases in batch size done before\r\n               algorithm is terminated\r\n            batch_arg_name: name of the attribute that stores the batch size.\r\n                It is expected that the user has provided a model or datamodule that has a hyperparameter\r\n                with that name. We will look for this attribute name in the following places\r\n\r\n                - ``model``\r\n                - ``model.hparams``\r\n                - ``trainer.datamodule`` (the datamodule passed to the tune method)\r\n\r\n        \"\"\"\r\n        _check_tuner_configuration(train_dataloaders, val_dataloaders, dataloaders, method)\r\n        _check_scale_batch_size_configuration(self._trainer)\r\n\r\n        from lightning.pytorch.callbacks.batch_size_finder import BatchSizeFinder\r\n\r\n        batch_size_finder: Callback = BatchSizeFinder(\r\n            mode=mode,\r\n            steps_per_trial=steps_per_trial,\r\n            init_val=init_val,\r\n            max_trials=max_trials,\r\n            batch_arg_name=batch_arg_name,\r\n        )\r\n        batch_size_finder._early_exit = True\r\n        self._trainer.callbacks = [batch_size_finder] + self._trainer.callbacks\r\n\r\n        if method == \"fit\":\r\n            self._trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)\r\n        elif method == \"validate\":\r\n            self._trainer.validate(model, dataloaders, datamodule=datamodule)\r\n        elif method == \"test\":\r\n            self._trainer.test(model, dataloaders, datamodule=datamodule)\r\n        elif method == \"predict\":\r\n            self._trainer.predict(model, dataloaders, datamodule=datamodule)\r\n\r\n        self._trainer.callbacks = [cb for cb in self._trainer.callbacks if cb is not batch_size_finder]\r\n        return batch_size_finder.optimal_batch_size", "language": "python", "code": "def scale_batch_size(\r\n        self,\r\n        model: \"pl.LightningModule\",\r\n        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, \"pl.LightningDataModule\"]] = None,\r\n        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        datamodule: Optional[\"pl.LightningDataModule\"] = None,\r\n        method: Literal[\"fit\", \"validate\", \"test\", \"predict\"] = \"fit\",\r\n        mode: str = \"power\",\r\n        steps_per_trial: int = 3,\r\n        init_val: int = 2,\r\n        max_trials: int = 25,\r\n        batch_arg_name: str = \"batch_size\",\r\n    ) -> Optional[int]:\r\n        \"\"\"Iteratively try to find the largest batch size for a given model that does not give an out of memory (OOM)\r\n        error.\r\n\r\n        Args:\r\n            model: Model to tune.\r\n            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\r\n                :class:`~lightning.pytorch.core.datamodule.LightningDataModule` specifying training samples.\r\n                In the case of multiple dataloaders, please see this :ref:`section <multiple-dataloaders>`.\r\n            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\r\n            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying val/test/predict\r\n                samples used for running tuner on validation/testing/prediction.\r\n            datamodule: An instance of :class:`~lightning.pytorch.core.datamodule.LightningDataModule`.\r\n            method: Method to run tuner on. It can be any of ``(\"fit\", \"validate\", \"test\", \"predict\")``.\r\n            mode: Search strategy to update the batch size:\r\n\r\n                - ``'power'``: Keep multiplying the batch size by 2, until we get an OOM error.\r\n                - ``'binsearch'``: Initially keep multiplying by 2 and after encountering an OOM error\r\n                    do a binary search between the last successful batch size and the batch size that failed.\r\n\r\n            steps_per_trial: number of steps to run with a given batch size.\r\n                Ideally 1 should be enough to test if an OOM error occurs,\r\n                however in practise a few are needed\r\n            init_val: initial batch size to start the search with\r\n            max_trials: max number of increases in batch size done before\r\n               algorithm is terminated\r\n            batch_arg_name: name of the attribute that stores the batch size.\r\n                It is expected that the user has provided a model or datamodule that has a hyperparameter\r\n                with that name. We will look for this attribute name in the following places\r\n\r\n                - ``model``\r\n                - ``model.hparams``\r\n                - ``trainer.datamodule`` (the datamodule passed to the tune method)\r\n\r\n        \"\"\"\r\n        _check_tuner_configuration(train_dataloaders, val_dataloaders, dataloaders, method)\r\n        _check_scale_batch_size_configuration(self._trainer)\r\n\r\n        from lightning.pytorch.callbacks.batch_size_finder import BatchSizeFinder\r\n\r\n        batch_size_finder: Callback = BatchSizeFinder(\r\n            mode=mode,\r\n            steps_per_trial=steps_per_trial,\r\n            init_val=init_val,\r\n            max_trials=max_trials,\r\n            batch_arg_name=batch_arg_name,\r\n        )\r\n        batch_size_finder._early_exit = True\r\n        self._trainer.callbacks = [batch_size_finder] + self._trainer.callbacks\r\n\r\n        if method == \"fit\":\r\n            self._trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)\r\n        elif method == \"validate\":\r\n            self._trainer.validate(model, dataloaders, datamodule=datamodule)\r\n        elif method == \"test\":\r\n            self._trainer.test(model, dataloaders, datamodule=datamodule)\r\n        elif method == \"predict\":\r\n            self._trainer.predict(model, dataloaders, datamodule=datamodule)\r\n\r\n        self._trainer.callbacks = [cb for cb in self._trainer.callbacks if cb is not batch_size_finder]\r\n        return batch_size_finder.optimal_batch_size", "code_tokens": ["def", "scale_batch_size", "(", "self", ",", "model", ":", "STRING", ",", "train_dataloaders", ":", "Optional", "[", "Union", "[", "TRAIN_DATALOADERS", ",", "STRING", "]", "]", "=", "None", ",", "val_dataloaders", ":", "Optional", "[", "EVAL_DATALOADERS", "]", "=", "None", ",", "dataloaders", ":", "Optional", "[", "EVAL_DATALOADERS", "]", "=", "None", ",", "datamodule", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "method", ":", "Literal", "[", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", "]", "=", "STRING", ",", "mode", ":", "str", "=", "STRING", ",", "steps_per_trial", ":", "int", "=", "3", ",", "init_val", ":", "int", "=", "2", ",", "max_trials", ":", "int", "=", "25", ",", "batch_arg_name", ":", "str", "=", "STRING", ",", ")", "-", ">", "Optional", "[", "int", "]", ":", "STRING", "_check_tuner_configuration", "(", "train_dataloaders", ",", "val_dataloaders", ",", "dataloaders", ",", "method", ")", "_check_scale_batch_size_configuration", "(", "self", ".", "_trainer", ")", "from", "lightning", ".", "pytorch", ".", "callbacks", ".", "batch_size_finder", "import", "BatchSizeFinder", "batch_size_finder", ":", "Callback", "=", "BatchSizeFinder", "(", "mode", "=", "mode", ",", "steps_per_trial", "=", "steps_per_trial", ",", "init_val", "=", "init_val", ",", "max_trials", "=", "max_trials", ",", "batch_arg_name", "=", "batch_arg_name", ",", ")", "batch_size_finder", ".", "_early_exit", "=", "True", "self", ".", "_trainer", ".", "callbacks", "=", "[", "batch_size_finder", "]", "+", "self", ".", "_trainer", ".", "callbacks", "if", "method", "=", "=", "STRING", ":", "self", ".", "_trainer", ".", "fit", "(", "model", ",", "train_dataloaders", ",", "val_dataloaders", ",", "datamodule", ")", "elif", "method", "=", "=", "STRING", ":", "self", ".", "_trainer", ".", "validate", "(", "model", ",", "dataloaders", ",", "datamodule", "=", "datamodule", ")", "elif", "method", "=", "=", "STRING", ":", "self", ".", "_trainer", ".", "test", "(", "model", ",", "dataloaders", ",", "datamodule", "=", "datamodule", ")", "elif", "method", "=", "=", "STRING", ":", "self", ".", "_trainer", ".", "predict", "(", "model", ",", "dataloaders", ",", "datamodule", "=", "datamodule", ")", "self", ".", "_trainer", ".", "callbacks", "=", "[", "cb", "for", "cb", "in", "self", ".", "_trainer", ".", "callbacks", "if", "cb", "is", "not", "batch_size_finder", "]", "return", "batch_size_finder", ".", "optimal_batch_size"], "docstring": "local import to avoid circular import do not continue with the loop in case Tuner is used", "docstring_tokens": ["local", "import", "to", "avoid", "circular", "import", "do", "not", "continue", "with", "the", "loop", "in", "case", "tuner", "is", "used"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\tuning.py", "start_line": 30, "end_line": 105, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\tuner\\tuning.py", "func_name": "function_270", "original_string": "def lr_find(\r\n        self,\r\n        model: \"pl.LightningModule\",\r\n        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, \"pl.LightningDataModule\"]] = None,\r\n        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        datamodule: Optional[\"pl.LightningDataModule\"] = None,\r\n        method: Literal[\"fit\", \"validate\", \"test\", \"predict\"] = \"fit\",\r\n        min_lr: float = 1e-8,\r\n        max_lr: float = 1,\r\n        num_training: int = 100,\r\n        mode: str = \"exponential\",\r\n        early_stop_threshold: Optional[float] = 4.0,\r\n        update_attr: bool = True,\r\n        attr_name: str = \"\",\r\n    ) -> Optional[\"_LRFinder\"]:\r\n        \"\"\"Enables the user to do a range test of good initial learning rates, to reduce the amount of guesswork in\r\n        picking a good starting learning rate.\r\n\r\n        Args:\r\n            model: Model to tune.\r\n            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\r\n                :class:`~lightning.pytorch.core.datamodule.LightningDataModule` specifying training samples.\r\n                In the case of multiple dataloaders, please see this :ref:`section <multiple-dataloaders>`.\r\n            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\r\n            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying val/test/predict\r\n                samples used for running tuner on validation/testing/prediction.\r\n            datamodule: An instance of :class:`~lightning.pytorch.core.datamodule.LightningDataModule`.\r\n            method: Method to run tuner on. It can be any of ``(\"fit\", \"validate\", \"test\", \"predict\")``.\r\n            min_lr: minimum learning rate to investigate\r\n            max_lr: maximum learning rate to investigate\r\n            num_training: number of learning rates to test\r\n            mode: Search strategy to update learning rate after each batch:\r\n\r\n                - ``'exponential'``: Increases the learning rate exponentially.\r\n                - ``'linear'``: Increases the learning rate linearly.\r\n\r\n            early_stop_threshold: Threshold for stopping the search. If the\r\n                loss at any point is larger than early_stop_threshold*best_loss\r\n                then the search is stopped. To disable, set to None.\r\n            update_attr: Whether to update the learning rate attribute or not.\r\n            attr_name: Name of the attribute which stores the learning rate. The names 'learning_rate' or 'lr' get\r\n                automatically detected. Otherwise, set the name here.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If learning rate/lr in ``model`` or ``model.hparams`` isn't overridden,\r\n                or if you are using more than one optimizer.\r\n\r\n        \"\"\"\r\n        if method != \"fit\":\r\n            raise MisconfigurationException(\"method='fit' is the only valid configuration to run lr finder.\")\r\n\r\n        _check_tuner_configuration(train_dataloaders, val_dataloaders, dataloaders, method)\r\n        _check_lr_find_configuration(self._trainer)\r\n\r\n        from lightning.pytorch.callbacks.lr_finder import LearningRateFinder\r\n\r\n        lr_finder_callback: Callback = LearningRateFinder(\r\n            min_lr=min_lr,\r\n            max_lr=max_lr,\r\n            num_training_steps=num_training,\r\n            mode=mode,\r\n            early_stop_threshold=early_stop_threshold,\r\n            update_attr=update_attr,\r\n            attr_name=attr_name,\r\n        )\r\n\r\n        lr_finder_callback._early_exit = True\r\n        self._trainer.callbacks = [lr_finder_callback] + self._trainer.callbacks\r\n\r\n        self._trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)\r\n\r\n        self._trainer.callbacks = [cb for cb in self._trainer.callbacks if cb is not lr_finder_callback]\r\n\r\n        return lr_finder_callback.optimal_lr", "language": "python", "code": "def lr_find(\r\n        self,\r\n        model: \"pl.LightningModule\",\r\n        train_dataloaders: Optional[Union[TRAIN_DATALOADERS, \"pl.LightningDataModule\"]] = None,\r\n        val_dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        dataloaders: Optional[EVAL_DATALOADERS] = None,\r\n        datamodule: Optional[\"pl.LightningDataModule\"] = None,\r\n        method: Literal[\"fit\", \"validate\", \"test\", \"predict\"] = \"fit\",\r\n        min_lr: float = 1e-8,\r\n        max_lr: float = 1,\r\n        num_training: int = 100,\r\n        mode: str = \"exponential\",\r\n        early_stop_threshold: Optional[float] = 4.0,\r\n        update_attr: bool = True,\r\n        attr_name: str = \"\",\r\n    ) -> Optional[\"_LRFinder\"]:\r\n        \"\"\"Enables the user to do a range test of good initial learning rates, to reduce the amount of guesswork in\r\n        picking a good starting learning rate.\r\n\r\n        Args:\r\n            model: Model to tune.\r\n            train_dataloaders: A collection of :class:`torch.utils.data.DataLoader` or a\r\n                :class:`~lightning.pytorch.core.datamodule.LightningDataModule` specifying training samples.\r\n                In the case of multiple dataloaders, please see this :ref:`section <multiple-dataloaders>`.\r\n            val_dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying validation samples.\r\n            dataloaders: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying val/test/predict\r\n                samples used for running tuner on validation/testing/prediction.\r\n            datamodule: An instance of :class:`~lightning.pytorch.core.datamodule.LightningDataModule`.\r\n            method: Method to run tuner on. It can be any of ``(\"fit\", \"validate\", \"test\", \"predict\")``.\r\n            min_lr: minimum learning rate to investigate\r\n            max_lr: maximum learning rate to investigate\r\n            num_training: number of learning rates to test\r\n            mode: Search strategy to update learning rate after each batch:\r\n\r\n                - ``'exponential'``: Increases the learning rate exponentially.\r\n                - ``'linear'``: Increases the learning rate linearly.\r\n\r\n            early_stop_threshold: Threshold for stopping the search. If the\r\n                loss at any point is larger than early_stop_threshold*best_loss\r\n                then the search is stopped. To disable, set to None.\r\n            update_attr: Whether to update the learning rate attribute or not.\r\n            attr_name: Name of the attribute which stores the learning rate. The names 'learning_rate' or 'lr' get\r\n                automatically detected. Otherwise, set the name here.\r\n\r\n        Raises:\r\n            MisconfigurationException:\r\n                If learning rate/lr in ``model`` or ``model.hparams`` isn't overridden,\r\n                or if you are using more than one optimizer.\r\n\r\n        \"\"\"\r\n        if method != \"fit\":\r\n            raise MisconfigurationException(\"method='fit' is the only valid configuration to run lr finder.\")\r\n\r\n        _check_tuner_configuration(train_dataloaders, val_dataloaders, dataloaders, method)\r\n        _check_lr_find_configuration(self._trainer)\r\n\r\n        from lightning.pytorch.callbacks.lr_finder import LearningRateFinder\r\n\r\n        lr_finder_callback: Callback = LearningRateFinder(\r\n            min_lr=min_lr,\r\n            max_lr=max_lr,\r\n            num_training_steps=num_training,\r\n            mode=mode,\r\n            early_stop_threshold=early_stop_threshold,\r\n            update_attr=update_attr,\r\n            attr_name=attr_name,\r\n        )\r\n\r\n        lr_finder_callback._early_exit = True\r\n        self._trainer.callbacks = [lr_finder_callback] + self._trainer.callbacks\r\n\r\n        self._trainer.fit(model, train_dataloaders, val_dataloaders, datamodule)\r\n\r\n        self._trainer.callbacks = [cb for cb in self._trainer.callbacks if cb is not lr_finder_callback]\r\n\r\n        return lr_finder_callback.optimal_lr", "code_tokens": ["def", "lr_find", "(", "self", ",", "model", ":", "STRING", ",", "train_dataloaders", ":", "Optional", "[", "Union", "[", "TRAIN_DATALOADERS", ",", "STRING", "]", "]", "=", "None", ",", "val_dataloaders", ":", "Optional", "[", "EVAL_DATALOADERS", "]", "=", "None", ",", "dataloaders", ":", "Optional", "[", "EVAL_DATALOADERS", "]", "=", "None", ",", "datamodule", ":", "Optional", "[", "STRING", "]", "=", "None", ",", "method", ":", "Literal", "[", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", "]", "=", "STRING", ",", "min_lr", ":", "float", "=", "1e", "-", "8", ",", "max_lr", ":", "float", "=", "1", ",", "num_training", ":", "int", "=", "100", ",", "mode", ":", "str", "=", "STRING", ",", "early_stop_threshold", ":", "Optional", "[", "float", "]", "=", "4", ".", "0", ",", "update_attr", ":", "bool", "=", "True", ",", "attr_name", ":", "str", "=", "STRING", ",", ")", "-", ">", "Optional", "[", "STRING", "]", ":", "STRING", "if", "method", "!", "=", "STRING", ":", "raise", "MisconfigurationException", "(", "STRING", ")", "_check_tuner_configuration", "(", "train_dataloaders", ",", "val_dataloaders", ",", "dataloaders", ",", "method", ")", "_check_lr_find_configuration", "(", "self", ".", "_trainer", ")", "from", "lightning", ".", "pytorch", ".", "callbacks", ".", "lr_finder", "import", "LearningRateFinder", "lr_finder_callback", ":", "Callback", "=", "LearningRateFinder", "(", "min_lr", "=", "min_lr", ",", "max_lr", "=", "max_lr", ",", "num_training_steps", "=", "num_training", ",", "mode", "=", "mode", ",", "early_stop_threshold", "=", "early_stop_threshold", ",", "update_attr", "=", "update_attr", ",", "attr_name", "=", "attr_name", ",", ")", "lr_finder_callback", ".", "_early_exit", "=", "True", "self", ".", "_trainer", ".", "callbacks", "=", "[", "lr_finder_callback", "]", "+", "self", ".", "_trainer", ".", "callbacks", "self", ".", "_trainer", ".", "fit", "(", "model", ",", "train_dataloaders", ",", "val_dataloaders", ",", "datamodule", ")", "self", ".", "_trainer", ".", "callbacks", "=", "[", "cb", "for", "cb", "in", "self", ".", "_trainer", ".", "callbacks", "if", "cb", "is", "not", "lr_finder_callback", "]", "return", "lr_finder_callback", ".", "optimal_lr"], "docstring": "local import to avoid circular import", "docstring_tokens": ["local", "import", "to", "avoid", "circular", "import"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\tuner\\tuning.py", "start_line": 107, "end_line": 183, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\argparse.py", "func_name": "function_271", "original_string": "def _parse_env_variables(cls: type, template: str = \"PL_%(cls_name)s_%(cls_argument)s\") -> Namespace:\r\n    \"\"\"Parse environment arguments if they are defined.\r\n\r\n    Examples:\r\n\r\n        >>> from lightning.pytorch import Trainer\r\n        >>> _parse_env_variables(Trainer)\r\n        Namespace()\r\n        >>> import os\r\n        >>> os.environ[\"PL_TRAINER_DEVICES\"] = '42'\r\n        >>> os.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\r\n        >>> _parse_env_variables(Trainer)\r\n        Namespace(devices=42)\r\n        >>> del os.environ[\"PL_TRAINER_DEVICES\"]\r\n\r\n    \"\"\"\r\n    env_args = {}\r\n    for arg_name in inspect.signature(cls).parameters:\r\n        env = template % {\"cls_name\": cls.__name__.upper(), \"cls_argument\": arg_name.upper()}\r\n        val = os.environ.get(env)\r\n        if not (val is None or val == \"\"):\r\n            with suppress(Exception):\r\n                val = literal_eval(val)\r\n            env_args[arg_name] = val\r\n    return Namespace(**env_args)", "language": "python", "code": "def _parse_env_variables(cls: type, template: str = \"PL_%(cls_name)s_%(cls_argument)s\") -> Namespace:\r\n    \"\"\"Parse environment arguments if they are defined.\r\n\r\n    Examples:\r\n\r\n        >>> from lightning.pytorch import Trainer\r\n        >>> _parse_env_variables(Trainer)\r\n        Namespace()\r\n        >>> import os\r\n        >>> os.environ[\"PL_TRAINER_DEVICES\"] = '42'\r\n        >>> os.environ[\"PL_TRAINER_BLABLABLA\"] = '1.23'\r\n        >>> _parse_env_variables(Trainer)\r\n        Namespace(devices=42)\r\n        >>> del os.environ[\"PL_TRAINER_DEVICES\"]\r\n\r\n    \"\"\"\r\n    env_args = {}\r\n    for arg_name in inspect.signature(cls).parameters:\r\n        env = template % {\"cls_name\": cls.__name__.upper(), \"cls_argument\": arg_name.upper()}\r\n        val = os.environ.get(env)\r\n        if not (val is None or val == \"\"):\r\n            with suppress(Exception):\r\n                val = literal_eval(val)\r\n            env_args[arg_name] = val\r\n    return Namespace(**env_args)", "code_tokens": ["def", "_parse_env_variables", "(", "cls", ":", "type", ",", "template", ":", "str", "=", "STRING", ")", "-", ">", "Namespace", ":", "STRING", "env_args", "=", "{", "}", "for", "arg_name", "in", "inspect", ".", "signature", "(", "cls", ")", ".", "parameters", ":", "env", "=", "template", "%", "{", "STRING", ":", "cls", ".", "__name__", ".", "upper", "(", ")", ",", "STRING", ":", "arg_name", ".", "upper", "(", ")", "}", "val", "=", "os", ".", "environ", ".", "get", "(", "env", ")", "if", "not", "(", "val", "is", "None", "or", "val", "=", "=", "STRING", ")", ":", "with", "suppress", "(", "Exception", ")", ":", "val", "=", "literal_eval", "(", "val", ")", "env_args", "[", "arg_name", "]", "=", "val", "return", "Namespace", "(", "*", "*", "env_args", ")"], "docstring": "todo: specify the possible exception converting to native types like int/float/bool", "docstring_tokens": ["todo", "specify", "the", "possible", "exception", "converting", "to", "native", "types", "like", "int", "float", "bool"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\argparse.py", "start_line": 26, "end_line": 52, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\combined_loader.py", "func_name": "function_272", "original_string": "def flattened(self, flattened: list[Any]) -> None:\r\n        \"\"\"Setter to conveniently update the list of iterables.\"\"\"\r\n        if len(flattened) != len(self._flattened):\r\n            raise ValueError(\r\n                f\"Mismatch in flattened length ({len(flattened)}) and existing length ({len(self._flattened)})\"\r\n            )\r\n        self._iterables = tree_unflatten(flattened, self._spec)\r\n        self._flattened = flattened", "language": "python", "code": "def flattened(self, flattened: list[Any]) -> None:\r\n        \"\"\"Setter to conveniently update the list of iterables.\"\"\"\r\n        if len(flattened) != len(self._flattened):\r\n            raise ValueError(\r\n                f\"Mismatch in flattened length ({len(flattened)}) and existing length ({len(self._flattened)})\"\r\n            )\r\n        self._iterables = tree_unflatten(flattened, self._spec)\r\n        self._flattened = flattened", "code_tokens": ["def", "flattened", "(", "self", ",", "flattened", ":", "list", "[", "Any", "]", ")", "-", ">", "None", ":", "STRING", "if", "len", "(", "flattened", ")", "!", "=", "len", "(", "self", ".", "_flattened", ")", ":", "raise", "ValueError", "(", "fSTRING", ")", "self", ".", "_iterables", "=", "tree_unflatten", "(", "flattened", ",", "self", ".", "_spec", ")", "self", ".", "_flattened", "=", "flattened"], "docstring": "update the iterable collection", "docstring_tokens": ["update", "the", "iterable", "collection"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\combined_loader.py", "start_line": 313, "end_line": 321, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\consolidate_checkpoint.py", "func_name": "function_273", "original_string": "def _format_checkpoint(checkpoint: dict[str, Any]) -> dict[str, Any]:\r\n    \"\"\"Converts the special FSDP checkpoint format to the standard format the Lightning Trainer can load.\"\"\"\r\n    checkpoint[\"state_dict\"] = checkpoint.pop(\"model\")\r\n\r\n    optimizer_keys = [key for key in checkpoint if re.match(\"optimizer_[0-9]+\", key)]\r\n    if not optimizer_keys:\r\n        return checkpoint\r\n\r\n    checkpoint[\"optimizer_states\"] = [checkpoint.pop(f\"optimizer_{opt_idx}\") for opt_idx in range(len(optimizer_keys))]\r\n    return checkpoint", "language": "python", "code": "def _format_checkpoint(checkpoint: dict[str, Any]) -> dict[str, Any]:\r\n    \"\"\"Converts the special FSDP checkpoint format to the standard format the Lightning Trainer can load.\"\"\"\r\n    checkpoint[\"state_dict\"] = checkpoint.pop(\"model\")\r\n\r\n    optimizer_keys = [key for key in checkpoint if re.match(\"optimizer_[0-9]+\", key)]\r\n    if not optimizer_keys:\r\n        return checkpoint\r\n\r\n    checkpoint[\"optimizer_states\"] = [checkpoint.pop(f\"optimizer_{opt_idx}\") for opt_idx in range(len(optimizer_keys))]\r\n    return checkpoint", "code_tokens": ["def", "_format_checkpoint", "(", "checkpoint", ":", "dict", "[", "str", ",", "Any", "]", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "checkpoint", "[", "STRING", "]", "=", "checkpoint", ".", "pop", "(", "STRING", ")", "optimizer_keys", "=", "[", "key", "for", "key", "in", "checkpoint", "if", "re", ".", "match", "(", "STRING", ",", "key", ")", "]", "if", "not", "optimizer_keys", ":", "return", "checkpoint", "checkpoint", "[", "STRING", "]", "=", "[", "checkpoint", ".", "pop", "(", "fSTRING", ")", "for", "opt_idx", "in", "range", "(", "len", "(", "optimizer_keys", ")", ")", "]", "return", "checkpoint"], "docstring": "Rename the model key Optimizers are saved in special keys named `optimizer_0`, `optimizer_1`, etc. These need to be merged back into a Python list", "docstring_tokens": ["rename", "the", "model", "key", "optimizers", "are", "saved", "in", "special", "keys", "named", "optimizer_0", "optimizer_1", "etc", "these", "need", "to", "be", "merged", "back", "into", "a", "python", "list"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\consolidate_checkpoint.py", "start_line": 9, "end_line": 21, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\data.py", "func_name": "function_274", "original_string": "def has_len_all_ranks(\r\n    dataloader: object,\r\n    strategy: \"pl.strategies.Strategy\",\r\n    allow_zero_length_dataloader_with_multiple_devices: bool = False,\r\n) -> TypeGuard[Sized]:\r\n    \"\"\"Checks if a given object has ``__len__`` method implemented on all ranks.\"\"\"\r\n    local_length = sized_len(dataloader)\r\n    if local_length is None:\r\n        return False\r\n\r\n    total_length = strategy.reduce(torch.tensor(local_length, device=strategy.root_device), reduce_op=\"sum\")\r\n    if total_length == 0:\r\n        rank_zero_warn(\r\n            f\"Total length of `{type(dataloader).__name__}` across ranks is zero.\"\r\n            \" Please make sure this was your intention.\"\r\n        )\r\n    if total_length > 0 and local_length == 0:\r\n        dataloader_cls_name = type(dataloader).__name__\r\n        if not allow_zero_length_dataloader_with_multiple_devices:\r\n            raise RuntimeError(\r\n                f\"`{dataloader_cls_name}` within local rank has zero length.\"\r\n                \" Please make sure that it returns at least 1 batch.\"\r\n            )\r\n        rank_zero_warn(\r\n            f\"Total length of `{dataloader_cls_name}` across ranks is zero, but local rank has zero\"\r\n            \" length. Please be cautious of uneven batch length.\"\r\n        )\r\n\r\n    if has_iterable_dataset(dataloader):\r\n        rank_zero_warn(\r\n            \"Your `IterableDataset` has `__len__` defined.\"\r\n            \" In combination with multi-process data loading (when num_workers > 1),\"\r\n            \" `__len__` could be inaccurate if each worker is not configured independently\"\r\n            \" to avoid having duplicate data.\"\r\n        )\r\n    return True", "language": "python", "code": "def has_len_all_ranks(\r\n    dataloader: object,\r\n    strategy: \"pl.strategies.Strategy\",\r\n    allow_zero_length_dataloader_with_multiple_devices: bool = False,\r\n) -> TypeGuard[Sized]:\r\n    \"\"\"Checks if a given object has ``__len__`` method implemented on all ranks.\"\"\"\r\n    local_length = sized_len(dataloader)\r\n    if local_length is None:\r\n        return False\r\n\r\n    total_length = strategy.reduce(torch.tensor(local_length, device=strategy.root_device), reduce_op=\"sum\")\r\n    if total_length == 0:\r\n        rank_zero_warn(\r\n            f\"Total length of `{type(dataloader).__name__}` across ranks is zero.\"\r\n            \" Please make sure this was your intention.\"\r\n        )\r\n    if total_length > 0 and local_length == 0:\r\n        dataloader_cls_name = type(dataloader).__name__\r\n        if not allow_zero_length_dataloader_with_multiple_devices:\r\n            raise RuntimeError(\r\n                f\"`{dataloader_cls_name}` within local rank has zero length.\"\r\n                \" Please make sure that it returns at least 1 batch.\"\r\n            )\r\n        rank_zero_warn(\r\n            f\"Total length of `{dataloader_cls_name}` across ranks is zero, but local rank has zero\"\r\n            \" length. Please be cautious of uneven batch length.\"\r\n        )\r\n\r\n    if has_iterable_dataset(dataloader):\r\n        rank_zero_warn(\r\n            \"Your `IterableDataset` has `__len__` defined.\"\r\n            \" In combination with multi-process data loading (when num_workers > 1),\"\r\n            \" `__len__` could be inaccurate if each worker is not configured independently\"\r\n            \" to avoid having duplicate data.\"\r\n        )\r\n    return True", "code_tokens": ["def", "has_len_all_ranks", "(", "dataloader", ":", "object", ",", "strategy", ":", "STRING", ",", "allow_zero_length_dataloader_with_multiple_devices", ":", "bool", "=", "False", ",", ")", "-", ">", "TypeGuard", "[", "Sized", "]", ":", "STRING", "local_length", "=", "sized_len", "(", "dataloader", ")", "if", "local_length", "is", "None", ":", "return", "False", "total_length", "=", "strategy", ".", "reduce", "(", "torch", ".", "tensor", "(", "local_length", ",", "device", "=", "strategy", ".", "root_device", ")", ",", "reduce_op", "=", "STRING", ")", "if", "total_length", "=", "=", "0", ":", "rank_zero_warn", "(", "fSTRING", "STRING", ")", "if", "total_length", ">", "0", "and", "local_length", "=", "=", "0", ":", "dataloader_cls_name", "=", "type", "(", "dataloader", ")", ".", "__name__", "if", "not", "allow_zero_length_dataloader_with_multiple_devices", ":", "raise", "RuntimeError", "(", "fSTRING", "STRING", ")", "rank_zero_warn", "(", "fSTRING", "STRING", ")", "if", "has_iterable_dataset", "(", "dataloader", ")", ":", "rank_zero_warn", "(", "STRING", "STRING", "STRING", "STRING", ")", "return", "True"], "docstring": "__len__ is not defined, skip these checks", "docstring_tokens": ["__len__", "is", "not", "defined", "skip", "these", "checks"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\data.py", "start_line": 92, "end_line": 128, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\data.py", "func_name": "function_275", "original_string": "def _dataloader_init_kwargs_resolve_sampler(\r\n    dataloader: DataLoader,\r\n    sampler: Union[Sampler, Iterable],\r\n    mode: Optional[RunningStage] = None,\r\n) -> dict[str, Any]:\r\n    \"\"\"This function is used to handle the sampler, batch_sampler arguments associated within a DataLoader for its re-\r\n    instantiation.\r\n\r\n    If the dataloader is being used for prediction, the sampler will be wrapped into an `_IndexBatchSamplerWrapper`, so\r\n    Lightning can keep track of its indices.\r\n\r\n    \"\"\"\r\n    is_predicting = mode == RunningStage.PREDICTING\r\n    batch_sampler = getattr(dataloader, \"batch_sampler\")\r\n    batch_sampler_cls = type(batch_sampler)\r\n\r\n    if batch_sampler is not None and (batch_sampler_cls is not BatchSampler or is_predicting):\r\n        if hasattr(batch_sampler, \"__pl_saved_args\"):\r\n            args = batch_sampler.__pl_saved_args\r\n            kwargs = batch_sampler.__pl_saved_kwargs\r\n            default_kwargs = batch_sampler.__pl_saved_default_kwargs\r\n            arg_names = batch_sampler.__pl_saved_arg_names\r\n\r\n            if is_predicting:\r\n                success, args, kwargs = _replace_value_in_saved_args(\r\n                    \"drop_last\", False, args, kwargs, default_kwargs, arg_names\r\n                )\r\n                if not success:\r\n                    rank_zero_warn(\r\n                        f\"Trying to inject `drop_last=False` into batch sampler since you are predicting, however \"\r\n                        f\"it seems the class `{batch_sampler_cls.__qualname__}` does not support it. \"\r\n                        \"Your predictions might be incomplete. To mitigate this, expose `drop_last` in \"\r\n                        \"the `__init__` method of your custom class.\"\r\n                    )\r\n\r\n            success, args, kwargs = _replace_value_in_saved_args(\r\n                \"sampler\", sampler, args, kwargs, default_kwargs, arg_names\r\n            )\r\n            if not success:\r\n                raise TypeError(\r\n                    \"Trying to inject a modified sampler into the batch sampler; however, it seems the class \"\r\n                    f\"`{batch_sampler_cls.__qualname__}` does not have an argument called `sampler.` To mitigate \"\r\n                    \"this, expose an argument `sampler` in the `__init__` method of your custom class.\"\r\n                )\r\n\r\n            batch_sampler = _reinstantiate_wrapped_cls(batch_sampler, *args, **kwargs)\r\n        elif hasattr(batch_sampler, \"batch_size\") and hasattr(batch_sampler, \"drop_last\"):\r\n            try:\r\n                batch_sampler = batch_sampler_cls(\r\n                    sampler,\r\n                    batch_size=batch_sampler.batch_size,\r\n                    drop_last=(False if is_predicting else batch_sampler.drop_last),\r\n                )\r\n            except TypeError as ex:\r\n                import re\r\n\r\n                match = re.match(r\".*__init__\\(\\) (got multiple values)|(missing \\d required)\", str(ex))\r\n                if not match:\r\n                    raise\r\n\r\n                raise TypeError(\r\n                    \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                    \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler` and\"\r\n                    \" instantiate your custom batch sampler inside the `*_dataloader` hook of your module,\"\r\n                    \" or set `Trainer(use_distributed_sampler=False)`. If you choose the latter, you will be\"\r\n                    \" responsible for handling the distributed sampling within your batch sampler.\"\r\n                ) from ex\r\n        elif is_predicting:\r\n            rank_zero_warn(\r\n                f\"You are using a custom batch sampler `{batch_sampler_cls.__qualname__}` for prediction.\"\r\n                \" Lightning would normally set `drop_last=False` to ensure all samples are returned, but for\"\r\n                \" custom samplers it can't guarantee this. Make sure your sampler is configured correctly to return\"\r\n                \" all indices.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n        else:\r\n            raise TypeError(\r\n                \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                \" or set `Trainer(use_distributed_sampler=False)`. If you choose the latter, you will be\"\r\n                \" responsible for handling the distributed sampling within your batch sampler.\"\r\n            )\r\n\r\n        if is_predicting:\r\n            batch_sampler = _IndexBatchSamplerWrapper(batch_sampler)\r\n\r\n        return {\r\n            \"sampler\": None,\r\n            \"shuffle\": False,\r\n            \"batch_sampler\": batch_sampler,\r\n            \"batch_size\": 1,\r\n            \"drop_last\": False,\r\n        }\r\n\r\n    return {\"sampler\": sampler, \"shuffle\": False, \"batch_sampler\": None}", "language": "python", "code": "def _dataloader_init_kwargs_resolve_sampler(\r\n    dataloader: DataLoader,\r\n    sampler: Union[Sampler, Iterable],\r\n    mode: Optional[RunningStage] = None,\r\n) -> dict[str, Any]:\r\n    \"\"\"This function is used to handle the sampler, batch_sampler arguments associated within a DataLoader for its re-\r\n    instantiation.\r\n\r\n    If the dataloader is being used for prediction, the sampler will be wrapped into an `_IndexBatchSamplerWrapper`, so\r\n    Lightning can keep track of its indices.\r\n\r\n    \"\"\"\r\n    is_predicting = mode == RunningStage.PREDICTING\r\n    batch_sampler = getattr(dataloader, \"batch_sampler\")\r\n    batch_sampler_cls = type(batch_sampler)\r\n\r\n    if batch_sampler is not None and (batch_sampler_cls is not BatchSampler or is_predicting):\r\n        if hasattr(batch_sampler, \"__pl_saved_args\"):\r\n            args = batch_sampler.__pl_saved_args\r\n            kwargs = batch_sampler.__pl_saved_kwargs\r\n            default_kwargs = batch_sampler.__pl_saved_default_kwargs\r\n            arg_names = batch_sampler.__pl_saved_arg_names\r\n\r\n            if is_predicting:\r\n                success, args, kwargs = _replace_value_in_saved_args(\r\n                    \"drop_last\", False, args, kwargs, default_kwargs, arg_names\r\n                )\r\n                if not success:\r\n                    rank_zero_warn(\r\n                        f\"Trying to inject `drop_last=False` into batch sampler since you are predicting, however \"\r\n                        f\"it seems the class `{batch_sampler_cls.__qualname__}` does not support it. \"\r\n                        \"Your predictions might be incomplete. To mitigate this, expose `drop_last` in \"\r\n                        \"the `__init__` method of your custom class.\"\r\n                    )\r\n\r\n            success, args, kwargs = _replace_value_in_saved_args(\r\n                \"sampler\", sampler, args, kwargs, default_kwargs, arg_names\r\n            )\r\n            if not success:\r\n                raise TypeError(\r\n                    \"Trying to inject a modified sampler into the batch sampler; however, it seems the class \"\r\n                    f\"`{batch_sampler_cls.__qualname__}` does not have an argument called `sampler.` To mitigate \"\r\n                    \"this, expose an argument `sampler` in the `__init__` method of your custom class.\"\r\n                )\r\n\r\n            batch_sampler = _reinstantiate_wrapped_cls(batch_sampler, *args, **kwargs)\r\n        elif hasattr(batch_sampler, \"batch_size\") and hasattr(batch_sampler, \"drop_last\"):\r\n            try:\r\n                batch_sampler = batch_sampler_cls(\r\n                    sampler,\r\n                    batch_size=batch_sampler.batch_size,\r\n                    drop_last=(False if is_predicting else batch_sampler.drop_last),\r\n                )\r\n            except TypeError as ex:\r\n                import re\r\n\r\n                match = re.match(r\".*__init__\\(\\) (got multiple values)|(missing \\d required)\", str(ex))\r\n                if not match:\r\n                    raise\r\n\r\n                raise TypeError(\r\n                    \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                    \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler` and\"\r\n                    \" instantiate your custom batch sampler inside the `*_dataloader` hook of your module,\"\r\n                    \" or set `Trainer(use_distributed_sampler=False)`. If you choose the latter, you will be\"\r\n                    \" responsible for handling the distributed sampling within your batch sampler.\"\r\n                ) from ex\r\n        elif is_predicting:\r\n            rank_zero_warn(\r\n                f\"You are using a custom batch sampler `{batch_sampler_cls.__qualname__}` for prediction.\"\r\n                \" Lightning would normally set `drop_last=False` to ensure all samples are returned, but for\"\r\n                \" custom samplers it can't guarantee this. Make sure your sampler is configured correctly to return\"\r\n                \" all indices.\",\r\n                category=PossibleUserWarning,\r\n            )\r\n        else:\r\n            raise TypeError(\r\n                \" Lightning can't inject a (distributed) sampler into your batch sampler, because it doesn't\"\r\n                \" subclass PyTorch's `BatchSampler`. To mitigate this, either follow the API of `BatchSampler`\"\r\n                \" or set `Trainer(use_distributed_sampler=False)`. If you choose the latter, you will be\"\r\n                \" responsible for handling the distributed sampling within your batch sampler.\"\r\n            )\r\n\r\n        if is_predicting:\r\n            batch_sampler = _IndexBatchSamplerWrapper(batch_sampler)\r\n\r\n        return {\r\n            \"sampler\": None,\r\n            \"shuffle\": False,\r\n            \"batch_sampler\": batch_sampler,\r\n            \"batch_size\": 1,\r\n            \"drop_last\": False,\r\n        }\r\n\r\n    return {\"sampler\": sampler, \"shuffle\": False, \"batch_sampler\": None}", "code_tokens": ["def", "_dataloader_init_kwargs_resolve_sampler", "(", "dataloader", ":", "DataLoader", ",", "sampler", ":", "Union", "[", "Sampler", ",", "Iterable", "]", ",", "mode", ":", "Optional", "[", "RunningStage", "]", "=", "None", ",", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "is_predicting", "=", "mode", "=", "=", "RunningStage", ".", "PREDICTING", "batch_sampler", "=", "getattr", "(", "dataloader", ",", "STRING", ")", "batch_sampler_cls", "=", "type", "(", "batch_sampler", ")", "if", "batch_sampler", "is", "not", "None", "and", "(", "batch_sampler_cls", "is", "not", "BatchSampler", "or", "is_predicting", ")", ":", "if", "hasattr", "(", "batch_sampler", ",", "STRING", ")", ":", "args", "=", "batch_sampler", ".", "__pl_saved_args", "kwargs", "=", "batch_sampler", ".", "__pl_saved_kwargs", "default_kwargs", "=", "batch_sampler", ".", "__pl_saved_default_kwargs", "arg_names", "=", "batch_sampler", ".", "__pl_saved_arg_names", "if", "is_predicting", ":", "success", ",", "args", ",", "kwargs", "=", "_replace_value_in_saved_args", "(", "STRING", ",", "False", ",", "args", ",", "kwargs", ",", "default_kwargs", ",", "arg_names", ")", "if", "not", "success", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", "STRING", "STRING", ")", "success", ",", "args", ",", "kwargs", "=", "_replace_value_in_saved_args", "(", "STRING", ",", "sampler", ",", "args", ",", "kwargs", ",", "default_kwargs", ",", "arg_names", ")", "if", "not", "success", ":", "raise", "TypeError", "(", "STRING", "fSTRING", "STRING", ")", "batch_sampler", "=", "_reinstantiate_wrapped_cls", "(", "batch_sampler", ",", "*", "args", ",", "*", "*", "kwargs", ")", "elif", "hasattr", "(", "batch_sampler", ",", "STRING", ")", "and", "hasattr", "(", "batch_sampler", ",", "STRING", ")", ":", "try", ":", "batch_sampler", "=", "batch_sampler_cls", "(", "sampler", ",", "batch_size", "=", "batch_sampler", ".", "batch_size", ",", "drop_last", "=", "(", "False", "if", "is_predicting", "else", "batch_sampler", ".", "drop_last", ")", ",", ")", "except", "TypeError", "as", "ex", ":", "import", "re", "match", "=", "re", ".", "match", "(", "rSTRING", ",", "str", "(", "ex", ")", ")", "if", "not", "match", ":", "raise", "raise", "TypeError", "(", "STRING", "STRING", "STRING", "STRING", "STRING", ")", "from", "ex", "elif", "is_predicting", ":", "rank_zero_warn", "(", "fSTRING", "STRING", "STRING", "STRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "else", ":", "raise", "TypeError", "(", "STRING", "STRING", "STRING", "STRING", ")", "if", "is_predicting", ":", "batch_sampler", "=", "_IndexBatchSamplerWrapper", "(", "batch_sampler", ")", "return", "{", "STRING", ":", "None", ",", "STRING", ":", "False", ",", "STRING", ":", "batch_sampler", ",", "STRING", ":", "1", ",", "STRING", ":", "False", ",", "}", "return", "{", "STRING", ":", "sampler", ",", "STRING", ":", "False", ",", "STRING", ":", "None", "}"], "docstring": "This is a PyTorch `BatchSampler` subclass for which we captured the init args This is a sampler for which we could not capture the init args, but it kinda looks like a batch sampler even if it does not inherit from PyTorch's interface. an unexpected `TypeError`, continue failure There could either be too few or too many arguments. Customizing the message based on this doesn't make much sense since our MisconfigurationException is going to be raised from the original one. The sampler is not a PyTorch `BatchSampler`, we don't know how to inject a custom sampler or how to adjust the `drop_last` value batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last", "docstring_tokens": ["this", "is", "a", "pytorch", "batchsampler", "subclass", "for", "which", "we", "captured", "the", "init", "args", "this", "is", "a", "sampler", "for", "which", "we", "could", "not", "capture", "the", "init", "args", "but", "it", "kinda", "looks", "like", "a", "batch", "sampler", "even", "if", "it", "does", "not", "inherit", "from", "pytorch", "s", "interface", "an", "unexpected", "typeerror", "continue", "failure", "there", "could", "either", "be", "too", "few", "or", "too", "many", "arguments", "customizing", "the", "message", "based", "on", "this", "doesn", "t", "make", "much", "sense", "since", "our", "misconfigurationexception", "is", "going", "to", "be", "raised", "from", "the", "original", "one", "the", "sampler", "is", "not", "a", "pytorch", "batchsampler", "we", "don", "t", "know", "how", "to", "inject", "a", "custom", "sampler", "or", "how", "to", "adjust", "the", "drop_last", "value", "batch_sampler", "option", "is", "mutually", "exclusive", "with", "batch_size", "shuffle", "sampler", "and", "drop_last"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\data.py", "start_line": 232, "end_line": 335, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\deepspeed.py", "func_name": "function_276", "original_string": "def convert_zero_checkpoint_to_fp32_state_dict(\r\n    checkpoint_dir: _PATH, output_file: _PATH, tag: str | None = None\r\n) -> dict[str, Any]:\r\n    \"\"\"Convert ZeRO 2 or 3 checkpoint into a single fp32 consolidated ``state_dict`` file that can be loaded with\r\n    ``torch.load(file)`` + ``load_state_dict()`` and used for training without DeepSpeed. It gets copied into the top\r\n    level checkpoint dir, so the user can easily do the conversion at any point in the future. Once extracted, the\r\n    weights don't require DeepSpeed and can be used in any application. Additionally the script has been modified to\r\n    ensure we keep the lightning state inside the state dict for being able to run\r\n    ``LightningModule.load_from_checkpoint('...')```.\r\n\r\n    Args:\r\n        checkpoint_dir: path to the desired checkpoint folder.\r\n            (one that contains the tag-folder, like ``global_step14``)\r\n        output_file: path to the pytorch fp32 state_dict output file (e.g. path/pytorch_model.bin)\r\n        tag: checkpoint tag used as a unique identifier for checkpoint. If not provided will attempt\r\n            to load tag in the file named ``latest`` in the checkpoint folder, e.g., ``global_step14``\r\n\r\n    Examples::\r\n\r\n        convert_zero_checkpoint_to_fp32_state_dict(\r\n            \"lightning_logs/version_0/checkpoints/epoch=0-step=0.ckpt/\",\r\n            \"lightning_model.pt\"\r\n        )\r\n\r\n    \"\"\"\r\n    if not _DEEPSPEED_AVAILABLE:\r\n        raise ModuleNotFoundError(str(_DEEPSPEED_AVAILABLE))\r\n\r\n    from deepspeed.utils.zero_to_fp32 import (\r\n        get_fp32_state_dict_from_zero_checkpoint,\r\n        get_model_state_file,\r\n        get_optim_files,\r\n    )\r\n\r\n    state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir, tag)\r\n\r\n    deepspeed_states = [\r\n        \"module\",\r\n        \"optimizer\",\r\n        \"lr_scheduler\",\r\n        \"csr_tensor_module_names\",\r\n        \"skipped_steps\",\r\n        \"global_steps\",\r\n        \"dp_world_size\",\r\n        \"mp_world_size\",\r\n    ]\r\n    checkpoint_dir = ds_checkpoint_dir(checkpoint_dir)\r\n    optim_files = get_optim_files(checkpoint_dir)\r\n    optim_state = torch.load(optim_files[0], map_location=CPU_DEVICE, weights_only=False)\r\n    zero_stage = optim_state[\"optimizer_state_dict\"][\"zero_stage\"]\r\n    model_file = get_model_state_file(checkpoint_dir, zero_stage)\r\n    client_state = torch.load(model_file, map_location=CPU_DEVICE, weights_only=False)\r\n    client_state = {key: value for key, value in client_state.items() if key not in deepspeed_states}\r\n    state_dict = {_remove_prefix(k, \"_forward_module.\"): state_dict[k] for k in state_dict}\r\n    client_state[\"state_dict\"] = state_dict\r\n\r\n    print(f\"Saving fp32 state dict to {output_file}\")\r\n    torch.save(client_state, output_file)\r\n\r\n    return client_state", "language": "python", "code": "def convert_zero_checkpoint_to_fp32_state_dict(\r\n    checkpoint_dir: _PATH, output_file: _PATH, tag: str | None = None\r\n) -> dict[str, Any]:\r\n    \"\"\"Convert ZeRO 2 or 3 checkpoint into a single fp32 consolidated ``state_dict`` file that can be loaded with\r\n    ``torch.load(file)`` + ``load_state_dict()`` and used for training without DeepSpeed. It gets copied into the top\r\n    level checkpoint dir, so the user can easily do the conversion at any point in the future. Once extracted, the\r\n    weights don't require DeepSpeed and can be used in any application. Additionally the script has been modified to\r\n    ensure we keep the lightning state inside the state dict for being able to run\r\n    ``LightningModule.load_from_checkpoint('...')```.\r\n\r\n    Args:\r\n        checkpoint_dir: path to the desired checkpoint folder.\r\n            (one that contains the tag-folder, like ``global_step14``)\r\n        output_file: path to the pytorch fp32 state_dict output file (e.g. path/pytorch_model.bin)\r\n        tag: checkpoint tag used as a unique identifier for checkpoint. If not provided will attempt\r\n            to load tag in the file named ``latest`` in the checkpoint folder, e.g., ``global_step14``\r\n\r\n    Examples::\r\n\r\n        convert_zero_checkpoint_to_fp32_state_dict(\r\n            \"lightning_logs/version_0/checkpoints/epoch=0-step=0.ckpt/\",\r\n            \"lightning_model.pt\"\r\n        )\r\n\r\n    \"\"\"\r\n    if not _DEEPSPEED_AVAILABLE:\r\n        raise ModuleNotFoundError(str(_DEEPSPEED_AVAILABLE))\r\n\r\n    from deepspeed.utils.zero_to_fp32 import (\r\n        get_fp32_state_dict_from_zero_checkpoint,\r\n        get_model_state_file,\r\n        get_optim_files,\r\n    )\r\n\r\n    state_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir, tag)\r\n\r\n    deepspeed_states = [\r\n        \"module\",\r\n        \"optimizer\",\r\n        \"lr_scheduler\",\r\n        \"csr_tensor_module_names\",\r\n        \"skipped_steps\",\r\n        \"global_steps\",\r\n        \"dp_world_size\",\r\n        \"mp_world_size\",\r\n    ]\r\n    checkpoint_dir = ds_checkpoint_dir(checkpoint_dir)\r\n    optim_files = get_optim_files(checkpoint_dir)\r\n    optim_state = torch.load(optim_files[0], map_location=CPU_DEVICE, weights_only=False)\r\n    zero_stage = optim_state[\"optimizer_state_dict\"][\"zero_stage\"]\r\n    model_file = get_model_state_file(checkpoint_dir, zero_stage)\r\n    client_state = torch.load(model_file, map_location=CPU_DEVICE, weights_only=False)\r\n    client_state = {key: value for key, value in client_state.items() if key not in deepspeed_states}\r\n    state_dict = {_remove_prefix(k, \"_forward_module.\"): state_dict[k] for k in state_dict}\r\n    client_state[\"state_dict\"] = state_dict\r\n\r\n    print(f\"Saving fp32 state dict to {output_file}\")\r\n    torch.save(client_state, output_file)\r\n\r\n    return client_state", "code_tokens": ["def", "convert_zero_checkpoint_to_fp32_state_dict", "(", "checkpoint_dir", ":", "_PATH", ",", "output_file", ":", "_PATH", ",", "tag", ":", "str", "|", "None", "=", "None", ")", "-", ">", "dict", "[", "str", ",", "Any", "]", ":", "STRING", "if", "not", "_DEEPSPEED_AVAILABLE", ":", "raise", "ModuleNotFoundError", "(", "str", "(", "_DEEPSPEED_AVAILABLE", ")", ")", "from", "deepspeed", ".", "utils", ".", "zero_to_fp32", "import", "(", "get_fp32_state_dict_from_zero_checkpoint", ",", "get_model_state_file", ",", "get_optim_files", ",", ")", "state_dict", "=", "get_fp32_state_dict_from_zero_checkpoint", "(", "checkpoint_dir", ",", "tag", ")", "deepspeed_states", "=", "[", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", ",", "STRING", ",", "]", "checkpoint_dir", "=", "ds_checkpoint_dir", "(", "checkpoint_dir", ")", "optim_files", "=", "get_optim_files", "(", "checkpoint_dir", ")", "optim_state", "=", "torch", ".", "load", "(", "optim_files", "[", "0", "]", ",", "map_location", "=", "CPU_DEVICE", ",", "weights_only", "=", "False", ")", "zero_stage", "=", "optim_state", "[", "STRING", "]", "[", "STRING", "]", "model_file", "=", "get_model_state_file", "(", "checkpoint_dir", ",", "zero_stage", ")", "client_state", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "CPU_DEVICE", ",", "weights_only", "=", "False", ")", "client_state", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "client_state", ".", "items", "(", ")", "if", "key", "not", "in", "deepspeed_states", "}", "state_dict", "=", "{", "_remove_prefix", "(", "k", ",", "STRING", ")", ":", "state_dict", "[", "k", "]", "for", "k", "in", "state_dict", "}", "client_state", "[", "STRING", "]", "=", "state_dict", "print", "(", "fSTRING", ")", "torch", ".", "save", "(", "client_state", ",", "output_file", ")", "return", "client_state"], "docstring": "Lightning deepspeed has saved a directory instead of a file additional logic to ensure we keep the lightning state dict as well from rank 0. State dict keys will include reference to wrapper _LightningModuleWrapperBase in old checkpoints created in Lightning version < 2.1. Delete the `_forward_module` prefix before saving.", "docstring_tokens": ["lightning", "deepspeed", "has", "saved", "a", "directory", "instead", "of", "a", "file", "additional", "logic", "to", "ensure", "we", "keep", "the", "lightning", "state", "dict", "as", "well", "from", "rank", "0", "state", "dict", "keys", "will", "include", "reference", "to", "wrapper", "_lightningmodulewrapperbase", "in", "old", "checkpoints", "created", "in", "lightning", "version", "2", "1", "delete", "the", "_forward_module", "prefix", "before", "saving"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\deepspeed.py", "start_line": 45, "end_line": 108, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\memory.py", "func_name": "function_277", "original_string": "def garbage_collection_cuda() -> None:\r\n    \"\"\"Garbage collection Torch (CUDA) memory.\"\"\"\r\n    gc.collect()\r\n    try:\r\n        torch.cuda.empty_cache()\r\n    except RuntimeError as exception:\r\n        if not is_oom_error(exception):\r\n            raise", "language": "python", "code": "def garbage_collection_cuda() -> None:\r\n    \"\"\"Garbage collection Torch (CUDA) memory.\"\"\"\r\n    gc.collect()\r\n    try:\r\n        torch.cuda.empty_cache()\r\n    except RuntimeError as exception:\r\n        if not is_oom_error(exception):\r\n            raise", "code_tokens": ["def", "garbage_collection_cuda", "(", ")", "-", ">", "None", ":", "STRING", "gc", ".", "collect", "(", ")", "try", ":", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "except", "RuntimeError", "as", "exception", ":", "if", "not", "is_oom_error", "(", "exception", ")", ":", "raise"], "docstring": "This is the last thing that should cause an OOM error, but seemingly it can. Only handle OOM errors", "docstring_tokens": ["this", "is", "the", "last", "thing", "that", "should", "cause", "an", "oom", "error", "but", "seemingly", "it", "can", "only", "handle", "oom", "errors"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\memory.py", "start_line": 82, "end_line": 91, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_278", "original_string": "def _is_registry(text: Optional[_PATH]) -> bool:\r\n    \"\"\"Check if a string equals 'registry' or starts with 'registry:'.\r\n\r\n    Args:\r\n        text: The string to check\r\n\r\n    >>> _is_registry(\"registry\")\r\n    True\r\n    >>> _is_registry(\"REGISTRY:model-name\")\r\n    True\r\n    >>> _is_registry(\"something_registry\")\r\n    False\r\n    >>> _is_registry(\"\")\r\n    False\r\n\r\n    \"\"\"\r\n    if not isinstance(text, str):\r\n        return False\r\n\r\n    pattern = r\"^registry(:.*|$)\"\r\n    return bool(re.match(pattern, text.lower()))", "language": "python", "code": "def _is_registry(text: Optional[_PATH]) -> bool:\r\n    \"\"\"Check if a string equals 'registry' or starts with 'registry:'.\r\n\r\n    Args:\r\n        text: The string to check\r\n\r\n    >>> _is_registry(\"registry\")\r\n    True\r\n    >>> _is_registry(\"REGISTRY:model-name\")\r\n    True\r\n    >>> _is_registry(\"something_registry\")\r\n    False\r\n    >>> _is_registry(\"\")\r\n    False\r\n\r\n    \"\"\"\r\n    if not isinstance(text, str):\r\n        return False\r\n\r\n    pattern = r\"^registry(:.*|$)\"\r\n    return bool(re.match(pattern, text.lower()))", "code_tokens": ["def", "_is_registry", "(", "text", ":", "Optional", "[", "_PATH", "]", ")", "-", ">", "bool", ":", "STRING", "if", "not", "isinstance", "(", "text", ",", "str", ")", ":", "return", "False", "pattern", "=", "rSTRING", "return", "bool", "(", "re", ".", "match", "(", "pattern", ",", "text", ".", "lower", "(", ")", ")", ")"], "docstring": "Pattern matches exactly 'registry' or 'registry:' followed by any characters", "docstring_tokens": ["pattern", "matches", "exactly", "registry", "or", "registry", "followed", "by", "any", "characters"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 28, "end_line": 49, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_279", "original_string": "def _parse_registry_model_version(ckpt_path: Optional[_PATH]) -> tuple[str, str]:\r\n    \"\"\"Parse the model version from a registry path.\r\n\r\n    Args:\r\n        ckpt_path: The checkpoint path\r\n\r\n    Returns:\r\n        string name and version of the model\r\n\r\n    >>> _parse_registry_model_version(\"registry:model-name:version:1.0\")\r\n    ('model-name', '1.0')\r\n    >>> _parse_registry_model_version(\"registry:model-name\")\r\n    ('model-name', '')\r\n    >>> _parse_registry_model_version(\"registry:VERSION:v2\")\r\n    ('', 'v2')\r\n\r\n    \"\"\"\r\n    if not ckpt_path or not _is_registry(ckpt_path):\r\n        raise ValueError(f\"Invalid registry path: {ckpt_path}\")\r\n\r\n    parts = str(ckpt_path).split(\":\")\r\n    model_name, version = \"\", \"\"\r\n\r\n    if len(parts) >= 2 and parts[1].lower() != \"version\":\r\n        model_name = parts[1]\r\n    if len(parts) == 3 and parts[1].lower() == \"version\":\r\n        version = parts[2]\r\n    elif len(parts) == 4 and parts[2].lower() == \"version\":\r\n        version = parts[3]\r\n\r\n    return model_name, version", "language": "python", "code": "def _parse_registry_model_version(ckpt_path: Optional[_PATH]) -> tuple[str, str]:\r\n    \"\"\"Parse the model version from a registry path.\r\n\r\n    Args:\r\n        ckpt_path: The checkpoint path\r\n\r\n    Returns:\r\n        string name and version of the model\r\n\r\n    >>> _parse_registry_model_version(\"registry:model-name:version:1.0\")\r\n    ('model-name', '1.0')\r\n    >>> _parse_registry_model_version(\"registry:model-name\")\r\n    ('model-name', '')\r\n    >>> _parse_registry_model_version(\"registry:VERSION:v2\")\r\n    ('', 'v2')\r\n\r\n    \"\"\"\r\n    if not ckpt_path or not _is_registry(ckpt_path):\r\n        raise ValueError(f\"Invalid registry path: {ckpt_path}\")\r\n\r\n    parts = str(ckpt_path).split(\":\")\r\n    model_name, version = \"\", \"\"\r\n\r\n    if len(parts) >= 2 and parts[1].lower() != \"version\":\r\n        model_name = parts[1]\r\n    if len(parts) == 3 and parts[1].lower() == \"version\":\r\n        version = parts[2]\r\n    elif len(parts) == 4 and parts[2].lower() == \"version\":\r\n        version = parts[3]\r\n\r\n    return model_name, version", "code_tokens": ["def", "_parse_registry_model_version", "(", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ")", "-", ">", "tuple", "[", "str", ",", "str", "]", ":", "STRING", "if", "not", "ckpt_path", "or", "not", "_is_registry", "(", "ckpt_path", ")", ":", "raise", "ValueError", "(", "fSTRING", ")", "parts", "=", "str", "(", "ckpt_path", ")", ".", "split", "(", "STRING", ")", "model_name", ",", "version", "=", "STRING", ",", "STRING", "if", "len", "(", "parts", ")", ">", "=", "2", "and", "parts", "[", "1", "]", ".", "lower", "(", ")", "!", "=", "STRING", ":", "model_name", "=", "parts", "[", "1", "]", "if", "len", "(", "parts", ")", "=", "=", "3", "and", "parts", "[", "1", "]", ".", "lower", "(", ")", "=", "=", "STRING", ":", "version", "=", "parts", "[", "2", "]", "elif", "len", "(", "parts", ")", "=", "=", "4", "and", "parts", "[", "2", "]", ".", "lower", "(", ")", "=", "=", "STRING", ":", "version", "=", "parts", "[", "3", "]", "return", "model_name", ",", "version"], "docstring": "Split the path by ':' Default values Extract the model name and version based on the parts", "docstring_tokens": ["split", "the", "path", "by", "default", "values", "extract", "the", "model", "name", "and", "version", "based", "on", "the", "parts"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 52, "end_line": 85, "has_examples": true, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_280", "original_string": "def _determine_model_name(ckpt_path: Optional[_PATH], default_model_registry: Optional[str]) -> str:\r\n    \"\"\"Determine the model name from the checkpoint path.\r\n\r\n    Args:\r\n        ckpt_path: The checkpoint path\r\n        default_model_registry: The default model registry\r\n\r\n    Returns:\r\n        string name of the model with optional version\r\n\r\n    >>> _determine_model_name(\"registry:model-name:version:1.0\", \"default-model\")\r\n    'model-name:1.0'\r\n    >>> _determine_model_name(\"registry:model-name\", \"default-model\")\r\n    'model-name'\r\n    >>> _determine_model_name(\"registry:version:v2\", \"default-model\")\r\n    'default-model:v2'\r\n\r\n    \"\"\"\r\n    model_name, model_version = _parse_registry_model_version(ckpt_path)\r\n    if not model_name and default_model_registry:\r\n        model_name = default_model_registry\r\n    if not model_name:\r\n        raise ValueError(f\"Invalid model registry: '{ckpt_path}'\")\r\n    model_registry = model_name\r\n    model_registry += f\":{model_version}\" if model_version else \"\"\r\n    return model_registry", "language": "python", "code": "def _determine_model_name(ckpt_path: Optional[_PATH], default_model_registry: Optional[str]) -> str:\r\n    \"\"\"Determine the model name from the checkpoint path.\r\n\r\n    Args:\r\n        ckpt_path: The checkpoint path\r\n        default_model_registry: The default model registry\r\n\r\n    Returns:\r\n        string name of the model with optional version\r\n\r\n    >>> _determine_model_name(\"registry:model-name:version:1.0\", \"default-model\")\r\n    'model-name:1.0'\r\n    >>> _determine_model_name(\"registry:model-name\", \"default-model\")\r\n    'model-name'\r\n    >>> _determine_model_name(\"registry:version:v2\", \"default-model\")\r\n    'default-model:v2'\r\n\r\n    \"\"\"\r\n    model_name, model_version = _parse_registry_model_version(ckpt_path)\r\n    if not model_name and default_model_registry:\r\n        model_name = default_model_registry\r\n    if not model_name:\r\n        raise ValueError(f\"Invalid model registry: '{ckpt_path}'\")\r\n    model_registry = model_name\r\n    model_registry += f\":{model_version}\" if model_version else \"\"\r\n    return model_registry", "code_tokens": ["def", "_determine_model_name", "(", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ",", "default_model_registry", ":", "Optional", "[", "str", "]", ")", "-", ">", "str", ":", "STRING", "model_name", ",", "model_version", "=", "_parse_registry_model_version", "(", "ckpt_path", ")", "if", "not", "model_name", "and", "default_model_registry", ":", "model_name", "=", "default_model_registry", "if", "not", "model_name", ":", "raise", "ValueError", "(", "fSTRING", ")", "model_registry", "=", "model_name", "model_registry", "+", "=", "fSTRING", "if", "model_version", "else", "STRING", "return", "model_registry"], "docstring": "try to find model and version omitted model name try to use the model registry from Trainer", "docstring_tokens": ["try", "to", "find", "model", "and", "version", "omitted", "model", "name", "try", "to", "use", "the", "model", "registry", "from", "trainer"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 88, "end_line": 115, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_281", "original_string": "def _determine_model_folder(model_name: str, default_root_dir: str) -> str:\r\n    \"\"\"Determine the local model folder based on the model registry.\r\n\r\n    Args:\r\n        model_name: The model name\r\n        default_root_dir: The default root directory\r\n\r\n    Returns:\r\n        string path to the local model folder\r\n\r\n    >>> _determine_model_folder(\"model-name\", \"/path/to/root\")\r\n    '/path/to/root/model-name'\r\n    >>> _determine_model_folder(\"model-name:1.0\", \"/path/to/root\")\r\n    '/path/to/root/model-name_1.0'\r\n\r\n    \"\"\"\r\n    if not model_name:\r\n        raise ValueError(f\"Invalid model registry: '{model_name}'\")\r\n    model_name = model_name.replace(\"/\", \"_\")\r\n    model_name = model_name.replace(\":\", \"_\")\r\n    local_model_dir = os.path.join(default_root_dir, model_name)\r\n    return local_model_dir", "language": "python", "code": "def _determine_model_folder(model_name: str, default_root_dir: str) -> str:\r\n    \"\"\"Determine the local model folder based on the model registry.\r\n\r\n    Args:\r\n        model_name: The model name\r\n        default_root_dir: The default root directory\r\n\r\n    Returns:\r\n        string path to the local model folder\r\n\r\n    >>> _determine_model_folder(\"model-name\", \"/path/to/root\")\r\n    '/path/to/root/model-name'\r\n    >>> _determine_model_folder(\"model-name:1.0\", \"/path/to/root\")\r\n    '/path/to/root/model-name_1.0'\r\n\r\n    \"\"\"\r\n    if not model_name:\r\n        raise ValueError(f\"Invalid model registry: '{model_name}'\")\r\n    model_name = model_name.replace(\"/\", \"_\")\r\n    model_name = model_name.replace(\":\", \"_\")\r\n    local_model_dir = os.path.join(default_root_dir, model_name)\r\n    return local_model_dir", "code_tokens": ["def", "_determine_model_folder", "(", "model_name", ":", "str", ",", "default_root_dir", ":", "str", ")", "-", ">", "str", ":", "STRING", "if", "not", "model_name", ":", "raise", "ValueError", "(", "fSTRING", ")", "model_name", "=", "model_name", ".", "replace", "(", "STRING", ",", "STRING", ")", "model_name", "=", "model_name", ".", "replace", "(", "STRING", ",", "STRING", ")", "local_model_dir", "=", "os", ".", "path", ".", "join", "(", "default_root_dir", ",", "model_name", ")", "return", "local_model_dir"], "docstring": "download the latest checkpoint from the model registry", "docstring_tokens": ["download", "the", "latest", "checkpoint", "from", "the", "model", "registry"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 118, "end_line": 140, "has_examples": true, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_282", "original_string": "def find_model_local_ckpt_path(\r\n    ckpt_path: Optional[_PATH], default_model_registry: Optional[str], default_root_dir: str\r\n) -> str:\r\n    \"\"\"Find the local checkpoint path for a model.\"\"\"\r\n    model_registry = _determine_model_name(ckpt_path, default_model_registry)\r\n    local_model_dir = _determine_model_folder(model_registry, default_root_dir)\r\n\r\n    folder_files = [fn for fn in os.listdir(local_model_dir) if fn.endswith(\".ckpt\")]\r\n    if not folder_files:\r\n        raise RuntimeError(f\"Parsing files from downloaded model: {model_registry}\")\r\n    return os.path.join(local_model_dir, folder_files[0])", "language": "python", "code": "def find_model_local_ckpt_path(\r\n    ckpt_path: Optional[_PATH], default_model_registry: Optional[str], default_root_dir: str\r\n) -> str:\r\n    \"\"\"Find the local checkpoint path for a model.\"\"\"\r\n    model_registry = _determine_model_name(ckpt_path, default_model_registry)\r\n    local_model_dir = _determine_model_folder(model_registry, default_root_dir)\r\n\r\n    folder_files = [fn for fn in os.listdir(local_model_dir) if fn.endswith(\".ckpt\")]\r\n    if not folder_files:\r\n        raise RuntimeError(f\"Parsing files from downloaded model: {model_registry}\")\r\n    return os.path.join(local_model_dir, folder_files[0])", "code_tokens": ["def", "find_model_local_ckpt_path", "(", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ",", "default_model_registry", ":", "Optional", "[", "str", "]", ",", "default_root_dir", ":", "str", ")", "-", ">", "str", ":", "STRING", "model_registry", "=", "_determine_model_name", "(", "ckpt_path", ",", "default_model_registry", ")", "local_model_dir", "=", "_determine_model_folder", "(", "model_registry", ",", "default_root_dir", ")", "folder_files", "=", "[", "fn", "for", "fn", "in", "os", ".", "listdir", "(", "local_model_dir", ")", "if", "fn", ".", "endswith", "(", "STRING", ")", "]", "if", "not", "folder_files", ":", "raise", "RuntimeError", "(", "fSTRING", ")", "return", "os", ".", "path", ".", "join", "(", "local_model_dir", ",", "folder_files", "[", "0", "]", ")"], "docstring": "todo: resolve if there are multiple checkpoints print(f\"local RANK {self.trainer.local_rank}: using model files: {folder_files}\")", "docstring_tokens": ["todo", "resolve", "if", "there", "are", "multiple", "checkpoints", "print", "f", "local", "rank", "self", "trainer", "local_rank", "using", "model", "files", "folder_files"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 143, "end_line": 155, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "func_name": "function_283", "original_string": "def download_model_from_registry(ckpt_path: Optional[_PATH], trainer: \"pl.Trainer\") -> None:\r\n    \"\"\"Download a model from the Lightning Model Registry.\"\"\"\r\n    if trainer.local_rank == 0:\r\n        if not module_available(\"litmodels\"):\r\n            raise ImportError(\r\n                \"The `litmodels` package is not installed. Please install it with `pip install litmodels`.\"\r\n            )\r\n\r\n        from litmodels import download_model\r\n\r\n        model_registry = _determine_model_name(ckpt_path, trainer._model_registry)\r\n        local_model_dir = _determine_model_folder(model_registry, trainer.default_root_dir)\r\n\r\n        model_files = download_model(model_registry, download_dir=local_model_dir)\r\n        if not model_files:\r\n            raise RuntimeError(f\"Download model failed - {model_registry}\")\r\n\r\n    trainer.strategy.barrier(\"download_model_from_registry\")", "language": "python", "code": "def download_model_from_registry(ckpt_path: Optional[_PATH], trainer: \"pl.Trainer\") -> None:\r\n    \"\"\"Download a model from the Lightning Model Registry.\"\"\"\r\n    if trainer.local_rank == 0:\r\n        if not module_available(\"litmodels\"):\r\n            raise ImportError(\r\n                \"The `litmodels` package is not installed. Please install it with `pip install litmodels`.\"\r\n            )\r\n\r\n        from litmodels import download_model\r\n\r\n        model_registry = _determine_model_name(ckpt_path, trainer._model_registry)\r\n        local_model_dir = _determine_model_folder(model_registry, trainer.default_root_dir)\r\n\r\n        model_files = download_model(model_registry, download_dir=local_model_dir)\r\n        if not model_files:\r\n            raise RuntimeError(f\"Download model failed - {model_registry}\")\r\n\r\n    trainer.strategy.barrier(\"download_model_from_registry\")", "code_tokens": ["def", "download_model_from_registry", "(", "ckpt_path", ":", "Optional", "[", "_PATH", "]", ",", "trainer", ":", "STRING", ")", "-", ">", "None", ":", "STRING", "if", "trainer", ".", "local_rank", "=", "=", "0", ":", "if", "not", "module_available", "(", "STRING", ")", ":", "raise", "ImportError", "(", "STRING", ")", "from", "litmodels", "import", "download_model", "model_registry", "=", "_determine_model_name", "(", "ckpt_path", ",", "trainer", ".", "_model_registry", ")", "local_model_dir", "=", "_determine_model_folder", "(", "model_registry", ",", "trainer", ".", "default_root_dir", ")", "model_files", "=", "download_model", "(", "model_registry", ",", "download_dir", "=", "local_model_dir", ")", "if", "not", "model_files", ":", "raise", "RuntimeError", "(", "fSTRING", ")", "trainer", ".", "strategy", ".", "barrier", "(", "STRING", ")"], "docstring": "print(f\"Rank {self.trainer.local_rank} downloads model checkpoint '{model_registry}'\") print(f\"Model checkpoint '{model_registry}' was downloaded to '{local_model_dir}'\")", "docstring_tokens": ["print", "f", "rank", "self", "trainer", "local_rank", "downloads", "model", "checkpoint", "model_registry", "print", "f", "model", "checkpoint", "model_registry", "was", "downloaded", "to", "local_model_dir"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_registry.py", "start_line": 158, "end_line": 177, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\parsing.py", "func_name": "function_284", "original_string": "def parse_class_init_keys(cls: type) -> tuple[str, Optional[str], Optional[str]]:\r\n    \"\"\"Parse key words for standard ``self``, ``*args`` and ``**kwargs``.\r\n\r\n    Examples:\r\n\r\n        >>> class Model:\r\n        ...     def __init__(self, hparams, *my_args, anykw=42, **my_kwargs):\r\n        ...         pass\r\n        >>> parse_class_init_keys(Model)\r\n        ('self', 'my_args', 'my_kwargs')\r\n\r\n    \"\"\"\r\n    init_parameters = inspect.signature(cls.__init__).parameters  # type: ignore[misc]\r\n    init_params = list(init_parameters.values())\r\n    n_self = init_params[0].name\r\n\r\n    def _get_first_if_any(\r\n        params: list[inspect.Parameter],\r\n        param_type: Literal[inspect._ParameterKind.VAR_POSITIONAL, inspect._ParameterKind.VAR_KEYWORD],\r\n    ) -> Optional[str]:\r\n        for p in params:\r\n            if p.kind == param_type:\r\n                return p.name\r\n        return None\r\n\r\n    n_args = _get_first_if_any(init_params, inspect.Parameter.VAR_POSITIONAL)\r\n    n_kwargs = _get_first_if_any(init_params, inspect.Parameter.VAR_KEYWORD)\r\n\r\n    return n_self, n_args, n_kwargs", "language": "python", "code": "def parse_class_init_keys(cls: type) -> tuple[str, Optional[str], Optional[str]]:\r\n    \"\"\"Parse key words for standard ``self``, ``*args`` and ``**kwargs``.\r\n\r\n    Examples:\r\n\r\n        >>> class Model:\r\n        ...     def __init__(self, hparams, *my_args, anykw=42, **my_kwargs):\r\n        ...         pass\r\n        >>> parse_class_init_keys(Model)\r\n        ('self', 'my_args', 'my_kwargs')\r\n\r\n    \"\"\"\r\n    init_parameters = inspect.signature(cls.__init__).parameters  # type: ignore[misc]\r\n    init_params = list(init_parameters.values())\r\n    n_self = init_params[0].name\r\n\r\n    def _get_first_if_any(\r\n        params: list[inspect.Parameter],\r\n        param_type: Literal[inspect._ParameterKind.VAR_POSITIONAL, inspect._ParameterKind.VAR_KEYWORD],\r\n    ) -> Optional[str]:\r\n        for p in params:\r\n            if p.kind == param_type:\r\n                return p.name\r\n        return None\r\n\r\n    n_args = _get_first_if_any(init_params, inspect.Parameter.VAR_POSITIONAL)\r\n    n_kwargs = _get_first_if_any(init_params, inspect.Parameter.VAR_KEYWORD)\r\n\r\n    return n_self, n_args, n_kwargs", "code_tokens": ["def", "parse_class_init_keys", "(", "cls", ":", "type", ")", "-", ">", "tuple", "[", "str", ",", "Optional", "[", "str", "]", ",", "Optional", "[", "str", "]", "]", ":", "STRING", "init_parameters", "=", "inspect", ".", "signature", "(", "cls", ".", "__init__", ")", ".", "parameters", "#", "type", ":", "ignore", "[", "misc", "]", "init_params", "=", "list", "(", "init_parameters", ".", "values", "(", ")", ")", "n_self", "=", "init_params", "[", "0", "]", ".", "name", "def", "_get_first_if_any", "(", "params", ":", "list", "[", "inspect", ".", "Parameter", "]", ",", "param_type", ":", "Literal", "[", "inspect", ".", "_ParameterKind", ".", "VAR_POSITIONAL", ",", "inspect", ".", "_ParameterKind", ".", "VAR_KEYWORD", "]", ",", ")", "-", ">", "Optional", "[", "str", "]", ":", "for", "p", "in", "params", ":", "if", "p", ".", "kind", "=", "=", "param_type", ":", "return", "p", ".", "name", "return", "None", "n_args", "=", "_get_first_if_any", "(", "init_params", ",", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", ")", "n_kwargs", "=", "_get_first_if_any", "(", "init_params", ",", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", ")", "return", "n_self", ",", "n_args", ",", "n_kwargs"], "docstring": "docs claims the params are always ordered https://docs.python.org/3/library/inspect.html#inspect.Signature.parameters self is always first", "docstring_tokens": ["docs", "claims", "the", "params", "are", "always", "ordered", "https", "docs", "python", "org", "3", "library", "inspect", "html", "inspect", "signature", "parameters", "self", "is", "always", "first"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\parsing.py", "start_line": 51, "end_line": 82, "has_examples": true, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\parsing.py", "func_name": "function_285", "original_string": "def collect_init_args(\r\n    frame: types.FrameType,\r\n    path_args: list[dict[str, Any]],\r\n    inside: bool = False,\r\n    classes: tuple[type, ...] = (),\r\n) -> list[dict[str, Any]]:\r\n    \"\"\"Recursively collects the arguments passed to the child constructors in the inheritance tree.\r\n\r\n    Args:\r\n        frame: the current stack frame\r\n        path_args: a list of dictionaries containing the constructor args in all parent classes\r\n        inside: track if we are inside inheritance path, avoid terminating too soon\r\n        classes: the classes in which to inspect the frames\r\n\r\n    Return:\r\n          A list of dictionaries where each dictionary contains the arguments passed to the\r\n          constructor at that level. The last entry corresponds to the constructor call of the\r\n          most specific class in the hierarchy.\r\n\r\n    \"\"\"\r\n    _, _, _, local_vars = inspect.getargvalues(frame)\r\n    if not isinstance(frame.f_back, types.FrameType):\r\n        return path_args\r\n\r\n    local_self, local_args = _get_init_args(frame)\r\n    if \"__class__\" in local_vars and (not classes or isinstance(local_self, classes)):\r\n        path_args.append(local_args)\r\n        return collect_init_args(frame.f_back, path_args, inside=True, classes=classes)\r\n    if not inside:\r\n        return collect_init_args(frame.f_back, path_args, inside=False, classes=classes)\r\n    return path_args", "language": "python", "code": "def collect_init_args(\r\n    frame: types.FrameType,\r\n    path_args: list[dict[str, Any]],\r\n    inside: bool = False,\r\n    classes: tuple[type, ...] = (),\r\n) -> list[dict[str, Any]]:\r\n    \"\"\"Recursively collects the arguments passed to the child constructors in the inheritance tree.\r\n\r\n    Args:\r\n        frame: the current stack frame\r\n        path_args: a list of dictionaries containing the constructor args in all parent classes\r\n        inside: track if we are inside inheritance path, avoid terminating too soon\r\n        classes: the classes in which to inspect the frames\r\n\r\n    Return:\r\n          A list of dictionaries where each dictionary contains the arguments passed to the\r\n          constructor at that level. The last entry corresponds to the constructor call of the\r\n          most specific class in the hierarchy.\r\n\r\n    \"\"\"\r\n    _, _, _, local_vars = inspect.getargvalues(frame)\r\n    if not isinstance(frame.f_back, types.FrameType):\r\n        return path_args\r\n\r\n    local_self, local_args = _get_init_args(frame)\r\n    if \"__class__\" in local_vars and (not classes or isinstance(local_self, classes)):\r\n        path_args.append(local_args)\r\n        return collect_init_args(frame.f_back, path_args, inside=True, classes=classes)\r\n    if not inside:\r\n        return collect_init_args(frame.f_back, path_args, inside=False, classes=classes)\r\n    return path_args", "code_tokens": ["def", "collect_init_args", "(", "frame", ":", "types", ".", "FrameType", ",", "path_args", ":", "list", "[", "dict", "[", "str", ",", "Any", "]", "]", ",", "inside", ":", "bool", "=", "False", ",", "classes", ":", "tuple", "[", "type", ",", ".", ".", ".", "]", "=", "(", ")", ",", ")", "-", ">", "list", "[", "dict", "[", "str", ",", "Any", "]", "]", ":", "STRING", "_", ",", "_", ",", "_", ",", "local_vars", "=", "inspect", ".", "getargvalues", "(", "frame", ")", "if", "not", "isinstance", "(", "frame", ".", "f_back", ",", "types", ".", "FrameType", ")", ":", "return", "path_args", "local_self", ",", "local_args", "=", "_get_init_args", "(", "frame", ")", "if", "STRING", "in", "local_vars", "and", "(", "not", "classes", "or", "isinstance", "(", "local_self", ",", "classes", ")", ")", ":", "path_args", ".", "append", "(", "local_args", ")", "return", "collect_init_args", "(", "frame", ".", "f_back", ",", "path_args", ",", "inside", "=", "True", ",", "classes", "=", "classes", ")", "if", "not", "inside", ":", "return", "collect_init_args", "(", "frame", ".", "f_back", ",", "path_args", ",", "inside", "=", "False", ",", "classes", "=", "classes", ")", "return", "path_args"], "docstring": "frame.f_back must be of a type types.FrameType for get_init_args/collect_init_args due to mypy recursive update", "docstring_tokens": ["frame", "f_back", "must", "be", "of", "a", "type", "types", "frametype", "for", "get_init_args", "collect_init_args", "due", "to", "mypy", "recursive", "update"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\parsing.py", "start_line": 110, "end_line": 142, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\parsing.py", "func_name": "function_286", "original_string": "def save_hyperparameters(\r\n    obj: Any,\r\n    *args: Any,\r\n    ignore: Optional[Union[Sequence[str], str]] = None,\r\n    frame: Optional[types.FrameType] = None,\r\n    given_hparams: Optional[dict[str, Any]] = None,\r\n) -> None:\r\n    \"\"\"See :meth:`~lightning.pytorch.LightningModule.save_hyperparameters`\"\"\"\r\n\r\n    if len(args) == 1 and not isinstance(args, str) and not args[0]:\r\n        return\r\n\r\n    if not frame:\r\n        current_frame = inspect.currentframe()\r\n        if current_frame:\r\n            frame = current_frame.f_back\r\n    if not isinstance(frame, types.FrameType):\r\n        raise AttributeError(\"There is no `frame` available while being required.\")\r\n\r\n    if given_hparams is not None:\r\n        init_args = given_hparams\r\n    elif is_dataclass(obj):\r\n        obj_fields = fields(obj)\r\n        init_args = {f.name: getattr(obj, f.name) for f in obj_fields if f.init}\r\n    else:\r\n        init_args = {}\r\n\r\n        from lightning.pytorch.core.mixins import HyperparametersMixin\r\n\r\n        for local_args in collect_init_args(frame, [], classes=(HyperparametersMixin,)):\r\n            init_args.update(local_args)\r\n\r\n    if ignore is None:\r\n        ignore = []\r\n    elif isinstance(ignore, str):\r\n        ignore = [ignore]\r\n    elif isinstance(ignore, (list, tuple)):\r\n        ignore = [arg for arg in ignore if isinstance(arg, str)]\r\n\r\n    ignore = list(set(ignore))\r\n    init_args = {k: v for k, v in init_args.items() if k not in ignore}\r\n\r\n    if not args:\r\n        hp = init_args\r\n        obj._hparams_name = \"kwargs\" if hp else None\r\n    else:\r\n        isx_non_str = [i for i, arg in enumerate(args) if not isinstance(arg, str)]\r\n        if len(isx_non_str) == 1:\r\n            hp = args[isx_non_str[0]]\r\n            cand_names = [k for k, v in init_args.items() if v == hp]\r\n            obj._hparams_name = cand_names[0] if cand_names else None\r\n        else:\r\n            hp = {arg: init_args[arg] for arg in args if isinstance(arg, str)}\r\n            obj._hparams_name = \"kwargs\"\r\n\r\n    obj._set_hparams(hp)\r\n\r\n    for k, v in obj._hparams.items():\r\n        if isinstance(v, nn.Module):\r\n            rank_zero_warn(\r\n                f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\r\n                f\" It is recommended to ignore them using `self.save_hyperparameters(ignore=[{k!r}])`.\"\r\n            )\r\n\r\n    obj._hparams_initial = copy.deepcopy(obj._hparams)", "language": "python", "code": "def save_hyperparameters(\r\n    obj: Any,\r\n    *args: Any,\r\n    ignore: Optional[Union[Sequence[str], str]] = None,\r\n    frame: Optional[types.FrameType] = None,\r\n    given_hparams: Optional[dict[str, Any]] = None,\r\n) -> None:\r\n    \"\"\"See :meth:`~lightning.pytorch.LightningModule.save_hyperparameters`\"\"\"\r\n\r\n    if len(args) == 1 and not isinstance(args, str) and not args[0]:\r\n        return\r\n\r\n    if not frame:\r\n        current_frame = inspect.currentframe()\r\n        if current_frame:\r\n            frame = current_frame.f_back\r\n    if not isinstance(frame, types.FrameType):\r\n        raise AttributeError(\"There is no `frame` available while being required.\")\r\n\r\n    if given_hparams is not None:\r\n        init_args = given_hparams\r\n    elif is_dataclass(obj):\r\n        obj_fields = fields(obj)\r\n        init_args = {f.name: getattr(obj, f.name) for f in obj_fields if f.init}\r\n    else:\r\n        init_args = {}\r\n\r\n        from lightning.pytorch.core.mixins import HyperparametersMixin\r\n\r\n        for local_args in collect_init_args(frame, [], classes=(HyperparametersMixin,)):\r\n            init_args.update(local_args)\r\n\r\n    if ignore is None:\r\n        ignore = []\r\n    elif isinstance(ignore, str):\r\n        ignore = [ignore]\r\n    elif isinstance(ignore, (list, tuple)):\r\n        ignore = [arg for arg in ignore if isinstance(arg, str)]\r\n\r\n    ignore = list(set(ignore))\r\n    init_args = {k: v for k, v in init_args.items() if k not in ignore}\r\n\r\n    if not args:\r\n        hp = init_args\r\n        obj._hparams_name = \"kwargs\" if hp else None\r\n    else:\r\n        isx_non_str = [i for i, arg in enumerate(args) if not isinstance(arg, str)]\r\n        if len(isx_non_str) == 1:\r\n            hp = args[isx_non_str[0]]\r\n            cand_names = [k for k, v in init_args.items() if v == hp]\r\n            obj._hparams_name = cand_names[0] if cand_names else None\r\n        else:\r\n            hp = {arg: init_args[arg] for arg in args if isinstance(arg, str)}\r\n            obj._hparams_name = \"kwargs\"\r\n\r\n    obj._set_hparams(hp)\r\n\r\n    for k, v in obj._hparams.items():\r\n        if isinstance(v, nn.Module):\r\n            rank_zero_warn(\r\n                f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\r\n                f\" It is recommended to ignore them using `self.save_hyperparameters(ignore=[{k!r}])`.\"\r\n            )\r\n\r\n    obj._hparams_initial = copy.deepcopy(obj._hparams)", "code_tokens": ["def", "save_hyperparameters", "(", "obj", ":", "Any", ",", "*", "args", ":", "Any", ",", "ignore", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "str", "]", "]", "=", "None", ",", "frame", ":", "Optional", "[", "types", ".", "FrameType", "]", "=", "None", ",", "given_hparams", ":", "Optional", "[", "dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", ")", "-", ">", "None", ":", "STRING", "if", "len", "(", "args", ")", "=", "=", "1", "and", "not", "isinstance", "(", "args", ",", "str", ")", "and", "not", "args", "[", "0", "]", ":", "return", "if", "not", "frame", ":", "current_frame", "=", "inspect", ".", "currentframe", "(", ")", "if", "current_frame", ":", "frame", "=", "current_frame", ".", "f_back", "if", "not", "isinstance", "(", "frame", ",", "types", ".", "FrameType", ")", ":", "raise", "AttributeError", "(", "STRING", ")", "if", "given_hparams", "is", "not", "None", ":", "init_args", "=", "given_hparams", "elif", "is_dataclass", "(", "obj", ")", ":", "obj_fields", "=", "fields", "(", "obj", ")", "init_args", "=", "{", "f", ".", "name", ":", "getattr", "(", "obj", ",", "f", ".", "name", ")", "for", "f", "in", "obj_fields", "if", "f", ".", "init", "}", "else", ":", "init_args", "=", "{", "}", "from", "lightning", ".", "pytorch", ".", "core", ".", "mixins", "import", "HyperparametersMixin", "for", "local_args", "in", "collect_init_args", "(", "frame", ",", "[", "]", ",", "classes", "=", "(", "HyperparametersMixin", ",", ")", ")", ":", "init_args", ".", "update", "(", "local_args", ")", "if", "ignore", "is", "None", ":", "ignore", "=", "[", "]", "elif", "isinstance", "(", "ignore", ",", "str", ")", ":", "ignore", "=", "[", "ignore", "]", "elif", "isinstance", "(", "ignore", ",", "(", "list", ",", "tuple", ")", ")", ":", "ignore", "=", "[", "arg", "for", "arg", "in", "ignore", "if", "isinstance", "(", "arg", ",", "str", ")", "]", "ignore", "=", "list", "(", "set", "(", "ignore", ")", ")", "init_args", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "init_args", ".", "items", "(", ")", "if", "k", "not", "in", "ignore", "}", "if", "not", "args", ":", "hp", "=", "init_args", "obj", ".", "_hparams_name", "=", "STRING", "if", "hp", "else", "None", "else", ":", "isx_non_str", "=", "[", "i", "for", "i", ",", "arg", "in", "enumerate", "(", "args", ")", "if", "not", "isinstance", "(", "arg", ",", "str", ")", "]", "if", "len", "(", "isx_non_str", ")", "=", "=", "1", ":", "hp", "=", "args", "[", "isx_non_str", "[", "0", "]", "]", "cand_names", "=", "[", "k", "for", "k", ",", "v", "in", "init_args", ".", "items", "(", ")", "if", "v", "=", "=", "hp", "]", "obj", ".", "_hparams_name", "=", "cand_names", "[", "0", "]", "if", "cand_names", "else", "None", "else", ":", "hp", "=", "{", "arg", ":", "init_args", "[", "arg", "]", "for", "arg", "in", "args", "if", "isinstance", "(", "arg", ",", "str", ")", "}", "obj", ".", "_hparams_name", "=", "STRING", "obj", ".", "_set_hparams", "(", "hp", ")", "for", "k", ",", "v", "in", "obj", ".", "_hparams", ".", "items", "(", ")", ":", "if", "isinstance", "(", "v", ",", "nn", ".", "Module", ")", ":", "rank_zero_warn", "(", "fSTRING", "fSTRING", ")", "obj", ".", "_hparams_initial", "=", "copy", ".", "deepcopy", "(", "obj", ".", "_hparams", ")"], "docstring": "args[0] is an empty container inspect.currentframe() return type is Optional[types.FrameType]: current_frame.f_back called only if available take all arguments take only listed arguments in `save_hparams` `hparams` are expected here make a deep copy so there are no other runtime changes reflected", "docstring_tokens": ["args", "0", "is", "an", "empty", "container", "inspect", "currentframe", "return", "type", "is", "optional", "types", "frametype", "current_frame", "f_back", "called", "only", "if", "available", "take", "all", "arguments", "take", "only", "listed", "arguments", "in", "save_hparams", "hparams", "are", "expected", "here", "make", "a", "deep", "copy", "so", "there", "are", "no", "other", "runtime", "changes", "reflected"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\parsing.py", "start_line": 145, "end_line": 215, "has_examples": false, "num_comments": 6, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\parsing.py", "func_name": "function_287", "original_string": "def _lightning_get_all_attr_holders(model: \"pl.LightningModule\", attribute: str) -> list[Any]:\r\n    \"\"\"Special attribute finding for Lightning.\r\n\r\n    Gets all of the objects or dicts that holds attribute. Checks for attribute in model namespace, the old hparams\r\n    namespace/dict, and the datamodule.\r\n\r\n    \"\"\"\r\n    holders: list[Any] = []\r\n\r\n    if hasattr(model, attribute):\r\n        holders.append(model)\r\n\r\n    if hasattr(model, \"hparams\") and attribute in model.hparams:\r\n        holders.append(model.hparams)\r\n\r\n    trainer = model._trainer\r\n    if trainer is not None and trainer.datamodule is not None:\r\n        if hasattr(trainer.datamodule, attribute):\r\n            holders.append(trainer.datamodule)\r\n\r\n        if hasattr(trainer.datamodule, \"hparams\") and attribute in trainer.datamodule.hparams:\r\n            holders.append(trainer.datamodule.hparams)\r\n\r\n    return holders", "language": "python", "code": "def _lightning_get_all_attr_holders(model: \"pl.LightningModule\", attribute: str) -> list[Any]:\r\n    \"\"\"Special attribute finding for Lightning.\r\n\r\n    Gets all of the objects or dicts that holds attribute. Checks for attribute in model namespace, the old hparams\r\n    namespace/dict, and the datamodule.\r\n\r\n    \"\"\"\r\n    holders: list[Any] = []\r\n\r\n    if hasattr(model, attribute):\r\n        holders.append(model)\r\n\r\n    if hasattr(model, \"hparams\") and attribute in model.hparams:\r\n        holders.append(model.hparams)\r\n\r\n    trainer = model._trainer\r\n    if trainer is not None and trainer.datamodule is not None:\r\n        if hasattr(trainer.datamodule, attribute):\r\n            holders.append(trainer.datamodule)\r\n\r\n        if hasattr(trainer.datamodule, \"hparams\") and attribute in trainer.datamodule.hparams:\r\n            holders.append(trainer.datamodule.hparams)\r\n\r\n    return holders", "code_tokens": ["def", "_lightning_get_all_attr_holders", "(", "model", ":", "STRING", ",", "attribute", ":", "str", ")", "-", ">", "list", "[", "Any", "]", ":", "STRING", "holders", ":", "list", "[", "Any", "]", "=", "[", "]", "if", "hasattr", "(", "model", ",", "attribute", ")", ":", "holders", ".", "append", "(", "model", ")", "if", "hasattr", "(", "model", ",", "STRING", ")", "and", "attribute", "in", "model", ".", "hparams", ":", "holders", ".", "append", "(", "model", ".", "hparams", ")", "trainer", "=", "model", ".", "_trainer", "if", "trainer", "is", "not", "None", "and", "trainer", ".", "datamodule", "is", "not", "None", ":", "if", "hasattr", "(", "trainer", ".", "datamodule", ",", "attribute", ")", ":", "holders", ".", "append", "(", "trainer", ".", "datamodule", ")", "if", "hasattr", "(", "trainer", ".", "datamodule", ",", "STRING", ")", "and", "attribute", "in", "trainer", ".", "datamodule", ".", "hparams", ":", "holders", ".", "append", "(", "trainer", ".", "datamodule", ".", "hparams", ")", "return", "holders"], "docstring": "Check if attribute in model Check if attribute in model.hparams, either namespace or dict Check if the attribute in datamodule (datamodule gets registered in Trainer)", "docstring_tokens": ["check", "if", "attribute", "in", "model", "check", "if", "attribute", "in", "model", "hparams", "either", "namespace", "or", "dict", "check", "if", "the", "attribute", "in", "datamodule", "datamodule", "gets", "registered", "in", "trainer"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\parsing.py", "start_line": 236, "end_line": 262, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\parsing.py", "func_name": "function_288", "original_string": "def _lightning_get_first_attr_holder(model: \"pl.LightningModule\", attribute: str) -> Optional[Any]:\r\n    \"\"\"Special attribute finding for Lightning.\r\n\r\n    Gets the object or dict that holds attribute, or None. Checks for attribute in model namespace, the old hparams\r\n    namespace/dict, and the datamodule, returns the last one that has it.\r\n\r\n    \"\"\"\r\n    holders = _lightning_get_all_attr_holders(model, attribute)\r\n    if len(holders) == 0:\r\n        return None\r\n    return holders[-1]", "language": "python", "code": "def _lightning_get_first_attr_holder(model: \"pl.LightningModule\", attribute: str) -> Optional[Any]:\r\n    \"\"\"Special attribute finding for Lightning.\r\n\r\n    Gets the object or dict that holds attribute, or None. Checks for attribute in model namespace, the old hparams\r\n    namespace/dict, and the datamodule, returns the last one that has it.\r\n\r\n    \"\"\"\r\n    holders = _lightning_get_all_attr_holders(model, attribute)\r\n    if len(holders) == 0:\r\n        return None\r\n    return holders[-1]", "code_tokens": ["def", "_lightning_get_first_attr_holder", "(", "model", ":", "STRING", ",", "attribute", ":", "str", ")", "-", ">", "Optional", "[", "Any", "]", ":", "STRING", "holders", "=", "_lightning_get_all_attr_holders", "(", "model", ",", "attribute", ")", "if", "len", "(", "holders", ")", "=", "=", "0", ":", "return", "None", "return", "holders", "[", "-", "1", "]"], "docstring": "using the last holder to preserve backwards compatibility", "docstring_tokens": ["using", "the", "last", "holder", "to", "preserve", "backwards", "compatibility"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\parsing.py", "start_line": 265, "end_line": 276, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\signature_utils.py", "func_name": "function_289", "original_string": "def is_param_in_hook_signature(\r\n    hook_fx: Callable, param: str, explicit: bool = False, min_args: Optional[int] = None\r\n) -> bool:\r\n    \"\"\"\r\n    Args:\r\n        hook_fx: the hook callable\r\n        param: the name of the parameter to check\r\n        explicit: whether the parameter has to be explicitly declared\r\n        min_args: whether the `signature` has at least `min_args` parameters\r\n    \"\"\"\r\n    if hasattr(hook_fx, \"__wrapped__\"):\r\n        hook_fx = hook_fx.__wrapped__\r\n    parameters = inspect.getfullargspec(hook_fx)\r\n    args = parameters.args[1:]  # ignore `self`\r\n    return (\r\n        param in args\r\n        or (not explicit and (parameters.varargs is not None))\r\n        or (isinstance(min_args, int) and len(args) >= min_args)\r\n    )", "language": "python", "code": "def is_param_in_hook_signature(\r\n    hook_fx: Callable, param: str, explicit: bool = False, min_args: Optional[int] = None\r\n) -> bool:\r\n    \"\"\"\r\n    Args:\r\n        hook_fx: the hook callable\r\n        param: the name of the parameter to check\r\n        explicit: whether the parameter has to be explicitly declared\r\n        min_args: whether the `signature` has at least `min_args` parameters\r\n    \"\"\"\r\n    if hasattr(hook_fx, \"__wrapped__\"):\r\n        hook_fx = hook_fx.__wrapped__\r\n    parameters = inspect.getfullargspec(hook_fx)\r\n    args = parameters.args[1:]  # ignore `self`\r\n    return (\r\n        param in args\r\n        or (not explicit and (parameters.varargs is not None))\r\n        or (isinstance(min_args, int) and len(args) >= min_args)\r\n    )", "code_tokens": ["def", "is_param_in_hook_signature", "(", "hook_fx", ":", "Callable", ",", "param", ":", "str", ",", "explicit", ":", "bool", "=", "False", ",", "min_args", ":", "Optional", "[", "int", "]", "=", "None", ")", "-", ">", "bool", ":", "STRING", "if", "hasattr", "(", "hook_fx", ",", "STRING", ")", ":", "hook_fx", "=", "hook_fx", ".", "__wrapped__", "parameters", "=", "inspect", ".", "getfullargspec", "(", "hook_fx", ")", "args", "=", "parameters", ".", "args", "[", "1", ":", "]", "#", "ignore", "`", "self", "`", "return", "(", "param", "in", "args", "or", "(", "not", "explicit", "and", "(", "parameters", ".", "varargs", "is", "not", "None", ")", ")", "or", "(", "isinstance", "(", "min_args", ",", "int", ")", "and", "len", "(", "args", ")", ">", "=", "min_args", ")", ")"], "docstring": "in case the hook has a decorator", "docstring_tokens": ["in", "case", "the", "hook", "has", "a", "decorator"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\signature_utils.py", "start_line": 17, "end_line": 36, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "func_name": "function_290", "original_string": "def _migrate_loop_global_step_to_progress_tracking(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Sets the `global_step` value for checkpoints before v1.6 without the progress tracking state. It will be\r\n    overwritten by the loop's state if it was also saved.\r\n\r\n    Version: 1.6.0\r\n    Commit: c67b075\r\n    PR: #13645, #11805\r\n\r\n    \"\"\"\r\n    global_step = checkpoint[\"global_step\"]\r\n    checkpoint.setdefault(\"loops\", {\"fit_loop\": _get_fit_loop_initial_state_1_6_0()})\r\n    checkpoint[\"loops\"].setdefault(\"fit_loop\", _get_fit_loop_initial_state_1_6_0())\r\n    optim_progress = checkpoint[\"loops\"][\"fit_loop\"][\"epoch_loop.batch_loop.optimizer_loop.optim_progress\"]\r\n    optim_progress[\"optimizer\"][\"step\"][\"total\"][\"completed\"] = global_step\r\n    optim_step_progress = checkpoint[\"loops\"][\"fit_loop\"][\"epoch_loop.batch_loop.manual_loop.optim_step_progress\"]\r\n    optim_step_progress[\"total\"][\"completed\"] = global_step\r\n    return checkpoint", "language": "python", "code": "def _migrate_loop_global_step_to_progress_tracking(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Sets the `global_step` value for checkpoints before v1.6 without the progress tracking state. It will be\r\n    overwritten by the loop's state if it was also saved.\r\n\r\n    Version: 1.6.0\r\n    Commit: c67b075\r\n    PR: #13645, #11805\r\n\r\n    \"\"\"\r\n    global_step = checkpoint[\"global_step\"]\r\n    checkpoint.setdefault(\"loops\", {\"fit_loop\": _get_fit_loop_initial_state_1_6_0()})\r\n    checkpoint[\"loops\"].setdefault(\"fit_loop\", _get_fit_loop_initial_state_1_6_0())\r\n    optim_progress = checkpoint[\"loops\"][\"fit_loop\"][\"epoch_loop.batch_loop.optimizer_loop.optim_progress\"]\r\n    optim_progress[\"optimizer\"][\"step\"][\"total\"][\"completed\"] = global_step\r\n    optim_step_progress = checkpoint[\"loops\"][\"fit_loop\"][\"epoch_loop.batch_loop.manual_loop.optim_step_progress\"]\r\n    optim_step_progress[\"total\"][\"completed\"] = global_step\r\n    return checkpoint", "code_tokens": ["def", "_migrate_loop_global_step_to_progress_tracking", "(", "checkpoint", ":", "_CHECKPOINT", ")", "-", ">", "_CHECKPOINT", ":", "STRING", "global_step", "=", "checkpoint", "[", "STRING", "]", "checkpoint", ".", "setdefault", "(", "STRING", ",", "{", "STRING", ":", "_get_fit_loop_initial_state_1_6_0", "(", ")", "}", ")", "checkpoint", "[", "STRING", "]", ".", "setdefault", "(", "STRING", ",", "_get_fit_loop_initial_state_1_6_0", "(", ")", ")", "optim_progress", "=", "checkpoint", "[", "STRING", "]", "[", "STRING", "]", "[", "STRING", "]", "optim_progress", "[", "STRING", "]", "[", "STRING", "]", "[", "STRING", "]", "[", "STRING", "]", "=", "global_step", "optim_step_progress", "=", "checkpoint", "[", "STRING", "]", "[", "STRING", "]", "[", "STRING", "]", "optim_step_progress", "[", "STRING", "]", "[", "STRING", "]", "=", "global_step", "return", "checkpoint"], "docstring": "for automatic optimization for manual optimization", "docstring_tokens": ["for", "automatic", "optimization", "for", "manual", "optimization"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "start_line": 85, "end_line": 103, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "func_name": "function_291", "original_string": "def _migrate_model_checkpoint_save_on_train_epoch_end_default(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"The ``save_on_train_epoch_end`` was removed from the state-key of ``ModelCheckpoint`` in 1.9.0, and this\r\n    migration drops it from the state-keys saved in the checkpoint dict so that the keys match when the Trainer loads\r\n    the callback state.\r\n\r\n    Version: 1.9.0\r\n    Commit: f4ca56\r\n    PR: #15300, #15606\r\n\r\n    \"\"\"\r\n    if \"callbacks\" not in checkpoint:\r\n        return checkpoint\r\n\r\n    def new_key(old_key: str) -> str:\r\n        if not old_key.startswith(\"ModelCheckpoint\"):\r\n            return old_key\r\n        return re.sub(\", 'save_on_train_epoch_end': (None|True|False)\", \"\", old_key)\r\n\r\n    num_keys = len(checkpoint[\"callbacks\"])\r\n    new_callback_states = {\r\n        new_key(old_key): state for old_key, state in checkpoint[\"callbacks\"].items() if isinstance(old_key, str)\r\n    }\r\n    if len(new_callback_states) < num_keys:\r\n        rank_zero_warn(\r\n            \"You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys\"\r\n            \" that would end up colliding with each other after an upgrade, which means we can't differentiate\"\r\n            \" which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint`\"\r\n            \" callbacks will not be able to reload the state.\",\r\n            category=PossibleUserWarning,\r\n        )\r\n        return checkpoint\r\n\r\n    checkpoint[\"callbacks\"] = new_callback_states\r\n    return checkpoint", "language": "python", "code": "def _migrate_model_checkpoint_save_on_train_epoch_end_default(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"The ``save_on_train_epoch_end`` was removed from the state-key of ``ModelCheckpoint`` in 1.9.0, and this\r\n    migration drops it from the state-keys saved in the checkpoint dict so that the keys match when the Trainer loads\r\n    the callback state.\r\n\r\n    Version: 1.9.0\r\n    Commit: f4ca56\r\n    PR: #15300, #15606\r\n\r\n    \"\"\"\r\n    if \"callbacks\" not in checkpoint:\r\n        return checkpoint\r\n\r\n    def new_key(old_key: str) -> str:\r\n        if not old_key.startswith(\"ModelCheckpoint\"):\r\n            return old_key\r\n        return re.sub(\", 'save_on_train_epoch_end': (None|True|False)\", \"\", old_key)\r\n\r\n    num_keys = len(checkpoint[\"callbacks\"])\r\n    new_callback_states = {\r\n        new_key(old_key): state for old_key, state in checkpoint[\"callbacks\"].items() if isinstance(old_key, str)\r\n    }\r\n    if len(new_callback_states) < num_keys:\r\n        rank_zero_warn(\r\n            \"You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys\"\r\n            \" that would end up colliding with each other after an upgrade, which means we can't differentiate\"\r\n            \" which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint`\"\r\n            \" callbacks will not be able to reload the state.\",\r\n            category=PossibleUserWarning,\r\n        )\r\n        return checkpoint\r\n\r\n    checkpoint[\"callbacks\"] = new_callback_states\r\n    return checkpoint", "code_tokens": ["def", "_migrate_model_checkpoint_save_on_train_epoch_end_default", "(", "checkpoint", ":", "_CHECKPOINT", ")", "-", ">", "_CHECKPOINT", ":", "STRING", "if", "STRING", "not", "in", "checkpoint", ":", "return", "checkpoint", "def", "new_key", "(", "old_key", ":", "str", ")", "-", ">", "str", ":", "if", "not", "old_key", ".", "startswith", "(", "STRING", ")", ":", "return", "old_key", "return", "re", ".", "sub", "(", "STRING", ",", "STRING", ",", "old_key", ")", "num_keys", "=", "len", "(", "checkpoint", "[", "STRING", "]", ")", "new_callback_states", "=", "{", "new_key", "(", "old_key", ")", ":", "state", "for", "old_key", ",", "state", "in", "checkpoint", "[", "STRING", "]", ".", "items", "(", ")", "if", "isinstance", "(", "old_key", ",", "str", ")", "}", "if", "len", "(", "new_callback_states", ")", "<", "num_keys", ":", "rank_zero_warn", "(", "STRING", "STRING", "STRING", "STRING", ",", "category", "=", "PossibleUserWarning", ",", ")", "return", "checkpoint", "checkpoint", "[", "STRING", "]", "=", "new_callback_states", "return", "checkpoint"], "docstring": "Note: only iterate over keys that are strings. The legacy state key was the type of the callback.", "docstring_tokens": ["note", "only", "iterate", "over", "keys", "that", "are", "strings", "the", "legacy", "state", "key", "was", "the", "type", "of", "the", "callback"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "start_line": 183, "end_line": 217, "has_examples": false, "num_comments": 1, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "func_name": "function_292", "original_string": "def _migrate_loop_structure_after_tbptt_removal(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Adjusts the loop structure since it changed when the support for truncated backpropagation was removed. The\r\n    optimizer loop and the manual loop were previously children of the training batch loop. After its removal, they\r\n    became the children of the training epoch loop.\r\n\r\n    Version: 2.0.0\r\n    Commit: 7807454\r\n    PR: #16337, #16172\r\n\r\n    \"\"\"\r\n    if \"loops\" not in checkpoint:\r\n        return checkpoint\r\n    if \"fit_loop\" not in checkpoint[\"loops\"]:\r\n        return checkpoint\r\n    fit_loop = checkpoint[\"loops\"][\"fit_loop\"]\r\n\r\n    old_key_new_key_mapping = {\r\n        \"epoch_loop.batch_loop.manual_loop.optim_step_progress\": \"epoch_loop.manual_loop.optim_step_progress\",\r\n        \"epoch_loop.batch_loop.manual_loop.state_dict\": \"epoch_loop.manual_loop.state_dict\",\r\n        \"epoch_loop.batch_loop.optimizer_loop.optim_progress\": \"epoch_loop.optimizer_loop.optim_progress\",\r\n        \"epoch_loop.batch_loop.optimizer_loop.state_dict\": \"epoch_loop.optimizer_loop.state_dict\",\r\n    }\r\n    for old, new in list(old_key_new_key_mapping.items()):\r\n        if old in fit_loop:\r\n            fit_loop[new] = fit_loop[old]\r\n            del fit_loop[old]\r\n\r\n    if \"epoch_loop.batch_loop.state_dict\" in fit_loop and fit_loop[\"epoch_loop.batch_loop.state_dict\"]:\r\n        fit_loop[\"epoch_loop.state_dict\"][\"old_batch_loop_state_dict\"] = fit_loop[\"epoch_loop.batch_loop.state_dict\"]\r\n    fit_loop.pop(\"epoch_loop.batch_loop.state_dict\", None)\r\n\r\n    return checkpoint", "language": "python", "code": "def _migrate_loop_structure_after_tbptt_removal(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Adjusts the loop structure since it changed when the support for truncated backpropagation was removed. The\r\n    optimizer loop and the manual loop were previously children of the training batch loop. After its removal, they\r\n    became the children of the training epoch loop.\r\n\r\n    Version: 2.0.0\r\n    Commit: 7807454\r\n    PR: #16337, #16172\r\n\r\n    \"\"\"\r\n    if \"loops\" not in checkpoint:\r\n        return checkpoint\r\n    if \"fit_loop\" not in checkpoint[\"loops\"]:\r\n        return checkpoint\r\n    fit_loop = checkpoint[\"loops\"][\"fit_loop\"]\r\n\r\n    old_key_new_key_mapping = {\r\n        \"epoch_loop.batch_loop.manual_loop.optim_step_progress\": \"epoch_loop.manual_loop.optim_step_progress\",\r\n        \"epoch_loop.batch_loop.manual_loop.state_dict\": \"epoch_loop.manual_loop.state_dict\",\r\n        \"epoch_loop.batch_loop.optimizer_loop.optim_progress\": \"epoch_loop.optimizer_loop.optim_progress\",\r\n        \"epoch_loop.batch_loop.optimizer_loop.state_dict\": \"epoch_loop.optimizer_loop.state_dict\",\r\n    }\r\n    for old, new in list(old_key_new_key_mapping.items()):\r\n        if old in fit_loop:\r\n            fit_loop[new] = fit_loop[old]\r\n            del fit_loop[old]\r\n\r\n    if \"epoch_loop.batch_loop.state_dict\" in fit_loop and fit_loop[\"epoch_loop.batch_loop.state_dict\"]:\r\n        fit_loop[\"epoch_loop.state_dict\"][\"old_batch_loop_state_dict\"] = fit_loop[\"epoch_loop.batch_loop.state_dict\"]\r\n    fit_loop.pop(\"epoch_loop.batch_loop.state_dict\", None)\r\n\r\n    return checkpoint", "code_tokens": ["def", "_migrate_loop_structure_after_tbptt_removal", "(", "checkpoint", ":", "_CHECKPOINT", ")", "-", ">", "_CHECKPOINT", ":", "STRING", "if", "STRING", "not", "in", "checkpoint", ":", "return", "checkpoint", "if", "STRING", "not", "in", "checkpoint", "[", "STRING", "]", ":", "return", "checkpoint", "fit_loop", "=", "checkpoint", "[", "STRING", "]", "[", "STRING", "]", "old_key_new_key_mapping", "=", "{", "STRING", ":", "STRING", ",", "STRING", ":", "STRING", ",", "STRING", ":", "STRING", ",", "STRING", ":", "STRING", ",", "}", "for", "old", ",", "new", "in", "list", "(", "old_key_new_key_mapping", ".", "items", "(", ")", ")", ":", "if", "old", "in", "fit_loop", ":", "fit_loop", "[", "new", "]", "=", "fit_loop", "[", "old", "]", "del", "fit_loop", "[", "old", "]", "if", "STRING", "in", "fit_loop", "and", "fit_loop", "[", "STRING", "]", ":", "fit_loop", "[", "STRING", "]", "[", "STRING", "]", "=", "fit_loop", "[", "STRING", "]", "fit_loop", ".", "pop", "(", "STRING", ",", "None", ")", "return", "checkpoint"], "docstring": "remap `x.batch_loop.y` to `x.y` We can safely drop this key: our default implementation of `batch_loop` did not have state. If there was state from a custom batch loop, we wouldn't be able to load it meaningfully. But just in case, we save a copy of it in `epoch_loop.state_dict` in case the user wants to process it after loading the checkpoint.", "docstring_tokens": ["remap", "x", "batch_loop", "y", "to", "x", "y", "we", "can", "safely", "drop", "this", "key", "our", "default", "implementation", "of", "batch_loop", "did", "not", "have", "state", "if", "there", "was", "state", "from", "a", "custom", "batch", "loop", "we", "wouldn", "t", "be", "able", "to", "load", "it", "meaningfully", "but", "just", "in", "case", "we", "save", "a", "copy", "of", "it", "in", "epoch_loop", "state_dict", "in", "case", "the", "user", "wants", "to", "process", "it", "after", "loading", "the", "checkpoint"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "start_line": 236, "end_line": 272, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "func_name": "function_293", "original_string": "def _migrate_loop_structure_after_optimizer_loop_removal(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Adjusts the loop structure since it changed when the support for multiple optimizers in automatic optimization\r\n    mode was removed. There is no longer a loop over optimizer, and hence no position to store for resuming the loop.\r\n\r\n    Version: 2.0.0\r\n    Commit: 6a56586\r\n    PR: #16539, #16598\r\n\r\n    \"\"\"\r\n    if \"loops\" not in checkpoint:\r\n        return checkpoint\r\n    if \"fit_loop\" not in checkpoint[\"loops\"]:\r\n        return checkpoint\r\n    fit_loop = checkpoint[\"loops\"][\"fit_loop\"]\r\n\r\n    if \"epoch_loop.optimizer_loop.optim_progress\" in fit_loop:\r\n        fit_loop[\"epoch_loop.optimizer_loop.optim_progress\"].pop(\"optimizer_position\", None)\r\n\r\n    if \"epoch_loop.optimizer_loop.state_dict\" in fit_loop:\r\n        fit_loop[\"epoch_loop.automatic_optimization.state_dict\"] = fit_loop.pop(\"epoch_loop.optimizer_loop.state_dict\")\r\n        fit_loop[\"epoch_loop.automatic_optimization.optim_progress\"] = fit_loop.pop(\r\n            \"epoch_loop.optimizer_loop.optim_progress\"\r\n        )\r\n    if \"epoch_loop.manual_loop.state_dict\" in fit_loop:\r\n        fit_loop[\"epoch_loop.manual_optimization.state_dict\"] = fit_loop.pop(\"epoch_loop.manual_loop.state_dict\")\r\n        fit_loop[\"epoch_loop.manual_optimization.optim_step_progress\"] = fit_loop.pop(\r\n            \"epoch_loop.manual_loop.optim_step_progress\"\r\n        )\r\n    return checkpoint", "language": "python", "code": "def _migrate_loop_structure_after_optimizer_loop_removal(checkpoint: _CHECKPOINT) -> _CHECKPOINT:\r\n    \"\"\"Adjusts the loop structure since it changed when the support for multiple optimizers in automatic optimization\r\n    mode was removed. There is no longer a loop over optimizer, and hence no position to store for resuming the loop.\r\n\r\n    Version: 2.0.0\r\n    Commit: 6a56586\r\n    PR: #16539, #16598\r\n\r\n    \"\"\"\r\n    if \"loops\" not in checkpoint:\r\n        return checkpoint\r\n    if \"fit_loop\" not in checkpoint[\"loops\"]:\r\n        return checkpoint\r\n    fit_loop = checkpoint[\"loops\"][\"fit_loop\"]\r\n\r\n    if \"epoch_loop.optimizer_loop.optim_progress\" in fit_loop:\r\n        fit_loop[\"epoch_loop.optimizer_loop.optim_progress\"].pop(\"optimizer_position\", None)\r\n\r\n    if \"epoch_loop.optimizer_loop.state_dict\" in fit_loop:\r\n        fit_loop[\"epoch_loop.automatic_optimization.state_dict\"] = fit_loop.pop(\"epoch_loop.optimizer_loop.state_dict\")\r\n        fit_loop[\"epoch_loop.automatic_optimization.optim_progress\"] = fit_loop.pop(\r\n            \"epoch_loop.optimizer_loop.optim_progress\"\r\n        )\r\n    if \"epoch_loop.manual_loop.state_dict\" in fit_loop:\r\n        fit_loop[\"epoch_loop.manual_optimization.state_dict\"] = fit_loop.pop(\"epoch_loop.manual_loop.state_dict\")\r\n        fit_loop[\"epoch_loop.manual_optimization.optim_step_progress\"] = fit_loop.pop(\r\n            \"epoch_loop.manual_loop.optim_step_progress\"\r\n        )\r\n    return checkpoint", "code_tokens": ["def", "_migrate_loop_structure_after_optimizer_loop_removal", "(", "checkpoint", ":", "_CHECKPOINT", ")", "-", ">", "_CHECKPOINT", ":", "STRING", "if", "STRING", "not", "in", "checkpoint", ":", "return", "checkpoint", "if", "STRING", "not", "in", "checkpoint", "[", "STRING", "]", ":", "return", "checkpoint", "fit_loop", "=", "checkpoint", "[", "STRING", "]", "[", "STRING", "]", "if", "STRING", "in", "fit_loop", ":", "fit_loop", "[", "STRING", "]", ".", "pop", "(", "STRING", ",", "None", ")", "if", "STRING", "in", "fit_loop", ":", "fit_loop", "[", "STRING", "]", "=", "fit_loop", ".", "pop", "(", "STRING", ")", "fit_loop", "[", "STRING", "]", "=", "fit_loop", ".", "pop", "(", "STRING", ")", "if", "STRING", "in", "fit_loop", ":", "fit_loop", "[", "STRING", "]", "=", "fit_loop", ".", "pop", "(", "STRING", ")", "fit_loop", "[", "STRING", "]", "=", "fit_loop", ".", "pop", "(", "STRING", ")", "return", "checkpoint"], "docstring": "optimizer_position is no longer used the subloop attribute names have changed", "docstring_tokens": ["optimizer_position", "is", "no", "longer", "used", "the", "subloop", "attribute", "names", "have", "changed"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\migration\\migration.py", "start_line": 275, "end_line": 305, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\migration\\utils.py", "func_name": "function_294", "original_string": "def _pl_migrate_checkpoint(checkpoint: _CHECKPOINT, checkpoint_path: Optional[_PATH] = None) -> _CHECKPOINT:\r\n    \"\"\"Applies Lightning version migrations to a checkpoint dictionary and prints infos for the user.\r\n\r\n    This function is used by the Lightning Trainer when resuming from a checkpoint.\r\n\r\n    \"\"\"\r\n    old_version = _get_version(checkpoint)\r\n    checkpoint, migrations = migrate_checkpoint(checkpoint)\r\n    new_version = _get_version(checkpoint)\r\n    if not migrations or checkpoint_path is None:\r\n        return checkpoint\r\n\r\n    path_hint = os.path.relpath(checkpoint_path, os.getcwd()) if not _IS_WINDOWS else os.path.abspath(checkpoint_path)\r\n    _log.info(\r\n        f\"Lightning automatically upgraded your loaded checkpoint from v{old_version} to v{new_version}.\"\r\n        \" To apply the upgrade to your files permanently, run\"\r\n        f\" `python -m lightning.pytorch.utilities.upgrade_checkpoint {str(path_hint)}`\"\r\n    )\r\n    return checkpoint", "language": "python", "code": "def _pl_migrate_checkpoint(checkpoint: _CHECKPOINT, checkpoint_path: Optional[_PATH] = None) -> _CHECKPOINT:\r\n    \"\"\"Applies Lightning version migrations to a checkpoint dictionary and prints infos for the user.\r\n\r\n    This function is used by the Lightning Trainer when resuming from a checkpoint.\r\n\r\n    \"\"\"\r\n    old_version = _get_version(checkpoint)\r\n    checkpoint, migrations = migrate_checkpoint(checkpoint)\r\n    new_version = _get_version(checkpoint)\r\n    if not migrations or checkpoint_path is None:\r\n        return checkpoint\r\n\r\n    path_hint = os.path.relpath(checkpoint_path, os.getcwd()) if not _IS_WINDOWS else os.path.abspath(checkpoint_path)\r\n    _log.info(\r\n        f\"Lightning automatically upgraded your loaded checkpoint from v{old_version} to v{new_version}.\"\r\n        \" To apply the upgrade to your files permanently, run\"\r\n        f\" `python -m lightning.pytorch.utilities.upgrade_checkpoint {str(path_hint)}`\"\r\n    )\r\n    return checkpoint", "code_tokens": ["def", "_pl_migrate_checkpoint", "(", "checkpoint", ":", "_CHECKPOINT", ",", "checkpoint_path", ":", "Optional", "[", "_PATH", "]", "=", "None", ")", "-", ">", "_CHECKPOINT", ":", "STRING", "old_version", "=", "_get_version", "(", "checkpoint", ")", "checkpoint", ",", "migrations", "=", "migrate_checkpoint", "(", "checkpoint", ")", "new_version", "=", "_get_version", "(", "checkpoint", ")", "if", "not", "migrations", "or", "checkpoint_path", "is", "None", ":", "return", "checkpoint", "path_hint", "=", "os", ".", "path", ".", "relpath", "(", "checkpoint_path", ",", "os", ".", "getcwd", "(", ")", ")", "if", "not", "_IS_WINDOWS", "else", "os", ".", "path", ".", "abspath", "(", "checkpoint_path", ")", "_log", ".", "info", "(", "fSTRING", "STRING", "fSTRING", ")", "return", "checkpoint"], "docstring": "the checkpoint was already a new one, no migrations were needed include the full upgrade command, including the path to the loaded file in the error message, so user can copy-paste and run if they want side-step bug: ValueError: path is on mount 'C:', start on mount 'D:'", "docstring_tokens": ["the", "checkpoint", "was", "already", "a", "new", "one", "no", "migrations", "were", "needed", "include", "the", "full", "upgrade", "command", "including", "the", "path", "to", "the", "loaded", "file", "in", "the", "error", "message", "so", "user", "can", "copy", "paste", "and", "run", "if", "they", "want", "side", "step", "bug", "valueerror", "path", "is", "on", "mount", "c", "start", "on", "mount", "d"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\migration\\utils.py", "start_line": 136, "end_line": 158, "has_examples": false, "num_comments": 2, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_summary\\model_summary.py", "func_name": "function_295", "original_string": "def _forward_example_input(self) -> None:\r\n        \"\"\"Run the example input through each layer to get input- and output sizes.\"\"\"\r\n        model = self._model\r\n        trainer = self._model._trainer\r\n\r\n        input_ = model.example_input_array\r\n        input_ = model._on_before_batch_transfer(input_)\r\n        input_ = model._apply_batch_transfer_handler(input_)\r\n\r\n        mode = _ModuleMode()\r\n        mode.capture(model)\r\n        model.eval()\r\n\r\n        flop_context = (\r\n            contextlib.nullcontext()\r\n            if (\r\n                not _TORCH_GREATER_EQUAL_2_4\r\n                and any(isinstance(m, torch.jit.ScriptModule) for m in self._model.modules())\r\n            )\r\n            else self._flop_counter\r\n        )\r\n\r\n        forward_context = contextlib.nullcontext() if trainer is None else trainer.precision_plugin.forward_context()\r\n        with torch.no_grad(), forward_context, flop_context:\r\n            if isinstance(input_, (list, tuple)):\r\n                model(*input_)\r\n            elif isinstance(input_, dict):\r\n                model(**input_)\r\n            else:\r\n                model(input_)\r\n        mode.restore(model)", "language": "python", "code": "def _forward_example_input(self) -> None:\r\n        \"\"\"Run the example input through each layer to get input- and output sizes.\"\"\"\r\n        model = self._model\r\n        trainer = self._model._trainer\r\n\r\n        input_ = model.example_input_array\r\n        input_ = model._on_before_batch_transfer(input_)\r\n        input_ = model._apply_batch_transfer_handler(input_)\r\n\r\n        mode = _ModuleMode()\r\n        mode.capture(model)\r\n        model.eval()\r\n\r\n        flop_context = (\r\n            contextlib.nullcontext()\r\n            if (\r\n                not _TORCH_GREATER_EQUAL_2_4\r\n                and any(isinstance(m, torch.jit.ScriptModule) for m in self._model.modules())\r\n            )\r\n            else self._flop_counter\r\n        )\r\n\r\n        forward_context = contextlib.nullcontext() if trainer is None else trainer.precision_plugin.forward_context()\r\n        with torch.no_grad(), forward_context, flop_context:\r\n            if isinstance(input_, (list, tuple)):\r\n                model(*input_)\r\n            elif isinstance(input_, dict):\r\n                model(**input_)\r\n            else:\r\n                model(input_)\r\n        mode.restore(model)", "code_tokens": ["def", "_forward_example_input", "(", "self", ")", "-", ">", "None", ":", "STRING", "model", "=", "self", ".", "_model", "trainer", "=", "self", ".", "_model", ".", "_trainer", "input_", "=", "model", ".", "example_input_array", "input_", "=", "model", ".", "_on_before_batch_transfer", "(", "input_", ")", "input_", "=", "model", ".", "_apply_batch_transfer_handler", "(", "input_", ")", "mode", "=", "_ModuleMode", "(", ")", "mode", ".", "capture", "(", "model", ")", "model", ".", "eval", "(", ")", "flop_context", "=", "(", "contextlib", ".", "nullcontext", "(", ")", "if", "(", "not", "_TORCH_GREATER_EQUAL_2_4", "and", "any", "(", "isinstance", "(", "m", ",", "torch", ".", "jit", ".", "ScriptModule", ")", "for", "m", "in", "self", ".", "_model", ".", "modules", "(", ")", ")", ")", "else", "self", ".", "_flop_counter", ")", "forward_context", "=", "contextlib", ".", "nullcontext", "(", ")", "if", "trainer", "is", "None", "else", "trainer", ".", "precision_plugin", ".", "forward_context", "(", ")", "with", "torch", ".", "no_grad", "(", ")", ",", "forward_context", ",", "flop_context", ":", "if", "isinstance", "(", "input_", ",", "(", "list", ",", "tuple", ")", ")", ":", "model", "(", "*", "input_", ")", "elif", "isinstance", "(", "input_", ",", "dict", ")", ":", "model", "(", "*", "*", "input_", ")", "else", ":", "model", "(", "input_", ")", "mode", ".", "restore", "(", "model", ")"], "docstring": "the summary is supported without a trainer instance so we need to use the underscore property FlopCounterMode does not support ScriptModules before torch 2.4.0, so we use a null context let the model hooks collect the input- and output shapes", "docstring_tokens": ["the", "summary", "is", "supported", "without", "a", "trainer", "instance", "so", "we", "need", "to", "use", "the", "underscore", "property", "flopcountermode", "does", "not", "support", "scriptmodules", "before", "torch", "2", "4", "0", "so", "we", "use", "a", "null", "context", "let", "the", "model", "hooks", "collect", "the", "input", "and", "output", "shapes"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_summary\\model_summary.py", "start_line": 338, "end_line": 371, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
{"repo": "pytorch-lightning", "path": "src\\lightning\\pytorch\\utilities\\model_summary\\model_summary.py", "func_name": "function_296", "original_string": "def _format_summary_table(\r\n    total_parameters: int,\r\n    trainable_parameters: int,\r\n    model_size: float,\r\n    total_training_modes: dict[str, int],\r\n    total_flops: int,\r\n    *cols: tuple[str, list[str]],\r\n) -> str:\r\n    \"\"\"Takes in a number of arrays, each specifying a column in the summary table, and combines them all into one big\r\n    string defining the summary table that are nicely formatted.\"\"\"\r\n    n_rows = len(cols[0][1])\r\n    n_cols = 1 + len(cols)\r\n\r\n    col_widths = []\r\n    for c in cols:\r\n        col_width = max(len(str(a)) for a in c[1]) if n_rows else 0\r\n        col_width = max(col_width, len(c[0]))  # minimum length is header length\r\n        col_widths.append(col_width)\r\n\r\n    s = \"{:<{}}\"\r\n    total_width = sum(col_widths) + 3 * n_cols\r\n    header = [s.format(c[0], w) for c, w in zip(cols, col_widths)]\r\n\r\n    summary = \" | \".join(header) + \"\\n\" + \"-\" * total_width\r\n    for i in range(n_rows):\r\n        line = []\r\n        for c, w in zip(cols, col_widths):\r\n            line.append(s.format(str(c[1][i]), w))\r\n        summary += \"\\n\" + \" | \".join(line)\r\n    summary += \"\\n\" + \"-\" * total_width\r\n\r\n    summary += \"\\n\" + s.format(get_human_readable_count(trainable_parameters), 10)\r\n    summary += \"Trainable params\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_parameters - trainable_parameters), 10)\r\n    summary += \"Non-trainable params\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_parameters), 10)\r\n    summary += \"Total params\"\r\n    summary += \"\\n\" + s.format(get_formatted_model_size(model_size), 10)\r\n    summary += \"Total estimated model params size (MB)\"\r\n    summary += \"\\n\" + s.format(total_training_modes[\"train\"], 10)\r\n    summary += \"Modules in train mode\"\r\n    summary += \"\\n\" + s.format(total_training_modes[\"eval\"], 10)\r\n    summary += \"Modules in eval mode\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_flops), 10)\r\n    summary += \"Total Flops\"\r\n\r\n    return summary", "language": "python", "code": "def _format_summary_table(\r\n    total_parameters: int,\r\n    trainable_parameters: int,\r\n    model_size: float,\r\n    total_training_modes: dict[str, int],\r\n    total_flops: int,\r\n    *cols: tuple[str, list[str]],\r\n) -> str:\r\n    \"\"\"Takes in a number of arrays, each specifying a column in the summary table, and combines them all into one big\r\n    string defining the summary table that are nicely formatted.\"\"\"\r\n    n_rows = len(cols[0][1])\r\n    n_cols = 1 + len(cols)\r\n\r\n    col_widths = []\r\n    for c in cols:\r\n        col_width = max(len(str(a)) for a in c[1]) if n_rows else 0\r\n        col_width = max(col_width, len(c[0]))  # minimum length is header length\r\n        col_widths.append(col_width)\r\n\r\n    s = \"{:<{}}\"\r\n    total_width = sum(col_widths) + 3 * n_cols\r\n    header = [s.format(c[0], w) for c, w in zip(cols, col_widths)]\r\n\r\n    summary = \" | \".join(header) + \"\\n\" + \"-\" * total_width\r\n    for i in range(n_rows):\r\n        line = []\r\n        for c, w in zip(cols, col_widths):\r\n            line.append(s.format(str(c[1][i]), w))\r\n        summary += \"\\n\" + \" | \".join(line)\r\n    summary += \"\\n\" + \"-\" * total_width\r\n\r\n    summary += \"\\n\" + s.format(get_human_readable_count(trainable_parameters), 10)\r\n    summary += \"Trainable params\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_parameters - trainable_parameters), 10)\r\n    summary += \"Non-trainable params\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_parameters), 10)\r\n    summary += \"Total params\"\r\n    summary += \"\\n\" + s.format(get_formatted_model_size(model_size), 10)\r\n    summary += \"Total estimated model params size (MB)\"\r\n    summary += \"\\n\" + s.format(total_training_modes[\"train\"], 10)\r\n    summary += \"Modules in train mode\"\r\n    summary += \"\\n\" + s.format(total_training_modes[\"eval\"], 10)\r\n    summary += \"Modules in eval mode\"\r\n    summary += \"\\n\" + s.format(get_human_readable_count(total_flops), 10)\r\n    summary += \"Total Flops\"\r\n\r\n    return summary", "code_tokens": ["def", "_format_summary_table", "(", "total_parameters", ":", "int", ",", "trainable_parameters", ":", "int", ",", "model_size", ":", "float", ",", "total_training_modes", ":", "dict", "[", "str", ",", "int", "]", ",", "total_flops", ":", "int", ",", "*", "cols", ":", "tuple", "[", "str", ",", "list", "[", "str", "]", "]", ",", ")", "-", ">", "str", ":", "STRING", "n_rows", "=", "len", "(", "cols", "[", "0", "]", "[", "1", "]", ")", "n_cols", "=", "1", "+", "len", "(", "cols", ")", "col_widths", "=", "[", "]", "for", "c", "in", "cols", ":", "col_width", "=", "max", "(", "len", "(", "str", "(", "a", ")", ")", "for", "a", "in", "c", "[", "1", "]", ")", "if", "n_rows", "else", "0", "col_width", "=", "max", "(", "col_width", ",", "len", "(", "c", "[", "0", "]", ")", ")", "#", "minimum", "length", "is", "header", "length", "col_widths", ".", "append", "(", "col_width", ")", "s", "=", "STRING", "total_width", "=", "sum", "(", "col_widths", ")", "+", "3", "*", "n_cols", "header", "=", "[", "s", ".", "format", "(", "c", "[", "0", "]", ",", "w", ")", "for", "c", ",", "w", "in", "zip", "(", "cols", ",", "col_widths", ")", "]", "summary", "=", "STRING", ".", "join", "(", "header", ")", "+", "STRING", "+", "STRING", "*", "total_width", "for", "i", "in", "range", "(", "n_rows", ")", ":", "line", "=", "[", "]", "for", "c", ",", "w", "in", "zip", "(", "cols", ",", "col_widths", ")", ":", "line", ".", "append", "(", "s", ".", "format", "(", "str", "(", "c", "[", "1", "]", "[", "i", "]", ")", ",", "w", ")", ")", "summary", "+", "=", "STRING", "+", "STRING", ".", "join", "(", "line", ")", "summary", "+", "=", "STRING", "+", "STRING", "*", "total_width", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "get_human_readable_count", "(", "trainable_parameters", ")", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "get_human_readable_count", "(", "total_parameters", "-", "trainable_parameters", ")", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "get_human_readable_count", "(", "total_parameters", ")", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "get_formatted_model_size", "(", "model_size", ")", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "total_training_modes", "[", "STRING", "]", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "total_training_modes", "[", "STRING", "]", ",", "10", ")", "summary", "+", "=", "STRING", "summary", "+", "=", "STRING", "+", "s", ".", "format", "(", "get_human_readable_count", "(", "total_flops", ")", ",", "10", ")", "summary", "+", "=", "STRING", "return", "summary"], "docstring": "Get formatting width of each column Formatting Summary = header + divider + Rest of table", "docstring_tokens": ["get", "formatting", "width", "of", "each", "column", "formatting", "summary", "header", "divider", "rest", "of", "table"], "partition": "test", "url": "https://github.com/Lightning-AI/pytorch-lightning", "metadata": {"file_path": "src\\lightning\\pytorch\\utilities\\model_summary\\model_summary.py", "start_line": 443, "end_line": 492, "has_examples": false, "num_comments": 3, "description": "Developer comments to code"}}
