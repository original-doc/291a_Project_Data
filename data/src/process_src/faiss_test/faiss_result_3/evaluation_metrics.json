{
  "per_query": [
    {
      "query_id": 1,
      "query": "What parameters does the ModelCheckpoint callback accept and what do save_top_k and monitor do?",
      "query_type": "api_usage",
      "num_retrieved": 5,
      "num_relevant": 3,
      "latency": 0.014023303985595703,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.4,
      "recall@5": 0.6666666666666666,
      "ndcg@5": 0.4367467095119258,
      "precision@10": 0.2,
      "recall@10": 0.6666666666666666,
      "ndcg@10": 0.4367467095119258,
      "mrr": 0.3333333333333333,
      "ap": 0.27777777777777773
    },
    {
      "query_id": 2,
      "query": "How do I set up early stopping in PyTorch Lightning that stops training when validation loss doesn't improve for 5 epochs, and saves the best model based on that metric?",
      "query_type": "implementation",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.017544031143188477,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 3,
      "query": "My training is crashing with 'CUDA out of memory' error when using PyTorch Lightning Trainer. How can I reduce memory usage during training?",
      "query_type": "debugging",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.004999876022338867,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.8,
      "recall@5": 0.6666666666666666,
      "ndcg@5": 0.8687949224876582,
      "precision@10": 0.4,
      "recall@10": 0.6666666666666666,
      "ndcg@10": 0.7751482523375255,
      "mrr": 1.0,
      "ap": 0.6666666666666666
    },
    {
      "query_id": 4,
      "query": "What's the difference between training_step and validation_step in LightningModule, and when is each one called during the training loop?",
      "query_type": "conceptual",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.007037162780761719,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 5,
      "query": "How do I set up distributed training on 4 GPUs using DDP strategy in PyTorch Lightning with automatic batch size scaling and gradient accumulation?",
      "query_type": "advanced_configuration",
      "num_retrieved": 5,
      "num_relevant": 7,
      "latency": 0.006354808807373047,
      "precision@1": 1.0,
      "recall@1": 0.14285714285714285,
      "ndcg@1": 1.0,
      "precision@5": 0.6,
      "recall@5": 0.42857142857142855,
      "ndcg@5": 0.6843515475204855,
      "precision@10": 0.3,
      "recall@10": 0.42857142857142855,
      "ndcg@10": 0.5546406709327603,
      "mrr": 1.0,
      "ap": 0.37142857142857144
    }
  ],
  "aggregate": {
    "total_queries": 5,
    "avg_latency": 0.009991836547851563,
    "std_latency": 0.004902369032430006,
    "precision@1": 0.4,
    "recall@1": 0.06190476190476191,
    "ndcg@1": 0.4,
    "precision@5": 0.36000000000000004,
    "recall@5": 0.35238095238095235,
    "ndcg@5": 0.39797863590401394,
    "precision@10": 0.18000000000000002,
    "recall@10": 0.35238095238095235,
    "ndcg@10": 0.3533071265564423,
    "mrr": 0.4666666666666666,
    "map": 0.26317460317460317
  },
  "by_type_aggregate": {
    "api_usage": {
      "count": 1,
      "avg_latency": 0.014023303985595703,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.4,
      "recall@5": 0.6666666666666666,
      "ndcg@5": 0.4367467095119258,
      "precision@10": 0.2,
      "recall@10": 0.6666666666666666,
      "ndcg@10": 0.4367467095119258,
      "mrr": 0.3333333333333333,
      "map": 0.27777777777777773
    },
    "implementation": {
      "count": 1,
      "avg_latency": 0.017544031143188477,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "map": 0.0
    },
    "debugging": {
      "count": 1,
      "avg_latency": 0.004999876022338867,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.8,
      "recall@5": 0.6666666666666666,
      "ndcg@5": 0.8687949224876582,
      "precision@10": 0.4,
      "recall@10": 0.6666666666666666,
      "ndcg@10": 0.7751482523375255,
      "mrr": 1.0,
      "map": 0.6666666666666666
    },
    "conceptual": {
      "count": 1,
      "avg_latency": 0.007037162780761719,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "map": 0.0
    },
    "advanced_configuration": {
      "count": 1,
      "avg_latency": 0.006354808807373047,
      "precision@1": 1.0,
      "recall@1": 0.14285714285714285,
      "ndcg@1": 1.0,
      "precision@5": 0.6,
      "recall@5": 0.42857142857142855,
      "ndcg@5": 0.6843515475204855,
      "precision@10": 0.3,
      "recall@10": 0.42857142857142855,
      "ndcg@10": 0.5546406709327603,
      "mrr": 1.0,
      "map": 0.37142857142857144
    }
  }
}