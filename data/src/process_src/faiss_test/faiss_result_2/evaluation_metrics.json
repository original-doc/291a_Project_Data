{
  "per_query": [
    {
      "query_id": 1,
      "query": "How to fix CUDA out of memory error in PyTorch Lightning?",
      "query_type": "debugging",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.018494844436645508,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 2,
      "query": "Why is my validation loss not decreasing?",
      "query_type": "debugging",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.0071637630462646484,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 3,
      "query": "What parameters does the Lightning Trainer accept?",
      "query_type": "api_usage",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.00956869125366211,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.4,
      "recall@5": 0.4,
      "ndcg@5": 0.38356636737133565,
      "precision@10": 0.2,
      "recall@10": 0.4,
      "ndcg@10": 0.38356636737133565,
      "mrr": 0.5,
      "ap": 0.2333333333333333
    },
    {
      "query_id": 4,
      "query": "How to use early stopping callback?",
      "query_type": "api_usage",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.006999492645263672,
      "precision@1": 1.0,
      "recall@1": 0.2,
      "ndcg@1": 1.0,
      "precision@5": 1.0,
      "recall@5": 1.0,
      "ndcg@5": 1.0,
      "precision@10": 0.5,
      "recall@10": 1.0,
      "ndcg@10": 1.0,
      "mrr": 1.0,
      "ap": 1.0
    },
    {
      "query_id": 5,
      "query": "Implement custom callback in PyTorch Lightning",
      "query_type": "implementation",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.010211706161499023,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 6,
      "query": "Multi-GPU training setup",
      "query_type": "implementation",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.009517669677734375,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.4,
      "recall@5": 0.4,
      "ndcg@5": 0.3156484524795145,
      "precision@10": 0.2,
      "recall@10": 0.4,
      "ndcg@10": 0.3156484524795145,
      "mrr": 0.3333333333333333,
      "ap": 0.16666666666666666
    },
    {
      "query_id": 7,
      "query": "Difference between training_step and validation_step",
      "query_type": "conceptual",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.010335922241210938,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 8,
      "query": "How does automatic optimization work?",
      "query_type": "conceptual",
      "num_retrieved": 5,
      "num_relevant": 5,
      "latency": 0.008594036102294922,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.4,
      "recall@5": 0.4,
      "ndcg@5": 0.27727342735504823,
      "precision@10": 0.2,
      "recall@10": 0.4,
      "ndcg@10": 0.27727342735504823,
      "mrr": 0.25,
      "ap": 0.13
    }
  ],
  "aggregate": {
    "total_queries": 8,
    "avg_latency": 0.0101107656955719,
    "std_latency": 0.0033849775043361626,
    "precision@1": 0.125,
    "recall@1": 0.025,
    "ndcg@1": 0.125,
    "precision@5": 0.275,
    "recall@5": 0.275,
    "ndcg@5": 0.2470610309007373,
    "precision@10": 0.1375,
    "recall@10": 0.275,
    "ndcg@10": 0.2470610309007373,
    "mrr": 0.26041666666666663,
    "map": 0.19125
  },
  "by_type_aggregate": {
    "debugging": {
      "count": 2,
      "avg_latency": 0.012829303741455078,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "map": 0.0
    },
    "api_usage": {
      "count": 2,
      "avg_latency": 0.00828409194946289,
      "precision@1": 0.5,
      "recall@1": 0.1,
      "ndcg@1": 0.5,
      "precision@5": 0.7,
      "recall@5": 0.7,
      "ndcg@5": 0.6917831836856678,
      "precision@10": 0.35,
      "recall@10": 0.7,
      "ndcg@10": 0.6917831836856678,
      "mrr": 0.75,
      "map": 0.6166666666666667
    },
    "implementation": {
      "count": 2,
      "avg_latency": 0.0098646879196167,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.2,
      "recall@5": 0.2,
      "ndcg@5": 0.15782422623975725,
      "precision@10": 0.1,
      "recall@10": 0.2,
      "ndcg@10": 0.15782422623975725,
      "mrr": 0.16666666666666666,
      "map": 0.08333333333333333
    },
    "conceptual": {
      "count": 2,
      "avg_latency": 0.00946497917175293,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.2,
      "recall@5": 0.2,
      "ndcg@5": 0.13863671367752411,
      "precision@10": 0.1,
      "recall@10": 0.2,
      "ndcg@10": 0.13863671367752411,
      "mrr": 0.125,
      "map": 0.065
    }
  }
}