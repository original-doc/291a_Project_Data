{
  "per_query": [
    {
      "query_id": 1,
      "query": "What parameters does the ModelCheckpoint callback accept and what do save_top_k and monitor do?",
      "query_type": "api_usage",
      "num_retrieved": 5,
      "num_relevant": 3,
      "latency": 0.04948902130126953,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 2,
      "query": "How do I set up early stopping in PyTorch Lightning that stops training when validation loss doesn't improve for 5 epochs, and saves the best model based on that metric?",
      "query_type": "implementation",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.04913139343261719,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.4,
      "recall@5": 0.3333333333333333,
      "ndcg@5": 0.5531464700081437,
      "precision@10": 0.2,
      "recall@10": 0.3333333333333333,
      "ndcg@10": 0.4935232796777481,
      "mrr": 1.0,
      "ap": 0.3333333333333333
    },
    {
      "query_id": 3,
      "query": "My training is crashing with 'CUDA out of memory' error when using PyTorch Lightning Trainer. How can I reduce memory usage during training?",
      "query_type": "debugging",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.04155373573303223,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.4,
      "recall@5": 0.3333333333333333,
      "ndcg@5": 0.5531464700081437,
      "precision@10": 0.2,
      "recall@10": 0.3333333333333333,
      "ndcg@10": 0.4935232796777481,
      "mrr": 1.0,
      "ap": 0.3333333333333333
    },
    {
      "query_id": 4,
      "query": "What's the difference between training_step and validation_step in LightningModule, and when is each one called during the training loop?",
      "query_type": "conceptual",
      "num_retrieved": 5,
      "num_relevant": 6,
      "latency": 0.035971641540527344,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "ap": 0.0
    },
    {
      "query_id": 5,
      "query": "How do I set up distributed training on 4 GPUs using DDP strategy in PyTorch Lightning with automatic batch size scaling and gradient accumulation?",
      "query_type": "advanced_configuration",
      "num_retrieved": 5,
      "num_relevant": 7,
      "latency": 0.04093194007873535,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.2,
      "recall@5": 0.14285714285714285,
      "ndcg@5": 0.16958010263680806,
      "precision@10": 0.1,
      "recall@10": 0.14285714285714285,
      "ndcg@10": 0.13743816645714543,
      "mrr": 0.3333333333333333,
      "ap": 0.047619047619047616
    }
  ],
  "aggregate": {
    "total_queries": 5,
    "avg_latency": 0.04341554641723633,
    "std_latency": 0.005188532809035151,
    "precision@1": 0.4,
    "recall@1": 0.06666666666666667,
    "ndcg@1": 0.4,
    "precision@5": 0.2,
    "recall@5": 0.1619047619047619,
    "ndcg@5": 0.2551746085306191,
    "precision@10": 0.1,
    "recall@10": 0.1619047619047619,
    "ndcg@10": 0.2248969451625283,
    "mrr": 0.4666666666666667,
    "map": 0.14285714285714285
  },
  "by_type_aggregate": {
    "api_usage": {
      "count": 1,
      "avg_latency": 0.04948902130126953,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "map": 0.0
    },
    "implementation": {
      "count": 1,
      "avg_latency": 0.04913139343261719,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.4,
      "recall@5": 0.3333333333333333,
      "ndcg@5": 0.5531464700081437,
      "precision@10": 0.2,
      "recall@10": 0.3333333333333333,
      "ndcg@10": 0.4935232796777481,
      "mrr": 1.0,
      "map": 0.3333333333333333
    },
    "debugging": {
      "count": 1,
      "avg_latency": 0.04155373573303223,
      "precision@1": 1.0,
      "recall@1": 0.16666666666666666,
      "ndcg@1": 1.0,
      "precision@5": 0.4,
      "recall@5": 0.3333333333333333,
      "ndcg@5": 0.5531464700081437,
      "precision@10": 0.2,
      "recall@10": 0.3333333333333333,
      "ndcg@10": 0.4935232796777481,
      "mrr": 1.0,
      "map": 0.3333333333333333
    },
    "conceptual": {
      "count": 1,
      "avg_latency": 0.035971641540527344,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.0,
      "recall@5": 0.0,
      "ndcg@5": 0.0,
      "precision@10": 0.0,
      "recall@10": 0.0,
      "ndcg@10": 0.0,
      "mrr": 0.0,
      "map": 0.0
    },
    "advanced_configuration": {
      "count": 1,
      "avg_latency": 0.04093194007873535,
      "precision@1": 0.0,
      "recall@1": 0.0,
      "ndcg@1": 0.0,
      "precision@5": 0.2,
      "recall@5": 0.14285714285714285,
      "ndcg@5": 0.16958010263680806,
      "precision@10": 0.1,
      "recall@10": 0.14285714285714285,
      "ndcg@10": 0.13743816645714543,
      "mrr": 0.3333333333333333,
      "map": 0.047619047619047616
    }
  }
}